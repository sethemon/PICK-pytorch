{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('1002-043; A RANDOMIZED, DOUBLE-BLIND, PLACEBO-CONTROLLED STUDY TO ASSESS THE EFFECTS OF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "3\n",
      "Tesla P100-PCIE-16GB\n",
      "Tesla P100-PCIE-16GB\n",
      "Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(torch.cuda.get_device_name(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "Tesla P100-PCIE-16GB\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "[2022-03-28 17:35:09,231 - train - INFO] - Distributed GPU training model start...\n",
      "[2022-03-28 17:35:09,231 - train - INFO] - [Process 23753] Initializing process group with: {'MASTER_ADDR': '127.0.0.1', 'MASTER_PORT': '5555', 'RANK': '0', 'WORLD_SIZE': 3}\n",
      "[2022-03-28 17:35:10,236 - train - INFO] - [Process 23753] world_size = 3, rank = 0, backend=nccl\n",
      "[2022-03-28 17:35:10,239 - train - INFO] - Dataloader instances created. Train datasets: 154 samples Validation datasets: 52 samples.\n",
      "[2022-03-28 17:35:10,966 - train - INFO] - Model created, trainable parameters: 68565292.\n",
      "[2022-03-28 17:35:10,968 - train - INFO] - Optimizer and lr_scheduler created.\n",
      "[2022-03-28 17:35:10,968 - train - INFO] - Max_epochs: 100 Log_per_step: 10 Validation_per_step: 50.\n",
      "[2022-03-28 17:35:10,968 - train - INFO] - Training start...\n",
      "[2022-03-28 17:35:11,000 - trainer - INFO] - [Process 23753] world_size = 3, rank = 0, n_gpu/process = 1, device_ids = [0]\n",
      "/home/cdsw/.local/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:102: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\"torch.distributed.reduce_op is deprecated, please use \"\n",
      "/home/cdsw/.local/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:102: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\"torch.distributed.reduce_op is deprecated, please use \"\n",
      "/home/cdsw/.local/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:102: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\"torch.distributed.reduce_op is deprecated, please use \"\n",
      "[2022-03-28 17:35:38,929 - trainer - INFO] - Train Epoch:[1/100] Step:[10/26] Total Loss: 523.185425 GL_Loss: 0.586333 CRF_Loss: 522.599121\n",
      "[2022-03-28 17:36:02,501 - trainer - INFO] - Train Epoch:[1/100] Step:[20/26] Total Loss: 522.598877 GL_Loss: 1.078609 CRF_Loss: 521.520264\n",
      "[2022-03-28 17:36:30,125 - trainer - INFO] - [Epoch Validation] Epoch:[1/100] Total Loss: 461.805094 GL_Loss: 0.009160 CRF_Loss: 460.889129 \n",
      "+---------+-------------+------------+-------------+------------+\n",
      "| name    |         mEP |        mER |         mEF |        mEA |\n",
      "+=========+=============+============+=============+============+\n",
      "| header  | 0           | 0          | 0           | 0          |\n",
      "+---------+-------------+------------+-------------+------------+\n",
      "| keys    | 0.000328839 | 0.00639269 | 0.000625503 | 0.00639269 |\n",
      "+---------+-------------+------------+-------------+------------+\n",
      "| values  | 0.00117625  | 0.030012   | 0.00226378  | 0.030012   |\n",
      "+---------+-------------+------------+-------------+------------+\n",
      "| overall | 0.000752021 | 0.0155189  | 0.00143453  | 0.0155189  |\n",
      "+---------+-------------+------------+-------------+------------+\n",
      "[2022-03-28 17:36:53,527 - trainer - INFO] - Train Epoch:[2/100] Step:[10/26] Total Loss: 543.132751 GL_Loss: 0.810126 CRF_Loss: 542.322632\n",
      "[2022-03-28 17:37:16,429 - trainer - INFO] - Train Epoch:[2/100] Step:[20/26] Total Loss: 346.317047 GL_Loss: 1.972573 CRF_Loss: 344.344482\n",
      "[2022-03-28 17:37:44,671 - trainer - INFO] - [Epoch Validation] Epoch:[2/100] Total Loss: 406.351419 GL_Loss: 0.011497 CRF_Loss: 405.201729 \n",
      "+---------+-----------+-----------+------------+-----------+\n",
      "| name    |       mEP |       mER |        mEF |       mEA |\n",
      "+=========+===========+===========+============+===========+\n",
      "| header  | 0         | 0         | 0          | 0         |\n",
      "+---------+-----------+-----------+------------+-----------+\n",
      "| keys    | 0.0042526 | 0.0182648 | 0.00689893 | 0.0182648 |\n",
      "+---------+-----------+-----------+------------+-----------+\n",
      "| values  | 0.0231671 | 0.102041  | 0.037761   | 0.102041  |\n",
      "+---------+-----------+-----------+------------+-----------+\n",
      "| overall | 0.0108696 | 0.0509214 | 0.017915   | 0.0509214 |\n",
      "+---------+-----------+-----------+------------+-----------+\n",
      "[2022-03-28 17:38:09,546 - trainer - INFO] - Train Epoch:[3/100] Step:[10/26] Total Loss: 229.773575 GL_Loss: 2.850219 CRF_Loss: 226.923355\n",
      "[2022-03-28 17:38:33,411 - trainer - INFO] - Train Epoch:[3/100] Step:[20/26] Total Loss: 183.433380 GL_Loss: 0.686304 CRF_Loss: 182.747070\n",
      "[2022-03-28 17:39:00,681 - trainer - INFO] - [Epoch Validation] Epoch:[3/100] Total Loss: 320.623302 GL_Loss: 0.008730 CRF_Loss: 319.750291 \n",
      "+---------+------------+-----------+-----------+-----------+\n",
      "| name    |        mEP |       mER |       mEF |       mEA |\n",
      "+=========+============+===========+===========+===========+\n",
      "| header  | 0.00540784 | 0.0895522 | 0.0101997 | 0.0895522 |\n",
      "+---------+------------+-----------+-----------+-----------+\n",
      "| keys    | 0.0339261  | 0.113242  | 0.0522105 | 0.113242  |\n",
      "+---------+------------+-----------+-----------+-----------+\n",
      "| values  | 0.0260233  | 0.115246  | 0.0424591 | 0.115246  |\n",
      "+---------+------------+-----------+-----------+-----------+\n",
      "| overall | 0.0242602  | 0.112512  | 0.039914  | 0.112512  |\n",
      "+---------+------------+-----------+-----------+-----------+\n",
      "[2022-03-28 17:39:24,930 - trainer - INFO] - Train Epoch:[4/100] Step:[10/26] Total Loss: 187.777588 GL_Loss: 1.585146 CRF_Loss: 186.192444\n",
      "[2022-03-28 17:39:47,226 - trainer - INFO] - Train Epoch:[4/100] Step:[20/26] Total Loss: 233.129654 GL_Loss: 0.382043 CRF_Loss: 232.747604\n",
      "[2022-03-28 17:40:14,600 - trainer - INFO] - [Epoch Validation] Epoch:[4/100] Total Loss: 295.329592 GL_Loss: 0.009095 CRF_Loss: 294.420050 \n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| name    |       mEP |       mER |       mEF |       mEA |\n",
      "+=========+===========+===========+===========+===========+\n",
      "| header  | 0         | 0         | 0         | 0         |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| keys    | 0.0164993 | 0.0630137 | 0.0261512 | 0.0630137 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| values  | 0.0213333 | 0.0960384 | 0.0349116 | 0.0960384 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| overall | 0.0176478 | 0.0722599 | 0.0283674 | 0.0722599 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "[2022-03-28 17:40:37,831 - trainer - INFO] - Train Epoch:[5/100] Step:[10/26] Total Loss: 268.180115 GL_Loss: 2.586208 CRF_Loss: 265.593903\n",
      "[2022-03-28 17:41:02,903 - trainer - INFO] - Train Epoch:[5/100] Step:[20/26] Total Loss: 363.863129 GL_Loss: 0.981355 CRF_Loss: 362.881775\n",
      "[2022-03-28 17:41:29,680 - trainer - INFO] - [Epoch Validation] Epoch:[5/100] Total Loss: 268.025257 GL_Loss: 0.015661 CRF_Loss: 266.459139 \n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| name    |       mEP |      mER |       mEF |      mEA |\n",
      "+=========+===========+==========+===========+==========+\n",
      "| header  | 0         | 0        | 0         | 0        |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| keys    | 0.0556492 | 0.150685 | 0.0812808 | 0.150685 |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| values  | 0.0342097 | 0.129652 | 0.0541353 | 0.129652 |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| overall | 0.0427632 | 0.132396 | 0.064646  | 0.132396 |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "[2022-03-28 17:41:53,627 - trainer - INFO] - Train Epoch:[6/100] Step:[10/26] Total Loss: 208.330063 GL_Loss: 0.555064 CRF_Loss: 207.774994\n",
      "[2022-03-28 17:42:17,260 - trainer - INFO] - Train Epoch:[6/100] Step:[20/26] Total Loss: 367.458893 GL_Loss: 1.212183 CRF_Loss: 366.246704\n",
      "[2022-03-28 17:42:45,010 - trainer - INFO] - [Epoch Validation] Epoch:[6/100] Total Loss: 256.399517 GL_Loss: 0.009448 CRF_Loss: 255.454737 \n",
      "+---------+------------+-----------+-----------+-----------+\n",
      "| name    |        mEP |       mER |       mEF |       mEA |\n",
      "+=========+============+===========+===========+===========+\n",
      "| header  | 0.00493097 | 0.0373134 | 0.0087108 | 0.0373134 |\n",
      "+---------+------------+-----------+-----------+-----------+\n",
      "| keys    | 0.065317   | 0.156164  | 0.0921088 | 0.156164  |\n",
      "+---------+------------+-----------+-----------+-----------+\n",
      "| values  | 0.0939199  | 0.228091  | 0.133053  | 0.228091  |\n",
      "+---------+------------+-----------+-----------+-----------+\n",
      "| overall | 0.0647215  | 0.177498  | 0.0948555 | 0.177498  |\n",
      "+---------+------------+-----------+-----------+-----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-28 17:43:09,496 - trainer - INFO] - Train Epoch:[7/100] Step:[10/26] Total Loss: 198.065048 GL_Loss: 0.431818 CRF_Loss: 197.633224\n",
      "[2022-03-28 17:43:31,563 - trainer - INFO] - Train Epoch:[7/100] Step:[20/26] Total Loss: 148.992706 GL_Loss: 0.405427 CRF_Loss: 148.587280\n",
      "[2022-03-28 17:43:58,480 - trainer - INFO] - [Epoch Validation] Epoch:[7/100] Total Loss: 194.104997 GL_Loss: 0.008058 CRF_Loss: 193.299169 \n",
      "+---------+------------+-----------+------------+-----------+\n",
      "| name    |        mEP |       mER |        mEF |       mEA |\n",
      "+=========+============+===========+============+===========+\n",
      "| header  | 0.00223881 | 0.0223881 | 0.00407056 | 0.0223881 |\n",
      "+---------+------------+-----------+------------+-----------+\n",
      "| keys    | 0.0652993  | 0.142466  | 0.0895522  | 0.142466  |\n",
      "+---------+------------+-----------+------------+-----------+\n",
      "| values  | 0.0876866  | 0.169268  | 0.115526   | 0.169268  |\n",
      "+---------+------------+-----------+------------+-----------+\n",
      "| overall | 0.0562114  | 0.14549   | 0.081092   | 0.14549   |\n",
      "+---------+------------+-----------+------------+-----------+\n",
      "[2022-03-28 17:44:22,543 - trainer - INFO] - Train Epoch:[8/100] Step:[10/26] Total Loss: 160.866333 GL_Loss: 0.773396 CRF_Loss: 160.092941\n",
      "[2022-03-28 17:44:47,363 - trainer - INFO] - Train Epoch:[8/100] Step:[20/26] Total Loss: 92.779358 GL_Loss: 1.602603 CRF_Loss: 91.176758\n",
      "[2022-03-28 17:45:14,471 - trainer - INFO] - [Epoch Validation] Epoch:[8/100] Total Loss: 183.740300 GL_Loss: 0.010804 CRF_Loss: 182.659895 \n",
      "+---------+------------+-----------+-----------+-----------+\n",
      "| name    |        mEP |       mER |       mEF |       mEA |\n",
      "+=========+============+===========+===========+===========+\n",
      "| header  | 0.00961538 | 0.0522388 | 0.0162413 | 0.0522388 |\n",
      "+---------+------------+-----------+-----------+-----------+\n",
      "| keys    | 0.077912   | 0.182648  | 0.10923   | 0.182648  |\n",
      "+---------+------------+-----------+-----------+-----------+\n",
      "| values  | 0.0852429  | 0.223289  | 0.123383  | 0.223289  |\n",
      "+---------+------------+-----------+-----------+-----------+\n",
      "| overall | 0.0717546  | 0.190592  | 0.104258  | 0.190592  |\n",
      "+---------+------------+-----------+-----------+-----------+\n",
      "[2022-03-28 17:45:40,209 - trainer - INFO] - Train Epoch:[9/100] Step:[10/26] Total Loss: 173.374771 GL_Loss: 0.780045 CRF_Loss: 172.594727\n",
      "[2022-03-28 17:46:03,362 - trainer - INFO] - Train Epoch:[9/100] Step:[20/26] Total Loss: 163.350052 GL_Loss: 0.574809 CRF_Loss: 162.775238\n",
      "[2022-03-28 17:46:30,039 - trainer - INFO] - [Epoch Validation] Epoch:[9/100] Total Loss: 176.504287 GL_Loss: 0.006752 CRF_Loss: 175.829104 \n",
      "+---------+------------+-----------+-----------+-----------+\n",
      "| name    |        mEP |       mER |       mEF |       mEA |\n",
      "+=========+============+===========+===========+===========+\n",
      "| header  | 0.00810185 | 0.0522388 | 0.0140281 | 0.0522388 |\n",
      "+---------+------------+-----------+-----------+-----------+\n",
      "| keys    | 0.0708333  | 0.155251  | 0.0972818 | 0.155251  |\n",
      "+---------+------------+-----------+-----------+-----------+\n",
      "| values  | 0.0826667  | 0.223289  | 0.120662  | 0.223289  |\n",
      "+---------+------------+-----------+-----------+-----------+\n",
      "| overall | 0.0658324  | 0.176043  | 0.0958289 | 0.176043  |\n",
      "+---------+------------+-----------+-----------+-----------+\n",
      "[2022-03-28 17:46:53,645 - trainer - INFO] - Train Epoch:[10/100] Step:[10/26] Total Loss: 146.282471 GL_Loss: 2.057033 CRF_Loss: 144.225433\n",
      "[2022-03-28 17:47:15,712 - trainer - INFO] - Train Epoch:[10/100] Step:[20/26] Total Loss: 141.448914 GL_Loss: 0.612370 CRF_Loss: 140.836548\n",
      "[2022-03-28 17:47:42,251 - trainer - INFO] - [Epoch Validation] Epoch:[10/100] Total Loss: 150.545812 GL_Loss: 0.013721 CRF_Loss: 149.173720 \n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| name    |       mEP |       mER |       mEF |       mEA |\n",
      "+=========+===========+===========+===========+===========+\n",
      "| header  | 0.0153509 | 0.0522388 | 0.0237288 | 0.0522388 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| keys    | 0.130851  | 0.224658  | 0.165378  | 0.224658  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| values  | 0.0745957 | 0.171669  | 0.104     | 0.171669  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| overall | 0.0931107 | 0.192047  | 0.125416  | 0.192047  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "[2022-03-28 17:48:06,085 - trainer - INFO] - Train Epoch:[11/100] Step:[10/26] Total Loss: 145.401886 GL_Loss: 0.471832 CRF_Loss: 144.930054\n",
      "[2022-03-28 17:48:30,053 - trainer - INFO] - Train Epoch:[11/100] Step:[20/26] Total Loss: 98.584633 GL_Loss: 1.182200 CRF_Loss: 97.402435\n",
      "[2022-03-28 17:48:57,419 - trainer - INFO] - [Epoch Validation] Epoch:[11/100] Total Loss: 143.818265 GL_Loss: 0.006201 CRF_Loss: 143.198124 \n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| name    |       mEP |      mER |       mEF |      mEA |\n",
      "+=========+===========+==========+===========+==========+\n",
      "| header  | 0.0337349 | 0.104478 | 0.0510018 | 0.104478 |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| keys    | 0.149715  | 0.287671 | 0.196937  | 0.287671 |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| values  | 0.0990712 | 0.230492 | 0.138578  | 0.230492 |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| overall | 0.116895  | 0.252667 | 0.15984   | 0.252667 |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "[2022-03-28 17:49:21,677 - trainer - INFO] - Train Epoch:[12/100] Step:[10/26] Total Loss: 101.109444 GL_Loss: 0.631660 CRF_Loss: 100.477783\n",
      "[2022-03-28 17:49:44,615 - trainer - INFO] - Train Epoch:[12/100] Step:[20/26] Total Loss: 123.296669 GL_Loss: 0.229530 CRF_Loss: 123.067139\n",
      "[2022-03-28 17:50:11,100 - trainer - INFO] - [Epoch Validation] Epoch:[12/100] Total Loss: 107.031956 GL_Loss: 0.004387 CRF_Loss: 106.593212 \n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| name    |      mEP |       mER |       mEF |       mEA |\n",
      "+=========+==========+===========+===========+===========+\n",
      "| header  | 0.037594 | 0.0373134 | 0.0374532 | 0.0373134 |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| keys    | 0.184239 | 0.309589  | 0.231005  | 0.309589  |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| values  | 0.139562 | 0.283313  | 0.187005  | 0.283313  |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| overall | 0.158297 | 0.28128   | 0.202585  | 0.28128   |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "[2022-03-28 17:50:35,192 - trainer - INFO] - Train Epoch:[13/100] Step:[10/26] Total Loss: 123.747566 GL_Loss: 0.483162 CRF_Loss: 123.264404\n",
      "[2022-03-28 17:50:57,873 - trainer - INFO] - Train Epoch:[13/100] Step:[20/26] Total Loss: 109.609550 GL_Loss: 0.449311 CRF_Loss: 109.160240\n",
      "[2022-03-28 17:51:24,617 - trainer - INFO] - [Epoch Validation] Epoch:[13/100] Total Loss: 104.976385 GL_Loss: 0.007084 CRF_Loss: 104.267945 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0        | 0        | 0        | 0        |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.401874 | 0.665753 | 0.501203 | 0.665753 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.130531 | 0.283313 | 0.17872  | 0.283313 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.264094 | 0.467992 | 0.337649 | 0.467992 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 17:51:48,229 - trainer - INFO] - Train Epoch:[14/100] Step:[10/26] Total Loss: 50.030163 GL_Loss: 0.269054 CRF_Loss: 49.761108\n",
      "[2022-03-28 17:52:10,518 - trainer - INFO] - Train Epoch:[14/100] Step:[20/26] Total Loss: 98.193459 GL_Loss: 0.958060 CRF_Loss: 97.235397\n",
      "[2022-03-28 17:52:37,924 - trainer - INFO] - [Epoch Validation] Epoch:[14/100] Total Loss: 84.347906 GL_Loss: 0.005632 CRF_Loss: 83.784707 \n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| name    |       mEP |       mER |       mEF |       mEA |\n",
      "+=========+===========+===========+===========+===========+\n",
      "| header  | 0.0577778 | 0.0970149 | 0.0724234 | 0.0970149 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| keys    | 0.408377  | 0.783562  | 0.536921  | 0.783562  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| values  | 0.236656  | 0.441777  | 0.308208  | 0.441777  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| overall | 0.319248  | 0.600873  | 0.416961  | 0.600873  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-28 17:53:01,993 - trainer - INFO] - Train Epoch:[15/100] Step:[10/26] Total Loss: 70.407661 GL_Loss: 0.793808 CRF_Loss: 69.613853\n",
      "[2022-03-28 17:53:25,588 - trainer - INFO] - Train Epoch:[15/100] Step:[20/26] Total Loss: 57.870728 GL_Loss: 0.354002 CRF_Loss: 57.516727\n",
      "[2022-03-28 17:53:53,201 - trainer - INFO] - [Epoch Validation] Epoch:[15/100] Total Loss: 82.035306 GL_Loss: 0.007740 CRF_Loss: 81.261333 \n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| name    |       mEP |      mER |       mEF |      mEA |\n",
      "+=========+===========+==========+===========+==========+\n",
      "| header  | 0.0323575 | 0.156716 | 0.0536398 | 0.156716 |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| keys    | 0.3541    | 0.607306 | 0.44736   | 0.607306 |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| values  | 0.222888  | 0.402161 | 0.286815  | 0.402161 |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| overall | 0.25335   | 0.49515  | 0.335194  | 0.49515  |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "[2022-03-28 17:54:18,277 - trainer - INFO] - Train Epoch:[16/100] Step:[10/26] Total Loss: 189.145905 GL_Loss: 0.544497 CRF_Loss: 188.601410\n",
      "[2022-03-28 17:54:41,426 - trainer - INFO] - Train Epoch:[16/100] Step:[20/26] Total Loss: 62.017479 GL_Loss: 0.404359 CRF_Loss: 61.613121\n",
      "[2022-03-28 17:55:07,569 - trainer - INFO] - [Epoch Validation] Epoch:[16/100] Total Loss: 90.861841 GL_Loss: 0.005181 CRF_Loss: 90.343712 \n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| name    |       mEP |       mER |       mEF |       mEA |\n",
      "+=========+===========+===========+===========+===========+\n",
      "| header  | 0.0808824 | 0.0820896 | 0.0814815 | 0.0820896 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| keys    | 0.401007  | 0.654795  | 0.497399  | 0.654795  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| values  | 0.278998  | 0.762305  | 0.408491  | 0.762305  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| overall | 0.324524  | 0.661009  | 0.435324  | 0.661009  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "[2022-03-28 17:55:31,733 - trainer - INFO] - Train Epoch:[17/100] Step:[10/26] Total Loss: 61.549881 GL_Loss: 3.206374 CRF_Loss: 58.343506\n",
      "[2022-03-28 17:55:54,829 - trainer - INFO] - Train Epoch:[17/100] Step:[20/26] Total Loss: 96.377296 GL_Loss: 1.433853 CRF_Loss: 94.943443\n",
      "[2022-03-28 17:56:21,177 - trainer - INFO] - [Epoch Validation] Epoch:[17/100] Total Loss: 101.742192 GL_Loss: 0.016449 CRF_Loss: 100.097255 \n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| name    |       mEP |       mER |       mEF |       mEA |\n",
      "+=========+===========+===========+===========+===========+\n",
      "| header  | 0.0454545 | 0.0746269 | 0.0564972 | 0.0746269 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| keys    | 0.465405  | 0.786301  | 0.58472   | 0.786301  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| values  | 0.300231  | 0.468187  | 0.365854  | 0.468187  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| overall | 0.374295  | 0.611542  | 0.464371  | 0.611542  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "[2022-03-28 17:56:44,748 - trainer - INFO] - Train Epoch:[18/100] Step:[10/26] Total Loss: 22.364759 GL_Loss: 0.458510 CRF_Loss: 21.906250\n",
      "[2022-03-28 17:57:08,585 - trainer - INFO] - Train Epoch:[18/100] Step:[20/26] Total Loss: 56.529022 GL_Loss: 1.284552 CRF_Loss: 55.244469\n",
      "[2022-03-28 17:57:35,381 - trainer - INFO] - [Epoch Validation] Epoch:[18/100] Total Loss: 51.665740 GL_Loss: 0.006472 CRF_Loss: 51.018560 \n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| name    |       mEP |      mER |       mEF |      mEA |\n",
      "+=========+===========+==========+===========+==========+\n",
      "| header  | 0.0450161 | 0.208955 | 0.0740741 | 0.208955 |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| keys    | 0.400655  | 0.782648 | 0.529994  | 0.782648 |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| values  | 0.281572  | 0.52461  | 0.366457  | 0.52461  |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| overall | 0.306515  | 0.641125 | 0.414745  | 0.641125 |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "[2022-03-28 17:57:59,328 - trainer - INFO] - Train Epoch:[19/100] Step:[10/26] Total Loss: 57.270828 GL_Loss: 0.672273 CRF_Loss: 56.598557\n",
      "[2022-03-28 17:58:23,464 - trainer - INFO] - Train Epoch:[19/100] Step:[20/26] Total Loss: 76.422256 GL_Loss: 0.504816 CRF_Loss: 75.917442\n",
      "[2022-03-28 17:58:49,425 - trainer - INFO] - [Epoch Validation] Epoch:[19/100] Total Loss: 53.519478 GL_Loss: 0.007117 CRF_Loss: 52.807733 \n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| name    |       mEP |      mER |       mEF |      mEA |\n",
      "+=========+===========+==========+===========+==========+\n",
      "| header  | 0.0338983 | 0.134328 | 0.0541353 | 0.134328 |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| keys    | 0.377578  | 0.652055 | 0.478232  | 0.652055 |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| values  | 0.373952  | 0.696279 | 0.486577  | 0.696279 |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| overall | 0.330229  | 0.636275 | 0.434797  | 0.636275 |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "[2022-03-28 17:59:12,195 - trainer - INFO] - Train Epoch:[20/100] Step:[10/26] Total Loss: 10.326692 GL_Loss: 0.281282 CRF_Loss: 10.045410\n",
      "[2022-03-28 17:59:36,184 - trainer - INFO] - Train Epoch:[20/100] Step:[20/26] Total Loss: 20.268835 GL_Loss: 0.348016 CRF_Loss: 19.920818\n",
      "[2022-03-28 18:00:02,996 - trainer - INFO] - [Epoch Validation] Epoch:[20/100] Total Loss: 29.682522 GL_Loss: 0.005683 CRF_Loss: 29.114180 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.108949 | 0.208955 | 0.143223 | 0.208955 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.520151 | 0.754338 | 0.615729 | 0.754338 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.457007 | 0.810324 | 0.584416 | 0.810324 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.460265 | 0.741513 | 0.567979 | 0.741513 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 18:00:04,962 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-03-28 18:00:29,943 - trainer - INFO] - Train Epoch:[21/100] Step:[10/26] Total Loss: 36.559288 GL_Loss: 0.844605 CRF_Loss: 35.714684\n",
      "[2022-03-28 18:00:53,075 - trainer - INFO] - Train Epoch:[21/100] Step:[20/26] Total Loss: 36.494648 GL_Loss: 0.363380 CRF_Loss: 36.131268\n",
      "[2022-03-28 18:01:18,960 - trainer - INFO] - [Epoch Validation] Epoch:[21/100] Total Loss: 28.161807 GL_Loss: 0.005242 CRF_Loss: 27.637635 \n",
      "+---------+-----------+----------+----------+----------+\n",
      "| name    |       mEP |      mER |      mEF |      mEA |\n",
      "+=========+===========+==========+==========+==========+\n",
      "| header  | 0.0706052 | 0.365672 | 0.118357 | 0.365672 |\n",
      "+---------+-----------+----------+----------+----------+\n",
      "| keys    | 0.377222  | 0.716895 | 0.494332 | 0.716895 |\n",
      "+---------+-----------+----------+----------+----------+\n",
      "| values  | 0.418157  | 0.729892 | 0.531701 | 0.729892 |\n",
      "+---------+-----------+----------+----------+----------+\n",
      "| overall | 0.340979  | 0.699321 | 0.458433 | 0.699321 |\n",
      "+---------+-----------+----------+----------+----------+\n",
      "[2022-03-28 18:01:41,761 - trainer - INFO] - Train Epoch:[22/100] Step:[10/26] Total Loss: 36.997925 GL_Loss: 0.548907 CRF_Loss: 36.449017\n",
      "[2022-03-28 18:02:05,477 - trainer - INFO] - Train Epoch:[22/100] Step:[20/26] Total Loss: 52.113510 GL_Loss: 0.350164 CRF_Loss: 51.763348\n",
      "[2022-03-28 18:02:32,518 - trainer - INFO] - [Epoch Validation] Epoch:[22/100] Total Loss: 29.131479 GL_Loss: 0.004762 CRF_Loss: 28.655268 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.262295 | 0.119403 | 0.164103 | 0.119403 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.529486 | 0.770776 | 0.627743 | 0.770776 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.402292 | 0.80072  | 0.535528 | 0.80072  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.460912 | 0.740543 | 0.568186 | 0.740543 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-28 18:02:56,393 - trainer - INFO] - Train Epoch:[23/100] Step:[10/26] Total Loss: 39.659683 GL_Loss: 0.643407 CRF_Loss: 39.016277\n",
      "[2022-03-28 18:03:19,453 - trainer - INFO] - Train Epoch:[23/100] Step:[20/26] Total Loss: 6.586519 GL_Loss: 1.328300 CRF_Loss: 5.258220\n",
      "[2022-03-28 18:03:45,862 - trainer - INFO] - [Epoch Validation] Epoch:[23/100] Total Loss: 35.031566 GL_Loss: 0.005937 CRF_Loss: 34.437841 \n",
      "+---------+-----------+----------+----------+----------+\n",
      "| name    |       mEP |      mER |      mEF |      mEA |\n",
      "+=========+===========+==========+==========+==========+\n",
      "| header  | 0.0661765 | 0.335821 | 0.110565 | 0.335821 |\n",
      "+---------+-----------+----------+----------+----------+\n",
      "| keys    | 0.408845  | 0.759817 | 0.531629 | 0.759817 |\n",
      "+---------+-----------+----------+----------+----------+\n",
      "| values  | 0.431373  | 0.739496 | 0.544892 | 0.739496 |\n",
      "+---------+-----------+----------+----------+----------+\n",
      "| overall | 0.360367  | 0.724054 | 0.481225 | 0.724054 |\n",
      "+---------+-----------+----------+----------+----------+\n",
      "[2022-03-28 18:04:10,060 - trainer - INFO] - Train Epoch:[24/100] Step:[10/26] Total Loss: 32.343552 GL_Loss: 0.392704 CRF_Loss: 31.950848\n",
      "[2022-03-28 18:04:31,551 - trainer - INFO] - Train Epoch:[24/100] Step:[20/26] Total Loss: 19.477579 GL_Loss: 0.397662 CRF_Loss: 19.079916\n",
      "[2022-03-28 18:04:59,467 - trainer - INFO] - [Epoch Validation] Epoch:[24/100] Total Loss: 37.243722 GL_Loss: 0.004807 CRF_Loss: 36.763029 \n",
      "+---------+-----------+----------+----------+----------+\n",
      "| name    |       mEP |      mER |      mEF |      mEA |\n",
      "+=========+===========+==========+==========+==========+\n",
      "| header  | 0.0864865 | 0.238806 | 0.126984 | 0.238806 |\n",
      "+---------+-----------+----------+----------+----------+\n",
      "| keys    | 0.411081  | 0.840183 | 0.552055 | 0.840183 |\n",
      "+---------+-----------+----------+----------+----------+\n",
      "| values  | 0.352428  | 0.77551  | 0.484621 | 0.77551  |\n",
      "+---------+-----------+----------+----------+----------+\n",
      "| overall | 0.359829  | 0.774976 | 0.491465 | 0.774976 |\n",
      "+---------+-----------+----------+----------+----------+\n",
      "[2022-03-28 18:05:24,171 - trainer - INFO] - Train Epoch:[25/100] Step:[10/26] Total Loss: 33.754929 GL_Loss: 0.519249 CRF_Loss: 33.235680\n",
      "[2022-03-28 18:05:47,274 - trainer - INFO] - Train Epoch:[25/100] Step:[20/26] Total Loss: 18.954912 GL_Loss: 0.358802 CRF_Loss: 18.596109\n",
      "[2022-03-28 18:06:13,952 - trainer - INFO] - [Epoch Validation] Epoch:[25/100] Total Loss: 38.272922 GL_Loss: 0.004434 CRF_Loss: 37.829566 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.163866 | 0.291045 | 0.209677 | 0.291045 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.515312 | 0.891324 | 0.653061 | 0.891324 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.401498 | 0.643457 | 0.494465 | 0.643457 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.447361 | 0.752182 | 0.561042 | 0.752182 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 18:06:38,553 - trainer - INFO] - Train Epoch:[26/100] Step:[10/26] Total Loss: 9.508555 GL_Loss: 0.454925 CRF_Loss: 9.053630\n",
      "[2022-03-28 18:07:49,881 - trainer - INFO] - Train Epoch:[27/100] Step:[10/26] Total Loss: 33.419468 GL_Loss: 0.304723 CRF_Loss: 33.114746\n",
      "[2022-03-28 18:08:14,374 - trainer - INFO] - Train Epoch:[27/100] Step:[20/26] Total Loss: 31.422194 GL_Loss: 0.263501 CRF_Loss: 31.158691\n",
      "[2022-03-28 18:08:42,726 - trainer - INFO] - [Epoch Validation] Epoch:[27/100] Total Loss: 27.327212 GL_Loss: 0.003323 CRF_Loss: 26.994871 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.132812 | 0.380597 | 0.196911 | 0.380597 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.4465   | 0.815525 | 0.57706  | 0.815525 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.383221 | 0.685474 | 0.491606 | 0.685474 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.391069 | 0.734724 | 0.510445 | 0.734724 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 18:09:05,623 - trainer - INFO] - Train Epoch:[28/100] Step:[10/26] Total Loss: 16.692379 GL_Loss: 4.845862 CRF_Loss: 11.846518\n",
      "[2022-03-28 18:09:30,313 - trainer - INFO] - Train Epoch:[28/100] Step:[20/26] Total Loss: 35.413364 GL_Loss: 0.568230 CRF_Loss: 34.845135\n",
      "[2022-03-28 18:09:58,107 - trainer - INFO] - [Epoch Validation] Epoch:[28/100] Total Loss: 57.645002 GL_Loss: 0.014278 CRF_Loss: 56.217225 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.101266 | 0.119403 | 0.109589 | 0.119403 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.382038 | 0.749772 | 0.506165 | 0.749772 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.332943 | 0.683073 | 0.447679 | 0.683073 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.3501   | 0.681862 | 0.462652 | 0.681862 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 18:10:23,308 - trainer - INFO] - Train Epoch:[29/100] Step:[10/26] Total Loss: 35.558044 GL_Loss: 0.618673 CRF_Loss: 34.939373\n",
      "[2022-03-28 18:10:45,672 - trainer - INFO] - Train Epoch:[29/100] Step:[20/26] Total Loss: 52.891148 GL_Loss: 0.557000 CRF_Loss: 52.334148\n",
      "[2022-03-28 18:11:12,659 - trainer - INFO] - [Epoch Validation] Epoch:[29/100] Total Loss: 36.183494 GL_Loss: 0.007262 CRF_Loss: 35.457343 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.128302 | 0.253731 | 0.170426 | 0.253731 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.577503 | 0.76895  | 0.659616 | 0.76895  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.439079 | 0.709484 | 0.542451 | 0.709484 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.478006 | 0.711445 | 0.571818 | 0.711445 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 18:11:37,572 - trainer - INFO] - Train Epoch:[30/100] Step:[10/26] Total Loss: 9.979171 GL_Loss: 0.429284 CRF_Loss: 9.549887\n",
      "[2022-03-28 18:12:01,146 - trainer - INFO] - Train Epoch:[30/100] Step:[20/26] Total Loss: 15.524070 GL_Loss: 0.239971 CRF_Loss: 15.284099\n",
      "[2022-03-28 18:12:26,669 - trainer - INFO] - [Epoch Validation] Epoch:[30/100] Total Loss: 20.621380 GL_Loss: 0.004060 CRF_Loss: 20.215381 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.177143 | 0.231343 | 0.200647 | 0.231343 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.585943 | 0.700457 | 0.638103 | 0.700457 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.47924  | 0.817527 | 0.604259 | 0.817527 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.509122 | 0.717265 | 0.595531 | 0.717265 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 18:12:50,471 - trainer - INFO] - Train Epoch:[31/100] Step:[10/26] Total Loss: 8.138607 GL_Loss: 0.466854 CRF_Loss: 7.671753\n",
      "[2022-03-28 18:13:13,788 - trainer - INFO] - Train Epoch:[31/100] Step:[20/26] Total Loss: 4.179948 GL_Loss: 0.526546 CRF_Loss: 3.653402\n",
      "[2022-03-28 18:13:40,501 - trainer - INFO] - [Epoch Validation] Epoch:[31/100] Total Loss: 13.644088 GL_Loss: 0.005024 CRF_Loss: 13.141642 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.149466 | 0.313433 | 0.20241  | 0.313433 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.549751 | 0.807306 | 0.654088 | 0.807306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.499599 | 0.747899 | 0.599038 | 0.747899 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.493941 | 0.751212 | 0.595998 | 0.751212 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-28 18:14:04,469 - trainer - INFO] - Train Epoch:[32/100] Step:[10/26] Total Loss: 13.924250 GL_Loss: 0.535008 CRF_Loss: 13.389242\n",
      "[2022-03-28 18:14:27,266 - trainer - INFO] - Train Epoch:[32/100] Step:[20/26] Total Loss: 14.393034 GL_Loss: 0.371793 CRF_Loss: 14.021241\n",
      "[2022-03-28 18:14:53,561 - trainer - INFO] - [Epoch Validation] Epoch:[32/100] Total Loss: 11.843162 GL_Loss: 0.004157 CRF_Loss: 11.427493 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.150538 | 0.313433 | 0.20339  | 0.313433 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.523202 | 0.823744 | 0.639943 | 0.823744 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.47561  | 0.7491   | 0.581818 | 0.7491   |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.473002 | 0.760427 | 0.583225 | 0.760427 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 18:15:16,740 - trainer - INFO] - Train Epoch:[33/100] Step:[10/26] Total Loss: 4.733885 GL_Loss: 0.291665 CRF_Loss: 4.442220\n",
      "[2022-03-28 18:15:40,780 - trainer - INFO] - Train Epoch:[33/100] Step:[20/26] Total Loss: 7.425918 GL_Loss: 0.199192 CRF_Loss: 7.226726\n",
      "[2022-03-28 18:16:08,032 - trainer - INFO] - [Epoch Validation] Epoch:[33/100] Total Loss: 7.245270 GL_Loss: 0.003717 CRF_Loss: 6.873535 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.132743 | 0.335821 | 0.190275 | 0.335821 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.531026 | 0.812785 | 0.642367 | 0.812785 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.511722 | 0.759904 | 0.611594 | 0.759904 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.482165 | 0.760427 | 0.590139 | 0.760427 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 18:16:31,079 - trainer - INFO] - Train Epoch:[34/100] Step:[10/26] Total Loss: 7.731761 GL_Loss: 0.370717 CRF_Loss: 7.361043\n",
      "[2022-03-28 18:16:54,885 - trainer - INFO] - Train Epoch:[34/100] Step:[20/26] Total Loss: 7.074463 GL_Loss: 0.527425 CRF_Loss: 6.547038\n",
      "[2022-03-28 18:17:21,189 - trainer - INFO] - [Epoch Validation] Epoch:[34/100] Total Loss: 10.879873 GL_Loss: 0.004073 CRF_Loss: 10.472525 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.168582 | 0.328358 | 0.222785 | 0.328358 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.534554 | 0.826484 | 0.649211 | 0.826484 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.470987 | 0.7503   | 0.578704 | 0.7503   |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.479732 | 0.763337 | 0.589182 | 0.763337 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 18:17:45,195 - trainer - INFO] - Train Epoch:[35/100] Step:[10/26] Total Loss: 22.690041 GL_Loss: 0.344498 CRF_Loss: 22.345543\n",
      "[2022-03-28 18:18:08,800 - trainer - INFO] - Train Epoch:[35/100] Step:[20/26] Total Loss: 6.941036 GL_Loss: 0.452754 CRF_Loss: 6.488281\n",
      "[2022-03-28 18:18:34,788 - trainer - INFO] - [Epoch Validation] Epoch:[35/100] Total Loss: 8.152105 GL_Loss: 0.003986 CRF_Loss: 7.753497 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.150171 | 0.328358 | 0.206089 | 0.328358 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.561069 | 0.805479 | 0.661417 | 0.805479 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.503236 | 0.746699 | 0.601257 | 0.746699 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.499194 | 0.750727 | 0.599651 | 0.750727 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 18:18:59,271 - trainer - INFO] - Train Epoch:[36/100] Step:[10/26] Total Loss: 9.551871 GL_Loss: 0.254914 CRF_Loss: 9.296957\n",
      "[2022-03-28 18:19:21,989 - trainer - INFO] - Train Epoch:[36/100] Step:[20/26] Total Loss: 8.394509 GL_Loss: 0.174335 CRF_Loss: 8.220175\n",
      "[2022-03-28 18:19:48,868 - trainer - INFO] - [Epoch Validation] Epoch:[36/100] Total Loss: 7.197906 GL_Loss: 0.003125 CRF_Loss: 6.885405 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.130178 | 0.328358 | 0.186441 | 0.328358 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.532491 | 0.808219 | 0.642002 | 0.808219 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.486801 | 0.752701 | 0.591231 | 0.752701 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.473236 | 0.754607 | 0.581682 | 0.754607 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 18:20:11,973 - trainer - INFO] - Train Epoch:[37/100] Step:[10/26] Total Loss: 6.530137 GL_Loss: 0.345404 CRF_Loss: 6.184733\n",
      "[2022-03-28 18:20:35,025 - trainer - INFO] - Train Epoch:[37/100] Step:[20/26] Total Loss: 0.833900 GL_Loss: 0.212725 CRF_Loss: 0.621175\n",
      "[2022-03-28 18:21:01,714 - trainer - INFO] - [Epoch Validation] Epoch:[37/100] Total Loss: 6.776402 GL_Loss: 0.003645 CRF_Loss: 6.411919 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.15331  | 0.328358 | 0.209026 | 0.328358 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.539062 | 0.819178 | 0.650236 | 0.819178 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.480799 | 0.751501 | 0.586417 | 0.751501 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.481709 | 0.759942 | 0.589652 | 0.759942 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 18:21:25,229 - trainer - INFO] - Train Epoch:[38/100] Step:[10/26] Total Loss: 1.083211 GL_Loss: 0.225260 CRF_Loss: 0.857951\n",
      "[2022-03-28 18:21:49,201 - trainer - INFO] - Train Epoch:[38/100] Step:[20/26] Total Loss: 2.542879 GL_Loss: 0.222078 CRF_Loss: 2.320801\n",
      "[2022-03-28 18:22:15,732 - trainer - INFO] - [Epoch Validation] Epoch:[38/100] Total Loss: 6.030334 GL_Loss: 0.003223 CRF_Loss: 5.707994 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.133333 | 0.328358 | 0.189655 | 0.328358 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.544471 | 0.827397 | 0.65676  | 0.827397 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.506462 | 0.752701 | 0.605505 | 0.752701 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.487933 | 0.764791 | 0.595769 | 0.764791 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 18:22:41,022 - trainer - INFO] - Train Epoch:[39/100] Step:[10/26] Total Loss: 5.858521 GL_Loss: 0.412802 CRF_Loss: 5.445720\n",
      "[2022-03-28 18:23:03,196 - trainer - INFO] - Train Epoch:[39/100] Step:[20/26] Total Loss: 7.024476 GL_Loss: 0.202616 CRF_Loss: 6.821859\n",
      "[2022-03-28 18:23:29,648 - trainer - INFO] - [Epoch Validation] Epoch:[39/100] Total Loss: 8.544505 GL_Loss: 0.003271 CRF_Loss: 8.217440 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.143791 | 0.328358 | 0.2      | 0.328358 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.530205 | 0.825571 | 0.645714 | 0.825571 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.495994 | 0.743097 | 0.594906 | 0.743097 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.480822 | 0.759942 | 0.588987 | 0.759942 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-28 18:23:52,385 - trainer - INFO] - Train Epoch:[40/100] Step:[10/26] Total Loss: 8.227869 GL_Loss: 0.341231 CRF_Loss: 7.886638\n",
      "[2022-03-28 18:24:15,657 - trainer - INFO] - Train Epoch:[40/100] Step:[20/26] Total Loss: 2.747915 GL_Loss: 0.222036 CRF_Loss: 2.525879\n",
      "[2022-03-28 18:24:42,886 - trainer - INFO] - [Epoch Validation] Epoch:[40/100] Total Loss: 7.499432 GL_Loss: 0.003355 CRF_Loss: 7.163884 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.144737 | 0.328358 | 0.200913 | 0.328358 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.539645 | 0.832877 | 0.654937 | 0.832877 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.515781 | 0.745498 | 0.60972  | 0.745498 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.493121 | 0.764791 | 0.59962  | 0.764791 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 18:24:44,994 - trainer - INFO] - Saving checkpoint: saved/models/PICK_Default/test_0328_173509/checkpoint-epoch40.pth ...\n",
      "[2022-03-28 18:25:08,347 - trainer - INFO] - Train Epoch:[41/100] Step:[10/26] Total Loss: 3.402960 GL_Loss: 0.351121 CRF_Loss: 3.051839\n",
      "[2022-03-28 18:25:31,559 - trainer - INFO] - Train Epoch:[41/100] Step:[20/26] Total Loss: 5.527825 GL_Loss: 0.469557 CRF_Loss: 5.058269\n",
      "[2022-03-28 18:25:57,936 - trainer - INFO] - [Epoch Validation] Epoch:[41/100] Total Loss: 7.160745 GL_Loss: 0.003053 CRF_Loss: 6.855413 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.160714 | 0.335821 | 0.217391 | 0.335821 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.545509 | 0.831963 | 0.658951 | 0.831963 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.474251 | 0.740696 | 0.578257 | 0.740696 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.483851 | 0.762852 | 0.592133 | 0.762852 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 18:26:21,736 - trainer - INFO] - Train Epoch:[42/100] Step:[10/26] Total Loss: 9.151133 GL_Loss: 0.267913 CRF_Loss: 8.883220\n",
      "[2022-03-28 18:26:44,366 - trainer - INFO] - Train Epoch:[42/100] Step:[20/26] Total Loss: 7.261331 GL_Loss: 0.321429 CRF_Loss: 6.939901\n",
      "[2022-03-28 18:27:11,529 - trainer - INFO] - [Epoch Validation] Epoch:[42/100] Total Loss: 6.444004 GL_Loss: 0.003780 CRF_Loss: 6.065965 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.175573 | 0.343284 | 0.232323 | 0.343284 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.580686 | 0.834703 | 0.684901 | 0.834703 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.566123 | 0.7503   | 0.645328 | 0.7503   |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.539116 | 0.768671 | 0.633747 | 0.768671 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 18:27:35,439 - trainer - INFO] - Train Epoch:[43/100] Step:[10/26] Total Loss: 5.744617 GL_Loss: 0.251371 CRF_Loss: 5.493246\n",
      "[2022-03-28 18:27:58,845 - trainer - INFO] - Train Epoch:[43/100] Step:[20/26] Total Loss: 8.598628 GL_Loss: 0.453283 CRF_Loss: 8.145346\n",
      "[2022-03-28 18:28:26,474 - trainer - INFO] - [Epoch Validation] Epoch:[43/100] Total Loss: 6.373033 GL_Loss: 0.003380 CRF_Loss: 6.035041 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.147157 | 0.328358 | 0.203233 | 0.328358 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.524855 | 0.829224 | 0.642832 | 0.829224 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.459337 | 0.732293 | 0.564553 | 0.732293 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.465296 | 0.757517 | 0.57649  | 0.757517 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 18:28:49,784 - trainer - INFO] - Train Epoch:[44/100] Step:[10/26] Total Loss: 6.143869 GL_Loss: 0.270008 CRF_Loss: 5.873861\n",
      "[2022-03-28 18:29:14,276 - trainer - INFO] - Train Epoch:[44/100] Step:[20/26] Total Loss: 22.049536 GL_Loss: 0.389460 CRF_Loss: 21.660076\n",
      "[2022-03-28 18:29:41,256 - trainer - INFO] - [Epoch Validation] Epoch:[44/100] Total Loss: 6.930025 GL_Loss: 0.003267 CRF_Loss: 6.603331 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.166667 | 0.343284 | 0.22439  | 0.343284 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.578075 | 0.828311 | 0.680931 | 0.828311 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.552773 | 0.741897 | 0.633521 | 0.741897 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.530206 | 0.761882 | 0.625274 | 0.761882 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 18:30:05,851 - trainer - INFO] - Train Epoch:[45/100] Step:[10/26] Total Loss: 6.892066 GL_Loss: 0.351904 CRF_Loss: 6.540162\n",
      "[2022-03-28 18:30:30,505 - trainer - INFO] - Train Epoch:[45/100] Step:[20/26] Total Loss: 5.227684 GL_Loss: 0.324363 CRF_Loss: 4.903320\n",
      "[2022-03-28 18:30:56,951 - trainer - INFO] - [Epoch Validation] Epoch:[45/100] Total Loss: 6.315807 GL_Loss: 0.003277 CRF_Loss: 5.988141 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.177866 | 0.335821 | 0.232558 | 0.335821 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.518052 | 0.825571 | 0.63662  | 0.825571 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.472519 | 0.743097 | 0.577695 | 0.743097 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.474002 | 0.760427 | 0.583985 | 0.760427 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 18:31:20,572 - trainer - INFO] - Train Epoch:[46/100] Step:[10/26] Total Loss: 9.264738 GL_Loss: 0.191170 CRF_Loss: 9.073568\n",
      "[2022-03-28 18:31:44,197 - trainer - INFO] - Train Epoch:[46/100] Step:[20/26] Total Loss: 3.225612 GL_Loss: 0.441432 CRF_Loss: 2.784180\n",
      "[2022-03-28 18:32:11,115 - trainer - INFO] - [Epoch Validation] Epoch:[46/100] Total Loss: 5.725119 GL_Loss: 0.003051 CRF_Loss: 5.420030 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.170543 | 0.328358 | 0.22449  | 0.328358 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.542515 | 0.827397 | 0.655335 | 0.827397 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.467562 | 0.752701 | 0.576817 | 0.752701 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.482411 | 0.764791 | 0.591634 | 0.764791 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 18:32:35,117 - trainer - INFO] - Train Epoch:[47/100] Step:[10/26] Total Loss: 2.058620 GL_Loss: 0.230251 CRF_Loss: 1.828369\n",
      "[2022-03-28 18:32:59,687 - trainer - INFO] - Train Epoch:[47/100] Step:[20/26] Total Loss: 4.748984 GL_Loss: 0.252076 CRF_Loss: 4.496908\n",
      "[2022-03-28 18:33:26,713 - trainer - INFO] - [Epoch Validation] Epoch:[47/100] Total Loss: 4.918781 GL_Loss: 0.002897 CRF_Loss: 4.629053 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.178571 | 0.335821 | 0.233161 | 0.335821 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.552503 | 0.826484 | 0.662276 | 0.826484 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.477134 | 0.751501 | 0.583683 | 0.751501 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.492192 | 0.764306 | 0.598784 | 0.764306 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-28 18:33:52,994 - trainer - INFO] - Train Epoch:[48/100] Step:[10/26] Total Loss: 1.578585 GL_Loss: 0.240857 CRF_Loss: 1.337728\n",
      "[2022-03-28 18:34:15,880 - trainer - INFO] - Train Epoch:[48/100] Step:[20/26] Total Loss: 5.558528 GL_Loss: 0.338476 CRF_Loss: 5.220052\n",
      "[2022-03-28 18:34:42,490 - trainer - INFO] - [Epoch Validation] Epoch:[48/100] Total Loss: 5.298411 GL_Loss: 0.003197 CRF_Loss: 4.978707 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.172    | 0.320896 | 0.223958 | 0.320896 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.56904  | 0.839269 | 0.678229 | 0.839269 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.521959 | 0.741897 | 0.612791 | 0.741897 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.518203 | 0.766246 | 0.618274 | 0.766246 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 18:35:07,192 - trainer - INFO] - Train Epoch:[49/100] Step:[10/26] Total Loss: 2.314136 GL_Loss: 0.243457 CRF_Loss: 2.070679\n",
      "[2022-03-28 18:35:31,959 - trainer - INFO] - Train Epoch:[49/100] Step:[20/26] Total Loss: 3.332862 GL_Loss: 0.441749 CRF_Loss: 2.891114\n",
      "[2022-03-28 18:35:58,317 - trainer - INFO] - [Epoch Validation] Epoch:[49/100] Total Loss: 5.240413 GL_Loss: 0.002769 CRF_Loss: 4.963507 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.171429 | 0.313433 | 0.221636 | 0.313433 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.565136 | 0.831963 | 0.67307  | 0.831963 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.519731 | 0.743097 | 0.61166  | 0.743097 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.515748 | 0.762367 | 0.615264 | 0.762367 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 18:36:24,380 - trainer - INFO] - Train Epoch:[50/100] Step:[10/26] Total Loss: 17.281437 GL_Loss: 0.254988 CRF_Loss: 17.026449\n",
      "[2022-03-28 18:36:45,797 - trainer - INFO] - Train Epoch:[50/100] Step:[20/26] Total Loss: 1.609559 GL_Loss: 0.258851 CRF_Loss: 1.350708\n",
      "[2022-03-28 18:37:12,908 - trainer - INFO] - [Epoch Validation] Epoch:[50/100] Total Loss: 4.590438 GL_Loss: 0.002554 CRF_Loss: 4.335031 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.158784 | 0.350746 | 0.218605 | 0.350746 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.564566 | 0.826484 | 0.670867 | 0.826484 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.508772 | 0.731092 | 0.6      | 0.731092 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.504199 | 0.757032 | 0.605273 | 0.757032 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 18:37:38,055 - trainer - INFO] - Train Epoch:[51/100] Step:[10/26] Total Loss: 2.970247 GL_Loss: 0.294303 CRF_Loss: 2.675944\n",
      "[2022-03-28 18:38:00,581 - trainer - INFO] - Train Epoch:[51/100] Step:[20/26] Total Loss: 7.042743 GL_Loss: 0.340595 CRF_Loss: 6.702148\n",
      "[2022-03-28 18:38:27,206 - trainer - INFO] - [Epoch Validation] Epoch:[51/100] Total Loss: 5.191834 GL_Loss: 0.002927 CRF_Loss: 4.899096 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.177165 | 0.335821 | 0.231959 | 0.335821 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.554368 | 0.805479 | 0.656739 | 0.805479 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.491739 | 0.7503   | 0.594106 | 0.7503   |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.498074 | 0.752667 | 0.599459 | 0.752667 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 18:38:53,055 - trainer - INFO] - Train Epoch:[52/100] Step:[10/26] Total Loss: 3.315632 GL_Loss: 0.260293 CRF_Loss: 3.055339\n",
      "[2022-03-28 18:39:16,065 - trainer - INFO] - Train Epoch:[52/100] Step:[20/26] Total Loss: 3.180665 GL_Loss: 0.219849 CRF_Loss: 2.960816\n",
      "[2022-03-28 18:39:41,673 - trainer - INFO] - [Epoch Validation] Epoch:[52/100] Total Loss: 4.768992 GL_Loss: 0.002809 CRF_Loss: 4.488066 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.163121 | 0.343284 | 0.221154 | 0.343284 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.519375 | 0.820091 | 0.635977 | 0.820091 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.452206 | 0.738295 | 0.560876 | 0.738295 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.462474 | 0.756062 | 0.5739   | 0.756062 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 18:40:05,698 - trainer - INFO] - Train Epoch:[53/100] Step:[10/26] Total Loss: 1.962875 GL_Loss: 0.218897 CRF_Loss: 1.743978\n",
      "[2022-03-28 18:40:28,772 - trainer - INFO] - Train Epoch:[53/100] Step:[20/26] Total Loss: 1.621903 GL_Loss: 0.181555 CRF_Loss: 1.440348\n",
      "[2022-03-28 18:40:56,107 - trainer - INFO] - [Epoch Validation] Epoch:[53/100] Total Loss: 5.280802 GL_Loss: 0.002578 CRF_Loss: 5.023040 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.202586 | 0.350746 | 0.256831 | 0.350746 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.540906 | 0.839269 | 0.657838 | 0.839269 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.48908  | 0.752701 | 0.592908 | 0.752701 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.495798 | 0.772551 | 0.603981 | 0.772551 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 18:41:21,270 - trainer - INFO] - Train Epoch:[54/100] Step:[10/26] Total Loss: 5.612750 GL_Loss: 0.225868 CRF_Loss: 5.386882\n",
      "[2022-03-28 18:41:44,552 - trainer - INFO] - Train Epoch:[54/100] Step:[20/26] Total Loss: 1.627397 GL_Loss: 0.152706 CRF_Loss: 1.474691\n",
      "[2022-03-28 18:42:09,799 - trainer - INFO] - [Epoch Validation] Epoch:[54/100] Total Loss: 4.870671 GL_Loss: 0.002748 CRF_Loss: 4.595864 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.158416 | 0.358209 | 0.21968  | 0.358209 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.55122  | 0.825571 | 0.66106  | 0.825571 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.51936  | 0.740696 | 0.610589 | 0.740696 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.501118 | 0.760912 | 0.604275 | 0.760912 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 18:42:33,772 - trainer - INFO] - Train Epoch:[55/100] Step:[10/26] Total Loss: 3.008714 GL_Loss: 0.226000 CRF_Loss: 2.782715\n",
      "[2022-03-28 18:42:57,784 - trainer - INFO] - Train Epoch:[55/100] Step:[20/26] Total Loss: 2.786608 GL_Loss: 0.355456 CRF_Loss: 2.431152\n",
      "[2022-03-28 18:43:23,939 - trainer - INFO] - [Epoch Validation] Epoch:[55/100] Total Loss: 4.432781 GL_Loss: 0.002596 CRF_Loss: 4.173205 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.195745 | 0.343284 | 0.249322 | 0.343284 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.571519 | 0.821005 | 0.673913 | 0.821005 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.504396 | 0.757503 | 0.605566 | 0.757503 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.515201 | 0.764306 | 0.615505 | 0.764306 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-28 18:43:48,948 - trainer - INFO] - Train Epoch:[56/100] Step:[10/26] Total Loss: 4.356572 GL_Loss: 0.334111 CRF_Loss: 4.022461\n",
      "[2022-03-28 18:44:12,181 - trainer - INFO] - Train Epoch:[56/100] Step:[20/26] Total Loss: 2.391223 GL_Loss: 0.144397 CRF_Loss: 2.246826\n",
      "[2022-03-28 18:44:37,923 - trainer - INFO] - [Epoch Validation] Epoch:[56/100] Total Loss: 4.312631 GL_Loss: 0.002814 CRF_Loss: 4.031234 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.188034 | 0.328358 | 0.23913  | 0.328358 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.591175 | 0.831963 | 0.691199 | 0.831963 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.525756 | 0.771909 | 0.625486 | 0.771909 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.533022 | 0.774976 | 0.631621 | 0.774976 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 18:45:02,325 - trainer - INFO] - Train Epoch:[57/100] Step:[10/26] Total Loss: 2.497048 GL_Loss: 0.283018 CRF_Loss: 2.214030\n",
      "[2022-03-28 18:45:25,168 - trainer - INFO] - Train Epoch:[57/100] Step:[20/26] Total Loss: 2.282620 GL_Loss: 0.178941 CRF_Loss: 2.103678\n",
      "[2022-03-28 18:45:52,475 - trainer - INFO] - [Epoch Validation] Epoch:[57/100] Total Loss: 3.837208 GL_Loss: 0.002547 CRF_Loss: 3.582467 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.186235 | 0.343284 | 0.24147  | 0.343284 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.561678 | 0.819178 | 0.666419 | 0.819178 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.520066 | 0.762305 | 0.618306 | 0.762305 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.514845 | 0.765276 | 0.615565 | 0.765276 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 18:46:17,252 - trainer - INFO] - Train Epoch:[58/100] Step:[10/26] Total Loss: 5.022474 GL_Loss: 0.153984 CRF_Loss: 4.868490\n",
      "[2022-03-28 18:46:41,061 - trainer - INFO] - Train Epoch:[58/100] Step:[20/26] Total Loss: 1.147547 GL_Loss: 0.158533 CRF_Loss: 0.989014\n",
      "[2022-03-28 18:47:07,031 - trainer - INFO] - [Epoch Validation] Epoch:[58/100] Total Loss: 3.986879 GL_Loss: 0.002266 CRF_Loss: 3.760329 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.171429 | 0.358209 | 0.231884 | 0.358209 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.54209  | 0.829224 | 0.655596 | 0.829224 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.488318 | 0.752701 | 0.592348 | 0.752701 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.488731 | 0.767701 | 0.597246 | 0.767701 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 18:47:32,058 - trainer - INFO] - Train Epoch:[59/100] Step:[10/26] Total Loss: 2.705845 GL_Loss: 0.201531 CRF_Loss: 2.504313\n",
      "[2022-03-28 18:47:55,569 - trainer - INFO] - Train Epoch:[59/100] Step:[20/26] Total Loss: 0.694767 GL_Loss: 0.167179 CRF_Loss: 0.527588\n",
      "[2022-03-28 18:48:22,013 - trainer - INFO] - [Epoch Validation] Epoch:[59/100] Total Loss: 4.762212 GL_Loss: 0.002643 CRF_Loss: 4.497955 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.18251  | 0.358209 | 0.241814 | 0.358209 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.556522 | 0.818265 | 0.662477 | 0.818265 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.4996   | 0.7491   | 0.599424 | 0.7491   |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.502242 | 0.760427 | 0.604938 | 0.760427 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 18:48:45,869 - trainer - INFO] - Train Epoch:[60/100] Step:[10/26] Total Loss: 2.861745 GL_Loss: 0.381521 CRF_Loss: 2.480225\n",
      "[2022-03-28 18:49:08,175 - trainer - INFO] - Train Epoch:[60/100] Step:[20/26] Total Loss: 4.297507 GL_Loss: 0.154847 CRF_Loss: 4.142660\n",
      "[2022-03-28 18:49:35,007 - trainer - INFO] - [Epoch Validation] Epoch:[60/100] Total Loss: 3.644793 GL_Loss: 0.002492 CRF_Loss: 3.395585 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.187251 | 0.350746 | 0.244156 | 0.350746 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.56087  | 0.824658 | 0.667652 | 0.824658 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.505263 | 0.7491   | 0.603482 | 0.7491   |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.508398 | 0.763337 | 0.610314 | 0.763337 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 18:49:37,039 - trainer - INFO] - Saving checkpoint: saved/models/PICK_Default/test_0328_173509/checkpoint-epoch60.pth ...\n",
      "[2022-03-28 18:50:00,412 - trainer - INFO] - Train Epoch:[61/100] Step:[10/26] Total Loss: 4.878963 GL_Loss: 0.173397 CRF_Loss: 4.705566\n",
      "[2022-03-28 18:50:24,556 - trainer - INFO] - Train Epoch:[61/100] Step:[20/26] Total Loss: 3.509996 GL_Loss: 0.380114 CRF_Loss: 3.129883\n",
      "[2022-03-28 18:50:52,365 - trainer - INFO] - [Epoch Validation] Epoch:[61/100] Total Loss: 3.648700 GL_Loss: 0.002655 CRF_Loss: 3.383249 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.200837 | 0.358209 | 0.257373 | 0.358209 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.592787 | 0.825571 | 0.690076 | 0.825571 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.555556 | 0.762305 | 0.642713 | 0.762305 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.545924 | 0.769641 | 0.63876  | 0.769641 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 18:51:16,995 - trainer - INFO] - Train Epoch:[62/100] Step:[10/26] Total Loss: 3.005803 GL_Loss: 0.155339 CRF_Loss: 2.850464\n",
      "[2022-03-28 18:51:38,632 - trainer - INFO] - Train Epoch:[62/100] Step:[20/26] Total Loss: 4.821358 GL_Loss: 0.168037 CRF_Loss: 4.653320\n",
      "[2022-03-28 18:52:05,003 - trainer - INFO] - [Epoch Validation] Epoch:[62/100] Total Loss: 3.373596 GL_Loss: 0.002557 CRF_Loss: 3.117945 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.172161 | 0.350746 | 0.230958 | 0.350746 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.557418 | 0.820091 | 0.66371  | 0.820091 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.507188 | 0.762305 | 0.609113 | 0.762305 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.503827 | 0.766246 | 0.607926 | 0.766246 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 18:52:28,986 - trainer - INFO] - Train Epoch:[63/100] Step:[10/26] Total Loss: 0.892383 GL_Loss: 0.162403 CRF_Loss: 0.729981\n",
      "[2022-03-28 18:52:52,907 - trainer - INFO] - Train Epoch:[63/100] Step:[20/26] Total Loss: 3.497953 GL_Loss: 0.223050 CRF_Loss: 3.274902\n",
      "[2022-03-28 18:53:18,588 - trainer - INFO] - [Epoch Validation] Epoch:[63/100] Total Loss: 3.268195 GL_Loss: 0.002567 CRF_Loss: 3.011477 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.200855 | 0.350746 | 0.255435 | 0.350746 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.598545 | 0.826484 | 0.694285 | 0.826484 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.542284 | 0.746699 | 0.628283 | 0.746699 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.544072 | 0.763337 | 0.635318 | 0.763337 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-28 18:53:41,947 - trainer - INFO] - Train Epoch:[64/100] Step:[10/26] Total Loss: 2.998858 GL_Loss: 0.237506 CRF_Loss: 2.761353\n",
      "[2022-03-28 18:54:05,079 - trainer - INFO] - Train Epoch:[64/100] Step:[20/26] Total Loss: 1.762902 GL_Loss: 0.210941 CRF_Loss: 1.551961\n",
      "[2022-03-28 18:54:32,776 - trainer - INFO] - [Epoch Validation] Epoch:[64/100] Total Loss: 3.777597 GL_Loss: 0.002236 CRF_Loss: 3.554011 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.189922 | 0.365672 | 0.25     | 0.365672 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.589005 | 0.821918 | 0.686237 | 0.821918 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.557811 | 0.758703 | 0.64293  | 0.758703 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.541624 | 0.766731 | 0.634812 | 0.766731 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 18:54:57,366 - trainer - INFO] - Train Epoch:[65/100] Step:[10/26] Total Loss: 2.676452 GL_Loss: 0.313639 CRF_Loss: 2.362813\n",
      "[2022-03-28 18:55:20,884 - trainer - INFO] - Train Epoch:[65/100] Step:[20/26] Total Loss: 2.194578 GL_Loss: 0.410764 CRF_Loss: 1.783813\n",
      "[2022-03-28 18:55:46,765 - trainer - INFO] - [Epoch Validation] Epoch:[65/100] Total Loss: 3.247418 GL_Loss: 0.002470 CRF_Loss: 3.000392 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.175182 | 0.358209 | 0.235294 | 0.358209 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.581691 | 0.835616 | 0.685907 | 0.835616 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.545139 | 0.753902 | 0.632746 | 0.753902 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.53051  | 0.771581 | 0.62873  | 0.771581 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 18:56:10,769 - trainer - INFO] - Train Epoch:[66/100] Step:[10/26] Total Loss: 0.857953 GL_Loss: 0.123822 CRF_Loss: 0.734131\n",
      "[2022-03-28 18:56:35,208 - trainer - INFO] - Train Epoch:[66/100] Step:[20/26] Total Loss: 3.116774 GL_Loss: 0.254876 CRF_Loss: 2.861898\n",
      "[2022-03-28 18:57:01,332 - trainer - INFO] - [Epoch Validation] Epoch:[66/100] Total Loss: 4.997880 GL_Loss: 0.002509 CRF_Loss: 4.747016 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.170909 | 0.350746 | 0.229829 | 0.350746 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.57017  | 0.827397 | 0.675112 | 0.827397 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.536789 | 0.770708 | 0.632824 | 0.770708 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.521242 | 0.773521 | 0.622804 | 0.773521 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 18:57:25,400 - trainer - INFO] - Train Epoch:[67/100] Step:[10/26] Total Loss: 0.811414 GL_Loss: 0.135267 CRF_Loss: 0.676147\n",
      "[2022-03-28 18:57:47,781 - trainer - INFO] - Train Epoch:[67/100] Step:[20/26] Total Loss: 0.782014 GL_Loss: 0.155712 CRF_Loss: 0.626302\n",
      "[2022-03-28 18:58:14,718 - trainer - INFO] - [Epoch Validation] Epoch:[67/100] Total Loss: 3.400640 GL_Loss: 0.002581 CRF_Loss: 3.142580 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.185039 | 0.350746 | 0.242268 | 0.350746 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.560074 | 0.830137 | 0.668874 | 0.830137 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.519672 | 0.761104 | 0.617633 | 0.761104 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.5134   | 0.771096 | 0.616399 | 0.771096 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 18:58:38,398 - trainer - INFO] - Train Epoch:[68/100] Step:[10/26] Total Loss: 3.733725 GL_Loss: 0.361329 CRF_Loss: 3.372396\n",
      "[2022-03-28 18:59:01,868 - trainer - INFO] - Train Epoch:[68/100] Step:[20/26] Total Loss: 2.360430 GL_Loss: 0.286211 CRF_Loss: 2.074219\n",
      "[2022-03-28 18:59:27,627 - trainer - INFO] - [Epoch Validation] Epoch:[68/100] Total Loss: 2.776890 GL_Loss: 0.002314 CRF_Loss: 2.545532 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.173145 | 0.365672 | 0.235012 | 0.365672 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.568408 | 0.834703 | 0.676286 | 0.834703 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.540773 | 0.756303 | 0.630631 | 0.756303 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.52127  | 0.772551 | 0.622509 | 0.772551 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 18:59:52,484 - trainer - INFO] - Train Epoch:[69/100] Step:[10/26] Total Loss: 4.217193 GL_Loss: 0.222075 CRF_Loss: 3.995117\n",
      "[2022-03-28 19:00:15,546 - trainer - INFO] - Train Epoch:[69/100] Step:[20/26] Total Loss: 1.676187 GL_Loss: 0.174437 CRF_Loss: 1.501750\n",
      "[2022-03-28 19:00:41,672 - trainer - INFO] - [Epoch Validation] Epoch:[69/100] Total Loss: 3.658846 GL_Loss: 0.002405 CRF_Loss: 3.418366 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.185328 | 0.358209 | 0.244275 | 0.358209 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.582262 | 0.827397 | 0.683516 | 0.827397 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.542128 | 0.764706 | 0.634462 | 0.764706 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.532107 | 0.771581 | 0.62985  | 0.771581 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 19:01:05,876 - trainer - INFO] - Train Epoch:[70/100] Step:[10/26] Total Loss: 3.261876 GL_Loss: 0.316075 CRF_Loss: 2.945801\n",
      "[2022-03-28 19:01:30,162 - trainer - INFO] - Train Epoch:[70/100] Step:[20/26] Total Loss: 4.613170 GL_Loss: 0.420461 CRF_Loss: 4.192708\n",
      "[2022-03-28 19:01:56,452 - trainer - INFO] - [Epoch Validation] Epoch:[70/100] Total Loss: 3.462757 GL_Loss: 0.002380 CRF_Loss: 3.224773 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.185328 | 0.358209 | 0.244275 | 0.358209 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.5734   | 0.834703 | 0.679807 | 0.834703 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.525021 | 0.768307 | 0.623782 | 0.768307 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.521484 | 0.776916 | 0.624075 | 0.776916 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 19:02:19,927 - trainer - INFO] - Train Epoch:[71/100] Step:[10/26] Total Loss: 3.515201 GL_Loss: 0.369449 CRF_Loss: 3.145752\n",
      "[2022-03-28 19:02:42,191 - trainer - INFO] - Train Epoch:[71/100] Step:[20/26] Total Loss: 4.892787 GL_Loss: 0.201951 CRF_Loss: 4.690836\n",
      "[2022-03-28 19:03:09,606 - trainer - INFO] - [Epoch Validation] Epoch:[71/100] Total Loss: 3.694784 GL_Loss: 0.002481 CRF_Loss: 3.446729 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.177122 | 0.358209 | 0.237037 | 0.358209 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.535928 | 0.817352 | 0.647378 | 0.817352 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.488281 | 0.7503   | 0.591576 | 0.7503   |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.486805 | 0.760427 | 0.593602 | 0.760427 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-28 19:03:33,059 - trainer - INFO] - Train Epoch:[72/100] Step:[10/26] Total Loss: 9.477381 GL_Loss: 0.240157 CRF_Loss: 9.237224\n",
      "[2022-03-28 19:03:55,627 - trainer - INFO] - Train Epoch:[72/100] Step:[20/26] Total Loss: 5.395050 GL_Loss: 0.419789 CRF_Loss: 4.975261\n",
      "[2022-03-28 19:04:23,902 - trainer - INFO] - [Epoch Validation] Epoch:[72/100] Total Loss: 3.799737 GL_Loss: 0.002487 CRF_Loss: 3.551060 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.206751 | 0.365672 | 0.264151 | 0.365672 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.600265 | 0.828311 | 0.696086 | 0.828311 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.560315 | 0.769508 | 0.648457 | 0.769508 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.552213 | 0.774491 | 0.644732 | 0.774491 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 19:04:47,627 - trainer - INFO] - Train Epoch:[73/100] Step:[10/26] Total Loss: 1.916560 GL_Loss: 0.249242 CRF_Loss: 1.667318\n",
      "[2022-03-28 19:05:10,693 - trainer - INFO] - Train Epoch:[73/100] Step:[20/26] Total Loss: 6.588153 GL_Loss: 0.223163 CRF_Loss: 6.364990\n",
      "[2022-03-28 19:05:37,863 - trainer - INFO] - [Epoch Validation] Epoch:[73/100] Total Loss: 3.802490 GL_Loss: 0.002633 CRF_Loss: 3.539160 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.20339  | 0.358209 | 0.259459 | 0.358209 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.566204 | 0.820091 | 0.669899 | 0.820091 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.512841 | 0.767107 | 0.614719 | 0.767107 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.516623 | 0.768671 | 0.617934 | 0.768671 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 19:06:03,380 - trainer - INFO] - Train Epoch:[74/100] Step:[10/26] Total Loss: 2.680200 GL_Loss: 0.248966 CRF_Loss: 2.431234\n",
      "[2022-03-28 19:06:26,205 - trainer - INFO] - Train Epoch:[74/100] Step:[20/26] Total Loss: 4.256763 GL_Loss: 0.330981 CRF_Loss: 3.925781\n",
      "[2022-03-28 19:06:53,299 - trainer - INFO] - [Epoch Validation] Epoch:[74/100] Total Loss: 3.157119 GL_Loss: 0.002629 CRF_Loss: 2.894196 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.191235 | 0.358209 | 0.249351 | 0.358209 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.586495 | 0.832877 | 0.688302 | 0.832877 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.542445 | 0.767107 | 0.635505 | 0.767107 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.535858 | 0.775461 | 0.633769 | 0.775461 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 19:07:18,380 - trainer - INFO] - Train Epoch:[75/100] Step:[10/26] Total Loss: 3.787686 GL_Loss: 0.178880 CRF_Loss: 3.608805\n",
      "[2022-03-28 19:07:41,515 - trainer - INFO] - Train Epoch:[75/100] Step:[20/26] Total Loss: 5.260441 GL_Loss: 0.320256 CRF_Loss: 4.940186\n",
      "[2022-03-28 19:08:08,289 - trainer - INFO] - [Epoch Validation] Epoch:[75/100] Total Loss: 3.858144 GL_Loss: 0.002523 CRF_Loss: 3.605878 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.184211 | 0.365672 | 0.245    | 0.365672 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.568081 | 0.819178 | 0.670905 | 0.819178 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.515028 | 0.761104 | 0.614341 | 0.761104 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.513654 | 0.766246 | 0.615025 | 0.766246 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 19:08:34,416 - trainer - INFO] - Train Epoch:[76/100] Step:[10/26] Total Loss: 7.378173 GL_Loss: 0.146565 CRF_Loss: 7.231608\n",
      "[2022-03-28 19:08:56,846 - trainer - INFO] - Train Epoch:[76/100] Step:[20/26] Total Loss: 2.959359 GL_Loss: 0.154264 CRF_Loss: 2.805094\n",
      "[2022-03-28 19:09:23,963 - trainer - INFO] - [Epoch Validation] Epoch:[76/100] Total Loss: 3.707740 GL_Loss: 0.002283 CRF_Loss: 3.479395 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.185039 | 0.350746 | 0.242268 | 0.350746 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.550091 | 0.827397 | 0.660832 | 0.827397 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.511457 | 0.7503   | 0.608273 | 0.7503   |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.505283 | 0.765276 | 0.608679 | 0.765276 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 19:09:47,409 - trainer - INFO] - Train Epoch:[77/100] Step:[10/26] Total Loss: 2.782288 GL_Loss: 0.272360 CRF_Loss: 2.509928\n",
      "[2022-03-28 19:10:10,517 - trainer - INFO] - Train Epoch:[77/100] Step:[20/26] Total Loss: 0.630315 GL_Loss: 0.101751 CRF_Loss: 0.528564\n",
      "[2022-03-28 19:10:38,035 - trainer - INFO] - [Epoch Validation] Epoch:[77/100] Total Loss: 4.149356 GL_Loss: 0.002305 CRF_Loss: 3.918867 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.204918 | 0.373134 | 0.26455  | 0.373134 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.589877 | 0.830137 | 0.689681 | 0.830137 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.555261 | 0.753902 | 0.639511 | 0.753902 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.544239 | 0.769641 | 0.637605 | 0.769641 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 19:11:01,810 - trainer - INFO] - Train Epoch:[78/100] Step:[10/26] Total Loss: 3.105156 GL_Loss: 0.136731 CRF_Loss: 2.968425\n",
      "[2022-03-28 19:11:25,818 - trainer - INFO] - Train Epoch:[78/100] Step:[20/26] Total Loss: 2.286843 GL_Loss: 0.205219 CRF_Loss: 2.081625\n",
      "[2022-03-28 19:11:52,034 - trainer - INFO] - [Epoch Validation] Epoch:[78/100] Total Loss: 4.158001 GL_Loss: 0.002159 CRF_Loss: 3.942139 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.181467 | 0.350746 | 0.239186 | 0.350746 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.585462 | 0.816438 | 0.681922 | 0.816438 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.553726 | 0.767107 | 0.643181 | 0.767107 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.537415 | 0.766246 | 0.631747 | 0.766246 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 19:12:16,719 - trainer - INFO] - Train Epoch:[79/100] Step:[10/26] Total Loss: 2.932524 GL_Loss: 0.211170 CRF_Loss: 2.721354\n",
      "[2022-03-28 19:12:40,673 - trainer - INFO] - Train Epoch:[79/100] Step:[20/26] Total Loss: 1.983615 GL_Loss: 0.273288 CRF_Loss: 1.710327\n",
      "[2022-03-28 19:13:06,703 - trainer - INFO] - [Epoch Validation] Epoch:[79/100] Total Loss: 3.799338 GL_Loss: 0.002268 CRF_Loss: 3.572579 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.181467 | 0.350746 | 0.239186 | 0.350746 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.587055 | 0.828311 | 0.687121 | 0.828311 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.561668 | 0.759904 | 0.645918 | 0.759904 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.541453 | 0.769641 | 0.63569  | 0.769641 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-28 19:13:29,729 - trainer - INFO] - Train Epoch:[80/100] Step:[10/26] Total Loss: 2.100111 GL_Loss: 0.159925 CRF_Loss: 1.940186\n",
      "[2022-03-28 19:13:53,625 - trainer - INFO] - Train Epoch:[80/100] Step:[20/26] Total Loss: 1.875726 GL_Loss: 0.162754 CRF_Loss: 1.712972\n",
      "[2022-03-28 19:14:20,276 - trainer - INFO] - [Epoch Validation] Epoch:[80/100] Total Loss: 4.527177 GL_Loss: 0.002283 CRF_Loss: 4.298910 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.177358 | 0.350746 | 0.235589 | 0.350746 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.577763 | 0.821005 | 0.678235 | 0.821005 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.559028 | 0.773109 | 0.648866 | 0.773109 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.534813 | 0.771096 | 0.631579 | 0.771096 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 19:14:22,357 - trainer - INFO] - Saving checkpoint: saved/models/PICK_Default/test_0328_173509/checkpoint-epoch80.pth ...\n",
      "[2022-03-28 19:14:47,764 - trainer - INFO] - Train Epoch:[81/100] Step:[10/26] Total Loss: 1.113721 GL_Loss: 0.225904 CRF_Loss: 0.887817\n",
      "[2022-03-28 19:15:09,788 - trainer - INFO] - Train Epoch:[81/100] Step:[20/26] Total Loss: 2.289543 GL_Loss: 0.494295 CRF_Loss: 1.795248\n",
      "[2022-03-28 19:15:36,892 - trainer - INFO] - [Epoch Validation] Epoch:[81/100] Total Loss: 3.931508 GL_Loss: 0.002908 CRF_Loss: 3.640745 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.177778 | 0.358209 | 0.237624 | 0.358209 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.544288 | 0.813699 | 0.652269 | 0.813699 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.479119 | 0.757503 | 0.586977 | 0.757503 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.486973 | 0.761397 | 0.594022 | 0.761397 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 19:16:01,557 - trainer - INFO] - Train Epoch:[82/100] Step:[10/26] Total Loss: 1.847916 GL_Loss: 0.374283 CRF_Loss: 1.473633\n",
      "[2022-03-28 19:16:24,333 - trainer - INFO] - Train Epoch:[82/100] Step:[20/26] Total Loss: 2.228460 GL_Loss: 0.162786 CRF_Loss: 2.065674\n",
      "[2022-03-28 19:16:51,390 - trainer - INFO] - [Epoch Validation] Epoch:[82/100] Total Loss: 3.721847 GL_Loss: 0.002567 CRF_Loss: 3.465112 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.192    | 0.358209 | 0.25     | 0.358209 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.551553 | 0.810959 | 0.656562 | 0.810959 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.504425 | 0.752701 | 0.604046 | 0.752701 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.503706 | 0.758002 | 0.605227 | 0.758002 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 19:17:16,301 - trainer - INFO] - Train Epoch:[83/100] Step:[10/26] Total Loss: 2.518708 GL_Loss: 0.161855 CRF_Loss: 2.356852\n",
      "[2022-03-28 19:17:39,606 - trainer - INFO] - Train Epoch:[83/100] Step:[20/26] Total Loss: 1.149656 GL_Loss: 0.176796 CRF_Loss: 0.972860\n",
      "[2022-03-28 19:18:07,087 - trainer - INFO] - [Epoch Validation] Epoch:[83/100] Total Loss: 3.522850 GL_Loss: 0.002451 CRF_Loss: 3.277726 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.172535 | 0.365672 | 0.23445  | 0.365672 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.573171 | 0.815525 | 0.6732   | 0.815525 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.554783 | 0.765906 | 0.643469 | 0.765906 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.528075 | 0.766246 | 0.625247 | 0.766246 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 19:18:31,266 - trainer - INFO] - Train Epoch:[84/100] Step:[10/26] Total Loss: 1.444059 GL_Loss: 0.194731 CRF_Loss: 1.249329\n",
      "[2022-03-28 19:18:55,927 - trainer - INFO] - Train Epoch:[84/100] Step:[20/26] Total Loss: 2.038626 GL_Loss: 0.122610 CRF_Loss: 1.916016\n",
      "[2022-03-28 19:19:21,482 - trainer - INFO] - [Epoch Validation] Epoch:[84/100] Total Loss: 4.622087 GL_Loss: 0.002486 CRF_Loss: 4.373465 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.176895 | 0.365672 | 0.238443 | 0.365672 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.528647 | 0.817352 | 0.642037 | 0.817352 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.475684 | 0.751501 | 0.582597 | 0.751501 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.477785 | 0.761397 | 0.587135 | 0.761397 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 19:19:45,926 - trainer - INFO] - Train Epoch:[85/100] Step:[10/26] Total Loss: 2.359425 GL_Loss: 0.141814 CRF_Loss: 2.217611\n",
      "[2022-03-28 19:20:09,451 - trainer - INFO] - Train Epoch:[85/100] Step:[20/26] Total Loss: 4.501364 GL_Loss: 0.155010 CRF_Loss: 4.346354\n",
      "[2022-03-28 19:20:35,533 - trainer - INFO] - [Epoch Validation] Epoch:[85/100] Total Loss: 3.047460 GL_Loss: 0.002261 CRF_Loss: 2.821373 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.16609  | 0.358209 | 0.22695  | 0.358209 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.574226 | 0.830137 | 0.678865 | 0.830137 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.575592 | 0.758703 | 0.654583 | 0.758703 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.535017 | 0.770611 | 0.631558 | 0.770611 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 19:20:58,297 - trainer - INFO] - Train Epoch:[86/100] Step:[10/26] Total Loss: 2.914371 GL_Loss: 0.241682 CRF_Loss: 2.672689\n",
      "[2022-03-28 19:21:22,453 - trainer - INFO] - Train Epoch:[86/100] Step:[20/26] Total Loss: 4.416623 GL_Loss: 0.240678 CRF_Loss: 4.175944\n",
      "[2022-03-28 19:21:50,373 - trainer - INFO] - [Epoch Validation] Epoch:[86/100] Total Loss: 3.559002 GL_Loss: 0.002287 CRF_Loss: 3.330302 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.172794 | 0.350746 | 0.231527 | 0.350746 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.578005 | 0.825571 | 0.679955 | 0.825571 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.56222  | 0.753902 | 0.644103 | 0.753902 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.53471  | 0.765761 | 0.629711 | 0.765761 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 19:22:14,989 - trainer - INFO] - Train Epoch:[87/100] Step:[10/26] Total Loss: 1.652230 GL_Loss: 0.408821 CRF_Loss: 1.243408\n",
      "[2022-03-28 19:22:39,936 - trainer - INFO] - Train Epoch:[87/100] Step:[20/26] Total Loss: 5.117706 GL_Loss: 0.245473 CRF_Loss: 4.872233\n",
      "[2022-03-28 19:23:06,605 - trainer - INFO] - [Epoch Validation] Epoch:[87/100] Total Loss: 3.554222 GL_Loss: 0.002217 CRF_Loss: 3.332491 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.203463 | 0.350746 | 0.257534 | 0.350746 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.581666 | 0.822831 | 0.681543 | 0.822831 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.532718 | 0.762305 | 0.62716  | 0.762305 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.532638 | 0.767701 | 0.628923 | 0.767701 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-28 19:23:31,935 - trainer - INFO] - Train Epoch:[88/100] Step:[10/26] Total Loss: 5.184273 GL_Loss: 0.302600 CRF_Loss: 4.881673\n",
      "[2022-03-28 19:23:54,374 - trainer - INFO] - Train Epoch:[88/100] Step:[20/26] Total Loss: 1.307873 GL_Loss: 0.149751 CRF_Loss: 1.158122\n",
      "[2022-03-28 19:24:20,484 - trainer - INFO] - [Epoch Validation] Epoch:[88/100] Total Loss: 3.810188 GL_Loss: 0.002866 CRF_Loss: 3.523563 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.175824 | 0.358209 | 0.235872 | 0.358209 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.573604 | 0.825571 | 0.6769   | 0.825571 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.524917 | 0.758703 | 0.62052  | 0.758703 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.518834 | 0.768186 | 0.619355 | 0.768186 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 19:24:45,672 - trainer - INFO] - Train Epoch:[89/100] Step:[10/26] Total Loss: 6.083620 GL_Loss: 0.197878 CRF_Loss: 5.885743\n",
      "[2022-03-28 19:25:08,608 - trainer - INFO] - Train Epoch:[89/100] Step:[20/26] Total Loss: 1.710312 GL_Loss: 0.232447 CRF_Loss: 1.477865\n",
      "[2022-03-28 19:25:35,094 - trainer - INFO] - [Epoch Validation] Epoch:[89/100] Total Loss: 3.229303 GL_Loss: 0.002457 CRF_Loss: 2.983575 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.179775 | 0.358209 | 0.239401 | 0.358209 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.564103 | 0.823744 | 0.669636 | 0.823744 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.53104  | 0.759904 | 0.625185 | 0.759904 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.517659 | 0.767701 | 0.618359 | 0.767701 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 19:26:00,561 - trainer - INFO] - Train Epoch:[90/100] Step:[10/26] Total Loss: 2.583989 GL_Loss: 0.385584 CRF_Loss: 2.198405\n",
      "[2022-03-28 19:26:23,136 - trainer - INFO] - Train Epoch:[90/100] Step:[20/26] Total Loss: 2.316704 GL_Loss: 0.550225 CRF_Loss: 1.766479\n",
      "[2022-03-28 19:26:49,672 - trainer - INFO] - [Epoch Validation] Epoch:[90/100] Total Loss: 4.014411 GL_Loss: 0.002916 CRF_Loss: 3.722773 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.181481 | 0.365672 | 0.242574 | 0.365672 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.553903 | 0.816438 | 0.660022 | 0.816438 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.501587 | 0.758703 | 0.603918 | 0.758703 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.500954 | 0.763822 | 0.605071 | 0.763822 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 19:27:16,198 - trainer - INFO] - Train Epoch:[91/100] Step:[10/26] Total Loss: 10.029796 GL_Loss: 0.234386 CRF_Loss: 9.795410\n",
      "[2022-03-28 19:27:38,509 - trainer - INFO] - Train Epoch:[91/100] Step:[20/26] Total Loss: 3.793304 GL_Loss: 0.247812 CRF_Loss: 3.545492\n",
      "[2022-03-28 19:28:05,777 - trainer - INFO] - [Epoch Validation] Epoch:[91/100] Total Loss: 3.388750 GL_Loss: 0.002240 CRF_Loss: 3.164781 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.188235 | 0.358209 | 0.246787 | 0.358209 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.565848 | 0.820091 | 0.66965  | 0.820091 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.536585 | 0.765906 | 0.631058 | 0.765906 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.5226   | 0.768186 | 0.62203  | 0.768186 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 19:28:29,862 - trainer - INFO] - Train Epoch:[92/100] Step:[10/26] Total Loss: 8.027766 GL_Loss: 0.205826 CRF_Loss: 7.821940\n",
      "[2022-03-28 19:28:52,567 - trainer - INFO] - Train Epoch:[92/100] Step:[20/26] Total Loss: 4.534698 GL_Loss: 0.294057 CRF_Loss: 4.240642\n",
      "[2022-03-28 19:29:18,790 - trainer - INFO] - [Epoch Validation] Epoch:[92/100] Total Loss: 3.959258 GL_Loss: 0.002303 CRF_Loss: 3.728935 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.200837 | 0.358209 | 0.257373 | 0.358209 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.571156 | 0.821005 | 0.673661 | 0.821005 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.514563 | 0.763505 | 0.61479  | 0.763505 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.519187 | 0.767701 | 0.619448 | 0.767701 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 19:29:42,535 - trainer - INFO] - Train Epoch:[93/100] Step:[10/26] Total Loss: 3.761859 GL_Loss: 0.239317 CRF_Loss: 3.522542\n",
      "[2022-03-28 19:30:06,192 - trainer - INFO] - Train Epoch:[93/100] Step:[20/26] Total Loss: 1.113850 GL_Loss: 0.258951 CRF_Loss: 0.854899\n",
      "[2022-03-28 19:30:32,967 - trainer - INFO] - [Epoch Validation] Epoch:[93/100] Total Loss: 3.387264 GL_Loss: 0.002244 CRF_Loss: 3.162826 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.177122 | 0.358209 | 0.237037 | 0.358209 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.541191 | 0.821918 | 0.652647 | 0.821918 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.504019 | 0.752701 | 0.603755 | 0.752701 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.495595 | 0.763822 | 0.601145 | 0.763822 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 19:30:57,125 - trainer - INFO] - Train Epoch:[94/100] Step:[10/26] Total Loss: 1.624022 GL_Loss: 0.400226 CRF_Loss: 1.223796\n",
      "[2022-03-28 19:31:20,624 - trainer - INFO] - Train Epoch:[94/100] Step:[20/26] Total Loss: 3.989149 GL_Loss: 0.454725 CRF_Loss: 3.534424\n",
      "[2022-03-28 19:31:47,876 - trainer - INFO] - [Epoch Validation] Epoch:[94/100] Total Loss: 3.729661 GL_Loss: 0.002593 CRF_Loss: 3.470351 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.198381 | 0.365672 | 0.257218 | 0.365672 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.557538 | 0.827397 | 0.666176 | 0.827397 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.524441 | 0.759904 | 0.620588 | 0.759904 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.515752 | 0.770126 | 0.617779 | 0.770126 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 19:32:12,368 - trainer - INFO] - Train Epoch:[95/100] Step:[10/26] Total Loss: 1.704241 GL_Loss: 0.235002 CRF_Loss: 1.469238\n",
      "[2022-03-28 19:32:36,027 - trainer - INFO] - Train Epoch:[95/100] Step:[20/26] Total Loss: 10.855442 GL_Loss: 0.271538 CRF_Loss: 10.583903\n",
      "[2022-03-28 19:33:03,054 - trainer - INFO] - [Epoch Validation] Epoch:[95/100] Total Loss: 5.412800 GL_Loss: 0.002485 CRF_Loss: 5.164261 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.192469 | 0.343284 | 0.246649 | 0.343284 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.560794 | 0.825571 | 0.667898 | 0.825571 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.507974 | 0.764706 | 0.610446 | 0.764706 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.511111 | 0.769641 | 0.614283 | 0.769641 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-28 19:33:26,747 - trainer - INFO] - Train Epoch:[96/100] Step:[10/26] Total Loss: 0.744357 GL_Loss: 0.140027 CRF_Loss: 0.604329\n",
      "[2022-03-28 19:33:50,279 - trainer - INFO] - Train Epoch:[96/100] Step:[20/26] Total Loss: 9.880262 GL_Loss: 0.282362 CRF_Loss: 9.597900\n",
      "[2022-03-28 19:34:16,987 - trainer - INFO] - [Epoch Validation] Epoch:[96/100] Total Loss: 3.756492 GL_Loss: 0.002490 CRF_Loss: 3.507511 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.181467 | 0.350746 | 0.239186 | 0.350746 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.601316 | 0.834703 | 0.699044 | 0.834703 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.581869 | 0.755102 | 0.657262 | 0.755102 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.555944 | 0.771096 | 0.646079 | 0.771096 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 19:34:42,467 - trainer - INFO] - Train Epoch:[97/100] Step:[10/26] Total Loss: 11.650650 GL_Loss: 0.412612 CRF_Loss: 11.238038\n",
      "[2022-03-28 19:35:05,223 - trainer - INFO] - Train Epoch:[97/100] Step:[20/26] Total Loss: 2.111384 GL_Loss: 0.160130 CRF_Loss: 1.951253\n",
      "[2022-03-28 19:35:31,214 - trainer - INFO] - [Epoch Validation] Epoch:[97/100] Total Loss: 3.168913 GL_Loss: 0.002709 CRF_Loss: 2.898017 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.164948 | 0.358209 | 0.225882 | 0.358209 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.545565 | 0.820091 | 0.655235 | 0.820091 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.535714 | 0.756303 | 0.627178 | 0.756303 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.506264 | 0.764306 | 0.609082 | 0.764306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 19:35:56,738 - trainer - INFO] - Train Epoch:[98/100] Step:[10/26] Total Loss: 0.918806 GL_Loss: 0.142845 CRF_Loss: 0.775960\n",
      "[2022-03-28 19:36:20,269 - trainer - INFO] - Train Epoch:[98/100] Step:[20/26] Total Loss: 3.960560 GL_Loss: 0.268909 CRF_Loss: 3.691651\n",
      "[2022-03-28 19:36:47,473 - trainer - INFO] - [Epoch Validation] Epoch:[98/100] Total Loss: 3.532614 GL_Loss: 0.002297 CRF_Loss: 3.302958 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.190476 | 0.358209 | 0.248705 | 0.358209 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.561713 | 0.814612 | 0.664927 | 0.814612 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.524752 | 0.763505 | 0.622005 | 0.763505 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.516383 | 0.764306 | 0.616347 | 0.764306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 19:37:12,483 - trainer - INFO] - Train Epoch:[99/100] Step:[10/26] Total Loss: 2.241795 GL_Loss: 0.229099 CRF_Loss: 2.012695\n",
      "[2022-03-28 19:37:35,312 - trainer - INFO] - Train Epoch:[99/100] Step:[20/26] Total Loss: 0.826111 GL_Loss: 0.244893 CRF_Loss: 0.581217\n",
      "[2022-03-28 19:38:02,075 - trainer - INFO] - [Epoch Validation] Epoch:[99/100] Total Loss: 3.920463 GL_Loss: 0.002360 CRF_Loss: 3.684492 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.212121 | 0.365672 | 0.268493 | 0.365672 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.579183 | 0.828311 | 0.681699 | 0.828311 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.528716 | 0.751501 | 0.620724 | 0.751501 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.530694 | 0.767216 | 0.627404 | 0.767216 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 19:38:26,575 - trainer - INFO] - Train Epoch:[100/100] Step:[10/26] Total Loss: 2.658175 GL_Loss: 0.355847 CRF_Loss: 2.302328\n",
      "[2022-03-28 19:38:50,379 - trainer - INFO] - Train Epoch:[100/100] Step:[20/26] Total Loss: 1.983590 GL_Loss: 0.238798 CRF_Loss: 1.744792\n",
      "[2022-03-28 19:39:16,569 - trainer - INFO] - [Epoch Validation] Epoch:[100/100] Total Loss: 3.735386 GL_Loss: 0.002657 CRF_Loss: 3.469670 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| header  | 0.196721 | 0.358209 | 0.253968 | 0.358209 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| keys    | 0.576531 | 0.825571 | 0.678934 | 0.825571 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.539642 | 0.759904 | 0.631107 | 0.759904 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.530988 | 0.768671 | 0.628096 | 0.768671 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-28 19:39:18,651 - trainer - INFO] - Saving checkpoint: saved/models/PICK_Default/test_0328_173509/checkpoint-epoch100.pth ...\n",
      "[2022-03-28 19:39:18,652 - train - INFO] - Training end...\n"
     ]
    }
   ],
   "source": [
    "!python3 -m torch.distributed.launch --nnodes=1 --node_rank=0 --nproc_per_node=3 --master_addr=127.0.0.1 --master_port=5555 \\\n",
    "train.py -c config_funsd.json --distributed true --local_world_size 3\n",
    "  # --resume /content/PICK-pytorch/saved/models/PICK_Default/test_0917_074722/model_best.pth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-02 12:58:36,484 - train - INFO] - One GPU or CPU training mode start...\n",
      "[2022-03-02 12:58:36,488 - train - INFO] - Dataloader instances created. Train datasets: 80 samples Validation datasets: 30 samples.\n",
      "[2022-03-02 12:58:37,236 - train - INFO] - Model created, trainable parameters: 75937502.\n",
      "[2022-03-02 12:58:37,237 - train - INFO] - Optimizer and lr_scheduler created.\n",
      "[2022-03-02 12:58:37,237 - train - INFO] - Max_epochs: 100 Log_per_step: 10 Validation_per_step: 50.\n",
      "[2022-03-02 12:58:37,237 - train - INFO] - Training start...\n",
      "[2022-03-02 12:58:37,270 - trainer - WARNING] - Training is using GPU 0!\n",
      "[2022-03-02 12:59:23,928 - trainer - INFO] - Train Epoch:[1/100] Step:[10/40] Total Loss: 2357.284180 GL_Loss: 0.951680 CRF_Loss: 2356.332520\n",
      "[2022-03-02 13:00:06,320 - trainer - INFO] - Train Epoch:[1/100] Step:[20/40] Total Loss: 2458.539795 GL_Loss: 0.387532 CRF_Loss: 2458.152344\n",
      "[2022-03-02 13:00:48,328 - trainer - INFO] - Train Epoch:[1/100] Step:[30/40] Total Loss: 2181.004150 GL_Loss: 0.240448 CRF_Loss: 2180.763672\n",
      "[2022-03-02 13:01:30,759 - trainer - INFO] - Train Epoch:[1/100] Step:[40/40] Total Loss: 2274.857422 GL_Loss: 0.798279 CRF_Loss: 2274.059082\n",
      "[2022-03-02 13:01:46,709 - trainer - INFO] - [Epoch Validation] Epoch:[1/100] Total Loss: 3089.024384 GL_Loss: 0.016836 CRF_Loss: 3087.340790 \n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| name                          |   mEP |   mER |   mEF |   mEA |\n",
      "+===============================+=======+=======+=======+=======+\n",
      "| address_2                     |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| curriculum_vitae              |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| zip_code                      |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| country                       |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| name_of_clinical_laboratory   |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| name_of_clinical_investigator |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| names_of_subinvestigators     |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| name_of_irb                   |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| address_1                     |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| city                          |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| name_of_medical_school        |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| state                         |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| other_statement               |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| overall                       |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "[2022-03-02 13:02:28,622 - trainer - INFO] - Train Epoch:[2/100] Step:[10/40] Total Loss: 2137.911377 GL_Loss: 0.203931 CRF_Loss: 2137.707520\n",
      "[2022-03-02 13:03:10,159 - trainer - INFO] - Train Epoch:[2/100] Step:[20/40] Total Loss: 2112.865479 GL_Loss: 0.217634 CRF_Loss: 2112.647949\n",
      "[2022-03-02 13:03:52,128 - trainer - INFO] - Train Epoch:[2/100] Step:[30/40] Total Loss: 2267.190186 GL_Loss: 0.350358 CRF_Loss: 2266.839844\n",
      "[2022-03-02 13:04:34,803 - trainer - INFO] - Train Epoch:[2/100] Step:[40/40] Total Loss: 2276.940674 GL_Loss: 0.267421 CRF_Loss: 2276.673340\n",
      "[2022-03-02 13:04:50,090 - trainer - INFO] - [Epoch Validation] Epoch:[2/100] Total Loss: 2237.935831 GL_Loss: 0.003409 CRF_Loss: 2237.594922 \n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| name                          |   mEP |   mER |   mEF |   mEA |\n",
      "+===============================+=======+=======+=======+=======+\n",
      "| address_2                     |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| curriculum_vitae              |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| zip_code                      |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| country                       |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| name_of_clinical_laboratory   |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| name_of_clinical_investigator |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| names_of_subinvestigators     |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| name_of_irb                   |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| address_1                     |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| city                          |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| name_of_medical_school        |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| state                         |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| other_statement               |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| overall                       |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "[2022-03-02 13:05:32,501 - trainer - INFO] - Train Epoch:[3/100] Step:[10/40] Total Loss: 2232.852783 GL_Loss: 0.357156 CRF_Loss: 2232.495605\n",
      "[2022-03-02 13:06:14,954 - trainer - INFO] - Train Epoch:[3/100] Step:[20/40] Total Loss: 2505.408203 GL_Loss: 0.285137 CRF_Loss: 2505.123047\n",
      "[2022-03-02 13:06:56,516 - trainer - INFO] - Train Epoch:[3/100] Step:[30/40] Total Loss: 2070.113281 GL_Loss: 0.268494 CRF_Loss: 2069.844727\n",
      "[2022-03-02 13:07:38,825 - trainer - INFO] - Train Epoch:[3/100] Step:[40/40] Total Loss: 2258.070801 GL_Loss: 0.303287 CRF_Loss: 2257.767578\n",
      "[2022-03-02 13:07:54,328 - trainer - INFO] - [Epoch Validation] Epoch:[3/100] Total Loss: 2226.083469 GL_Loss: 0.003022 CRF_Loss: 2225.781262 \n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| name                          |   mEP |   mER |   mEF |   mEA |\n",
      "+===============================+=======+=======+=======+=======+\n",
      "| address_2                     |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| curriculum_vitae              |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| zip_code                      |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| country                       |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| name_of_clinical_laboratory   |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| name_of_clinical_investigator |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| names_of_subinvestigators     |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| name_of_irb                   |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| address_1                     |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| city                          |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| name_of_medical_school        |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| state                         |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| other_statement               |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| overall                       |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-02 13:08:36,853 - trainer - INFO] - Train Epoch:[4/100] Step:[10/40] Total Loss: 2473.778076 GL_Loss: 0.402962 CRF_Loss: 2473.375000\n",
      "[2022-03-02 13:09:19,101 - trainer - INFO] - Train Epoch:[4/100] Step:[20/40] Total Loss: 2257.178467 GL_Loss: 0.308823 CRF_Loss: 2256.869629\n",
      "[2022-03-02 13:10:01,609 - trainer - INFO] - Train Epoch:[4/100] Step:[30/40] Total Loss: 2199.203613 GL_Loss: 0.668900 CRF_Loss: 2198.534668\n",
      "[2022-03-02 13:10:43,694 - trainer - INFO] - Train Epoch:[4/100] Step:[40/40] Total Loss: 1975.975342 GL_Loss: 0.420125 CRF_Loss: 1975.555176\n",
      "[2022-03-02 13:10:59,178 - trainer - INFO] - [Epoch Validation] Epoch:[4/100] Total Loss: 2202.534448 GL_Loss: 0.003667 CRF_Loss: 2202.167700 \n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| name                          |   mEP |   mER |   mEF |   mEA |\n",
      "+===============================+=======+=======+=======+=======+\n",
      "| address_2                     |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| curriculum_vitae              |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| zip_code                      |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| country                       |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| name_of_clinical_laboratory   |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| name_of_clinical_investigator |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| names_of_subinvestigators     |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| name_of_irb                   |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| address_1                     |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| city                          |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| name_of_medical_school        |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| state                         |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| other_statement               |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| overall                       |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "[2022-03-02 13:11:41,607 - trainer - INFO] - Train Epoch:[5/100] Step:[10/40] Total Loss: 1721.142212 GL_Loss: 2.694928 CRF_Loss: 1718.447266\n",
      "[2022-03-02 13:12:23,629 - trainer - INFO] - Train Epoch:[5/100] Step:[20/40] Total Loss: 1750.270752 GL_Loss: 3.164299 CRF_Loss: 1747.106445\n",
      "[2022-03-02 13:13:05,789 - trainer - INFO] - Train Epoch:[5/100] Step:[30/40] Total Loss: 1403.200684 GL_Loss: 1.835501 CRF_Loss: 1401.365234\n",
      "[2022-03-02 13:13:47,967 - trainer - INFO] - Train Epoch:[5/100] Step:[40/40] Total Loss: 1184.228027 GL_Loss: 1.222112 CRF_Loss: 1183.005859\n",
      "[2022-03-02 13:14:03,379 - trainer - INFO] - [Epoch Validation] Epoch:[5/100] Total Loss: 1646.187943 GL_Loss: 0.022409 CRF_Loss: 1643.947046 \n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| name                          |   mEP |   mER |   mEF |   mEA |\n",
      "+===============================+=======+=======+=======+=======+\n",
      "| name_of_irb                   |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| address_2                     |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| zip_code                      |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| country                       |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| name_of_clinical_laboratory   |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| name_of_clinical_investigator |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| curriculum_vitae              |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| names_of_subinvestigators     |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| address_1                     |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| city                          |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| name_of_medical_school        |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| state                         |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| other_statement               |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "| overall                       |     0 |     0 |     0 |     0 |\n",
      "+-------------------------------+-------+-------+-------+-------+\n",
      "[2022-03-02 13:14:45,535 - trainer - INFO] - Train Epoch:[6/100] Step:[10/40] Total Loss: 1307.293335 GL_Loss: 11.019888 CRF_Loss: 1296.273438\n",
      "[2022-03-02 13:15:27,360 - trainer - INFO] - Train Epoch:[6/100] Step:[20/40] Total Loss: 1079.928101 GL_Loss: 1.896855 CRF_Loss: 1078.031250\n",
      "[2022-03-02 13:16:09,263 - trainer - INFO] - Train Epoch:[6/100] Step:[30/40] Total Loss: 1155.213623 GL_Loss: 1.510485 CRF_Loss: 1153.703125\n",
      "[2022-03-02 13:16:50,862 - trainer - INFO] - Train Epoch:[6/100] Step:[40/40] Total Loss: 813.627502 GL_Loss: 3.165570 CRF_Loss: 810.461914\n",
      "[2022-03-02 13:17:06,143 - trainer - INFO] - [Epoch Validation] Epoch:[6/100] Total Loss: 1120.108813 GL_Loss: 0.033588 CRF_Loss: 1116.749976 \n",
      "+-------------------------------+------------+-----------+-----------+-----------+\n",
      "| name                          |        mEP |       mER |       mEF |       mEA |\n",
      "+===============================+============+===========+===========+===========+\n",
      "| curriculum_vitae              | 0          | 0         | 0         | 0         |\n",
      "+-------------------------------+------------+-----------+-----------+-----------+\n",
      "| name_of_irb                   | 0          | 0         | 0         | 0         |\n",
      "+-------------------------------+------------+-----------+-----------+-----------+\n",
      "| zip_code                      | 0          | 0         | 0         | 0         |\n",
      "+-------------------------------+------------+-----------+-----------+-----------+\n",
      "| country                       | 0          | 0         | 0         | 0         |\n",
      "+-------------------------------+------------+-----------+-----------+-----------+\n",
      "| names_of_subinvestigators     | 0          | 0         | 0         | 0         |\n",
      "+-------------------------------+------------+-----------+-----------+-----------+\n",
      "| address_2                     | 0          | 0         | 0         | 0         |\n",
      "+-------------------------------+------------+-----------+-----------+-----------+\n",
      "| name_of_clinical_laboratory   | 0          | 0         | 0         | 0         |\n",
      "+-------------------------------+------------+-----------+-----------+-----------+\n",
      "| name_of_clinical_investigator | 0          | 0         | 0         | 0         |\n",
      "+-------------------------------+------------+-----------+-----------+-----------+\n",
      "| address_1                     | 0.03125    | 0.190476  | 0.0536913 | 0.190476  |\n",
      "+-------------------------------+------------+-----------+-----------+-----------+\n",
      "| city                          | 0          | 0         | 0         | 0         |\n",
      "+-------------------------------+------------+-----------+-----------+-----------+\n",
      "| name_of_medical_school        | 0          | 0         | 0         | 0         |\n",
      "+-------------------------------+------------+-----------+-----------+-----------+\n",
      "| state                         | 0          | 0         | 0         | 0         |\n",
      "+-------------------------------+------------+-----------+-----------+-----------+\n",
      "| other_statement               | 0          | 0         | 0         | 0         |\n",
      "+-------------------------------+------------+-----------+-----------+-----------+\n",
      "| overall                       | 0.00644122 | 0.0272109 | 0.0104167 | 0.0272109 |\n",
      "+-------------------------------+------------+-----------+-----------+-----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-02 13:17:48,309 - trainer - INFO] - Train Epoch:[7/100] Step:[10/40] Total Loss: 853.194519 GL_Loss: 1.850793 CRF_Loss: 851.343750\n",
      "[2022-03-02 13:18:30,246 - trainer - INFO] - Train Epoch:[7/100] Step:[20/40] Total Loss: 1180.147705 GL_Loss: 22.054902 CRF_Loss: 1158.092773\n",
      "[2022-03-02 13:19:12,686 - trainer - INFO] - Train Epoch:[7/100] Step:[30/40] Total Loss: 797.173584 GL_Loss: 1.755592 CRF_Loss: 795.417969\n",
      "[2022-03-02 13:19:54,773 - trainer - INFO] - Train Epoch:[7/100] Step:[40/40] Total Loss: 578.421692 GL_Loss: 1.266422 CRF_Loss: 577.155273\n",
      "[2022-03-02 13:20:10,340 - trainer - INFO] - [Epoch Validation] Epoch:[7/100] Total Loss: 728.963883 GL_Loss: 0.059733 CRF_Loss: 722.990552 \n",
      "+-------------------------------+-----------+-----------+-----------+-----------+\n",
      "| name                          |       mEP |       mER |       mEF |       mEA |\n",
      "+===============================+===========+===========+===========+===========+\n",
      "| name_of_irb                   | 0.2       | 0.2       | 0.2       | 0.2       |\n",
      "+-------------------------------+-----------+-----------+-----------+-----------+\n",
      "| curriculum_vitae              | 0         | 0         | 0         | 0         |\n",
      "+-------------------------------+-----------+-----------+-----------+-----------+\n",
      "| zip_code                      | 0         | 0         | 0         | 0         |\n",
      "+-------------------------------+-----------+-----------+-----------+-----------+\n",
      "| country                       | 0.0909091 | 0.1       | 0.0952381 | 0.1       |\n",
      "+-------------------------------+-----------+-----------+-----------+-----------+\n",
      "| address_2                     | 0         | 0         | 0         | 0         |\n",
      "+-------------------------------+-----------+-----------+-----------+-----------+\n",
      "| name_of_clinical_investigator | 0.4       | 0.4       | 0.4       | 0.4       |\n",
      "+-------------------------------+-----------+-----------+-----------+-----------+\n",
      "| name_of_clinical_laboratory   | 0         | 0         | 0         | 0         |\n",
      "+-------------------------------+-----------+-----------+-----------+-----------+\n",
      "| names_of_subinvestigators     | 0         | 0         | 0         | 0         |\n",
      "+-------------------------------+-----------+-----------+-----------+-----------+\n",
      "| address_1                     | 0.0961538 | 0.238095  | 0.136986  | 0.238095  |\n",
      "+-------------------------------+-----------+-----------+-----------+-----------+\n",
      "| city                          | 0         | 0         | 0         | 0         |\n",
      "+-------------------------------+-----------+-----------+-----------+-----------+\n",
      "| name_of_medical_school        | 0.666667  | 0.8       | 0.727273  | 0.8       |\n",
      "+-------------------------------+-----------+-----------+-----------+-----------+\n",
      "| state                         | 0         | 0         | 0         | 0         |\n",
      "+-------------------------------+-----------+-----------+-----------+-----------+\n",
      "| other_statement               | 0         | 0         | 0         | 0         |\n",
      "+-------------------------------+-----------+-----------+-----------+-----------+\n",
      "| overall                       | 0.0327103 | 0.0952381 | 0.0486957 | 0.0952381 |\n",
      "+-------------------------------+-----------+-----------+-----------+-----------+\n",
      "[2022-03-02 13:20:52,581 - trainer - INFO] - Train Epoch:[8/100] Step:[10/40] Total Loss: 380.841797 GL_Loss: 1.080090 CRF_Loss: 379.761719\n",
      "[2022-03-02 13:21:35,346 - trainer - INFO] - Train Epoch:[8/100] Step:[20/40] Total Loss: 436.662567 GL_Loss: 6.712357 CRF_Loss: 429.950195\n",
      "[2022-03-02 13:22:17,640 - trainer - INFO] - Train Epoch:[8/100] Step:[30/40] Total Loss: 342.404358 GL_Loss: 1.759832 CRF_Loss: 340.644531\n",
      "[2022-03-02 13:22:59,761 - trainer - INFO] - Train Epoch:[8/100] Step:[40/40] Total Loss: 296.571777 GL_Loss: 1.777832 CRF_Loss: 294.793945\n",
      "[2022-03-02 13:23:15,331 - trainer - INFO] - [Epoch Validation] Epoch:[8/100] Total Loss: 428.470689 GL_Loss: 0.027748 CRF_Loss: 425.695898 \n",
      "+-------------------------------+-----------+----------+-----------+----------+\n",
      "| name                          |       mEP |      mER |       mEF |      mEA |\n",
      "+===============================+===========+==========+===========+==========+\n",
      "| name_of_irb                   | 0.6       | 0.6      | 0.6       | 0.6      |\n",
      "+-------------------------------+-----------+----------+-----------+----------+\n",
      "| address_2                     | 0.111111  | 0.153846 | 0.129032  | 0.153846 |\n",
      "+-------------------------------+-----------+----------+-----------+----------+\n",
      "| zip_code                      | 0.0909091 | 0.210526 | 0.126984  | 0.210526 |\n",
      "+-------------------------------+-----------+----------+-----------+----------+\n",
      "| country                       | 0.0909091 | 0.1      | 0.0952381 | 0.1      |\n",
      "+-------------------------------+-----------+----------+-----------+----------+\n",
      "| names_of_subinvestigators     | 0.25      | 0.125    | 0.166667  | 0.125    |\n",
      "+-------------------------------+-----------+----------+-----------+----------+\n",
      "| name_of_clinical_laboratory   | 0.25      | 0.4      | 0.307692  | 0.4      |\n",
      "+-------------------------------+-----------+----------+-----------+----------+\n",
      "| name_of_clinical_investigator | 0.75      | 0.6      | 0.666667  | 0.6      |\n",
      "+-------------------------------+-----------+----------+-----------+----------+\n",
      "| curriculum_vitae              | 0         | 0        | 0         | 0        |\n",
      "+-------------------------------+-----------+----------+-----------+----------+\n",
      "| address_1                     | 0.214286  | 0.285714 | 0.244898  | 0.285714 |\n",
      "+-------------------------------+-----------+----------+-----------+----------+\n",
      "| city                          | 0         | 0        | 0         | 0        |\n",
      "+-------------------------------+-----------+----------+-----------+----------+\n",
      "| name_of_medical_school        | 0.666667  | 0.8      | 0.727273  | 0.8      |\n",
      "+-------------------------------+-----------+----------+-----------+----------+\n",
      "| state                         | 0         | 0        | 0         | 0        |\n",
      "+-------------------------------+-----------+----------+-----------+----------+\n",
      "| other_statement               | 0         | 0        | 0         | 0        |\n",
      "+-------------------------------+-----------+----------+-----------+----------+\n",
      "| overall                       | 0.127962  | 0.183673 | 0.150838  | 0.183673 |\n",
      "+-------------------------------+-----------+----------+-----------+----------+\n",
      "[2022-03-02 13:24:01,566 - trainer - INFO] - Train Epoch:[9/100] Step:[10/40] Total Loss: 256.137909 GL_Loss: 4.195535 CRF_Loss: 251.942383\n",
      "[2022-03-02 13:24:47,387 - trainer - INFO] - Train Epoch:[9/100] Step:[20/40] Total Loss: 184.969025 GL_Loss: 2.804964 CRF_Loss: 182.164062\n",
      "[2022-03-02 13:25:33,341 - trainer - INFO] - Train Epoch:[9/100] Step:[30/40] Total Loss: 189.501328 GL_Loss: 1.560892 CRF_Loss: 187.940430\n",
      "[2022-03-02 13:26:18,835 - trainer - INFO] - Train Epoch:[9/100] Step:[40/40] Total Loss: 208.166306 GL_Loss: 1.345993 CRF_Loss: 206.820312\n",
      "[2022-03-02 13:26:34,453 - trainer - INFO] - [Epoch Validation] Epoch:[9/100] Total Loss: 227.617693 GL_Loss: 0.027132 CRF_Loss: 224.904492 \n",
      "+-------------------------------+-----------+----------+-----------+----------+\n",
      "| name                          |       mEP |      mER |       mEF |      mEA |\n",
      "+===============================+===========+==========+===========+==========+\n",
      "| name_of_irb                   | 0.8       | 0.8      | 0.8       | 0.8      |\n",
      "+-------------------------------+-----------+----------+-----------+----------+\n",
      "| address_2                     | 0.181818  | 0.153846 | 0.166667  | 0.153846 |\n",
      "+-------------------------------+-----------+----------+-----------+----------+\n",
      "| zip_code                      | 0.0740741 | 0.105263 | 0.0869565 | 0.105263 |\n",
      "+-------------------------------+-----------+----------+-----------+----------+\n",
      "| country                       | 0.111111  | 0.1      | 0.105263  | 0.1      |\n",
      "+-------------------------------+-----------+----------+-----------+----------+\n",
      "| name_of_clinical_laboratory   | 1         | 1        | 1         | 1        |\n",
      "+-------------------------------+-----------+----------+-----------+----------+\n",
      "| name_of_clinical_investigator | 1         | 1        | 1         | 1        |\n",
      "+-------------------------------+-----------+----------+-----------+----------+\n",
      "| names_of_subinvestigators     | 0.25      | 0.125    | 0.166667  | 0.125    |\n",
      "+-------------------------------+-----------+----------+-----------+----------+\n",
      "| curriculum_vitae              | 0.2       | 0.2      | 0.2       | 0.2      |\n",
      "+-------------------------------+-----------+----------+-----------+----------+\n",
      "| address_1                     | 0.333333  | 0.333333 | 0.333333  | 0.333333 |\n",
      "+-------------------------------+-----------+----------+-----------+----------+\n",
      "| city                          | 0.208333  | 0.25     | 0.227273  | 0.25     |\n",
      "+-------------------------------+-----------+----------+-----------+----------+\n",
      "| name_of_medical_school        | 0.8       | 0.8      | 0.8       | 0.8      |\n",
      "+-------------------------------+-----------+----------+-----------+----------+\n",
      "| state                         | 0         | 0        | 0         | 0        |\n",
      "+-------------------------------+-----------+----------+-----------+----------+\n",
      "| other_statement               | 0         | 0        | 0         | 0        |\n",
      "+-------------------------------+-----------+----------+-----------+----------+\n",
      "| overall                       | 0.260274  | 0.258503 | 0.259386  | 0.258503 |\n",
      "+-------------------------------+-----------+----------+-----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-02 13:27:20,455 - trainer - INFO] - Train Epoch:[10/100] Step:[10/40] Total Loss: 150.349777 GL_Loss: 0.881031 CRF_Loss: 149.468750\n",
      "[2022-03-02 13:28:06,617 - trainer - INFO] - Train Epoch:[10/100] Step:[20/40] Total Loss: 157.324814 GL_Loss: 1.040632 CRF_Loss: 156.284180\n",
      "[2022-03-02 13:28:52,530 - trainer - INFO] - Train Epoch:[10/100] Step:[30/40] Total Loss: 120.932487 GL_Loss: 0.935416 CRF_Loss: 119.997070\n",
      "[2022-03-02 13:29:38,703 - trainer - INFO] - Train Epoch:[10/100] Step:[40/40] Total Loss: 112.832703 GL_Loss: 0.853207 CRF_Loss: 111.979492\n",
      "[2022-03-02 13:29:54,250 - trainer - INFO] - [Epoch Validation] Epoch:[10/100] Total Loss: 149.923013 GL_Loss: 0.009897 CRF_Loss: 148.933350 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 0.4      | 0.4      | 0.4      | 0.4      |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 0.181818 | 0.210526 | 0.195122 | 0.210526 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 0.277778 | 0.25     | 0.263158 | 0.25     |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_2                     | 0.307692 | 0.307692 | 0.307692 | 0.307692 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.391304 | 0.428571 | 0.409091 | 0.428571 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 0.333333 | 0.35     | 0.341463 | 0.35     |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 0.8      | 0.8      | 0.8      | 0.8      |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 0        | 0        | 0        | 0        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 0.4      | 0.4      | 0.4      | 0.4      |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.375887 | 0.360544 | 0.368056 | 0.360544 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 13:30:40,489 - trainer - INFO] - Train Epoch:[11/100] Step:[10/40] Total Loss: 104.226860 GL_Loss: 0.797175 CRF_Loss: 103.429688\n",
      "[2022-03-02 13:31:26,029 - trainer - INFO] - Train Epoch:[11/100] Step:[20/40] Total Loss: 105.308800 GL_Loss: 0.816610 CRF_Loss: 104.492188\n",
      "[2022-03-02 13:32:12,103 - trainer - INFO] - Train Epoch:[11/100] Step:[30/40] Total Loss: 92.064850 GL_Loss: 0.779695 CRF_Loss: 91.285156\n",
      "[2022-03-02 13:32:58,308 - trainer - INFO] - Train Epoch:[11/100] Step:[40/40] Total Loss: 91.048691 GL_Loss: 0.594593 CRF_Loss: 90.454102\n",
      "[2022-03-02 13:33:13,916 - trainer - INFO] - [Epoch Validation] Epoch:[11/100] Total Loss: 110.197548 GL_Loss: 0.007755 CRF_Loss: 109.422070 \n",
      "+-------------------------------+----------+----------+-----------+----------+\n",
      "| name                          |      mEP |      mER |       mEF |      mEA |\n",
      "+===============================+==========+==========+===========+==========+\n",
      "| address_2                     | 0.692308 | 0.692308 | 0.692308  | 0.692308 |\n",
      "+-------------------------------+----------+----------+-----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1         | 1        |\n",
      "+-------------------------------+----------+----------+-----------+----------+\n",
      "| zip_code                      | 0.263158 | 0.263158 | 0.263158  | 0.263158 |\n",
      "+-------------------------------+----------+----------+-----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1         | 1        |\n",
      "+-------------------------------+----------+----------+-----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1         | 1        |\n",
      "+-------------------------------+----------+----------+-----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1         | 1        |\n",
      "+-------------------------------+----------+----------+-----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667  | 0.125    |\n",
      "+-------------------------------+----------+----------+-----------+----------+\n",
      "| country                       | 0.375    | 0.3      | 0.333333  | 0.3      |\n",
      "+-------------------------------+----------+----------+-----------+----------+\n",
      "| address_1                     | 0.7      | 0.666667 | 0.682927  | 0.666667 |\n",
      "+-------------------------------+----------+----------+-----------+----------+\n",
      "| city                          | 0.571429 | 0.6      | 0.585366  | 0.6      |\n",
      "+-------------------------------+----------+----------+-----------+----------+\n",
      "| name_of_medical_school        | 0.8      | 0.8      | 0.8       | 0.8      |\n",
      "+-------------------------------+----------+----------+-----------+----------+\n",
      "| state                         | 0.1      | 0.0625   | 0.0769231 | 0.0625   |\n",
      "+-------------------------------+----------+----------+-----------+----------+\n",
      "| other_statement               | 1        | 1        | 1         | 1        |\n",
      "+-------------------------------+----------+----------+-----------+----------+\n",
      "| overall                       | 0.578947 | 0.52381  | 0.55      | 0.52381  |\n",
      "+-------------------------------+----------+----------+-----------+----------+\n",
      "[2022-03-02 13:34:00,118 - trainer - INFO] - Train Epoch:[12/100] Step:[10/40] Total Loss: 101.138298 GL_Loss: 0.659781 CRF_Loss: 100.478516\n",
      "[2022-03-02 13:34:46,161 - trainer - INFO] - Train Epoch:[12/100] Step:[20/40] Total Loss: 83.274132 GL_Loss: 0.664754 CRF_Loss: 82.609375\n",
      "[2022-03-02 13:35:32,015 - trainer - INFO] - Train Epoch:[12/100] Step:[30/40] Total Loss: 71.823669 GL_Loss: 0.617617 CRF_Loss: 71.206055\n",
      "[2022-03-02 13:36:18,413 - trainer - INFO] - Train Epoch:[12/100] Step:[40/40] Total Loss: 72.780006 GL_Loss: 0.651097 CRF_Loss: 72.128906\n",
      "[2022-03-02 13:36:34,059 - trainer - INFO] - [Epoch Validation] Epoch:[12/100] Total Loss: 88.568844 GL_Loss: 0.006464 CRF_Loss: 87.922437 \n",
      "+-------------------------------+-----------+----------+-----------+----------+\n",
      "| name                          |       mEP |      mER |       mEF |      mEA |\n",
      "+===============================+===========+==========+===========+==========+\n",
      "| address_2                     | 0.692308  | 0.692308 | 0.692308  | 0.692308 |\n",
      "+-------------------------------+-----------+----------+-----------+----------+\n",
      "| curriculum_vitae              | 1         | 1        | 1         | 1        |\n",
      "+-------------------------------+-----------+----------+-----------+----------+\n",
      "| zip_code                      | 0.421053  | 0.421053 | 0.421053  | 0.421053 |\n",
      "+-------------------------------+-----------+----------+-----------+----------+\n",
      "| name_of_irb                   | 1         | 1        | 1         | 1        |\n",
      "+-------------------------------+-----------+----------+-----------+----------+\n",
      "| name_of_clinical_laboratory   | 1         | 1        | 1         | 1        |\n",
      "+-------------------------------+-----------+----------+-----------+----------+\n",
      "| name_of_clinical_investigator | 1         | 1        | 1         | 1        |\n",
      "+-------------------------------+-----------+----------+-----------+----------+\n",
      "| names_of_subinvestigators     | 0.25      | 0.125    | 0.166667  | 0.125    |\n",
      "+-------------------------------+-----------+----------+-----------+----------+\n",
      "| country                       | 0.166667  | 0.15     | 0.157895  | 0.15     |\n",
      "+-------------------------------+-----------+----------+-----------+----------+\n",
      "| address_1                     | 0.65      | 0.619048 | 0.634146  | 0.619048 |\n",
      "+-------------------------------+-----------+----------+-----------+----------+\n",
      "| city                          | 0.363636  | 0.4      | 0.380952  | 0.4      |\n",
      "+-------------------------------+-----------+----------+-----------+----------+\n",
      "| name_of_medical_school        | 0.8       | 0.8      | 0.8       | 0.8      |\n",
      "+-------------------------------+-----------+----------+-----------+----------+\n",
      "| state                         | 0.0833333 | 0.0625   | 0.0714286 | 0.0625   |\n",
      "+-------------------------------+-----------+----------+-----------+----------+\n",
      "| other_statement               | 1         | 1        | 1         | 1        |\n",
      "+-------------------------------+-----------+----------+-----------+----------+\n",
      "| overall                       | 0.521739  | 0.489796 | 0.505263  | 0.489796 |\n",
      "+-------------------------------+-----------+----------+-----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-02 13:37:20,220 - trainer - INFO] - Train Epoch:[13/100] Step:[10/40] Total Loss: 87.043404 GL_Loss: 0.585395 CRF_Loss: 86.458008\n",
      "[2022-03-02 13:38:06,285 - trainer - INFO] - Train Epoch:[13/100] Step:[20/40] Total Loss: 70.627304 GL_Loss: 0.496443 CRF_Loss: 70.130859\n",
      "[2022-03-02 13:38:52,584 - trainer - INFO] - Train Epoch:[13/100] Step:[30/40] Total Loss: 79.166023 GL_Loss: 0.549809 CRF_Loss: 78.616211\n",
      "[2022-03-02 13:39:38,742 - trainer - INFO] - Train Epoch:[13/100] Step:[40/40] Total Loss: 71.688408 GL_Loss: 0.544856 CRF_Loss: 71.143555\n",
      "[2022-03-02 13:39:54,347 - trainer - INFO] - [Epoch Validation] Epoch:[13/100] Total Loss: 73.398621 GL_Loss: 0.005963 CRF_Loss: 72.802319 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 0.923077 | 0.923077 | 0.923077 | 0.923077 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 0.526316 | 0.526316 | 0.526316 | 0.526316 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 0.352941 | 0.3      | 0.324324 | 0.3      |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.85     | 0.809524 | 0.829268 | 0.809524 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 0.454545 | 0.5      | 0.47619  | 0.5      |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 0.8      | 0.8      | 0.8      | 0.8      |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 0.5      | 0.375    | 0.428571 | 0.375    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.664234 | 0.619048 | 0.640845 | 0.619048 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 13:40:40,883 - trainer - INFO] - Train Epoch:[14/100] Step:[10/40] Total Loss: 60.074184 GL_Loss: 0.585904 CRF_Loss: 59.488281\n",
      "[2022-03-02 13:41:27,496 - trainer - INFO] - Train Epoch:[14/100] Step:[20/40] Total Loss: 59.504086 GL_Loss: 0.576350 CRF_Loss: 58.927734\n",
      "[2022-03-02 13:42:13,341 - trainer - INFO] - Train Epoch:[14/100] Step:[30/40] Total Loss: 64.995270 GL_Loss: 0.550935 CRF_Loss: 64.444336\n",
      "[2022-03-02 13:42:58,943 - trainer - INFO] - Train Epoch:[14/100] Step:[40/40] Total Loss: 62.419151 GL_Loss: 0.515830 CRF_Loss: 61.903320\n",
      "[2022-03-02 13:43:14,382 - trainer - INFO] - [Epoch Validation] Epoch:[14/100] Total Loss: 63.253731 GL_Loss: 0.005663 CRF_Loss: 62.687427 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 0.578947 | 0.578947 | 0.578947 | 0.578947 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 0.263158 | 0.25     | 0.25641  | 0.25     |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.9      | 0.857143 | 0.878049 | 0.857143 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 0.5      | 0.5      | 0.5      | 0.5      |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 0.8      | 0.8      | 0.8      | 0.8      |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 0.384615 | 0.3125   | 0.344828 | 0.3125   |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.666667 | 0.62585  | 0.645614 | 0.62585  |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 13:44:00,869 - trainer - INFO] - Train Epoch:[15/100] Step:[10/40] Total Loss: 59.809361 GL_Loss: 0.592563 CRF_Loss: 59.216797\n",
      "[2022-03-02 13:44:46,659 - trainer - INFO] - Train Epoch:[15/100] Step:[20/40] Total Loss: 59.228611 GL_Loss: 0.525487 CRF_Loss: 58.703125\n",
      "[2022-03-02 13:45:32,783 - trainer - INFO] - Train Epoch:[15/100] Step:[30/40] Total Loss: 49.939873 GL_Loss: 0.506278 CRF_Loss: 49.433594\n",
      "[2022-03-02 13:46:19,469 - trainer - INFO] - Train Epoch:[15/100] Step:[40/40] Total Loss: 48.797127 GL_Loss: 0.555915 CRF_Loss: 48.241211\n",
      "[2022-03-02 13:46:35,096 - trainer - INFO] - [Epoch Validation] Epoch:[15/100] Total Loss: 54.559751 GL_Loss: 0.005453 CRF_Loss: 54.014404 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 0.619048 | 0.684211 | 0.65     | 0.684211 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 0.52381  | 0.55     | 0.536585 | 0.55     |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 0.619048 | 0.65     | 0.634146 | 0.65     |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 0.25     | 0.25     | 0.25     | 0.25     |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.712329 | 0.707483 | 0.709898 | 0.707483 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-02 13:47:21,240 - trainer - INFO] - Train Epoch:[16/100] Step:[10/40] Total Loss: 38.196796 GL_Loss: 0.515157 CRF_Loss: 37.681641\n",
      "[2022-03-02 13:48:06,831 - trainer - INFO] - Train Epoch:[16/100] Step:[20/40] Total Loss: 45.349316 GL_Loss: 0.573924 CRF_Loss: 44.775391\n",
      "[2022-03-02 13:48:50,567 - trainer - INFO] - Train Epoch:[16/100] Step:[30/40] Total Loss: 47.566280 GL_Loss: 0.529169 CRF_Loss: 47.037109\n",
      "[2022-03-02 13:49:32,751 - trainer - INFO] - Train Epoch:[16/100] Step:[40/40] Total Loss: 45.116940 GL_Loss: 0.513424 CRF_Loss: 44.603516\n",
      "[2022-03-02 13:49:48,214 - trainer - INFO] - [Epoch Validation] Epoch:[16/100] Total Loss: 48.461541 GL_Loss: 0.005105 CRF_Loss: 47.951001 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 0.736842 | 0.736842 | 0.736842 | 0.736842 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 0.631579 | 0.6      | 0.615385 | 0.6      |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 0.6      | 0.6      | 0.6      | 0.6      |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 0.4375   | 0.4375   | 0.4375   | 0.4375   |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.765957 | 0.734694 | 0.75     | 0.734694 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 13:50:30,877 - trainer - INFO] - Train Epoch:[17/100] Step:[10/40] Total Loss: 44.861126 GL_Loss: 0.497846 CRF_Loss: 44.363281\n",
      "[2022-03-02 13:51:13,993 - trainer - INFO] - Train Epoch:[17/100] Step:[20/40] Total Loss: 40.899044 GL_Loss: 0.484004 CRF_Loss: 40.415039\n",
      "[2022-03-02 13:51:55,757 - trainer - INFO] - Train Epoch:[17/100] Step:[30/40] Total Loss: 40.585907 GL_Loss: 0.503876 CRF_Loss: 40.082031\n",
      "[2022-03-02 13:52:37,713 - trainer - INFO] - Train Epoch:[17/100] Step:[40/40] Total Loss: 35.317596 GL_Loss: 0.490447 CRF_Loss: 34.827148\n",
      "[2022-03-02 13:52:53,316 - trainer - INFO] - [Epoch Validation] Epoch:[17/100] Total Loss: 42.061688 GL_Loss: 0.004834 CRF_Loss: 41.578247 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 0.842105 | 0.842105 | 0.842105 | 0.842105 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 0.8      | 0.8      | 0.8      | 0.8      |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 0.6      | 0.6      | 0.6      | 0.6      |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 0.375    | 0.375    | 0.375    | 0.375    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.795775 | 0.768707 | 0.782007 | 0.768707 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 13:53:35,823 - trainer - INFO] - Train Epoch:[18/100] Step:[10/40] Total Loss: 42.424332 GL_Loss: 0.466325 CRF_Loss: 41.958008\n",
      "[2022-03-02 13:54:18,728 - trainer - INFO] - Train Epoch:[18/100] Step:[20/40] Total Loss: 40.048058 GL_Loss: 0.480676 CRF_Loss: 39.567383\n",
      "[2022-03-02 13:55:01,343 - trainer - INFO] - Train Epoch:[18/100] Step:[30/40] Total Loss: 36.354069 GL_Loss: 0.419497 CRF_Loss: 35.934570\n",
      "[2022-03-02 13:55:43,152 - trainer - INFO] - Train Epoch:[18/100] Step:[40/40] Total Loss: 37.091434 GL_Loss: 0.491824 CRF_Loss: 36.599609\n",
      "[2022-03-02 13:55:58,656 - trainer - INFO] - [Epoch Validation] Epoch:[18/100] Total Loss: 37.207230 GL_Loss: 0.004550 CRF_Loss: 36.752246 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 0.947368 | 0.947368 | 0.947368 | 0.947368 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 0.809524 | 0.85     | 0.829268 | 0.85     |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 0.95     | 0.95     | 0.95     | 0.95     |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 0.9375   | 0.9375   | 0.9375   | 0.9375   |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.923077 | 0.897959 | 0.910345 | 0.897959 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-02 13:56:41,034 - trainer - INFO] - Train Epoch:[19/100] Step:[10/40] Total Loss: 32.745872 GL_Loss: 0.453878 CRF_Loss: 32.291992\n",
      "[2022-03-02 13:57:24,029 - trainer - INFO] - Train Epoch:[19/100] Step:[20/40] Total Loss: 33.877907 GL_Loss: 0.484352 CRF_Loss: 33.393555\n",
      "[2022-03-02 13:58:05,809 - trainer - INFO] - Train Epoch:[19/100] Step:[30/40] Total Loss: 35.168610 GL_Loss: 0.395173 CRF_Loss: 34.773438\n",
      "[2022-03-02 13:58:48,272 - trainer - INFO] - Train Epoch:[19/100] Step:[40/40] Total Loss: 31.325102 GL_Loss: 0.420805 CRF_Loss: 30.904297\n",
      "[2022-03-02 13:59:03,899 - trainer - INFO] - [Epoch Validation] Epoch:[19/100] Total Loss: 33.647582 GL_Loss: 0.004503 CRF_Loss: 33.197241 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 0.684211 | 0.684211 | 0.684211 | 0.684211 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 0.6      | 0.6      | 0.6      | 0.6      |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 0.666667 | 0.7      | 0.682927 | 0.7      |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 0.5625   | 0.5625   | 0.5625   | 0.5625   |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.776224 | 0.755102 | 0.765517 | 0.755102 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 13:59:46,421 - trainer - INFO] - Train Epoch:[20/100] Step:[10/40] Total Loss: 28.677280 GL_Loss: 0.403844 CRF_Loss: 28.273438\n",
      "[2022-03-02 14:00:29,033 - trainer - INFO] - Train Epoch:[20/100] Step:[20/40] Total Loss: 30.487524 GL_Loss: 0.407446 CRF_Loss: 30.080078\n",
      "[2022-03-02 14:01:11,510 - trainer - INFO] - Train Epoch:[20/100] Step:[30/40] Total Loss: 27.937645 GL_Loss: 0.415184 CRF_Loss: 27.522461\n",
      "[2022-03-02 14:01:54,104 - trainer - INFO] - Train Epoch:[20/100] Step:[40/40] Total Loss: 28.790260 GL_Loss: 0.424050 CRF_Loss: 28.366211\n",
      "[2022-03-02 14:02:09,686 - trainer - INFO] - [Epoch Validation] Epoch:[20/100] Total Loss: 30.071165 GL_Loss: 0.004358 CRF_Loss: 29.635376 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 0.947368 | 0.947368 | 0.947368 | 0.947368 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 0.9      | 0.9      | 0.9      | 0.9      |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 0.75     | 0.75     | 0.75     | 0.75     |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 0.6875   | 0.6875   | 0.6875   | 0.6875   |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.880282 | 0.85034  | 0.865052 | 0.85034  |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 14:02:11,576 - trainer - INFO] - Saving checkpoint: saved/models/PICK_Default/test_0302_125836/checkpoint-epoch20.pth ...\n",
      "[2022-03-02 14:02:54,407 - trainer - INFO] - Train Epoch:[21/100] Step:[10/40] Total Loss: 28.035196 GL_Loss: 0.428751 CRF_Loss: 27.606445\n",
      "[2022-03-02 14:03:37,386 - trainer - INFO] - Train Epoch:[21/100] Step:[20/40] Total Loss: 27.498274 GL_Loss: 0.438704 CRF_Loss: 27.059570\n",
      "[2022-03-02 14:04:19,034 - trainer - INFO] - Train Epoch:[21/100] Step:[30/40] Total Loss: 24.339815 GL_Loss: 0.404268 CRF_Loss: 23.935547\n",
      "[2022-03-02 14:05:01,119 - trainer - INFO] - Train Epoch:[21/100] Step:[40/40] Total Loss: 26.104641 GL_Loss: 0.399563 CRF_Loss: 25.705078\n",
      "[2022-03-02 14:05:16,587 - trainer - INFO] - [Epoch Validation] Epoch:[21/100] Total Loss: 27.194145 GL_Loss: 0.004260 CRF_Loss: 26.768164 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-02 14:05:59,130 - trainer - INFO] - Train Epoch:[22/100] Step:[10/40] Total Loss: 28.019037 GL_Loss: 0.406733 CRF_Loss: 27.612305\n",
      "[2022-03-02 14:06:41,226 - trainer - INFO] - Train Epoch:[22/100] Step:[20/40] Total Loss: 28.254745 GL_Loss: 0.354355 CRF_Loss: 27.900391\n",
      "[2022-03-02 14:07:23,079 - trainer - INFO] - Train Epoch:[22/100] Step:[30/40] Total Loss: 31.922188 GL_Loss: 0.412423 CRF_Loss: 31.509766\n",
      "[2022-03-02 14:08:05,703 - trainer - INFO] - Train Epoch:[22/100] Step:[40/40] Total Loss: 30.214817 GL_Loss: 0.492161 CRF_Loss: 29.722656\n",
      "[2022-03-02 14:08:21,372 - trainer - INFO] - [Epoch Validation] Epoch:[22/100] Total Loss: 28.721857 GL_Loss: 0.004176 CRF_Loss: 28.304224 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 0.736842 | 0.736842 | 0.736842 | 0.736842 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 0.73913  | 0.85     | 0.790698 | 0.85     |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 0.75     | 0.75     | 0.75     | 0.75     |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 0.6875   | 0.6875   | 0.6875   | 0.6875   |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.827586 | 0.816327 | 0.821918 | 0.816327 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 14:09:03,759 - trainer - INFO] - Train Epoch:[23/100] Step:[10/40] Total Loss: 30.243099 GL_Loss: 0.375912 CRF_Loss: 29.867188\n",
      "[2022-03-02 14:09:45,762 - trainer - INFO] - Train Epoch:[23/100] Step:[20/40] Total Loss: 24.476126 GL_Loss: 0.409719 CRF_Loss: 24.066406\n",
      "[2022-03-02 14:10:28,466 - trainer - INFO] - Train Epoch:[23/100] Step:[30/40] Total Loss: 22.668997 GL_Loss: 0.428762 CRF_Loss: 22.240234\n",
      "[2022-03-02 14:11:10,720 - trainer - INFO] - Train Epoch:[23/100] Step:[40/40] Total Loss: 21.227674 GL_Loss: 0.388808 CRF_Loss: 20.838867\n",
      "[2022-03-02 14:11:26,239 - trainer - INFO] - [Epoch Validation] Epoch:[23/100] Total Loss: 26.086988 GL_Loss: 0.004093 CRF_Loss: 25.677661 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 0.952381 | 1        | 0.97561  | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 0.9375   | 0.9375   | 0.9375   | 0.9375   |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.958042 | 0.931973 | 0.944828 | 0.931973 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 14:12:08,747 - trainer - INFO] - Train Epoch:[24/100] Step:[10/40] Total Loss: 19.945532 GL_Loss: 0.451392 CRF_Loss: 19.494141\n",
      "[2022-03-02 14:12:50,929 - trainer - INFO] - Train Epoch:[24/100] Step:[20/40] Total Loss: 22.762543 GL_Loss: 0.393401 CRF_Loss: 22.369141\n",
      "[2022-03-02 14:13:33,173 - trainer - INFO] - Train Epoch:[24/100] Step:[30/40] Total Loss: 32.217518 GL_Loss: 0.399159 CRF_Loss: 31.818359\n",
      "[2022-03-02 14:14:15,680 - trainer - INFO] - Train Epoch:[24/100] Step:[40/40] Total Loss: 20.227562 GL_Loss: 0.400414 CRF_Loss: 19.827148\n",
      "[2022-03-02 14:14:31,248 - trainer - INFO] - [Epoch Validation] Epoch:[24/100] Total Loss: 22.285069 GL_Loss: 0.004012 CRF_Loss: 21.883911 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 0.947368 | 0.947368 | 0.947368 | 0.947368 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 0.9375   | 0.9375   | 0.9375   | 0.9375   |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.957746 | 0.92517  | 0.941176 | 0.92517  |\n",
      "+-------------------------------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-02 14:15:14,051 - trainer - INFO] - Train Epoch:[25/100] Step:[10/40] Total Loss: 20.840445 GL_Loss: 0.395131 CRF_Loss: 20.445312\n",
      "[2022-03-02 14:15:56,431 - trainer - INFO] - Train Epoch:[25/100] Step:[20/40] Total Loss: 18.599754 GL_Loss: 0.428856 CRF_Loss: 18.170898\n",
      "[2022-03-02 14:16:38,597 - trainer - INFO] - Train Epoch:[25/100] Step:[30/40] Total Loss: 20.015778 GL_Loss: 0.415192 CRF_Loss: 19.600586\n",
      "[2022-03-02 14:17:21,040 - trainer - INFO] - Train Epoch:[25/100] Step:[40/40] Total Loss: 18.560652 GL_Loss: 0.379987 CRF_Loss: 18.180664\n",
      "[2022-03-02 14:17:36,620 - trainer - INFO] - [Epoch Validation] Epoch:[25/100] Total Loss: 19.603791 GL_Loss: 0.003937 CRF_Loss: 19.210107 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 0.95     | 0.95     | 0.95     | 0.95     |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 0.9375   | 0.9375   | 0.9375   | 0.9375   |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.957746 | 0.92517  | 0.941176 | 0.92517  |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 14:18:19,347 - trainer - INFO] - Train Epoch:[26/100] Step:[10/40] Total Loss: 16.690985 GL_Loss: 0.408758 CRF_Loss: 16.282227\n",
      "[2022-03-02 14:19:02,089 - trainer - INFO] - Train Epoch:[26/100] Step:[20/40] Total Loss: 16.996252 GL_Loss: 0.354650 CRF_Loss: 16.641602\n",
      "[2022-03-02 14:19:44,299 - trainer - INFO] - Train Epoch:[26/100] Step:[30/40] Total Loss: 17.837891 GL_Loss: 0.364258 CRF_Loss: 17.473633\n",
      "[2022-03-02 14:20:26,596 - trainer - INFO] - Train Epoch:[26/100] Step:[40/40] Total Loss: 16.442926 GL_Loss: 0.368708 CRF_Loss: 16.074219\n",
      "[2022-03-02 14:20:42,187 - trainer - INFO] - [Epoch Validation] Epoch:[26/100] Total Loss: 17.366611 GL_Loss: 0.003738 CRF_Loss: 16.992773 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 14:21:24,824 - trainer - INFO] - Train Epoch:[27/100] Step:[10/40] Total Loss: 16.668926 GL_Loss: 0.402324 CRF_Loss: 16.266602\n",
      "[2022-03-02 14:22:06,717 - trainer - INFO] - Train Epoch:[27/100] Step:[20/40] Total Loss: 15.934284 GL_Loss: 0.336628 CRF_Loss: 15.597656\n",
      "[2022-03-02 14:22:49,155 - trainer - INFO] - Train Epoch:[27/100] Step:[30/40] Total Loss: 18.061440 GL_Loss: 0.353431 CRF_Loss: 17.708008\n",
      "[2022-03-02 14:23:31,597 - trainer - INFO] - Train Epoch:[27/100] Step:[40/40] Total Loss: 14.995287 GL_Loss: 0.393724 CRF_Loss: 14.601562\n",
      "[2022-03-02 14:23:47,178 - trainer - INFO] - [Epoch Validation] Epoch:[27/100] Total Loss: 16.405038 GL_Loss: 0.003606 CRF_Loss: 16.044482 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-02 14:24:30,047 - trainer - INFO] - Train Epoch:[28/100] Step:[10/40] Total Loss: 15.757322 GL_Loss: 0.351073 CRF_Loss: 15.406250\n",
      "[2022-03-02 14:25:12,663 - trainer - INFO] - Train Epoch:[28/100] Step:[20/40] Total Loss: 14.877265 GL_Loss: 0.349922 CRF_Loss: 14.527344\n",
      "[2022-03-02 14:25:55,361 - trainer - INFO] - Train Epoch:[28/100] Step:[30/40] Total Loss: 15.901903 GL_Loss: 0.343310 CRF_Loss: 15.558594\n",
      "[2022-03-02 14:26:37,832 - trainer - INFO] - Train Epoch:[28/100] Step:[40/40] Total Loss: 14.536904 GL_Loss: 0.354287 CRF_Loss: 14.182617\n",
      "[2022-03-02 14:26:53,567 - trainer - INFO] - [Epoch Validation] Epoch:[28/100] Total Loss: 15.294771 GL_Loss: 0.003532 CRF_Loss: 14.941602 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 0.95     | 0.95     | 0.95     | 0.95     |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 0.9375   | 0.9375   | 0.9375   | 0.9375   |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.957746 | 0.92517  | 0.941176 | 0.92517  |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 14:27:36,011 - trainer - INFO] - Train Epoch:[29/100] Step:[10/40] Total Loss: 17.289568 GL_Loss: 0.315936 CRF_Loss: 16.973633\n",
      "[2022-03-02 14:28:18,140 - trainer - INFO] - Train Epoch:[29/100] Step:[20/40] Total Loss: 13.804857 GL_Loss: 0.367358 CRF_Loss: 13.437500\n",
      "[2022-03-02 14:29:00,158 - trainer - INFO] - Train Epoch:[29/100] Step:[30/40] Total Loss: 13.891419 GL_Loss: 0.351380 CRF_Loss: 13.540039\n",
      "[2022-03-02 14:29:41,950 - trainer - INFO] - Train Epoch:[29/100] Step:[40/40] Total Loss: 13.249064 GL_Loss: 0.316447 CRF_Loss: 12.932617\n",
      "[2022-03-02 14:29:57,113 - trainer - INFO] - [Epoch Validation] Epoch:[29/100] Total Loss: 14.343213 GL_Loss: 0.003445 CRF_Loss: 13.998755 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 14:30:42,026 - trainer - INFO] - Train Epoch:[30/100] Step:[10/40] Total Loss: 13.557500 GL_Loss: 0.335820 CRF_Loss: 13.221680\n",
      "[2022-03-02 14:31:27,024 - trainer - INFO] - Train Epoch:[30/100] Step:[20/40] Total Loss: 12.612208 GL_Loss: 0.358302 CRF_Loss: 12.253906\n",
      "[2022-03-02 14:32:11,613 - trainer - INFO] - Train Epoch:[30/100] Step:[30/40] Total Loss: 15.066070 GL_Loss: 0.305327 CRF_Loss: 14.760742\n",
      "[2022-03-02 14:32:56,746 - trainer - INFO] - Train Epoch:[30/100] Step:[40/40] Total Loss: 14.775684 GL_Loss: 0.338184 CRF_Loss: 14.437500\n",
      "[2022-03-02 14:33:14,263 - trainer - INFO] - [Epoch Validation] Epoch:[30/100] Total Loss: 13.436369 GL_Loss: 0.003410 CRF_Loss: 13.095410 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 0.95     | 0.95     | 0.95     | 0.95     |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 0.809524 | 0.85     | 0.829268 | 0.85     |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 0.8125   | 0.8125   | 0.8125   | 0.8125   |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.916084 | 0.891156 | 0.903448 | 0.891156 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-02 14:33:56,805 - trainer - INFO] - Train Epoch:[31/100] Step:[10/40] Total Loss: 14.167802 GL_Loss: 0.311357 CRF_Loss: 13.856445\n",
      "[2022-03-02 14:34:39,171 - trainer - INFO] - Train Epoch:[31/100] Step:[20/40] Total Loss: 12.418285 GL_Loss: 0.339184 CRF_Loss: 12.079102\n",
      "[2022-03-02 14:35:21,557 - trainer - INFO] - Train Epoch:[31/100] Step:[30/40] Total Loss: 12.161582 GL_Loss: 0.337364 CRF_Loss: 11.824219\n",
      "[2022-03-02 14:36:03,964 - trainer - INFO] - Train Epoch:[31/100] Step:[40/40] Total Loss: 11.638253 GL_Loss: 0.331613 CRF_Loss: 11.306641\n",
      "[2022-03-02 14:36:19,675 - trainer - INFO] - [Epoch Validation] Epoch:[31/100] Total Loss: 12.685117 GL_Loss: 0.003378 CRF_Loss: 12.347363 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 14:37:02,255 - trainer - INFO] - Train Epoch:[32/100] Step:[10/40] Total Loss: 11.835529 GL_Loss: 0.324787 CRF_Loss: 11.510742\n",
      "[2022-03-02 14:37:44,044 - trainer - INFO] - Train Epoch:[32/100] Step:[20/40] Total Loss: 12.931231 GL_Loss: 0.345294 CRF_Loss: 12.585938\n",
      "[2022-03-02 14:38:26,597 - trainer - INFO] - Train Epoch:[32/100] Step:[30/40] Total Loss: 12.021178 GL_Loss: 0.333679 CRF_Loss: 11.687500\n",
      "[2022-03-02 14:39:09,618 - trainer - INFO] - Train Epoch:[32/100] Step:[40/40] Total Loss: 11.719592 GL_Loss: 0.336780 CRF_Loss: 11.382812\n",
      "[2022-03-02 14:39:25,043 - trainer - INFO] - [Epoch Validation] Epoch:[32/100] Total Loss: 12.112667 GL_Loss: 0.003348 CRF_Loss: 11.777905 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 14:40:07,969 - trainer - INFO] - Train Epoch:[33/100] Step:[10/40] Total Loss: 12.895436 GL_Loss: 0.309498 CRF_Loss: 12.585938\n",
      "[2022-03-02 14:40:49,652 - trainer - INFO] - Train Epoch:[33/100] Step:[20/40] Total Loss: 12.879148 GL_Loss: 0.303954 CRF_Loss: 12.575195\n",
      "[2022-03-02 14:41:31,998 - trainer - INFO] - Train Epoch:[33/100] Step:[30/40] Total Loss: 11.381113 GL_Loss: 0.357675 CRF_Loss: 11.023438\n",
      "[2022-03-02 14:42:14,102 - trainer - INFO] - Train Epoch:[33/100] Step:[40/40] Total Loss: 11.972246 GL_Loss: 0.330644 CRF_Loss: 11.641602\n",
      "[2022-03-02 14:42:29,568 - trainer - INFO] - [Epoch Validation] Epoch:[33/100] Total Loss: 11.959841 GL_Loss: 0.003271 CRF_Loss: 11.632715 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-02 14:43:11,497 - trainer - INFO] - Train Epoch:[34/100] Step:[10/40] Total Loss: 12.196925 GL_Loss: 0.333644 CRF_Loss: 11.863281\n",
      "[2022-03-02 14:43:53,723 - trainer - INFO] - Train Epoch:[34/100] Step:[20/40] Total Loss: 11.479073 GL_Loss: 0.335518 CRF_Loss: 11.143555\n",
      "[2022-03-02 14:44:35,793 - trainer - INFO] - Train Epoch:[34/100] Step:[30/40] Total Loss: 11.201163 GL_Loss: 0.342765 CRF_Loss: 10.858398\n",
      "[2022-03-02 14:45:17,722 - trainer - INFO] - Train Epoch:[34/100] Step:[40/40] Total Loss: 12.165130 GL_Loss: 0.346771 CRF_Loss: 11.818359\n",
      "[2022-03-02 14:45:33,120 - trainer - INFO] - [Epoch Validation] Epoch:[34/100] Total Loss: 12.010407 GL_Loss: 0.003312 CRF_Loss: 11.679224 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 14:46:15,449 - trainer - INFO] - Train Epoch:[35/100] Step:[10/40] Total Loss: 11.602262 GL_Loss: 0.325896 CRF_Loss: 11.276367\n",
      "[2022-03-02 14:46:57,247 - trainer - INFO] - Train Epoch:[35/100] Step:[20/40] Total Loss: 11.405714 GL_Loss: 0.364699 CRF_Loss: 11.041016\n",
      "[2022-03-02 14:47:39,748 - trainer - INFO] - Train Epoch:[35/100] Step:[30/40] Total Loss: 12.449187 GL_Loss: 0.302703 CRF_Loss: 12.146484\n",
      "[2022-03-02 14:48:21,849 - trainer - INFO] - Train Epoch:[35/100] Step:[40/40] Total Loss: 12.623872 GL_Loss: 0.309419 CRF_Loss: 12.314453\n",
      "[2022-03-02 14:48:37,183 - trainer - INFO] - [Epoch Validation] Epoch:[35/100] Total Loss: 11.779078 GL_Loss: 0.003313 CRF_Loss: 11.447778 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 14:49:19,921 - trainer - INFO] - Train Epoch:[36/100] Step:[10/40] Total Loss: 12.069888 GL_Loss: 0.349185 CRF_Loss: 11.720703\n",
      "[2022-03-02 14:50:02,091 - trainer - INFO] - Train Epoch:[36/100] Step:[20/40] Total Loss: 11.337286 GL_Loss: 0.350958 CRF_Loss: 10.986328\n",
      "[2022-03-02 14:50:44,410 - trainer - INFO] - Train Epoch:[36/100] Step:[30/40] Total Loss: 11.609877 GL_Loss: 0.319838 CRF_Loss: 11.290039\n",
      "[2022-03-02 14:51:26,588 - trainer - INFO] - Train Epoch:[36/100] Step:[40/40] Total Loss: 11.001322 GL_Loss: 0.350931 CRF_Loss: 10.650391\n",
      "[2022-03-02 14:51:41,872 - trainer - INFO] - [Epoch Validation] Epoch:[36/100] Total Loss: 11.697376 GL_Loss: 0.003279 CRF_Loss: 11.369507 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-02 14:52:24,902 - trainer - INFO] - Train Epoch:[37/100] Step:[10/40] Total Loss: 12.059608 GL_Loss: 0.295936 CRF_Loss: 11.763672\n",
      "[2022-03-02 14:53:07,262 - trainer - INFO] - Train Epoch:[37/100] Step:[20/40] Total Loss: 11.410923 GL_Loss: 0.318150 CRF_Loss: 11.092773\n",
      "[2022-03-02 14:53:49,226 - trainer - INFO] - Train Epoch:[37/100] Step:[30/40] Total Loss: 11.357268 GL_Loss: 0.317229 CRF_Loss: 11.040039\n",
      "[2022-03-02 14:54:31,040 - trainer - INFO] - Train Epoch:[37/100] Step:[40/40] Total Loss: 11.588414 GL_Loss: 0.357945 CRF_Loss: 11.230469\n",
      "[2022-03-02 14:54:46,566 - trainer - INFO] - [Epoch Validation] Epoch:[37/100] Total Loss: 11.661193 GL_Loss: 0.003282 CRF_Loss: 11.332959 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 14:55:28,630 - trainer - INFO] - Train Epoch:[38/100] Step:[10/40] Total Loss: 11.992905 GL_Loss: 0.346421 CRF_Loss: 11.646484\n",
      "[2022-03-02 14:56:10,948 - trainer - INFO] - Train Epoch:[38/100] Step:[20/40] Total Loss: 11.848057 GL_Loss: 0.369541 CRF_Loss: 11.478516\n",
      "[2022-03-02 14:56:53,371 - trainer - INFO] - Train Epoch:[38/100] Step:[30/40] Total Loss: 11.858205 GL_Loss: 0.326955 CRF_Loss: 11.531250\n",
      "[2022-03-02 14:58:32,982 - trainer - INFO] - Train Epoch:[39/100] Step:[10/40] Total Loss: 11.694708 GL_Loss: 0.333380 CRF_Loss: 11.361328\n",
      "[2022-03-02 14:59:15,473 - trainer - INFO] - Train Epoch:[39/100] Step:[20/40] Total Loss: 10.924312 GL_Loss: 0.334468 CRF_Loss: 10.589844\n",
      "[2022-03-02 14:59:57,857 - trainer - INFO] - Train Epoch:[39/100] Step:[30/40] Total Loss: 10.656312 GL_Loss: 0.321351 CRF_Loss: 10.334961\n",
      "[2022-03-02 15:00:40,088 - trainer - INFO] - Train Epoch:[39/100] Step:[40/40] Total Loss: 10.969666 GL_Loss: 0.336854 CRF_Loss: 10.632812\n",
      "[2022-03-02 15:00:55,607 - trainer - INFO] - [Epoch Validation] Epoch:[39/100] Total Loss: 11.370455 GL_Loss: 0.003330 CRF_Loss: 11.037476 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 15:01:37,941 - trainer - INFO] - Train Epoch:[40/100] Step:[10/40] Total Loss: 11.984387 GL_Loss: 0.306653 CRF_Loss: 11.677734\n",
      "[2022-03-02 15:02:20,356 - trainer - INFO] - Train Epoch:[40/100] Step:[20/40] Total Loss: 11.291025 GL_Loss: 0.324229 CRF_Loss: 10.966797\n",
      "[2022-03-02 15:03:03,003 - trainer - INFO] - Train Epoch:[40/100] Step:[30/40] Total Loss: 12.433379 GL_Loss: 0.316192 CRF_Loss: 12.117188\n",
      "[2022-03-02 15:03:45,458 - trainer - INFO] - Train Epoch:[40/100] Step:[40/40] Total Loss: 11.085531 GL_Loss: 0.295492 CRF_Loss: 10.790039\n",
      "[2022-03-02 15:04:01,142 - trainer - INFO] - [Epoch Validation] Epoch:[40/100] Total Loss: 11.285523 GL_Loss: 0.003248 CRF_Loss: 10.960718 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-02 15:04:03,018 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-03-02 15:04:45,753 - trainer - INFO] - Train Epoch:[41/100] Step:[10/40] Total Loss: 11.706926 GL_Loss: 0.351457 CRF_Loss: 11.355469\n",
      "[2022-03-02 15:05:27,739 - trainer - INFO] - Train Epoch:[41/100] Step:[20/40] Total Loss: 11.162420 GL_Loss: 0.363593 CRF_Loss: 10.798828\n",
      "[2022-03-02 15:06:10,480 - trainer - INFO] - Train Epoch:[41/100] Step:[30/40] Total Loss: 11.013658 GL_Loss: 0.345689 CRF_Loss: 10.667969\n",
      "[2022-03-02 15:06:52,884 - trainer - INFO] - Train Epoch:[41/100] Step:[40/40] Total Loss: 11.738651 GL_Loss: 0.336307 CRF_Loss: 11.402344\n",
      "[2022-03-02 15:07:08,508 - trainer - INFO] - [Epoch Validation] Epoch:[41/100] Total Loss: 11.287964 GL_Loss: 0.003264 CRF_Loss: 10.961597 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 15:07:51,310 - trainer - INFO] - Train Epoch:[42/100] Step:[10/40] Total Loss: 10.763785 GL_Loss: 0.321403 CRF_Loss: 10.442383\n",
      "[2022-03-02 15:08:34,047 - trainer - INFO] - Train Epoch:[42/100] Step:[20/40] Total Loss: 11.181952 GL_Loss: 0.304998 CRF_Loss: 10.876953\n",
      "[2022-03-02 15:09:16,153 - trainer - INFO] - Train Epoch:[42/100] Step:[30/40] Total Loss: 11.093823 GL_Loss: 0.311597 CRF_Loss: 10.782227\n",
      "[2022-03-02 15:09:58,389 - trainer - INFO] - Train Epoch:[42/100] Step:[40/40] Total Loss: 11.040073 GL_Loss: 0.363315 CRF_Loss: 10.676758\n",
      "[2022-03-02 15:10:14,174 - trainer - INFO] - [Epoch Validation] Epoch:[42/100] Total Loss: 11.172056 GL_Loss: 0.003251 CRF_Loss: 10.846997 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 15:10:56,951 - trainer - INFO] - Train Epoch:[43/100] Step:[10/40] Total Loss: 11.047774 GL_Loss: 0.326094 CRF_Loss: 10.721680\n",
      "[2022-03-02 15:11:38,894 - trainer - INFO] - Train Epoch:[43/100] Step:[20/40] Total Loss: 11.565106 GL_Loss: 0.304365 CRF_Loss: 11.260742\n",
      "[2022-03-02 15:12:21,565 - trainer - INFO] - Train Epoch:[43/100] Step:[30/40] Total Loss: 11.288559 GL_Loss: 0.316879 CRF_Loss: 10.971680\n",
      "[2022-03-02 15:13:03,965 - trainer - INFO] - Train Epoch:[43/100] Step:[40/40] Total Loss: 10.481602 GL_Loss: 0.305821 CRF_Loss: 10.175781\n",
      "[2022-03-02 15:13:19,632 - trainer - INFO] - [Epoch Validation] Epoch:[43/100] Total Loss: 11.147179 GL_Loss: 0.003256 CRF_Loss: 10.821582 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-02 15:14:02,252 - trainer - INFO] - Train Epoch:[44/100] Step:[10/40] Total Loss: 10.741749 GL_Loss: 0.337452 CRF_Loss: 10.404297\n",
      "[2022-03-02 15:14:44,723 - trainer - INFO] - Train Epoch:[44/100] Step:[20/40] Total Loss: 11.622511 GL_Loss: 0.325636 CRF_Loss: 11.296875\n",
      "[2022-03-02 15:15:27,261 - trainer - INFO] - Train Epoch:[44/100] Step:[30/40] Total Loss: 11.320751 GL_Loss: 0.296337 CRF_Loss: 11.024414\n",
      "[2022-03-02 15:16:09,543 - trainer - INFO] - Train Epoch:[44/100] Step:[40/40] Total Loss: 11.425292 GL_Loss: 0.315917 CRF_Loss: 11.109375\n",
      "[2022-03-02 15:16:24,888 - trainer - INFO] - [Epoch Validation] Epoch:[44/100] Total Loss: 11.091352 GL_Loss: 0.003252 CRF_Loss: 10.766113 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 15:17:07,425 - trainer - INFO] - Train Epoch:[45/100] Step:[10/40] Total Loss: 10.742794 GL_Loss: 0.311153 CRF_Loss: 10.431641\n",
      "[2022-03-02 15:17:49,490 - trainer - INFO] - Train Epoch:[45/100] Step:[20/40] Total Loss: 11.065154 GL_Loss: 0.294647 CRF_Loss: 10.770508\n",
      "[2022-03-02 15:18:32,010 - trainer - INFO] - Train Epoch:[45/100] Step:[30/40] Total Loss: 10.379157 GL_Loss: 0.301032 CRF_Loss: 10.078125\n",
      "[2022-03-02 15:19:14,272 - trainer - INFO] - Train Epoch:[45/100] Step:[40/40] Total Loss: 11.346650 GL_Loss: 0.338838 CRF_Loss: 11.007812\n",
      "[2022-03-02 15:19:29,927 - trainer - INFO] - [Epoch Validation] Epoch:[45/100] Total Loss: 10.951397 GL_Loss: 0.003195 CRF_Loss: 10.631909 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 15:20:12,421 - trainer - INFO] - Train Epoch:[46/100] Step:[10/40] Total Loss: 10.695663 GL_Loss: 0.292343 CRF_Loss: 10.403320\n",
      "[2022-03-02 15:20:54,345 - trainer - INFO] - Train Epoch:[46/100] Step:[20/40] Total Loss: 11.193128 GL_Loss: 0.320081 CRF_Loss: 10.873047\n",
      "[2022-03-02 15:21:36,949 - trainer - INFO] - Train Epoch:[46/100] Step:[30/40] Total Loss: 10.367811 GL_Loss: 0.316053 CRF_Loss: 10.051758\n",
      "[2022-03-02 15:22:19,378 - trainer - INFO] - Train Epoch:[46/100] Step:[40/40] Total Loss: 10.230506 GL_Loss: 0.275428 CRF_Loss: 9.955078\n",
      "[2022-03-02 15:22:34,780 - trainer - INFO] - [Epoch Validation] Epoch:[46/100] Total Loss: 10.883265 GL_Loss: 0.003213 CRF_Loss: 10.562012 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-02 15:23:17,332 - trainer - INFO] - Train Epoch:[47/100] Step:[10/40] Total Loss: 11.182817 GL_Loss: 0.344926 CRF_Loss: 10.837891\n",
      "[2022-03-02 15:23:59,795 - trainer - INFO] - Train Epoch:[47/100] Step:[20/40] Total Loss: 10.363134 GL_Loss: 0.320166 CRF_Loss: 10.042969\n",
      "[2022-03-02 15:24:42,258 - trainer - INFO] - Train Epoch:[47/100] Step:[30/40] Total Loss: 10.828648 GL_Loss: 0.317905 CRF_Loss: 10.510742\n",
      "[2022-03-02 15:25:24,316 - trainer - INFO] - Train Epoch:[47/100] Step:[40/40] Total Loss: 10.703380 GL_Loss: 0.306895 CRF_Loss: 10.396484\n",
      "[2022-03-02 15:25:41,599 - trainer - INFO] - [Epoch Validation] Epoch:[47/100] Total Loss: 10.778830 GL_Loss: 0.003196 CRF_Loss: 10.459277 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 15:26:24,147 - trainer - INFO] - Train Epoch:[48/100] Step:[10/40] Total Loss: 10.566972 GL_Loss: 0.332597 CRF_Loss: 10.234375\n",
      "[2022-03-02 15:27:06,604 - trainer - INFO] - Train Epoch:[48/100] Step:[20/40] Total Loss: 10.495450 GL_Loss: 0.335294 CRF_Loss: 10.160156\n",
      "[2022-03-02 15:27:48,619 - trainer - INFO] - Train Epoch:[48/100] Step:[30/40] Total Loss: 11.263620 GL_Loss: 0.327097 CRF_Loss: 10.936523\n",
      "[2022-03-02 15:28:31,326 - trainer - INFO] - Train Epoch:[48/100] Step:[40/40] Total Loss: 10.248239 GL_Loss: 0.302926 CRF_Loss: 9.945312\n",
      "[2022-03-02 15:28:46,788 - trainer - INFO] - [Epoch Validation] Epoch:[48/100] Total Loss: 10.750077 GL_Loss: 0.003188 CRF_Loss: 10.431250 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 15:29:29,649 - trainer - INFO] - Train Epoch:[49/100] Step:[10/40] Total Loss: 11.276031 GL_Loss: 0.327789 CRF_Loss: 10.948242\n",
      "[2022-03-02 15:30:12,280 - trainer - INFO] - Train Epoch:[49/100] Step:[20/40] Total Loss: 10.771558 GL_Loss: 0.297925 CRF_Loss: 10.473633\n",
      "[2022-03-02 15:30:54,704 - trainer - INFO] - Train Epoch:[49/100] Step:[30/40] Total Loss: 11.457640 GL_Loss: 0.339476 CRF_Loss: 11.118164\n",
      "[2022-03-02 15:31:37,017 - trainer - INFO] - Train Epoch:[49/100] Step:[40/40] Total Loss: 10.615987 GL_Loss: 0.338643 CRF_Loss: 10.277344\n",
      "[2022-03-02 15:31:52,608 - trainer - INFO] - [Epoch Validation] Epoch:[49/100] Total Loss: 10.689650 GL_Loss: 0.003198 CRF_Loss: 10.369824 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-02 15:32:35,954 - trainer - INFO] - Train Epoch:[50/100] Step:[10/40] Total Loss: 10.255979 GL_Loss: 0.353635 CRF_Loss: 9.902344\n",
      "[2022-03-02 15:33:17,894 - trainer - INFO] - Train Epoch:[50/100] Step:[20/40] Total Loss: 10.731148 GL_Loss: 0.324897 CRF_Loss: 10.406250\n",
      "[2022-03-02 15:33:59,973 - trainer - INFO] - Train Epoch:[50/100] Step:[30/40] Total Loss: 10.141985 GL_Loss: 0.285540 CRF_Loss: 9.856445\n",
      "[2022-03-02 15:34:44,896 - trainer - INFO] - Train Epoch:[50/100] Step:[40/40] Total Loss: 10.787384 GL_Loss: 0.303985 CRF_Loss: 10.483398\n",
      "[2022-03-02 15:35:02,550 - trainer - INFO] - [Epoch Validation] Epoch:[50/100] Total Loss: 10.584849 GL_Loss: 0.003176 CRF_Loss: 10.267261 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 15:35:45,972 - trainer - INFO] - Train Epoch:[51/100] Step:[10/40] Total Loss: 10.310120 GL_Loss: 0.343323 CRF_Loss: 9.966797\n",
      "[2022-03-02 15:36:28,499 - trainer - INFO] - Train Epoch:[51/100] Step:[20/40] Total Loss: 10.680399 GL_Loss: 0.301493 CRF_Loss: 10.378906\n",
      "[2022-03-02 15:37:11,178 - trainer - INFO] - Train Epoch:[51/100] Step:[30/40] Total Loss: 10.843973 GL_Loss: 0.315653 CRF_Loss: 10.528320\n",
      "[2022-03-02 15:37:53,590 - trainer - INFO] - Train Epoch:[51/100] Step:[40/40] Total Loss: 10.981815 GL_Loss: 0.297245 CRF_Loss: 10.684570\n",
      "[2022-03-02 15:38:09,101 - trainer - INFO] - [Epoch Validation] Epoch:[51/100] Total Loss: 10.591566 GL_Loss: 0.003188 CRF_Loss: 10.272754 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 15:38:51,233 - trainer - INFO] - Train Epoch:[52/100] Step:[10/40] Total Loss: 11.155256 GL_Loss: 0.276351 CRF_Loss: 10.878906\n",
      "[2022-03-02 15:39:33,750 - trainer - INFO] - Train Epoch:[52/100] Step:[20/40] Total Loss: 10.517183 GL_Loss: 0.343355 CRF_Loss: 10.173828\n",
      "[2022-03-02 15:40:15,969 - trainer - INFO] - Train Epoch:[52/100] Step:[30/40] Total Loss: 10.661976 GL_Loss: 0.300647 CRF_Loss: 10.361328\n",
      "[2022-03-02 15:40:58,210 - trainer - INFO] - Train Epoch:[52/100] Step:[40/40] Total Loss: 11.218510 GL_Loss: 0.308353 CRF_Loss: 10.910156\n",
      "[2022-03-02 15:41:13,459 - trainer - INFO] - [Epoch Validation] Epoch:[52/100] Total Loss: 10.530825 GL_Loss: 0.003143 CRF_Loss: 10.216528 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-02 15:41:55,790 - trainer - INFO] - Train Epoch:[53/100] Step:[10/40] Total Loss: 9.899561 GL_Loss: 0.297998 CRF_Loss: 9.601562\n",
      "[2022-03-02 15:42:37,928 - trainer - INFO] - Train Epoch:[53/100] Step:[20/40] Total Loss: 10.791719 GL_Loss: 0.313204 CRF_Loss: 10.478516\n",
      "[2022-03-02 15:43:20,327 - trainer - INFO] - Train Epoch:[53/100] Step:[30/40] Total Loss: 10.774463 GL_Loss: 0.310596 CRF_Loss: 10.463867\n",
      "[2022-03-02 15:44:02,355 - trainer - INFO] - Train Epoch:[53/100] Step:[40/40] Total Loss: 9.822470 GL_Loss: 0.316610 CRF_Loss: 9.505859\n",
      "[2022-03-02 15:44:17,623 - trainer - INFO] - [Epoch Validation] Epoch:[53/100] Total Loss: 10.502600 GL_Loss: 0.003139 CRF_Loss: 10.188721 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 15:44:59,802 - trainer - INFO] - Train Epoch:[54/100] Step:[10/40] Total Loss: 9.618958 GL_Loss: 0.302551 CRF_Loss: 9.316406\n",
      "[2022-03-02 15:45:41,257 - trainer - INFO] - Train Epoch:[54/100] Step:[20/40] Total Loss: 10.062860 GL_Loss: 0.320673 CRF_Loss: 9.742188\n",
      "[2022-03-02 15:46:23,920 - trainer - INFO] - Train Epoch:[54/100] Step:[30/40] Total Loss: 10.942665 GL_Loss: 0.313758 CRF_Loss: 10.628906\n",
      "[2022-03-02 15:47:06,178 - trainer - INFO] - Train Epoch:[54/100] Step:[40/40] Total Loss: 10.286331 GL_Loss: 0.307815 CRF_Loss: 9.978516\n",
      "[2022-03-02 15:47:21,439 - trainer - INFO] - [Epoch Validation] Epoch:[54/100] Total Loss: 10.318756 GL_Loss: 0.003147 CRF_Loss: 10.004102 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 15:48:03,957 - trainer - INFO] - Train Epoch:[55/100] Step:[10/40] Total Loss: 9.883018 GL_Loss: 0.304893 CRF_Loss: 9.578125\n",
      "[2022-03-02 15:48:46,586 - trainer - INFO] - Train Epoch:[55/100] Step:[20/40] Total Loss: 9.959890 GL_Loss: 0.314383 CRF_Loss: 9.645508\n",
      "[2022-03-02 15:49:29,179 - trainer - INFO] - Train Epoch:[55/100] Step:[30/40] Total Loss: 9.915196 GL_Loss: 0.301915 CRF_Loss: 9.613281\n",
      "[2022-03-02 15:50:11,758 - trainer - INFO] - Train Epoch:[55/100] Step:[40/40] Total Loss: 10.228109 GL_Loss: 0.332602 CRF_Loss: 9.895508\n",
      "[2022-03-02 15:50:27,311 - trainer - INFO] - [Epoch Validation] Epoch:[55/100] Total Loss: 10.269693 GL_Loss: 0.003117 CRF_Loss: 9.957959 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-02 15:51:10,110 - trainer - INFO] - Train Epoch:[56/100] Step:[10/40] Total Loss: 9.259822 GL_Loss: 0.294978 CRF_Loss: 8.964844\n",
      "[2022-03-02 15:51:52,520 - trainer - INFO] - Train Epoch:[56/100] Step:[20/40] Total Loss: 10.537332 GL_Loss: 0.302957 CRF_Loss: 10.234375\n",
      "[2022-03-02 15:52:34,822 - trainer - INFO] - Train Epoch:[56/100] Step:[30/40] Total Loss: 10.740634 GL_Loss: 0.322665 CRF_Loss: 10.417969\n",
      "[2022-03-02 15:53:16,941 - trainer - INFO] - Train Epoch:[56/100] Step:[40/40] Total Loss: 10.541338 GL_Loss: 0.322588 CRF_Loss: 10.218750\n",
      "[2022-03-02 15:53:32,410 - trainer - INFO] - [Epoch Validation] Epoch:[56/100] Total Loss: 10.239214 GL_Loss: 0.003131 CRF_Loss: 9.926123 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 15:54:14,886 - trainer - INFO] - Train Epoch:[57/100] Step:[10/40] Total Loss: 9.885882 GL_Loss: 0.297992 CRF_Loss: 9.587891\n",
      "[2022-03-02 15:54:57,244 - trainer - INFO] - Train Epoch:[57/100] Step:[20/40] Total Loss: 10.423558 GL_Loss: 0.296605 CRF_Loss: 10.126953\n",
      "[2022-03-02 15:55:39,786 - trainer - INFO] - Train Epoch:[57/100] Step:[30/40] Total Loss: 9.361111 GL_Loss: 0.316189 CRF_Loss: 9.044922\n",
      "[2022-03-02 15:56:22,322 - trainer - INFO] - Train Epoch:[57/100] Step:[40/40] Total Loss: 9.628184 GL_Loss: 0.313731 CRF_Loss: 9.314453\n",
      "[2022-03-02 15:56:37,952 - trainer - INFO] - [Epoch Validation] Epoch:[57/100] Total Loss: 10.104625 GL_Loss: 0.003118 CRF_Loss: 9.792798 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 15:57:20,686 - trainer - INFO] - Train Epoch:[58/100] Step:[10/40] Total Loss: 9.131379 GL_Loss: 0.311067 CRF_Loss: 8.820312\n",
      "[2022-03-02 15:58:02,880 - trainer - INFO] - Train Epoch:[58/100] Step:[20/40] Total Loss: 10.331429 GL_Loss: 0.326547 CRF_Loss: 10.004883\n",
      "[2022-03-02 15:58:44,763 - trainer - INFO] - Train Epoch:[58/100] Step:[30/40] Total Loss: 10.176015 GL_Loss: 0.287343 CRF_Loss: 9.888672\n",
      "[2022-03-02 15:59:27,011 - trainer - INFO] - Train Epoch:[58/100] Step:[40/40] Total Loss: 10.070776 GL_Loss: 0.316870 CRF_Loss: 9.753906\n",
      "[2022-03-02 15:59:42,573 - trainer - INFO] - [Epoch Validation] Epoch:[58/100] Total Loss: 9.994560 GL_Loss: 0.003121 CRF_Loss: 9.682471 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-02 16:00:25,294 - trainer - INFO] - Train Epoch:[59/100] Step:[10/40] Total Loss: 9.235363 GL_Loss: 0.305676 CRF_Loss: 8.929688\n",
      "[2022-03-02 16:01:07,607 - trainer - INFO] - Train Epoch:[59/100] Step:[20/40] Total Loss: 9.679097 GL_Loss: 0.296285 CRF_Loss: 9.382812\n",
      "[2022-03-02 16:01:49,945 - trainer - INFO] - Train Epoch:[59/100] Step:[30/40] Total Loss: 9.660267 GL_Loss: 0.306751 CRF_Loss: 9.353516\n",
      "[2022-03-02 16:02:32,566 - trainer - INFO] - Train Epoch:[59/100] Step:[40/40] Total Loss: 10.495586 GL_Loss: 0.320781 CRF_Loss: 10.174805\n",
      "[2022-03-02 16:02:48,035 - trainer - INFO] - [Epoch Validation] Epoch:[59/100] Total Loss: 9.984822 GL_Loss: 0.003087 CRF_Loss: 9.676123 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 16:03:30,185 - trainer - INFO] - Train Epoch:[60/100] Step:[10/40] Total Loss: 9.937529 GL_Loss: 0.303739 CRF_Loss: 9.633789\n",
      "[2022-03-02 16:04:12,395 - trainer - INFO] - Train Epoch:[60/100] Step:[20/40] Total Loss: 9.866695 GL_Loss: 0.292477 CRF_Loss: 9.574219\n",
      "[2022-03-02 16:04:54,417 - trainer - INFO] - Train Epoch:[60/100] Step:[30/40] Total Loss: 9.954931 GL_Loss: 0.346533 CRF_Loss: 9.608398\n",
      "[2022-03-02 16:05:37,252 - trainer - INFO] - Train Epoch:[60/100] Step:[40/40] Total Loss: 9.961159 GL_Loss: 0.295143 CRF_Loss: 9.666016\n",
      "[2022-03-02 16:05:52,401 - trainer - INFO] - [Epoch Validation] Epoch:[60/100] Total Loss: 9.921567 GL_Loss: 0.003076 CRF_Loss: 9.614014 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 16:05:54,642 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-03-02 16:06:37,084 - trainer - INFO] - Train Epoch:[61/100] Step:[10/40] Total Loss: 9.506328 GL_Loss: 0.266094 CRF_Loss: 9.240234\n",
      "[2022-03-02 16:07:19,347 - trainer - INFO] - Train Epoch:[61/100] Step:[20/40] Total Loss: 9.898985 GL_Loss: 0.324767 CRF_Loss: 9.574219\n",
      "[2022-03-02 16:08:01,623 - trainer - INFO] - Train Epoch:[61/100] Step:[30/40] Total Loss: 9.836255 GL_Loss: 0.303052 CRF_Loss: 9.533203\n",
      "[2022-03-02 16:08:43,452 - trainer - INFO] - Train Epoch:[61/100] Step:[40/40] Total Loss: 10.425273 GL_Loss: 0.303203 CRF_Loss: 10.122070\n",
      "[2022-03-02 16:08:58,960 - trainer - INFO] - [Epoch Validation] Epoch:[61/100] Total Loss: 9.855724 GL_Loss: 0.003109 CRF_Loss: 9.544873 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-02 16:09:41,543 - trainer - INFO] - Train Epoch:[62/100] Step:[10/40] Total Loss: 10.003846 GL_Loss: 0.330018 CRF_Loss: 9.673828\n",
      "[2022-03-02 16:10:23,670 - trainer - INFO] - Train Epoch:[62/100] Step:[20/40] Total Loss: 9.332971 GL_Loss: 0.294884 CRF_Loss: 9.038086\n",
      "[2022-03-02 16:11:05,501 - trainer - INFO] - Train Epoch:[62/100] Step:[30/40] Total Loss: 10.407415 GL_Loss: 0.325385 CRF_Loss: 10.082031\n",
      "[2022-03-02 16:11:47,839 - trainer - INFO] - Train Epoch:[62/100] Step:[40/40] Total Loss: 9.949248 GL_Loss: 0.316436 CRF_Loss: 9.632812\n",
      "[2022-03-02 16:12:03,550 - trainer - INFO] - [Epoch Validation] Epoch:[62/100] Total Loss: 9.867643 GL_Loss: 0.003075 CRF_Loss: 9.560107 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 16:12:48,354 - trainer - INFO] - Train Epoch:[63/100] Step:[10/40] Total Loss: 10.820701 GL_Loss: 0.294334 CRF_Loss: 10.526367\n",
      "[2022-03-02 16:13:31,810 - trainer - INFO] - Train Epoch:[63/100] Step:[20/40] Total Loss: 9.630580 GL_Loss: 0.310267 CRF_Loss: 9.320312\n",
      "[2022-03-02 16:14:14,051 - trainer - INFO] - Train Epoch:[63/100] Step:[30/40] Total Loss: 10.405479 GL_Loss: 0.317589 CRF_Loss: 10.087891\n",
      "[2022-03-02 16:14:56,613 - trainer - INFO] - Train Epoch:[63/100] Step:[40/40] Total Loss: 9.634429 GL_Loss: 0.310210 CRF_Loss: 9.324219\n",
      "[2022-03-02 16:15:12,328 - trainer - INFO] - [Epoch Validation] Epoch:[63/100] Total Loss: 9.847642 GL_Loss: 0.003080 CRF_Loss: 9.539673 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 16:15:55,204 - trainer - INFO] - Train Epoch:[64/100] Step:[10/40] Total Loss: 9.607750 GL_Loss: 0.318688 CRF_Loss: 9.289062\n",
      "[2022-03-02 16:16:37,496 - trainer - INFO] - Train Epoch:[64/100] Step:[20/40] Total Loss: 9.991167 GL_Loss: 0.295854 CRF_Loss: 9.695312\n",
      "[2022-03-02 16:17:20,083 - trainer - INFO] - Train Epoch:[64/100] Step:[30/40] Total Loss: 9.152281 GL_Loss: 0.294859 CRF_Loss: 8.857422\n",
      "[2022-03-02 16:18:02,556 - trainer - INFO] - Train Epoch:[64/100] Step:[40/40] Total Loss: 9.277399 GL_Loss: 0.312555 CRF_Loss: 8.964844\n",
      "[2022-03-02 16:18:18,122 - trainer - INFO] - [Epoch Validation] Epoch:[64/100] Total Loss: 9.768455 GL_Loss: 0.003071 CRF_Loss: 9.461328 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-02 16:19:01,042 - trainer - INFO] - Train Epoch:[65/100] Step:[10/40] Total Loss: 10.554153 GL_Loss: 0.295364 CRF_Loss: 10.258789\n",
      "[2022-03-02 16:19:43,929 - trainer - INFO] - Train Epoch:[65/100] Step:[20/40] Total Loss: 9.606312 GL_Loss: 0.311390 CRF_Loss: 9.294922\n",
      "[2022-03-02 16:20:25,947 - trainer - INFO] - Train Epoch:[65/100] Step:[30/40] Total Loss: 9.665820 GL_Loss: 0.304492 CRF_Loss: 9.361328\n",
      "[2022-03-02 16:21:08,194 - trainer - INFO] - Train Epoch:[65/100] Step:[40/40] Total Loss: 9.925928 GL_Loss: 0.325343 CRF_Loss: 9.600586\n",
      "[2022-03-02 16:21:23,679 - trainer - INFO] - [Epoch Validation] Epoch:[65/100] Total Loss: 9.906516 GL_Loss: 0.003127 CRF_Loss: 9.593799 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 16:22:06,129 - trainer - INFO] - Train Epoch:[66/100] Step:[10/40] Total Loss: 9.678225 GL_Loss: 0.293459 CRF_Loss: 9.384766\n",
      "[2022-03-02 16:22:48,286 - trainer - INFO] - Train Epoch:[66/100] Step:[20/40] Total Loss: 10.068630 GL_Loss: 0.309841 CRF_Loss: 9.758789\n",
      "[2022-03-02 16:23:30,505 - trainer - INFO] - Train Epoch:[66/100] Step:[30/40] Total Loss: 9.372303 GL_Loss: 0.325428 CRF_Loss: 9.046875\n",
      "[2022-03-02 16:24:12,919 - trainer - INFO] - Train Epoch:[66/100] Step:[40/40] Total Loss: 10.210368 GL_Loss: 0.309001 CRF_Loss: 9.901367\n",
      "[2022-03-02 16:24:28,430 - trainer - INFO] - [Epoch Validation] Epoch:[66/100] Total Loss: 9.845664 GL_Loss: 0.003071 CRF_Loss: 9.538574 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 16:25:10,983 - trainer - INFO] - Train Epoch:[67/100] Step:[10/40] Total Loss: 10.306006 GL_Loss: 0.292335 CRF_Loss: 10.013672\n",
      "[2022-03-02 16:25:52,693 - trainer - INFO] - Train Epoch:[67/100] Step:[20/40] Total Loss: 9.724493 GL_Loss: 0.324102 CRF_Loss: 9.400391\n",
      "[2022-03-02 16:26:35,325 - trainer - INFO] - Train Epoch:[67/100] Step:[30/40] Total Loss: 9.362296 GL_Loss: 0.306632 CRF_Loss: 9.055664\n",
      "[2022-03-02 16:27:17,649 - trainer - INFO] - Train Epoch:[67/100] Step:[40/40] Total Loss: 9.657424 GL_Loss: 0.312698 CRF_Loss: 9.344727\n",
      "[2022-03-02 16:27:33,295 - trainer - INFO] - [Epoch Validation] Epoch:[67/100] Total Loss: 9.772729 GL_Loss: 0.003069 CRF_Loss: 9.465820 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-02 16:28:15,696 - trainer - INFO] - Train Epoch:[68/100] Step:[10/40] Total Loss: 10.298110 GL_Loss: 0.308852 CRF_Loss: 9.989258\n",
      "[2022-03-02 16:28:57,665 - trainer - INFO] - Train Epoch:[68/100] Step:[20/40] Total Loss: 10.087177 GL_Loss: 0.314716 CRF_Loss: 9.772461\n",
      "[2022-03-02 16:29:40,556 - trainer - INFO] - Train Epoch:[68/100] Step:[30/40] Total Loss: 9.413285 GL_Loss: 0.305863 CRF_Loss: 9.107422\n",
      "[2022-03-02 16:30:22,999 - trainer - INFO] - Train Epoch:[68/100] Step:[40/40] Total Loss: 9.787768 GL_Loss: 0.313159 CRF_Loss: 9.474609\n",
      "[2022-03-02 16:30:38,587 - trainer - INFO] - [Epoch Validation] Epoch:[68/100] Total Loss: 9.842792 GL_Loss: 0.003142 CRF_Loss: 9.528589 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 16:31:21,012 - trainer - INFO] - Train Epoch:[69/100] Step:[10/40] Total Loss: 10.142335 GL_Loss: 0.305421 CRF_Loss: 9.836914\n",
      "[2022-03-02 16:32:03,246 - trainer - INFO] - Train Epoch:[69/100] Step:[20/40] Total Loss: 10.139441 GL_Loss: 0.297644 CRF_Loss: 9.841797\n",
      "[2022-03-02 16:32:45,546 - trainer - INFO] - Train Epoch:[69/100] Step:[30/40] Total Loss: 9.735875 GL_Loss: 0.282750 CRF_Loss: 9.453125\n",
      "[2022-03-02 16:33:28,305 - trainer - INFO] - Train Epoch:[69/100] Step:[40/40] Total Loss: 9.319388 GL_Loss: 0.333060 CRF_Loss: 8.986328\n",
      "[2022-03-02 16:33:43,811 - trainer - INFO] - [Epoch Validation] Epoch:[69/100] Total Loss: 9.778021 GL_Loss: 0.003100 CRF_Loss: 9.468018 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 16:34:26,612 - trainer - INFO] - Train Epoch:[70/100] Step:[10/40] Total Loss: 9.696873 GL_Loss: 0.343357 CRF_Loss: 9.353516\n",
      "[2022-03-02 16:35:09,045 - trainer - INFO] - Train Epoch:[70/100] Step:[20/40] Total Loss: 9.739619 GL_Loss: 0.313838 CRF_Loss: 9.425781\n",
      "[2022-03-02 16:35:51,418 - trainer - INFO] - Train Epoch:[70/100] Step:[30/40] Total Loss: 9.399804 GL_Loss: 0.320703 CRF_Loss: 9.079102\n",
      "[2022-03-02 16:36:33,264 - trainer - INFO] - Train Epoch:[70/100] Step:[40/40] Total Loss: 9.725248 GL_Loss: 0.315092 CRF_Loss: 9.410156\n",
      "[2022-03-02 16:36:48,902 - trainer - INFO] - [Epoch Validation] Epoch:[70/100] Total Loss: 9.758800 GL_Loss: 0.003094 CRF_Loss: 9.449414 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-02 16:37:30,883 - trainer - INFO] - Train Epoch:[71/100] Step:[10/40] Total Loss: 9.186521 GL_Loss: 0.301755 CRF_Loss: 8.884766\n",
      "[2022-03-02 16:38:13,543 - trainer - INFO] - Train Epoch:[71/100] Step:[20/40] Total Loss: 10.041628 GL_Loss: 0.328737 CRF_Loss: 9.712891\n",
      "[2022-03-02 16:38:56,314 - trainer - INFO] - Train Epoch:[71/100] Step:[30/40] Total Loss: 9.651792 GL_Loss: 0.294369 CRF_Loss: 9.357422\n",
      "[2022-03-02 16:39:38,565 - trainer - INFO] - Train Epoch:[71/100] Step:[40/40] Total Loss: 9.320964 GL_Loss: 0.301432 CRF_Loss: 9.019531\n",
      "[2022-03-02 16:39:54,053 - trainer - INFO] - [Epoch Validation] Epoch:[71/100] Total Loss: 9.817265 GL_Loss: 0.003083 CRF_Loss: 9.508960 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 16:40:37,417 - trainer - INFO] - Train Epoch:[72/100] Step:[10/40] Total Loss: 9.906905 GL_Loss: 0.339522 CRF_Loss: 9.567383\n",
      "[2022-03-02 16:41:19,539 - trainer - INFO] - Train Epoch:[72/100] Step:[20/40] Total Loss: 9.868226 GL_Loss: 0.307680 CRF_Loss: 9.560547\n",
      "[2022-03-02 16:42:01,871 - trainer - INFO] - Train Epoch:[72/100] Step:[30/40] Total Loss: 10.090188 GL_Loss: 0.310892 CRF_Loss: 9.779297\n",
      "[2022-03-02 16:42:43,575 - trainer - INFO] - Train Epoch:[72/100] Step:[40/40] Total Loss: 9.921606 GL_Loss: 0.290746 CRF_Loss: 9.630859\n",
      "[2022-03-02 16:42:59,032 - trainer - INFO] - [Epoch Validation] Epoch:[72/100] Total Loss: 9.696568 GL_Loss: 0.003061 CRF_Loss: 9.390430 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 16:43:41,322 - trainer - INFO] - Train Epoch:[73/100] Step:[10/40] Total Loss: 9.787105 GL_Loss: 0.310542 CRF_Loss: 9.476562\n",
      "[2022-03-02 16:44:22,830 - trainer - INFO] - Train Epoch:[73/100] Step:[20/40] Total Loss: 10.034465 GL_Loss: 0.294230 CRF_Loss: 9.740234\n",
      "[2022-03-02 16:45:05,464 - trainer - INFO] - Train Epoch:[73/100] Step:[30/40] Total Loss: 9.402124 GL_Loss: 0.292749 CRF_Loss: 9.109375\n",
      "[2022-03-02 16:45:48,168 - trainer - INFO] - Train Epoch:[73/100] Step:[40/40] Total Loss: 9.158970 GL_Loss: 0.295688 CRF_Loss: 8.863281\n",
      "[2022-03-02 16:46:03,923 - trainer - INFO] - [Epoch Validation] Epoch:[73/100] Total Loss: 9.794375 GL_Loss: 0.003075 CRF_Loss: 9.486865 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-02 16:46:46,715 - trainer - INFO] - Train Epoch:[74/100] Step:[10/40] Total Loss: 9.458714 GL_Loss: 0.302464 CRF_Loss: 9.156250\n",
      "[2022-03-02 16:47:29,119 - trainer - INFO] - Train Epoch:[74/100] Step:[20/40] Total Loss: 9.065346 GL_Loss: 0.288002 CRF_Loss: 8.777344\n",
      "[2022-03-02 16:48:11,110 - trainer - INFO] - Train Epoch:[74/100] Step:[30/40] Total Loss: 9.842694 GL_Loss: 0.317304 CRF_Loss: 9.525391\n",
      "[2022-03-02 16:48:53,516 - trainer - INFO] - Train Epoch:[74/100] Step:[40/40] Total Loss: 10.165966 GL_Loss: 0.304638 CRF_Loss: 9.861328\n",
      "[2022-03-02 16:49:09,073 - trainer - INFO] - [Epoch Validation] Epoch:[74/100] Total Loss: 9.703353 GL_Loss: 0.003088 CRF_Loss: 9.394580 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 16:49:51,966 - trainer - INFO] - Train Epoch:[75/100] Step:[10/40] Total Loss: 9.454003 GL_Loss: 0.310449 CRF_Loss: 9.143555\n",
      "[2022-03-02 16:50:34,503 - trainer - INFO] - Train Epoch:[75/100] Step:[20/40] Total Loss: 9.178912 GL_Loss: 0.298053 CRF_Loss: 8.880859\n",
      "[2022-03-02 16:51:16,591 - trainer - INFO] - Train Epoch:[75/100] Step:[30/40] Total Loss: 10.099967 GL_Loss: 0.285514 CRF_Loss: 9.814453\n",
      "[2022-03-02 16:51:58,610 - trainer - INFO] - Train Epoch:[75/100] Step:[40/40] Total Loss: 9.298845 GL_Loss: 0.293962 CRF_Loss: 9.004883\n",
      "[2022-03-02 16:52:14,086 - trainer - INFO] - [Epoch Validation] Epoch:[75/100] Total Loss: 9.709136 GL_Loss: 0.003061 CRF_Loss: 9.403027 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 16:52:57,359 - trainer - INFO] - Train Epoch:[76/100] Step:[10/40] Total Loss: 9.753290 GL_Loss: 0.292353 CRF_Loss: 9.460938\n",
      "[2022-03-02 16:53:39,243 - trainer - INFO] - Train Epoch:[76/100] Step:[20/40] Total Loss: 10.180882 GL_Loss: 0.310764 CRF_Loss: 9.870117\n",
      "[2022-03-02 16:54:21,570 - trainer - INFO] - Train Epoch:[76/100] Step:[30/40] Total Loss: 9.974701 GL_Loss: 0.320405 CRF_Loss: 9.654297\n",
      "[2022-03-02 16:55:03,797 - trainer - INFO] - Train Epoch:[76/100] Step:[40/40] Total Loss: 10.220567 GL_Loss: 0.298692 CRF_Loss: 9.921875\n",
      "[2022-03-02 16:55:19,397 - trainer - INFO] - [Epoch Validation] Epoch:[76/100] Total Loss: 9.728857 GL_Loss: 0.003083 CRF_Loss: 9.420605 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-02 16:56:02,256 - trainer - INFO] - Train Epoch:[77/100] Step:[10/40] Total Loss: 9.375499 GL_Loss: 0.298350 CRF_Loss: 9.077148\n",
      "[2022-03-02 16:56:44,364 - trainer - INFO] - Train Epoch:[77/100] Step:[20/40] Total Loss: 9.112799 GL_Loss: 0.294439 CRF_Loss: 8.818359\n",
      "[2022-03-02 16:57:26,510 - trainer - INFO] - Train Epoch:[77/100] Step:[30/40] Total Loss: 9.858179 GL_Loss: 0.298609 CRF_Loss: 9.559570\n",
      "[2022-03-02 16:58:08,667 - trainer - INFO] - Train Epoch:[77/100] Step:[40/40] Total Loss: 9.381095 GL_Loss: 0.316642 CRF_Loss: 9.064453\n",
      "[2022-03-02 16:58:24,134 - trainer - INFO] - [Epoch Validation] Epoch:[77/100] Total Loss: 9.731710 GL_Loss: 0.003104 CRF_Loss: 9.421313 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 16:59:06,918 - trainer - INFO] - Train Epoch:[78/100] Step:[10/40] Total Loss: 9.498520 GL_Loss: 0.295395 CRF_Loss: 9.203125\n",
      "[2022-03-02 16:59:49,223 - trainer - INFO] - Train Epoch:[78/100] Step:[20/40] Total Loss: 9.336213 GL_Loss: 0.303010 CRF_Loss: 9.033203\n",
      "[2022-03-02 17:00:31,474 - trainer - INFO] - Train Epoch:[78/100] Step:[30/40] Total Loss: 9.885366 GL_Loss: 0.313101 CRF_Loss: 9.572266\n",
      "[2022-03-02 17:01:13,792 - trainer - INFO] - Train Epoch:[78/100] Step:[40/40] Total Loss: 9.359224 GL_Loss: 0.318209 CRF_Loss: 9.041016\n",
      "[2022-03-02 17:01:29,257 - trainer - INFO] - [Epoch Validation] Epoch:[78/100] Total Loss: 9.637277 GL_Loss: 0.003072 CRF_Loss: 9.330078 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 17:02:11,663 - trainer - INFO] - Train Epoch:[79/100] Step:[10/40] Total Loss: 9.814059 GL_Loss: 0.292575 CRF_Loss: 9.521484\n",
      "[2022-03-02 17:02:54,588 - trainer - INFO] - Train Epoch:[79/100] Step:[20/40] Total Loss: 9.600800 GL_Loss: 0.337128 CRF_Loss: 9.263672\n",
      "[2022-03-02 17:03:36,096 - trainer - INFO] - Train Epoch:[79/100] Step:[30/40] Total Loss: 9.275798 GL_Loss: 0.322673 CRF_Loss: 8.953125\n",
      "[2022-03-02 17:04:17,630 - trainer - INFO] - Train Epoch:[79/100] Step:[40/40] Total Loss: 9.301329 GL_Loss: 0.305235 CRF_Loss: 8.996094\n",
      "[2022-03-02 17:04:33,416 - trainer - INFO] - [Epoch Validation] Epoch:[79/100] Total Loss: 9.747288 GL_Loss: 0.003024 CRF_Loss: 9.444897 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-02 17:05:16,365 - trainer - INFO] - Train Epoch:[80/100] Step:[10/40] Total Loss: 9.420521 GL_Loss: 0.313099 CRF_Loss: 9.107422\n",
      "[2022-03-02 17:05:58,486 - trainer - INFO] - Train Epoch:[80/100] Step:[20/40] Total Loss: 9.305551 GL_Loss: 0.336801 CRF_Loss: 8.968750\n",
      "[2022-03-02 17:06:40,354 - trainer - INFO] - Train Epoch:[80/100] Step:[30/40] Total Loss: 9.675955 GL_Loss: 0.317556 CRF_Loss: 9.358398\n",
      "[2022-03-02 17:07:22,483 - trainer - INFO] - Train Epoch:[80/100] Step:[40/40] Total Loss: 9.433541 GL_Loss: 0.321237 CRF_Loss: 9.112305\n",
      "[2022-03-02 17:07:38,203 - trainer - INFO] - [Epoch Validation] Epoch:[80/100] Total Loss: 9.745151 GL_Loss: 0.003065 CRF_Loss: 9.438696 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 17:07:40,442 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-03-02 17:08:23,023 - trainer - INFO] - Train Epoch:[81/100] Step:[10/40] Total Loss: 9.880472 GL_Loss: 0.313090 CRF_Loss: 9.567383\n",
      "[2022-03-02 17:09:05,397 - trainer - INFO] - Train Epoch:[81/100] Step:[20/40] Total Loss: 9.841913 GL_Loss: 0.294062 CRF_Loss: 9.547852\n",
      "[2022-03-02 17:09:47,719 - trainer - INFO] - Train Epoch:[81/100] Step:[30/40] Total Loss: 9.789285 GL_Loss: 0.297097 CRF_Loss: 9.492188\n",
      "[2022-03-02 17:10:29,962 - trainer - INFO] - Train Epoch:[81/100] Step:[40/40] Total Loss: 9.852674 GL_Loss: 0.324353 CRF_Loss: 9.528320\n",
      "[2022-03-02 17:10:45,653 - trainer - INFO] - [Epoch Validation] Epoch:[81/100] Total Loss: 9.728588 GL_Loss: 0.003072 CRF_Loss: 9.421436 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 17:11:28,421 - trainer - INFO] - Train Epoch:[82/100] Step:[10/40] Total Loss: 9.389824 GL_Loss: 0.309746 CRF_Loss: 9.080078\n",
      "[2022-03-02 17:12:11,009 - trainer - INFO] - Train Epoch:[82/100] Step:[20/40] Total Loss: 9.208912 GL_Loss: 0.310475 CRF_Loss: 8.898438\n",
      "[2022-03-02 17:12:53,143 - trainer - INFO] - Train Epoch:[82/100] Step:[30/40] Total Loss: 10.457458 GL_Loss: 0.300231 CRF_Loss: 10.157227\n",
      "[2022-03-02 17:13:35,170 - trainer - INFO] - Train Epoch:[82/100] Step:[40/40] Total Loss: 9.234523 GL_Loss: 0.283351 CRF_Loss: 8.951172\n",
      "[2022-03-02 17:13:50,773 - trainer - INFO] - [Epoch Validation] Epoch:[82/100] Total Loss: 9.700735 GL_Loss: 0.003072 CRF_Loss: 9.393555 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-02 17:14:33,346 - trainer - INFO] - Train Epoch:[83/100] Step:[10/40] Total Loss: 9.608113 GL_Loss: 0.332722 CRF_Loss: 9.275391\n",
      "[2022-03-02 17:15:15,486 - trainer - INFO] - Train Epoch:[83/100] Step:[20/40] Total Loss: 9.370397 GL_Loss: 0.297155 CRF_Loss: 9.073242\n",
      "[2022-03-02 17:15:57,180 - trainer - INFO] - Train Epoch:[83/100] Step:[30/40] Total Loss: 9.641140 GL_Loss: 0.292507 CRF_Loss: 9.348633\n",
      "[2022-03-02 17:16:40,073 - trainer - INFO] - Train Epoch:[83/100] Step:[40/40] Total Loss: 9.677086 GL_Loss: 0.316734 CRF_Loss: 9.360352\n",
      "[2022-03-02 17:16:57,721 - trainer - INFO] - [Epoch Validation] Epoch:[83/100] Total Loss: 9.658247 GL_Loss: 0.003084 CRF_Loss: 9.349854 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 17:17:40,082 - trainer - INFO] - Train Epoch:[84/100] Step:[10/40] Total Loss: 9.271031 GL_Loss: 0.292516 CRF_Loss: 8.978516\n",
      "[2022-03-02 17:18:22,655 - trainer - INFO] - Train Epoch:[84/100] Step:[20/40] Total Loss: 10.248753 GL_Loss: 0.318088 CRF_Loss: 9.930664\n",
      "[2022-03-02 17:19:05,171 - trainer - INFO] - Train Epoch:[84/100] Step:[30/40] Total Loss: 9.330477 GL_Loss: 0.305086 CRF_Loss: 9.025391\n",
      "[2022-03-02 17:19:47,723 - trainer - INFO] - Train Epoch:[84/100] Step:[40/40] Total Loss: 9.807282 GL_Loss: 0.297516 CRF_Loss: 9.509766\n",
      "[2022-03-02 17:20:03,383 - trainer - INFO] - [Epoch Validation] Epoch:[84/100] Total Loss: 9.690133 GL_Loss: 0.003087 CRF_Loss: 9.381396 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 17:20:46,116 - trainer - INFO] - Train Epoch:[85/100] Step:[10/40] Total Loss: 9.390822 GL_Loss: 0.300978 CRF_Loss: 9.089844\n",
      "[2022-03-02 17:21:28,445 - trainer - INFO] - Train Epoch:[85/100] Step:[20/40] Total Loss: 9.118057 GL_Loss: 0.287979 CRF_Loss: 8.830078\n",
      "[2022-03-02 17:22:10,907 - trainer - INFO] - Train Epoch:[85/100] Step:[30/40] Total Loss: 9.549655 GL_Loss: 0.314303 CRF_Loss: 9.235352\n",
      "[2022-03-02 17:22:53,330 - trainer - INFO] - Train Epoch:[85/100] Step:[40/40] Total Loss: 9.638650 GL_Loss: 0.323220 CRF_Loss: 9.315430\n",
      "[2022-03-02 17:23:08,864 - trainer - INFO] - [Epoch Validation] Epoch:[85/100] Total Loss: 9.658781 GL_Loss: 0.003046 CRF_Loss: 9.354224 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-02 17:23:51,338 - trainer - INFO] - Train Epoch:[86/100] Step:[10/40] Total Loss: 9.302461 GL_Loss: 0.299531 CRF_Loss: 9.002930\n",
      "[2022-03-02 17:24:33,905 - trainer - INFO] - Train Epoch:[86/100] Step:[20/40] Total Loss: 9.529524 GL_Loss: 0.306867 CRF_Loss: 9.222656\n",
      "[2022-03-02 17:25:16,087 - trainer - INFO] - Train Epoch:[86/100] Step:[30/40] Total Loss: 9.736882 GL_Loss: 0.310125 CRF_Loss: 9.426758\n",
      "[2022-03-02 17:25:58,830 - trainer - INFO] - Train Epoch:[86/100] Step:[40/40] Total Loss: 9.629030 GL_Loss: 0.326296 CRF_Loss: 9.302734\n",
      "[2022-03-02 17:26:14,318 - trainer - INFO] - [Epoch Validation] Epoch:[86/100] Total Loss: 9.616720 GL_Loss: 0.003060 CRF_Loss: 9.310742 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 17:26:57,318 - trainer - INFO] - Train Epoch:[87/100] Step:[10/40] Total Loss: 9.308936 GL_Loss: 0.328467 CRF_Loss: 8.980469\n",
      "[2022-03-02 17:27:39,376 - trainer - INFO] - Train Epoch:[87/100] Step:[20/40] Total Loss: 9.644904 GL_Loss: 0.284552 CRF_Loss: 9.360352\n",
      "[2022-03-02 17:28:21,329 - trainer - INFO] - Train Epoch:[87/100] Step:[30/40] Total Loss: 9.668965 GL_Loss: 0.333028 CRF_Loss: 9.335938\n",
      "[2022-03-02 17:29:03,989 - trainer - INFO] - Train Epoch:[87/100] Step:[40/40] Total Loss: 10.122006 GL_Loss: 0.316342 CRF_Loss: 9.805664\n",
      "[2022-03-02 17:29:19,507 - trainer - INFO] - [Epoch Validation] Epoch:[87/100] Total Loss: 9.652601 GL_Loss: 0.003076 CRF_Loss: 9.345020 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 17:30:01,863 - trainer - INFO] - Train Epoch:[88/100] Step:[10/40] Total Loss: 9.651237 GL_Loss: 0.318230 CRF_Loss: 9.333008\n",
      "[2022-03-02 17:30:44,315 - trainer - INFO] - Train Epoch:[88/100] Step:[20/40] Total Loss: 9.597922 GL_Loss: 0.301047 CRF_Loss: 9.296875\n",
      "[2022-03-02 17:31:26,690 - trainer - INFO] - Train Epoch:[88/100] Step:[30/40] Total Loss: 9.651529 GL_Loss: 0.330240 CRF_Loss: 9.321289\n",
      "[2022-03-02 17:32:08,868 - trainer - INFO] - Train Epoch:[88/100] Step:[40/40] Total Loss: 9.761966 GL_Loss: 0.286380 CRF_Loss: 9.475586\n",
      "[2022-03-02 17:32:24,469 - trainer - INFO] - [Epoch Validation] Epoch:[88/100] Total Loss: 9.627348 GL_Loss: 0.003042 CRF_Loss: 9.323145 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-02 17:33:07,984 - trainer - INFO] - Train Epoch:[89/100] Step:[10/40] Total Loss: 9.579285 GL_Loss: 0.334168 CRF_Loss: 9.245117\n",
      "[2022-03-02 17:33:51,446 - trainer - INFO] - Train Epoch:[89/100] Step:[20/40] Total Loss: 9.290477 GL_Loss: 0.296336 CRF_Loss: 8.994141\n",
      "[2022-03-02 17:34:35,507 - trainer - INFO] - Train Epoch:[89/100] Step:[30/40] Total Loss: 9.729114 GL_Loss: 0.301379 CRF_Loss: 9.427734\n",
      "[2022-03-02 17:35:19,024 - trainer - INFO] - Train Epoch:[89/100] Step:[40/40] Total Loss: 9.200666 GL_Loss: 0.306135 CRF_Loss: 8.894531\n",
      "[2022-03-02 17:35:34,777 - trainer - INFO] - [Epoch Validation] Epoch:[89/100] Total Loss: 9.654361 GL_Loss: 0.003036 CRF_Loss: 9.350806 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 17:36:18,912 - trainer - INFO] - Train Epoch:[90/100] Step:[10/40] Total Loss: 9.259986 GL_Loss: 0.320532 CRF_Loss: 8.939453\n",
      "[2022-03-02 17:37:02,364 - trainer - INFO] - Train Epoch:[90/100] Step:[20/40] Total Loss: 9.442242 GL_Loss: 0.285992 CRF_Loss: 9.156250\n",
      "[2022-03-02 17:37:45,790 - trainer - INFO] - Train Epoch:[90/100] Step:[30/40] Total Loss: 9.601623 GL_Loss: 0.308654 CRF_Loss: 9.292969\n",
      "[2022-03-02 17:38:29,206 - trainer - INFO] - Train Epoch:[90/100] Step:[40/40] Total Loss: 9.663088 GL_Loss: 0.285158 CRF_Loss: 9.377930\n",
      "[2022-03-02 17:38:45,014 - trainer - INFO] - [Epoch Validation] Epoch:[90/100] Total Loss: 9.640660 GL_Loss: 0.003041 CRF_Loss: 9.336548 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 17:39:28,527 - trainer - INFO] - Train Epoch:[91/100] Step:[10/40] Total Loss: 10.253924 GL_Loss: 0.298846 CRF_Loss: 9.955078\n",
      "[2022-03-02 17:40:11,158 - trainer - INFO] - Train Epoch:[91/100] Step:[20/40] Total Loss: 9.929797 GL_Loss: 0.308703 CRF_Loss: 9.621094\n",
      "[2022-03-02 17:40:54,509 - trainer - INFO] - Train Epoch:[91/100] Step:[30/40] Total Loss: 10.271121 GL_Loss: 0.308231 CRF_Loss: 9.962891\n",
      "[2022-03-02 17:41:38,828 - trainer - INFO] - Train Epoch:[91/100] Step:[40/40] Total Loss: 8.928462 GL_Loss: 0.299556 CRF_Loss: 8.628906\n",
      "[2022-03-02 17:41:54,460 - trainer - INFO] - [Epoch Validation] Epoch:[91/100] Total Loss: 9.628486 GL_Loss: 0.003048 CRF_Loss: 9.323730 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-02 17:42:38,224 - trainer - INFO] - Train Epoch:[92/100] Step:[10/40] Total Loss: 9.248674 GL_Loss: 0.311175 CRF_Loss: 8.937500\n",
      "[2022-03-02 17:43:21,452 - trainer - INFO] - Train Epoch:[92/100] Step:[20/40] Total Loss: 9.072048 GL_Loss: 0.296657 CRF_Loss: 8.775391\n",
      "[2022-03-02 17:44:04,973 - trainer - INFO] - Train Epoch:[92/100] Step:[30/40] Total Loss: 10.156823 GL_Loss: 0.293542 CRF_Loss: 9.863281\n",
      "[2022-03-02 17:44:48,414 - trainer - INFO] - Train Epoch:[92/100] Step:[40/40] Total Loss: 9.865858 GL_Loss: 0.321913 CRF_Loss: 9.543945\n",
      "[2022-03-02 17:45:03,999 - trainer - INFO] - [Epoch Validation] Epoch:[92/100] Total Loss: 9.650101 GL_Loss: 0.003079 CRF_Loss: 9.342187 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 17:45:47,472 - trainer - INFO] - Train Epoch:[93/100] Step:[10/40] Total Loss: 10.274876 GL_Loss: 0.308079 CRF_Loss: 9.966797\n",
      "[2022-03-02 17:46:31,209 - trainer - INFO] - Train Epoch:[93/100] Step:[20/40] Total Loss: 9.370216 GL_Loss: 0.325295 CRF_Loss: 9.044922\n",
      "[2022-03-02 17:47:14,467 - trainer - INFO] - Train Epoch:[93/100] Step:[30/40] Total Loss: 9.797895 GL_Loss: 0.289107 CRF_Loss: 9.508789\n",
      "[2022-03-02 17:47:57,802 - trainer - INFO] - Train Epoch:[93/100] Step:[40/40] Total Loss: 9.724536 GL_Loss: 0.296801 CRF_Loss: 9.427734\n",
      "[2022-03-02 17:48:13,429 - trainer - INFO] - [Epoch Validation] Epoch:[93/100] Total Loss: 9.736555 GL_Loss: 0.003072 CRF_Loss: 9.429346 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 17:48:56,975 - trainer - INFO] - Train Epoch:[94/100] Step:[10/40] Total Loss: 9.538352 GL_Loss: 0.303977 CRF_Loss: 9.234375\n",
      "[2022-03-02 17:49:40,348 - trainer - INFO] - Train Epoch:[94/100] Step:[20/40] Total Loss: 9.935346 GL_Loss: 0.325971 CRF_Loss: 9.609375\n",
      "[2022-03-02 17:50:23,812 - trainer - INFO] - Train Epoch:[94/100] Step:[30/40] Total Loss: 9.347455 GL_Loss: 0.304486 CRF_Loss: 9.042969\n",
      "[2022-03-02 17:51:07,620 - trainer - INFO] - Train Epoch:[94/100] Step:[40/40] Total Loss: 9.404512 GL_Loss: 0.295138 CRF_Loss: 9.109375\n",
      "[2022-03-02 17:51:23,350 - trainer - INFO] - [Epoch Validation] Epoch:[94/100] Total Loss: 9.614627 GL_Loss: 0.003082 CRF_Loss: 9.306445 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-02 17:52:07,729 - trainer - INFO] - Train Epoch:[95/100] Step:[10/40] Total Loss: 9.327797 GL_Loss: 0.294593 CRF_Loss: 9.033203\n",
      "[2022-03-02 17:52:51,486 - trainer - INFO] - Train Epoch:[95/100] Step:[20/40] Total Loss: 9.607432 GL_Loss: 0.314464 CRF_Loss: 9.292969\n",
      "[2022-03-02 17:53:35,040 - trainer - INFO] - Train Epoch:[95/100] Step:[30/40] Total Loss: 9.933119 GL_Loss: 0.292494 CRF_Loss: 9.640625\n",
      "[2022-03-02 17:54:18,336 - trainer - INFO] - Train Epoch:[95/100] Step:[40/40] Total Loss: 10.072984 GL_Loss: 0.339585 CRF_Loss: 9.733398\n",
      "[2022-03-02 17:54:34,008 - trainer - INFO] - [Epoch Validation] Epoch:[95/100] Total Loss: 9.697668 GL_Loss: 0.003053 CRF_Loss: 9.392334 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 17:55:18,039 - trainer - INFO] - Train Epoch:[96/100] Step:[10/40] Total Loss: 9.375527 GL_Loss: 0.323769 CRF_Loss: 9.051758\n",
      "[2022-03-02 17:56:01,380 - trainer - INFO] - Train Epoch:[96/100] Step:[20/40] Total Loss: 10.175474 GL_Loss: 0.300474 CRF_Loss: 9.875000\n",
      "[2022-03-02 17:56:44,711 - trainer - INFO] - Train Epoch:[96/100] Step:[30/40] Total Loss: 8.977742 GL_Loss: 0.274617 CRF_Loss: 8.703125\n",
      "[2022-03-02 17:57:28,322 - trainer - INFO] - Train Epoch:[96/100] Step:[40/40] Total Loss: 9.901623 GL_Loss: 0.288341 CRF_Loss: 9.613281\n",
      "[2022-03-02 17:57:43,875 - trainer - INFO] - [Epoch Validation] Epoch:[96/100] Total Loss: 9.661685 GL_Loss: 0.003068 CRF_Loss: 9.354907 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 17:58:27,555 - trainer - INFO] - Train Epoch:[97/100] Step:[10/40] Total Loss: 10.112898 GL_Loss: 0.305281 CRF_Loss: 9.807617\n",
      "[2022-03-02 17:59:11,296 - trainer - INFO] - Train Epoch:[97/100] Step:[20/40] Total Loss: 9.284619 GL_Loss: 0.315869 CRF_Loss: 8.968750\n",
      "[2022-03-02 17:59:54,729 - trainer - INFO] - Train Epoch:[97/100] Step:[30/40] Total Loss: 10.190976 GL_Loss: 0.304258 CRF_Loss: 9.886719\n",
      "[2022-03-02 18:00:38,594 - trainer - INFO] - Train Epoch:[97/100] Step:[40/40] Total Loss: 9.338472 GL_Loss: 0.268160 CRF_Loss: 9.070312\n",
      "[2022-03-02 18:00:54,127 - trainer - INFO] - [Epoch Validation] Epoch:[97/100] Total Loss: 9.677015 GL_Loss: 0.003063 CRF_Loss: 9.370703 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-02 18:01:36,922 - trainer - INFO] - Train Epoch:[98/100] Step:[10/40] Total Loss: 9.503158 GL_Loss: 0.308821 CRF_Loss: 9.194336\n",
      "[2022-03-02 18:02:20,692 - trainer - INFO] - Train Epoch:[98/100] Step:[20/40] Total Loss: 9.262951 GL_Loss: 0.356701 CRF_Loss: 8.906250\n",
      "[2022-03-02 18:03:04,143 - trainer - INFO] - Train Epoch:[98/100] Step:[30/40] Total Loss: 9.018577 GL_Loss: 0.295921 CRF_Loss: 8.722656\n",
      "[2022-03-02 18:03:47,678 - trainer - INFO] - Train Epoch:[98/100] Step:[40/40] Total Loss: 10.184498 GL_Loss: 0.317311 CRF_Loss: 9.867188\n",
      "[2022-03-02 18:04:03,309 - trainer - INFO] - [Epoch Validation] Epoch:[98/100] Total Loss: 9.583491 GL_Loss: 0.003044 CRF_Loss: 9.279077 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 18:04:47,026 - trainer - INFO] - Train Epoch:[99/100] Step:[10/40] Total Loss: 9.300750 GL_Loss: 0.292938 CRF_Loss: 9.007812\n",
      "[2022-03-02 18:05:30,339 - trainer - INFO] - Train Epoch:[99/100] Step:[20/40] Total Loss: 9.938913 GL_Loss: 0.315866 CRF_Loss: 9.623047\n",
      "[2022-03-02 18:06:13,769 - trainer - INFO] - Train Epoch:[99/100] Step:[30/40] Total Loss: 8.699225 GL_Loss: 0.285163 CRF_Loss: 8.414062\n",
      "[2022-03-02 18:06:57,337 - trainer - INFO] - Train Epoch:[99/100] Step:[40/40] Total Loss: 9.817983 GL_Loss: 0.310170 CRF_Loss: 9.507812\n",
      "[2022-03-02 18:07:12,927 - trainer - INFO] - [Epoch Validation] Epoch:[99/100] Total Loss: 9.632092 GL_Loss: 0.003049 CRF_Loss: 9.327148 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "[2022-03-02 18:07:56,227 - trainer - INFO] - Train Epoch:[100/100] Step:[10/40] Total Loss: 9.292171 GL_Loss: 0.315609 CRF_Loss: 8.976562\n",
      "[2022-03-02 18:08:40,723 - trainer - INFO] - Train Epoch:[100/100] Step:[20/40] Total Loss: 9.212635 GL_Loss: 0.320057 CRF_Loss: 8.892578\n",
      "[2022-03-02 18:09:24,098 - trainer - INFO] - Train Epoch:[100/100] Step:[30/40] Total Loss: 9.367251 GL_Loss: 0.273501 CRF_Loss: 9.093750\n",
      "[2022-03-02 18:10:08,141 - trainer - INFO] - Train Epoch:[100/100] Step:[40/40] Total Loss: 9.444398 GL_Loss: 0.304749 CRF_Loss: 9.139648\n",
      "[2022-03-02 18:10:23,632 - trainer - INFO] - [Epoch Validation] Epoch:[100/100] Total Loss: 9.616577 GL_Loss: 0.003050 CRF_Loss: 9.311548 \n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name                          |      mEP |      mER |      mEF |      mEA |\n",
      "+===============================+==========+==========+==========+==========+\n",
      "| address_2                     | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| curriculum_vitae              | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| zip_code                      | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| country                       | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_laboratory   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_clinical_investigator | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| names_of_subinvestigators     | 0.25     | 0.125    | 0.166667 | 0.125    |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_irb                   | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| address_1                     | 0.95     | 0.904762 | 0.926829 | 0.904762 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| city                          | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| name_of_medical_school        | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| state                         | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| other_statement               | 1        | 1        | 1        | 1        |\n",
      "+-------------------------------+----------+----------+----------+----------+\n",
      "| overall                       | 0.971831 | 0.938776 | 0.955017 | 0.938776 |\n",
      "+-------------------------------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-02 18:10:25,925 - trainer - INFO] - Saving current best: model_best.pth ...\r\n",
      "[2022-03-02 18:10:25,926 - train - INFO] - Training end...\r\n"
     ]
    }
   ],
   "source": [
    "# FORMs Dataset - Form1572\n",
    "!python3 train.py -c config_dla_original.json -d 0 -dist false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 10:08:52,289 - train - INFO] - One GPU or CPU training mode start...\n",
      "[2022-02-17 10:08:52,299 - train - INFO] - Dataloader instances created. Train datasets: 500 samples Validation datasets: 126 samples.\n",
      "[2022-02-17 10:08:53,036 - train - INFO] - Model created, trainable parameters: 68567386.\n",
      "[2022-02-17 10:08:53,037 - train - INFO] - Optimizer and lr_scheduler created.\n",
      "[2022-02-17 10:08:53,037 - train - INFO] - Max_epochs: 100 Log_per_step: 10 Validation_per_step: 50.\n",
      "[2022-02-17 10:08:53,037 - train - INFO] - Training start...\n",
      "[2022-02-17 10:08:53,065 - trainer - WARNING] - Training is using GPU 0!\n",
      "[2022-02-17 10:09:11,359 - trainer - INFO] - Train Epoch:[1/100] Step:[10/250] Total Loss: 404.605499 GL_Loss: 2.398964 CRF_Loss: 402.206543\n",
      "[2022-02-17 10:09:25,195 - trainer - INFO] - Train Epoch:[1/100] Step:[20/250] Total Loss: 1548.911011 GL_Loss: 0.521303 CRF_Loss: 1548.389648\n",
      "[2022-02-17 10:09:39,828 - trainer - INFO] - Train Epoch:[1/100] Step:[30/250] Total Loss: 370.047272 GL_Loss: 0.766925 CRF_Loss: 369.280334\n",
      "[2022-02-17 10:09:54,244 - trainer - INFO] - Train Epoch:[1/100] Step:[40/250] Total Loss: 423.524902 GL_Loss: 0.313961 CRF_Loss: 423.210938\n",
      "[2022-02-17 10:10:08,773 - trainer - INFO] - Train Epoch:[1/100] Step:[50/250] Total Loss: 419.765198 GL_Loss: 0.174495 CRF_Loss: 419.590698\n",
      "[2022-02-17 10:10:28,072 - trainer - INFO] - [Step Validation] Epoch:[1/100] Step:[50/250]  \n",
      "+---------+-------+-------+-------+-------+\n",
      "| name    |   mEP |   mER |   mEF |   mEA |\n",
      "+=========+=======+=======+=======+=======+\n",
      "| date    |     0 |     0 |     0 |     0 |\n",
      "+---------+-------+-------+-------+-------+\n",
      "| address |     0 |     0 |     0 |     0 |\n",
      "+---------+-------+-------+-------+-------+\n",
      "| total   |     0 |     0 |     0 |     0 |\n",
      "+---------+-------+-------+-------+-------+\n",
      "| company |     0 |     0 |     0 |     0 |\n",
      "+---------+-------+-------+-------+-------+\n",
      "| overall |     0 |     0 |     0 |     0 |\n",
      "+---------+-------+-------+-------+-------+\n",
      "[2022-02-17 10:10:29,873 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 10:10:43,846 - trainer - INFO] - Train Epoch:[1/100] Step:[60/250] Total Loss: 399.490295 GL_Loss: 0.507937 CRF_Loss: 398.982361\n",
      "[2022-02-17 10:10:57,800 - trainer - INFO] - Train Epoch:[1/100] Step:[70/250] Total Loss: 274.431122 GL_Loss: 0.382096 CRF_Loss: 274.049011\n",
      "[2022-02-17 10:11:11,903 - trainer - INFO] - Train Epoch:[1/100] Step:[80/250] Total Loss: 351.899780 GL_Loss: 0.320435 CRF_Loss: 351.579346\n",
      "[2022-02-17 10:11:27,159 - trainer - INFO] - Train Epoch:[1/100] Step:[90/250] Total Loss: 361.283539 GL_Loss: 0.662450 CRF_Loss: 360.621094\n",
      "[2022-02-17 10:11:41,643 - trainer - INFO] - Train Epoch:[1/100] Step:[100/250] Total Loss: 352.595764 GL_Loss: 0.517771 CRF_Loss: 352.078003\n",
      "[2022-02-17 10:12:00,849 - trainer - INFO] - [Step Validation] Epoch:[1/100] Step:[100/250]  \n",
      "+---------+-------+-------+-------+-------+\n",
      "| name    |   mEP |   mER |   mEF |   mEA |\n",
      "+=========+=======+=======+=======+=======+\n",
      "| date    |     0 |     0 |     0 |     0 |\n",
      "+---------+-------+-------+-------+-------+\n",
      "| address |     0 |     0 |     0 |     0 |\n",
      "+---------+-------+-------+-------+-------+\n",
      "| total   |     0 |     0 |     0 |     0 |\n",
      "+---------+-------+-------+-------+-------+\n",
      "| company |     0 |     0 |     0 |     0 |\n",
      "+---------+-------+-------+-------+-------+\n",
      "| overall |     0 |     0 |     0 |     0 |\n",
      "+---------+-------+-------+-------+-------+\n",
      "[2022-02-17 10:12:03,021 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 10:12:17,390 - trainer - INFO] - Train Epoch:[1/100] Step:[110/250] Total Loss: 376.417358 GL_Loss: 0.846323 CRF_Loss: 375.571045\n",
      "[2022-02-17 10:12:32,329 - trainer - INFO] - Train Epoch:[1/100] Step:[120/250] Total Loss: 365.662201 GL_Loss: 1.523720 CRF_Loss: 364.138489\n",
      "[2022-02-17 10:12:47,529 - trainer - INFO] - Train Epoch:[1/100] Step:[130/250] Total Loss: 412.156097 GL_Loss: 0.343712 CRF_Loss: 411.812378\n",
      "[2022-02-17 10:13:02,212 - trainer - INFO] - Train Epoch:[1/100] Step:[140/250] Total Loss: 356.474121 GL_Loss: 0.861438 CRF_Loss: 355.612671\n",
      "[2022-02-17 10:13:16,476 - trainer - INFO] - Train Epoch:[1/100] Step:[150/250] Total Loss: 177.273209 GL_Loss: 4.645884 CRF_Loss: 172.627319\n",
      "[2022-02-17 10:13:36,166 - trainer - INFO] - [Step Validation] Epoch:[1/100] Step:[150/250]  \n",
      "+---------+-------+-------+-------+-------+\n",
      "| name    |   mEP |   mER |   mEF |   mEA |\n",
      "+=========+=======+=======+=======+=======+\n",
      "| date    |     0 |     0 |     0 |     0 |\n",
      "+---------+-------+-------+-------+-------+\n",
      "| address |     0 |     0 |     0 |     0 |\n",
      "+---------+-------+-------+-------+-------+\n",
      "| total   |     0 |     0 |     0 |     0 |\n",
      "+---------+-------+-------+-------+-------+\n",
      "| company |     0 |     0 |     0 |     0 |\n",
      "+---------+-------+-------+-------+-------+\n",
      "| overall |     0 |     0 |     0 |     0 |\n",
      "+---------+-------+-------+-------+-------+\n",
      "[2022-02-17 10:13:38,382 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 10:13:52,259 - trainer - INFO] - Train Epoch:[1/100] Step:[160/250] Total Loss: 333.491333 GL_Loss: 12.015613 CRF_Loss: 321.475708\n",
      "[2022-02-17 10:14:06,667 - trainer - INFO] - Train Epoch:[1/100] Step:[170/250] Total Loss: 256.736908 GL_Loss: 0.726528 CRF_Loss: 256.010376\n",
      "[2022-02-17 10:14:20,428 - trainer - INFO] - Train Epoch:[1/100] Step:[180/250] Total Loss: 228.202316 GL_Loss: 0.970134 CRF_Loss: 227.232178\n",
      "[2022-02-17 10:14:33,759 - trainer - INFO] - Train Epoch:[1/100] Step:[190/250] Total Loss: 250.640411 GL_Loss: 0.727453 CRF_Loss: 249.912964\n",
      "[2022-02-17 10:14:48,321 - trainer - INFO] - Train Epoch:[1/100] Step:[200/250] Total Loss: 280.529175 GL_Loss: 0.851305 CRF_Loss: 279.677856\n",
      "[2022-02-17 10:15:07,424 - trainer - INFO] - [Step Validation] Epoch:[1/100] Step:[200/250]  \n",
      "+---------+-------+-------+-------+-------+\n",
      "| name    |   mEP |   mER |   mEF |   mEA |\n",
      "+=========+=======+=======+=======+=======+\n",
      "| date    |     0 |     0 |     0 |     0 |\n",
      "+---------+-------+-------+-------+-------+\n",
      "| address |     0 |     0 |     0 |     0 |\n",
      "+---------+-------+-------+-------+-------+\n",
      "| total   |     0 |     0 |     0 |     0 |\n",
      "+---------+-------+-------+-------+-------+\n",
      "| company |     0 |     0 |     0 |     0 |\n",
      "+---------+-------+-------+-------+-------+\n",
      "| overall |     0 |     0 |     0 |     0 |\n",
      "+---------+-------+-------+-------+-------+\n",
      "[2022-02-17 10:15:09,365 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 10:15:24,027 - trainer - INFO] - Train Epoch:[1/100] Step:[210/250] Total Loss: 354.981506 GL_Loss: 1.540829 CRF_Loss: 353.440674\n",
      "[2022-02-17 10:15:39,731 - trainer - INFO] - Train Epoch:[1/100] Step:[220/250] Total Loss: 342.447968 GL_Loss: 1.075274 CRF_Loss: 341.372681\n",
      "[2022-02-17 10:15:54,903 - trainer - INFO] - Train Epoch:[1/100] Step:[230/250] Total Loss: 235.481369 GL_Loss: 0.636282 CRF_Loss: 234.845093\n",
      "[2022-02-17 10:16:09,162 - trainer - INFO] - Train Epoch:[1/100] Step:[240/250] Total Loss: 284.986511 GL_Loss: 0.742991 CRF_Loss: 284.243530\n",
      "[2022-02-17 10:16:23,837 - trainer - INFO] - Train Epoch:[1/100] Step:[250/250] Total Loss: 377.702454 GL_Loss: 0.360155 CRF_Loss: 377.342285\n",
      "[2022-02-17 10:16:42,823 - trainer - INFO] - [Step Validation] Epoch:[1/100] Step:[250/250]  \n",
      "+---------+-----------+------------+------------+------------+\n",
      "| name    |       mEP |        mER |        mEF |        mEA |\n",
      "+=========+===========+============+============+============+\n",
      "| date    | 0         | 0          | 0          | 0          |\n",
      "+---------+-----------+------------+------------+------------+\n",
      "| address | 0.020979  | 0.00797872 | 0.0115607  | 0.00797872 |\n",
      "+---------+-----------+------------+------------+------------+\n",
      "| total   | 0         | 0          | 0          | 0          |\n",
      "+---------+-----------+------------+------------+------------+\n",
      "| company | 0         | 0          | 0          | 0          |\n",
      "+---------+-----------+------------+------------+------------+\n",
      "| overall | 0.0176471 | 0.00319489 | 0.00541028 | 0.00319489 |\n",
      "+---------+-----------+------------+------------+------------+\n",
      "[2022-02-17 10:16:44,839 - trainer - INFO] - Saving current best: model_best.pth ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 10:17:04,169 - trainer - INFO] - [Epoch Validation] Epoch:[1/100] Total Loss: 434.836513 GL_Loss: 0.023258 CRF_Loss: 432.510758 \n",
      "+---------+-----------+------------+------------+------------+\n",
      "| name    |       mEP |        mER |        mEF |        mEA |\n",
      "+=========+===========+============+============+============+\n",
      "| date    | 0         | 0          | 0          | 0          |\n",
      "+---------+-----------+------------+------------+------------+\n",
      "| address | 0.020979  | 0.00797872 | 0.0115607  | 0.00797872 |\n",
      "+---------+-----------+------------+------------+------------+\n",
      "| total   | 0         | 0          | 0          | 0          |\n",
      "+---------+-----------+------------+------------+------------+\n",
      "| company | 0         | 0          | 0          | 0          |\n",
      "+---------+-----------+------------+------------+------------+\n",
      "| overall | 0.0176471 | 0.00319489 | 0.00541028 | 0.00319489 |\n",
      "+---------+-----------+------------+------------+------------+\n",
      "[2022-02-17 10:17:18,757 - trainer - INFO] - Train Epoch:[2/100] Step:[10/250] Total Loss: 195.447510 GL_Loss: 0.439203 CRF_Loss: 195.008301\n",
      "[2022-02-17 10:17:33,700 - trainer - INFO] - Train Epoch:[2/100] Step:[20/250] Total Loss: 214.672501 GL_Loss: 1.200328 CRF_Loss: 213.472168\n",
      "[2022-02-17 10:17:49,022 - trainer - INFO] - Train Epoch:[2/100] Step:[30/250] Total Loss: 481.704803 GL_Loss: 0.493021 CRF_Loss: 481.211792\n",
      "[2022-02-17 10:18:03,415 - trainer - INFO] - Train Epoch:[2/100] Step:[40/250] Total Loss: 307.131226 GL_Loss: 0.238164 CRF_Loss: 306.893066\n",
      "[2022-02-17 10:18:17,674 - trainer - INFO] - Train Epoch:[2/100] Step:[50/250] Total Loss: 270.278168 GL_Loss: 0.815267 CRF_Loss: 269.462891\n",
      "[2022-02-17 10:18:36,914 - trainer - INFO] - [Step Validation] Epoch:[2/100] Step:[50/250]  \n",
      "+---------+-----------+------------+------------+------------+\n",
      "| name    |       mEP |        mER |        mEF |        mEA |\n",
      "+=========+===========+============+============+============+\n",
      "| date    | 0         | 0          | 0          | 0          |\n",
      "+---------+-----------+------------+------------+------------+\n",
      "| address | 0.0251046 | 0.0159574  | 0.0195122  | 0.0159574  |\n",
      "+---------+-----------+------------+------------+------------+\n",
      "| total   | 0         | 0          | 0          | 0          |\n",
      "+---------+-----------+------------+------------+------------+\n",
      "| company | 0         | 0          | 0          | 0          |\n",
      "+---------+-----------+------------+------------+------------+\n",
      "| overall | 0.0185185 | 0.00638978 | 0.00950119 | 0.00638978 |\n",
      "+---------+-----------+------------+------------+------------+\n",
      "[2022-02-17 10:18:39,038 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 10:18:52,852 - trainer - INFO] - Train Epoch:[2/100] Step:[60/250] Total Loss: 243.600143 GL_Loss: 1.212083 CRF_Loss: 242.388062\n",
      "[2022-02-17 10:19:06,874 - trainer - INFO] - Train Epoch:[2/100] Step:[70/250] Total Loss: 212.044510 GL_Loss: 1.229564 CRF_Loss: 210.814941\n",
      "[2022-02-17 10:19:21,251 - trainer - INFO] - Train Epoch:[2/100] Step:[80/250] Total Loss: 209.135010 GL_Loss: 0.798577 CRF_Loss: 208.336426\n",
      "[2022-02-17 10:19:35,944 - trainer - INFO] - Train Epoch:[2/100] Step:[90/250] Total Loss: 169.327881 GL_Loss: 0.548827 CRF_Loss: 168.779053\n",
      "[2022-02-17 10:19:50,921 - trainer - INFO] - Train Epoch:[2/100] Step:[100/250] Total Loss: 226.945709 GL_Loss: 0.739404 CRF_Loss: 226.206299\n",
      "[2022-02-17 10:20:10,116 - trainer - INFO] - [Step Validation] Epoch:[2/100] Step:[100/250]  \n",
      "+---------+------------+------------+------------+------------+\n",
      "| name    |        mEP |        mER |        mEF |        mEA |\n",
      "+=========+============+============+============+============+\n",
      "| date    | 0          | 0          | 0          | 0          |\n",
      "+---------+------------+------------+------------+------------+\n",
      "| address | 0.00990099 | 0.00265957 | 0.00419287 | 0.00265957 |\n",
      "+---------+------------+------------+------------+------------+\n",
      "| total   | 0          | 0          | 0          | 0          |\n",
      "+---------+------------+------------+------------+------------+\n",
      "| company | 0.05       | 0.0217391  | 0.030303   | 0.0217391  |\n",
      "+---------+------------+------------+------------+------------+\n",
      "| overall | 0.0212766  | 0.00319489 | 0.00555556 | 0.00319489 |\n",
      "+---------+------------+------------+------------+------------+\n",
      "[2022-02-17 10:20:24,849 - trainer - INFO] - Train Epoch:[2/100] Step:[110/250] Total Loss: 232.204163 GL_Loss: 0.396789 CRF_Loss: 231.807373\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 10:20:37,923 - trainer - INFO] - Train Epoch:[2/100] Step:[120/250] Total Loss: 210.512909 GL_Loss: 0.391573 CRF_Loss: 210.121338\n",
      "[2022-02-17 10:20:51,725 - trainer - INFO] - Train Epoch:[2/100] Step:[130/250] Total Loss: 281.601410 GL_Loss: 0.298051 CRF_Loss: 281.303345\n",
      "[2022-02-17 10:21:06,649 - trainer - INFO] - Train Epoch:[2/100] Step:[140/250] Total Loss: 201.625275 GL_Loss: 0.399572 CRF_Loss: 201.225708\n",
      "[2022-02-17 10:21:22,868 - trainer - INFO] - Train Epoch:[2/100] Step:[150/250] Total Loss: 217.842743 GL_Loss: 1.100671 CRF_Loss: 216.742065\n",
      "[2022-02-17 10:21:41,970 - trainer - INFO] - [Step Validation] Epoch:[2/100] Step:[150/250]  \n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| name    |       mEP |       mER |       mEF |       mEA |\n",
      "+=========+===========+===========+===========+===========+\n",
      "| date    | 0         | 0         | 0         | 0         |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| address | 0.0942029 | 0.0345745 | 0.0505837 | 0.0345745 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| total   | 0         | 0         | 0         | 0         |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| company | 0         | 0         | 0         | 0         |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| overall | 0.0755814 | 0.0138445 | 0.0234023 | 0.0138445 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "[2022-02-17 10:21:44,104 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 10:21:58,613 - trainer - INFO] - Train Epoch:[2/100] Step:[160/250] Total Loss: 177.460052 GL_Loss: 2.435025 CRF_Loss: 175.025024\n",
      "[2022-02-17 10:22:13,405 - trainer - INFO] - Train Epoch:[2/100] Step:[170/250] Total Loss: 172.171875 GL_Loss: 1.026367 CRF_Loss: 171.145508\n",
      "[2022-02-17 10:22:27,566 - trainer - INFO] - Train Epoch:[2/100] Step:[180/250] Total Loss: 191.994934 GL_Loss: 0.455867 CRF_Loss: 191.539062\n",
      "[2022-02-17 10:22:41,420 - trainer - INFO] - Train Epoch:[2/100] Step:[190/250] Total Loss: 199.871811 GL_Loss: 0.695909 CRF_Loss: 199.175903\n",
      "[2022-02-17 10:22:56,387 - trainer - INFO] - Train Epoch:[2/100] Step:[200/250] Total Loss: 198.256973 GL_Loss: 0.425485 CRF_Loss: 197.831482\n",
      "[2022-02-17 10:23:15,476 - trainer - INFO] - [Step Validation] Epoch:[2/100] Step:[200/250]  \n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| name    |       mEP |       mER |       mEF |       mEA |\n",
      "+=========+===========+===========+===========+===========+\n",
      "| date    | 0         | 0         | 0         | 0         |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| address | 0.0396825 | 0.0132979 | 0.0199203 | 0.0132979 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| total   | 0         | 0         | 0         | 0         |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| company | 0.136986  | 0.108696  | 0.121212  | 0.108696  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| overall | 0.0753769 | 0.0159744 | 0.026362  | 0.0159744 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "[2022-02-17 10:23:17,605 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 10:23:32,446 - trainer - INFO] - Train Epoch:[2/100] Step:[210/250] Total Loss: 155.337646 GL_Loss: 0.757195 CRF_Loss: 154.580444\n",
      "[2022-02-17 10:23:47,682 - trainer - INFO] - Train Epoch:[2/100] Step:[220/250] Total Loss: 171.174530 GL_Loss: 0.792324 CRF_Loss: 170.382202\n",
      "[2022-02-17 10:24:01,647 - trainer - INFO] - Train Epoch:[2/100] Step:[230/250] Total Loss: 224.097687 GL_Loss: 0.609038 CRF_Loss: 223.488647\n",
      "[2022-02-17 10:24:16,674 - trainer - INFO] - Train Epoch:[2/100] Step:[240/250] Total Loss: 180.998428 GL_Loss: 0.776135 CRF_Loss: 180.222290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 10:24:30,148 - trainer - INFO] - Train Epoch:[2/100] Step:[250/250] Total Loss: 161.994690 GL_Loss: 0.728818 CRF_Loss: 161.265869\n",
      "[2022-02-17 10:24:49,136 - trainer - INFO] - [Step Validation] Epoch:[2/100] Step:[250/250]  \n",
      "+---------+-----------+------------+------------+------------+\n",
      "| name    |       mEP |        mER |        mEF |        mEA |\n",
      "+=========+===========+============+============+============+\n",
      "| date    | 0         | 0          | 0          | 0          |\n",
      "+---------+-----------+------------+------------+------------+\n",
      "| address | 0.011976  | 0.00531915 | 0.00736648 | 0.00531915 |\n",
      "+---------+-----------+------------+------------+------------+\n",
      "| total   | 0         | 0          | 0          | 0          |\n",
      "+---------+-----------+------------+------------+------------+\n",
      "| company | 0.140187  | 0.163043   | 0.150754   | 0.163043   |\n",
      "+---------+-----------+------------+------------+------------+\n",
      "| overall | 0.0398126 | 0.0181044  | 0.0248902  | 0.0181044  |\n",
      "+---------+-----------+------------+------------+------------+\n",
      "[2022-02-17 10:25:08,298 - trainer - INFO] - [Epoch Validation] Epoch:[2/100] Total Loss: 287.076552 GL_Loss: 0.008497 CRF_Loss: 286.226879 \n",
      "+---------+-----------+------------+------------+------------+\n",
      "| name    |       mEP |        mER |        mEF |        mEA |\n",
      "+=========+===========+============+============+============+\n",
      "| date    | 0         | 0          | 0          | 0          |\n",
      "+---------+-----------+------------+------------+------------+\n",
      "| address | 0.011976  | 0.00531915 | 0.00736648 | 0.00531915 |\n",
      "+---------+-----------+------------+------------+------------+\n",
      "| total   | 0         | 0          | 0          | 0          |\n",
      "+---------+-----------+------------+------------+------------+\n",
      "| company | 0.140187  | 0.163043   | 0.150754   | 0.163043   |\n",
      "+---------+-----------+------------+------------+------------+\n",
      "| overall | 0.0398126 | 0.0181044  | 0.0248902  | 0.0181044  |\n",
      "+---------+-----------+------------+------------+------------+\n",
      "[2022-02-17 10:25:23,392 - trainer - INFO] - Train Epoch:[3/100] Step:[10/250] Total Loss: 165.868317 GL_Loss: 2.877957 CRF_Loss: 162.990356\n",
      "[2022-02-17 10:25:38,849 - trainer - INFO] - Train Epoch:[3/100] Step:[20/250] Total Loss: 155.623550 GL_Loss: 0.708267 CRF_Loss: 154.915283\n",
      "[2022-02-17 10:25:52,187 - trainer - INFO] - Train Epoch:[3/100] Step:[30/250] Total Loss: 151.912277 GL_Loss: 5.442734 CRF_Loss: 146.469543\n",
      "[2022-02-17 10:26:05,828 - trainer - INFO] - Train Epoch:[3/100] Step:[40/250] Total Loss: 171.799362 GL_Loss: 2.684248 CRF_Loss: 169.115112\n",
      "[2022-02-17 10:26:19,919 - trainer - INFO] - Train Epoch:[3/100] Step:[50/250] Total Loss: 193.396332 GL_Loss: 0.941138 CRF_Loss: 192.455200\n",
      "[2022-02-17 10:26:38,999 - trainer - INFO] - [Step Validation] Epoch:[3/100] Step:[50/250]  \n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| name    |       mEP |       mER |       mEF |       mEA |\n",
      "+=========+===========+===========+===========+===========+\n",
      "| date    | 0         | 0         | 0         | 0         |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| address | 0.0457516 | 0.018617  | 0.026465  | 0.018617  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| total   | 0         | 0         | 0         | 0         |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| company | 0.288462  | 0.326087  | 0.306122  | 0.326087  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| overall | 0.0737052 | 0.0394036 | 0.0513532 | 0.0394036 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "[2022-02-17 10:26:41,147 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 10:26:56,280 - trainer - INFO] - Train Epoch:[3/100] Step:[60/250] Total Loss: 1606.432129 GL_Loss: 1.375132 CRF_Loss: 1605.057007\n",
      "[2022-02-17 10:27:10,299 - trainer - INFO] - Train Epoch:[3/100] Step:[70/250] Total Loss: 199.407089 GL_Loss: 1.525980 CRF_Loss: 197.881104\n",
      "[2022-02-17 10:27:25,653 - trainer - INFO] - Train Epoch:[3/100] Step:[80/250] Total Loss: 169.420502 GL_Loss: 5.840302 CRF_Loss: 163.580200\n",
      "[2022-02-17 10:27:40,556 - trainer - INFO] - Train Epoch:[3/100] Step:[90/250] Total Loss: 155.717453 GL_Loss: 1.318160 CRF_Loss: 154.399292\n",
      "[2022-02-17 10:27:54,014 - trainer - INFO] - Train Epoch:[3/100] Step:[100/250] Total Loss: 339.112000 GL_Loss: 1.126275 CRF_Loss: 337.985718\n",
      "[2022-02-17 10:28:13,438 - trainer - INFO] - [Step Validation] Epoch:[3/100] Step:[100/250]  \n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| name    |       mEP |       mER |       mEF |       mEA |\n",
      "+=========+===========+===========+===========+===========+\n",
      "| date    | 0         | 0         | 0         | 0         |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| address | 0.0987654 | 0.0425532 | 0.0594796 | 0.0425532 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| total   | 0         | 0         | 0         | 0         |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| company | 0.226667  | 0.184783  | 0.203593  | 0.184783  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| overall | 0.0229485 | 0.0351438 | 0.0277661 | 0.0351438 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "[2022-02-17 10:28:29,462 - trainer - INFO] - Train Epoch:[3/100] Step:[110/250] Total Loss: 721.847900 GL_Loss: 3.147223 CRF_Loss: 718.700684\n",
      "[2022-02-17 10:28:43,535 - trainer - INFO] - Train Epoch:[3/100] Step:[120/250] Total Loss: 270.723541 GL_Loss: 0.862525 CRF_Loss: 269.861023\n",
      "[2022-02-17 10:28:57,386 - trainer - INFO] - Train Epoch:[3/100] Step:[130/250] Total Loss: 135.306732 GL_Loss: 2.325524 CRF_Loss: 132.981201\n",
      "[2022-02-17 10:29:11,655 - trainer - INFO] - Train Epoch:[3/100] Step:[140/250] Total Loss: 200.461151 GL_Loss: 2.637793 CRF_Loss: 197.823364\n",
      "[2022-02-17 10:29:25,339 - trainer - INFO] - Train Epoch:[3/100] Step:[150/250] Total Loss: 144.945541 GL_Loss: 1.713237 CRF_Loss: 143.232300\n",
      "[2022-02-17 10:29:44,350 - trainer - INFO] - [Step Validation] Epoch:[3/100] Step:[150/250]  \n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| name    |       mEP |       mER |       mEF |       mEA |\n",
      "+=========+===========+===========+===========+===========+\n",
      "| date    | 0         | 0         | 0         | 0         |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| address | 0.0890411 | 0.0345745 | 0.0498084 | 0.0345745 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| total   | 0         | 0         | 0         | 0         |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| company | 0.140845  | 0.108696  | 0.122699  | 0.108696  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| overall | 0.0373984 | 0.0244941 | 0.029601  | 0.0244941 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "[2022-02-17 10:29:58,550 - trainer - INFO] - Train Epoch:[3/100] Step:[160/250] Total Loss: 115.142036 GL_Loss: 0.721381 CRF_Loss: 114.420654\n",
      "[2022-02-17 10:30:13,711 - trainer - INFO] - Train Epoch:[3/100] Step:[170/250] Total Loss: 114.985870 GL_Loss: 0.567232 CRF_Loss: 114.418640\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 10:30:28,399 - trainer - INFO] - Train Epoch:[3/100] Step:[180/250] Total Loss: 81.690331 GL_Loss: 0.458271 CRF_Loss: 81.232056\n",
      "[2022-02-17 10:30:42,944 - trainer - INFO] - Train Epoch:[3/100] Step:[190/250] Total Loss: 141.605240 GL_Loss: 0.555319 CRF_Loss: 141.049927\n",
      "[2022-02-17 10:30:57,468 - trainer - INFO] - Train Epoch:[3/100] Step:[200/250] Total Loss: 117.965439 GL_Loss: 0.615951 CRF_Loss: 117.349487\n",
      "[2022-02-17 10:31:17,670 - trainer - INFO] - [Step Validation] Epoch:[3/100] Step:[200/250]  \n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| name    |       mEP |       mER |       mEF |       mEA |\n",
      "+=========+===========+===========+===========+===========+\n",
      "| date    | 0         | 0         | 0         | 0         |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| address | 0.104167  | 0.0398936 | 0.0576923 | 0.0398936 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| total   | 0         | 0         | 0         | 0         |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| company | 0.337349  | 0.304348  | 0.32      | 0.304348  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| overall | 0.0659509 | 0.0457934 | 0.0540541 | 0.0457934 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 10:31:19,757 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 10:31:36,332 - trainer - INFO] - Train Epoch:[3/100] Step:[210/250] Total Loss: 145.143982 GL_Loss: 3.537172 CRF_Loss: 141.606812\n",
      "[2022-02-17 10:31:50,854 - trainer - INFO] - Train Epoch:[3/100] Step:[220/250] Total Loss: 1177.022461 GL_Loss: 1.377544 CRF_Loss: 1175.644897\n",
      "[2022-02-17 10:32:05,999 - trainer - INFO] - Train Epoch:[3/100] Step:[230/250] Total Loss: 164.155182 GL_Loss: 0.734887 CRF_Loss: 163.420288\n",
      "[2022-02-17 10:32:21,121 - trainer - INFO] - Train Epoch:[3/100] Step:[240/250] Total Loss: 212.530182 GL_Loss: 0.636621 CRF_Loss: 211.893555\n",
      "[2022-02-17 10:32:35,814 - trainer - INFO] - Train Epoch:[3/100] Step:[250/250] Total Loss: 94.724525 GL_Loss: 0.636510 CRF_Loss: 94.088013\n",
      "[2022-02-17 10:32:55,007 - trainer - INFO] - [Step Validation] Epoch:[3/100] Step:[250/250]  \n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| name    |       mEP |       mER |       mEF |       mEA |\n",
      "+=========+===========+===========+===========+===========+\n",
      "| date    | 0         | 0         | 0         | 0         |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| address | 0.0482759 | 0.018617  | 0.0268714 | 0.018617  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| total   | 0         | 0         | 0         | 0         |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| company | 0.282051  | 0.23913   | 0.258824  | 0.23913   |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| overall | 0.0695444 | 0.0308839 | 0.0427729 | 0.0308839 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "[2022-02-17 10:33:14,779 - trainer - INFO] - [Epoch Validation] Epoch:[3/100] Total Loss: 235.112298 GL_Loss: 0.022571 CRF_Loss: 232.855179 \n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| name    |       mEP |       mER |       mEF |       mEA |\n",
      "+=========+===========+===========+===========+===========+\n",
      "| date    | 0         | 0         | 0         | 0         |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| address | 0.0482759 | 0.018617  | 0.0268714 | 0.018617  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| total   | 0         | 0         | 0         | 0         |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| company | 0.282051  | 0.23913   | 0.258824  | 0.23913   |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| overall | 0.0695444 | 0.0308839 | 0.0427729 | 0.0308839 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "[2022-02-17 10:33:29,669 - trainer - INFO] - Train Epoch:[4/100] Step:[10/250] Total Loss: 69.776619 GL_Loss: 1.051762 CRF_Loss: 68.724854\n",
      "[2022-02-17 10:33:45,855 - trainer - INFO] - Train Epoch:[4/100] Step:[20/250] Total Loss: 96.324631 GL_Loss: 1.106491 CRF_Loss: 95.218140\n",
      "[2022-02-17 10:33:59,221 - trainer - INFO] - Train Epoch:[4/100] Step:[30/250] Total Loss: 164.680191 GL_Loss: 1.211444 CRF_Loss: 163.468750\n",
      "[2022-02-17 10:34:14,000 - trainer - INFO] - Train Epoch:[4/100] Step:[40/250] Total Loss: 706.787231 GL_Loss: 1.397947 CRF_Loss: 705.389282\n",
      "[2022-02-17 10:34:27,563 - trainer - INFO] - Train Epoch:[4/100] Step:[50/250] Total Loss: 97.362419 GL_Loss: 1.377193 CRF_Loss: 95.985229\n",
      "[2022-02-17 10:34:47,189 - trainer - INFO] - [Step Validation] Epoch:[4/100] Step:[50/250]  \n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| name    |       mEP |       mER |       mEF |       mEA |\n",
      "+=========+===========+===========+===========+===========+\n",
      "| date    | 0         | 0         | 0         | 0         |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| address | 0.136364  | 0.0478723 | 0.0708661 | 0.0478723 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| total   | 0         | 0         | 0         | 0         |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| company | 0.402778  | 0.315217  | 0.353659  | 0.315217  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| overall | 0.0811744 | 0.0500532 | 0.0619236 | 0.0500532 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "[2022-02-17 10:34:49,360 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 10:35:03,471 - trainer - INFO] - Train Epoch:[4/100] Step:[60/250] Total Loss: 164.211380 GL_Loss: 0.986034 CRF_Loss: 163.225342\n",
      "[2022-02-17 10:35:17,138 - trainer - INFO] - Train Epoch:[4/100] Step:[70/250] Total Loss: 149.216644 GL_Loss: 0.431731 CRF_Loss: 148.784912\n",
      "[2022-02-17 10:35:30,930 - trainer - INFO] - Train Epoch:[4/100] Step:[80/250] Total Loss: 138.495178 GL_Loss: 0.482239 CRF_Loss: 138.012939\n",
      "[2022-02-17 10:35:45,522 - trainer - INFO] - Train Epoch:[4/100] Step:[90/250] Total Loss: 146.551987 GL_Loss: 3.791978 CRF_Loss: 142.760010\n",
      "[2022-02-17 10:35:59,504 - trainer - INFO] - Train Epoch:[4/100] Step:[100/250] Total Loss: 119.825066 GL_Loss: 4.385126 CRF_Loss: 115.439941\n",
      "[2022-02-17 10:36:18,772 - trainer - INFO] - [Step Validation] Epoch:[4/100] Step:[100/250]  \n",
      "+---------+------------+-----------+-----------+-----------+\n",
      "| name    |        mEP |       mER |       mEF |       mEA |\n",
      "+=========+============+===========+===========+===========+\n",
      "| date    | 0.00852878 | 0.0254777 | 0.0127796 | 0.0254777 |\n",
      "+---------+------------+-----------+-----------+-----------+\n",
      "| address | 0.154412   | 0.0558511 | 0.0820312 | 0.0558511 |\n",
      "+---------+------------+-----------+-----------+-----------+\n",
      "| total   | 0          | 0         | 0         | 0         |\n",
      "+---------+------------+-----------+-----------+-----------+\n",
      "| company | 0.0982143  | 0.119565  | 0.107843  | 0.119565  |\n",
      "+---------+------------+-----------+-----------+-----------+\n",
      "| overall | 0.0499307  | 0.0383387 | 0.0433735 | 0.0383387 |\n",
      "+---------+------------+-----------+-----------+-----------+\n",
      "[2022-02-17 10:36:32,434 - trainer - INFO] - Train Epoch:[4/100] Step:[110/250] Total Loss: 122.881569 GL_Loss: 1.048074 CRF_Loss: 121.833496\n",
      "[2022-02-17 10:36:45,245 - trainer - INFO] - Train Epoch:[4/100] Step:[120/250] Total Loss: 186.171234 GL_Loss: 2.436866 CRF_Loss: 183.734375\n",
      "[2022-02-17 10:36:59,827 - trainer - INFO] - Train Epoch:[4/100] Step:[130/250] Total Loss: 92.046524 GL_Loss: 5.429821 CRF_Loss: 86.616699\n",
      "[2022-02-17 10:37:14,242 - trainer - INFO] - Train Epoch:[4/100] Step:[140/250] Total Loss: 76.696991 GL_Loss: 2.771452 CRF_Loss: 73.925537\n",
      "[2022-02-17 10:37:28,986 - trainer - INFO] - Train Epoch:[4/100] Step:[150/250] Total Loss: 111.027954 GL_Loss: 0.707640 CRF_Loss: 110.320312\n",
      "[2022-02-17 10:37:48,027 - trainer - INFO] - [Step Validation] Epoch:[4/100] Step:[150/250]  \n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| name    |       mEP |       mER |       mEF |       mEA |\n",
      "+=========+===========+===========+===========+===========+\n",
      "| date    | 0.0114068 | 0.0191083 | 0.0142857 | 0.0191083 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| address | 0.193798  | 0.0664894 | 0.0990099 | 0.0664894 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| total   | 0         | 0         | 0         | 0         |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| company | 0.30137   | 0.23913   | 0.266667  | 0.23913   |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| overall | 0.105042  | 0.0532481 | 0.0706714 | 0.0532481 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "[2022-02-17 10:37:50,144 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 10:38:04,691 - trainer - INFO] - Train Epoch:[4/100] Step:[160/250] Total Loss: 84.872658 GL_Loss: 1.007848 CRF_Loss: 83.864807\n",
      "[2022-02-17 10:38:19,375 - trainer - INFO] - Train Epoch:[4/100] Step:[170/250] Total Loss: 88.295158 GL_Loss: 1.417226 CRF_Loss: 86.877930\n",
      "[2022-02-17 10:38:34,468 - trainer - INFO] - Train Epoch:[4/100] Step:[180/250] Total Loss: 235.226929 GL_Loss: 2.303828 CRF_Loss: 232.923096\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 10:38:48,896 - trainer - INFO] - Train Epoch:[4/100] Step:[190/250] Total Loss: 131.439438 GL_Loss: 1.950790 CRF_Loss: 129.488647\n",
      "[2022-02-17 10:39:04,040 - trainer - INFO] - Train Epoch:[4/100] Step:[200/250] Total Loss: 189.547607 GL_Loss: 1.200931 CRF_Loss: 188.346680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 10:39:23,129 - trainer - INFO] - [Step Validation] Epoch:[4/100] Step:[200/250]  \n",
      "+---------+------------+-----------+------------+-----------+\n",
      "| name    |        mEP |       mER |        mEF |       mEA |\n",
      "+=========+============+===========+============+===========+\n",
      "| date    | 0.00569801 | 0.0127389 | 0.00787402 | 0.0127389 |\n",
      "+---------+------------+-----------+------------+-----------+\n",
      "| address | 0.0561224  | 0.0292553 | 0.0384615  | 0.0292553 |\n",
      "+---------+------------+-----------+------------+-----------+\n",
      "| total   | 0          | 0         | 0          | 0         |\n",
      "+---------+------------+-----------+------------+-----------+\n",
      "| company | 0.0526316  | 0.0434783 | 0.047619   | 0.0434783 |\n",
      "+---------+------------+-----------+------------+-----------+\n",
      "| overall | 0.027027   | 0.0181044 | 0.0216837  | 0.0181044 |\n",
      "+---------+------------+-----------+------------+-----------+\n",
      "[2022-02-17 10:39:37,807 - trainer - INFO] - Train Epoch:[4/100] Step:[210/250] Total Loss: 178.257523 GL_Loss: 0.457712 CRF_Loss: 177.799805\n",
      "[2022-02-17 10:39:52,119 - trainer - INFO] - Train Epoch:[4/100] Step:[220/250] Total Loss: 79.523483 GL_Loss: 1.114549 CRF_Loss: 78.408936\n",
      "[2022-02-17 10:40:06,059 - trainer - INFO] - Train Epoch:[4/100] Step:[230/250] Total Loss: 128.128021 GL_Loss: 2.001497 CRF_Loss: 126.126526\n",
      "[2022-02-17 10:40:19,148 - trainer - INFO] - Train Epoch:[4/100] Step:[240/250] Total Loss: 114.262520 GL_Loss: 1.082591 CRF_Loss: 113.179932\n",
      "[2022-02-17 10:40:33,165 - trainer - INFO] - Train Epoch:[4/100] Step:[250/250] Total Loss: 106.999992 GL_Loss: 0.783687 CRF_Loss: 106.216309\n",
      "[2022-02-17 10:40:52,177 - trainer - INFO] - [Step Validation] Epoch:[4/100] Step:[250/250]  \n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| name    |      mEP |       mER |       mEF |       mEA |\n",
      "+=========+==========+===========+===========+===========+\n",
      "| date    | 0.034965 | 0.0636943 | 0.0451467 | 0.0636943 |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| address | 0.218978 | 0.0797872 | 0.116959  | 0.0797872 |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| total   | 0        | 0         | 0         | 0         |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| company | 0.358696 | 0.358696  | 0.358696  | 0.358696  |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| overall | 0.129433 | 0.0777423 | 0.0971391 | 0.0777423 |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "[2022-02-17 10:40:54,254 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 10:41:13,412 - trainer - INFO] - [Epoch Validation] Epoch:[4/100] Total Loss: 204.041555 GL_Loss: 0.020770 CRF_Loss: 201.964597 \n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| name    |      mEP |       mER |       mEF |       mEA |\n",
      "+=========+==========+===========+===========+===========+\n",
      "| date    | 0.034965 | 0.0636943 | 0.0451467 | 0.0636943 |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| address | 0.218978 | 0.0797872 | 0.116959  | 0.0797872 |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| total   | 0        | 0         | 0         | 0         |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| company | 0.358696 | 0.358696  | 0.358696  | 0.358696  |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| overall | 0.129433 | 0.0777423 | 0.0971391 | 0.0777423 |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "[2022-02-17 10:41:29,341 - trainer - INFO] - Train Epoch:[5/100] Step:[10/250] Total Loss: 89.426559 GL_Loss: 0.550581 CRF_Loss: 88.875977\n",
      "[2022-02-17 10:41:44,825 - trainer - INFO] - Train Epoch:[5/100] Step:[20/250] Total Loss: 210.460220 GL_Loss: 0.687632 CRF_Loss: 209.772583\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 10:41:58,977 - trainer - INFO] - Train Epoch:[5/100] Step:[30/250] Total Loss: 198.803024 GL_Loss: 1.123706 CRF_Loss: 197.679321\n",
      "[2022-02-17 10:42:13,699 - trainer - INFO] - Train Epoch:[5/100] Step:[40/250] Total Loss: 135.703384 GL_Loss: 1.566660 CRF_Loss: 134.136719\n",
      "[2022-02-17 10:42:28,718 - trainer - INFO] - Train Epoch:[5/100] Step:[50/250] Total Loss: 62.089497 GL_Loss: 1.491108 CRF_Loss: 60.598389\n",
      "[2022-02-17 10:42:47,804 - trainer - INFO] - [Step Validation] Epoch:[5/100] Step:[50/250]  \n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| name    |       mEP |       mER |       mEF |       mEA |\n",
      "+=========+===========+===========+===========+===========+\n",
      "| date    | 0.0940594 | 0.121019  | 0.10585   | 0.121019  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| address | 0.214286  | 0.0797872 | 0.116279  | 0.0797872 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| total   | 0         | 0         | 0         | 0         |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| company | 0.278689  | 0.184783  | 0.222222  | 0.184783  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| overall | 0.163366  | 0.0702875 | 0.0982874 | 0.0702875 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "[2022-02-17 10:42:49,947 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 10:43:05,509 - trainer - INFO] - Train Epoch:[5/100] Step:[60/250] Total Loss: 957.378113 GL_Loss: 2.206456 CRF_Loss: 955.171631\n",
      "[2022-02-17 10:43:20,238 - trainer - INFO] - Train Epoch:[5/100] Step:[70/250] Total Loss: 610.217590 GL_Loss: 1.575485 CRF_Loss: 608.642090\n",
      "[2022-02-17 10:43:34,163 - trainer - INFO] - Train Epoch:[5/100] Step:[80/250] Total Loss: 210.427261 GL_Loss: 4.711317 CRF_Loss: 205.715942\n",
      "[2022-02-17 10:43:49,101 - trainer - INFO] - Train Epoch:[5/100] Step:[90/250] Total Loss: 111.233116 GL_Loss: 1.167321 CRF_Loss: 110.065796\n",
      "[2022-02-17 10:44:02,979 - trainer - INFO] - Train Epoch:[5/100] Step:[100/250] Total Loss: 76.241272 GL_Loss: 4.839538 CRF_Loss: 71.401733\n",
      "[2022-02-17 10:44:23,420 - trainer - INFO] - [Step Validation] Epoch:[5/100] Step:[100/250]  \n",
      "+---------+----------+----------+-----------+----------+\n",
      "| name    |      mEP |      mER |       mEF |      mEA |\n",
      "+=========+==========+==========+===========+==========+\n",
      "| date    | 0.205263 | 0.248408 | 0.224784  | 0.248408 |\n",
      "+---------+----------+----------+-----------+----------+\n",
      "| address | 0.105263 | 0.037234 | 0.0550098 | 0.037234 |\n",
      "+---------+----------+----------+-----------+----------+\n",
      "| total   | 0        | 0        | 0         | 0        |\n",
      "+---------+----------+----------+-----------+----------+\n",
      "| company | 0.294737 | 0.304348 | 0.299465  | 0.304348 |\n",
      "+---------+----------+----------+-----------+----------+\n",
      "| overall | 0.185355 | 0.086262 | 0.117733  | 0.086262 |\n",
      "+---------+----------+----------+-----------+----------+\n",
      "[2022-02-17 10:44:25,504 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 10:44:41,448 - trainer - INFO] - Train Epoch:[5/100] Step:[110/250] Total Loss: 86.916008 GL_Loss: 1.872675 CRF_Loss: 85.043335\n",
      "[2022-02-17 10:44:56,065 - trainer - INFO] - Train Epoch:[5/100] Step:[120/250] Total Loss: 66.441544 GL_Loss: 0.647967 CRF_Loss: 65.793579\n",
      "[2022-02-17 10:45:11,722 - trainer - INFO] - Train Epoch:[5/100] Step:[130/250] Total Loss: 102.597954 GL_Loss: 0.527149 CRF_Loss: 102.070801\n",
      "[2022-02-17 10:45:25,631 - trainer - INFO] - Train Epoch:[5/100] Step:[140/250] Total Loss: 124.908287 GL_Loss: 0.466395 CRF_Loss: 124.441895\n",
      "[2022-02-17 10:45:40,345 - trainer - INFO] - Train Epoch:[5/100] Step:[150/250] Total Loss: 96.772537 GL_Loss: 0.423907 CRF_Loss: 96.348633\n",
      "[2022-02-17 10:45:59,525 - trainer - INFO] - [Step Validation] Epoch:[5/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.350181 | 0.617834 | 0.447005 | 0.617834 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.230769 | 0.087766 | 0.127168 | 0.087766 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0        | 0        | 0        | 0        |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.445652 | 0.445652 | 0.445652 | 0.445652 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.2736   | 0.182109 | 0.21867  | 0.182109 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 10:46:01,641 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 10:46:15,411 - trainer - INFO] - Train Epoch:[5/100] Step:[160/250] Total Loss: 125.738602 GL_Loss: 0.614087 CRF_Loss: 125.124512\n",
      "[2022-02-17 10:46:29,676 - trainer - INFO] - Train Epoch:[5/100] Step:[170/250] Total Loss: 148.879013 GL_Loss: 0.962019 CRF_Loss: 147.916992\n",
      "[2022-02-17 10:46:42,954 - trainer - INFO] - Train Epoch:[5/100] Step:[180/250] Total Loss: 45.654709 GL_Loss: 2.589402 CRF_Loss: 43.065308\n",
      "[2022-02-17 10:46:57,354 - trainer - INFO] - Train Epoch:[5/100] Step:[190/250] Total Loss: 131.082947 GL_Loss: 2.985654 CRF_Loss: 128.097290\n",
      "[2022-02-17 10:47:11,012 - trainer - INFO] - Train Epoch:[5/100] Step:[200/250] Total Loss: 724.802368 GL_Loss: 2.057195 CRF_Loss: 722.745178\n",
      "[2022-02-17 10:47:29,926 - trainer - INFO] - [Step Validation] Epoch:[5/100] Step:[200/250]  \n",
      "+---------+------------+------------+------------+------------+\n",
      "| name    |        mEP |        mER |        mEF |        mEA |\n",
      "+=========+============+============+============+============+\n",
      "| date    | 0.315113   | 0.624204   | 0.418803   | 0.624204   |\n",
      "+---------+------------+------------+------------+------------+\n",
      "| address | 0.00754717 | 0.00531915 | 0.00624025 | 0.00531915 |\n",
      "+---------+------------+------------+------------+------------+\n",
      "| total   | 0.141892   | 0.133758   | 0.137705   | 0.133758   |\n",
      "+---------+------------+------------+------------+------------+\n",
      "| company | 0.357895   | 0.369565   | 0.363636   | 0.369565   |\n",
      "+---------+------------+------------+------------+------------+\n",
      "| overall | 0.182006   | 0.187433   | 0.18468    | 0.187433   |\n",
      "+---------+------------+------------+------------+------------+\n",
      "[2022-02-17 10:47:43,272 - trainer - INFO] - Train Epoch:[5/100] Step:[210/250] Total Loss: 306.950043 GL_Loss: 2.085411 CRF_Loss: 304.864624\n",
      "[2022-02-17 10:47:57,478 - trainer - INFO] - Train Epoch:[5/100] Step:[220/250] Total Loss: 82.629410 GL_Loss: 0.891617 CRF_Loss: 81.737793\n",
      "[2022-02-17 10:48:10,765 - trainer - INFO] - Train Epoch:[5/100] Step:[230/250] Total Loss: 103.153931 GL_Loss: 2.130613 CRF_Loss: 101.023315\n",
      "[2022-02-17 10:48:24,759 - trainer - INFO] - Train Epoch:[5/100] Step:[240/250] Total Loss: 92.018867 GL_Loss: 2.502634 CRF_Loss: 89.516235\n",
      "[2022-02-17 10:48:38,478 - trainer - INFO] - Train Epoch:[5/100] Step:[250/250] Total Loss: 101.110931 GL_Loss: 1.371307 CRF_Loss: 99.739624\n",
      "[2022-02-17 10:48:57,553 - trainer - INFO] - [Step Validation] Epoch:[5/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.366197 | 0.66242  | 0.471655 | 0.66242  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.268966 | 0.103723 | 0.149712 | 0.103723 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0        | 0        | 0        | 0        |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.467391 | 0.467391 | 0.467391 | 0.467391 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.329204 | 0.198083 | 0.24734  | 0.198083 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 10:48:59,645 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 10:49:18,873 - trainer - INFO] - [Epoch Validation] Epoch:[5/100] Total Loss: 178.883153 GL_Loss: 0.022216 CRF_Loss: 176.661580 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.366197 | 0.66242  | 0.471655 | 0.66242  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.268966 | 0.103723 | 0.149712 | 0.103723 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0        | 0        | 0        | 0        |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.467391 | 0.467391 | 0.467391 | 0.467391 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.329204 | 0.198083 | 0.24734  | 0.198083 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 10:49:33,588 - trainer - INFO] - Train Epoch:[6/100] Step:[10/250] Total Loss: 79.988678 GL_Loss: 0.779205 CRF_Loss: 79.209473\n",
      "[2022-02-17 10:49:48,456 - trainer - INFO] - Train Epoch:[6/100] Step:[20/250] Total Loss: 143.294128 GL_Loss: 0.768011 CRF_Loss: 142.526123\n",
      "[2022-02-17 10:50:02,117 - trainer - INFO] - Train Epoch:[6/100] Step:[30/250] Total Loss: 146.113785 GL_Loss: 1.076671 CRF_Loss: 145.037109\n",
      "[2022-02-17 10:50:15,977 - trainer - INFO] - Train Epoch:[6/100] Step:[40/250] Total Loss: 64.165268 GL_Loss: 5.329576 CRF_Loss: 58.835693\n",
      "[2022-02-17 10:50:29,520 - trainer - INFO] - Train Epoch:[6/100] Step:[50/250] Total Loss: 194.893387 GL_Loss: 4.511557 CRF_Loss: 190.381836\n",
      "[2022-02-17 10:50:48,785 - trainer - INFO] - [Step Validation] Epoch:[6/100] Step:[50/250]  \n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| name    |       mEP |       mER |       mEF |       mEA |\n",
      "+=========+===========+===========+===========+===========+\n",
      "| date    | 0.383513  | 0.681529  | 0.490826  | 0.681529  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| address | 0.0555556 | 0.0212766 | 0.0307692 | 0.0212766 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| total   | 0.0649351 | 0.0159236 | 0.0255754 | 0.0159236 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| company | 0.422018  | 0.5       | 0.457711  | 0.5       |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| overall | 0.272578  | 0.176784  | 0.21447   | 0.176784  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "[2022-02-17 10:51:02,553 - trainer - INFO] - Train Epoch:[6/100] Step:[60/250] Total Loss: 60.423866 GL_Loss: 0.887855 CRF_Loss: 59.536011\n",
      "[2022-02-17 10:51:16,939 - trainer - INFO] - Train Epoch:[6/100] Step:[70/250] Total Loss: 636.465576 GL_Loss: 0.626194 CRF_Loss: 635.839355\n",
      "[2022-02-17 10:51:31,867 - trainer - INFO] - Train Epoch:[6/100] Step:[80/250] Total Loss: 436.335876 GL_Loss: 0.349196 CRF_Loss: 435.986694\n",
      "[2022-02-17 10:51:45,790 - trainer - INFO] - Train Epoch:[6/100] Step:[90/250] Total Loss: 109.598228 GL_Loss: 8.612264 CRF_Loss: 100.985962\n",
      "[2022-02-17 10:52:00,387 - trainer - INFO] - Train Epoch:[6/100] Step:[100/250] Total Loss: 667.771179 GL_Loss: 2.122006 CRF_Loss: 665.649170\n",
      "[2022-02-17 10:52:19,754 - trainer - INFO] - [Step Validation] Epoch:[6/100] Step:[100/250]  \n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| name    |      mEP |       mER |      mEF |       mEA |\n",
      "+=========+==========+===========+==========+===========+\n",
      "| date    | 0.21875  | 0.44586   | 0.293501 | 0.44586   |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| address | 0.316327 | 0.0824468 | 0.130802 | 0.0824468 |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| total   | 0.2      | 0.0541401 | 0.085213 | 0.0541401 |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| company | 0.22973  | 0.184783  | 0.204819 | 0.184783  |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| overall | 0.233969 | 0.14377   | 0.1781   | 0.14377   |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "[2022-02-17 10:52:35,189 - trainer - INFO] - Train Epoch:[6/100] Step:[110/250] Total Loss: 251.768631 GL_Loss: 0.251177 CRF_Loss: 251.517456\n",
      "[2022-02-17 10:52:49,019 - trainer - INFO] - Train Epoch:[6/100] Step:[120/250] Total Loss: 226.390152 GL_Loss: 0.332410 CRF_Loss: 226.057739\n",
      "[2022-02-17 10:53:04,310 - trainer - INFO] - Train Epoch:[6/100] Step:[130/250] Total Loss: 177.625046 GL_Loss: 0.773117 CRF_Loss: 176.851929\n",
      "[2022-02-17 10:53:18,782 - trainer - INFO] - Train Epoch:[6/100] Step:[140/250] Total Loss: 160.305038 GL_Loss: 1.231306 CRF_Loss: 159.073730\n",
      "[2022-02-17 10:53:33,054 - trainer - INFO] - Train Epoch:[6/100] Step:[150/250] Total Loss: 183.098160 GL_Loss: 1.020162 CRF_Loss: 182.078003\n",
      "[2022-02-17 10:53:52,239 - trainer - INFO] - [Step Validation] Epoch:[6/100] Step:[150/250]  \n",
      "+---------+------------+------------+------------+------------+\n",
      "| name    |        mEP |        mER |        mEF |        mEA |\n",
      "+=========+============+============+============+============+\n",
      "| date    | 0.348936   | 0.522293   | 0.418367   | 0.522293   |\n",
      "+---------+------------+------------+------------+------------+\n",
      "| address | 0.00584795 | 0.00265957 | 0.00365631 | 0.00265957 |\n",
      "+---------+------------+------------+------------+------------+\n",
      "| total   | 0.258475   | 0.388535   | 0.310433   | 0.388535   |\n",
      "+---------+------------+------------+------------+------------+\n",
      "| company | 0.201613   | 0.271739   | 0.231481   | 0.271739   |\n",
      "+---------+------------+------------+------------+------------+\n",
      "| overall | 0.229541   | 0.244941   | 0.236991   | 0.244941   |\n",
      "+---------+------------+------------+------------+------------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 10:54:06,997 - trainer - INFO] - Train Epoch:[6/100] Step:[160/250] Total Loss: 159.984406 GL_Loss: 1.203405 CRF_Loss: 158.781006\n",
      "[2022-02-17 10:54:22,098 - trainer - INFO] - Train Epoch:[6/100] Step:[170/250] Total Loss: 140.083282 GL_Loss: 0.944491 CRF_Loss: 139.138794\n",
      "[2022-02-17 10:54:37,272 - trainer - INFO] - Train Epoch:[6/100] Step:[180/250] Total Loss: 160.661957 GL_Loss: 1.186130 CRF_Loss: 159.475830\n",
      "[2022-02-17 10:54:52,685 - trainer - INFO] - Train Epoch:[6/100] Step:[190/250] Total Loss: 188.447693 GL_Loss: 2.249385 CRF_Loss: 186.198303\n",
      "[2022-02-17 10:55:06,291 - trainer - INFO] - Train Epoch:[6/100] Step:[200/250] Total Loss: 150.917404 GL_Loss: 2.179125 CRF_Loss: 148.738281\n",
      "[2022-02-17 10:55:25,557 - trainer - INFO] - [Step Validation] Epoch:[6/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.269565 | 0.394904 | 0.320413 | 0.394904 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0        | 0        | 0        | 0        |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.243028 | 0.194268 | 0.215929 | 0.194268 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.239583 | 0.25     | 0.244681 | 0.25     |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.215976 | 0.155485 | 0.180805 | 0.155485 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 10:55:40,806 - trainer - INFO] - Train Epoch:[6/100] Step:[210/250] Total Loss: 145.700623 GL_Loss: 1.038393 CRF_Loss: 144.662231\n",
      "[2022-02-17 10:55:56,278 - trainer - INFO] - Train Epoch:[6/100] Step:[220/250] Total Loss: 116.316216 GL_Loss: 0.744557 CRF_Loss: 115.571655\n",
      "[2022-02-17 10:56:10,012 - trainer - INFO] - Train Epoch:[6/100] Step:[230/250] Total Loss: 140.890259 GL_Loss: 1.020268 CRF_Loss: 139.869995\n",
      "[2022-02-17 10:56:25,009 - trainer - INFO] - Train Epoch:[6/100] Step:[240/250] Total Loss: 174.252594 GL_Loss: 0.777003 CRF_Loss: 173.475586\n",
      "[2022-02-17 10:56:38,654 - trainer - INFO] - Train Epoch:[6/100] Step:[250/250] Total Loss: 122.570419 GL_Loss: 1.212024 CRF_Loss: 121.358398\n",
      "[2022-02-17 10:56:57,771 - trainer - INFO] - [Step Validation] Epoch:[6/100] Step:[250/250]  \n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| name    |       mEP |       mER |       mEF |       mEA |\n",
      "+=========+===========+===========+===========+===========+\n",
      "| date    | 0.263566  | 0.649682  | 0.375     | 0.649682  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| address | 0.0240964 | 0.0106383 | 0.0147601 | 0.0106383 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| total   | 0.213592  | 0.210191  | 0.211878  | 0.210191  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| company | 0.35514   | 0.413043  | 0.38191   | 0.413043  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| overall | 0.216718  | 0.223642  | 0.220126  | 0.223642  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "[2022-02-17 10:57:16,860 - trainer - INFO] - [Epoch Validation] Epoch:[6/100] Total Loss: 209.802417 GL_Loss: 0.024497 CRF_Loss: 207.352721 \n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| name    |       mEP |       mER |       mEF |       mEA |\n",
      "+=========+===========+===========+===========+===========+\n",
      "| date    | 0.263566  | 0.649682  | 0.375     | 0.649682  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| address | 0.0240964 | 0.0106383 | 0.0147601 | 0.0106383 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| total   | 0.213592  | 0.210191  | 0.211878  | 0.210191  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| company | 0.35514   | 0.413043  | 0.38191   | 0.413043  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| overall | 0.216718  | 0.223642  | 0.220126  | 0.223642  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "[2022-02-17 10:57:32,916 - trainer - INFO] - Train Epoch:[7/100] Step:[10/250] Total Loss: 106.977730 GL_Loss: 0.578556 CRF_Loss: 106.399170\n",
      "[2022-02-17 10:57:47,808 - trainer - INFO] - Train Epoch:[7/100] Step:[20/250] Total Loss: 132.946411 GL_Loss: 1.092408 CRF_Loss: 131.854004\n",
      "[2022-02-17 10:58:02,268 - trainer - INFO] - Train Epoch:[7/100] Step:[30/250] Total Loss: 101.614510 GL_Loss: 0.999520 CRF_Loss: 100.614990\n",
      "[2022-02-17 10:58:17,101 - trainer - INFO] - Train Epoch:[7/100] Step:[40/250] Total Loss: 103.149010 GL_Loss: 1.107380 CRF_Loss: 102.041626\n",
      "[2022-02-17 10:58:32,542 - trainer - INFO] - Train Epoch:[7/100] Step:[50/250] Total Loss: 84.797821 GL_Loss: 1.151461 CRF_Loss: 83.646362\n",
      "[2022-02-17 10:58:51,597 - trainer - INFO] - [Step Validation] Epoch:[7/100] Step:[50/250]  \n",
      "+---------+-----------+------------+-----------+------------+\n",
      "| name    |       mEP |        mER |       mEF |        mEA |\n",
      "+=========+===========+============+===========+============+\n",
      "| date    | 0.532407  | 0.732484   | 0.616622  | 0.732484   |\n",
      "+---------+-----------+------------+-----------+------------+\n",
      "| address | 0.057554  | 0.0212766  | 0.031068  | 0.0212766  |\n",
      "+---------+-----------+------------+-----------+------------+\n",
      "| total   | 0.0434783 | 0.00636943 | 0.0111111 | 0.00636943 |\n",
      "+---------+-----------+------------+-----------+------------+\n",
      "| company | 0.404255  | 0.413043   | 0.408602  | 0.413043   |\n",
      "+---------+-----------+------------+-----------+------------+\n",
      "| overall | 0.329293  | 0.173589   | 0.227336  | 0.173589   |\n",
      "+---------+-----------+------------+-----------+------------+\n",
      "[2022-02-17 10:59:06,606 - trainer - INFO] - Train Epoch:[7/100] Step:[60/250] Total Loss: 234.618042 GL_Loss: 0.624641 CRF_Loss: 233.993408\n",
      "[2022-02-17 10:59:21,513 - trainer - INFO] - Train Epoch:[7/100] Step:[70/250] Total Loss: 140.268326 GL_Loss: 0.803604 CRF_Loss: 139.464722\n",
      "[2022-02-17 10:59:35,178 - trainer - INFO] - Train Epoch:[7/100] Step:[80/250] Total Loss: 97.491341 GL_Loss: 0.956551 CRF_Loss: 96.534790\n",
      "[2022-02-17 10:59:48,679 - trainer - INFO] - Train Epoch:[7/100] Step:[90/250] Total Loss: 202.582031 GL_Loss: 0.919674 CRF_Loss: 201.662354\n",
      "[2022-02-17 11:00:02,894 - trainer - INFO] - Train Epoch:[7/100] Step:[100/250] Total Loss: 86.072983 GL_Loss: 1.108869 CRF_Loss: 84.964111\n",
      "[2022-02-17 11:00:22,348 - trainer - INFO] - [Step Validation] Epoch:[7/100] Step:[100/250]  \n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| name    |       mEP |       mER |       mEF |       mEA |\n",
      "+=========+===========+===========+===========+===========+\n",
      "| date    | 0.38587   | 0.452229  | 0.416422  | 0.452229  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| address | 0.0875    | 0.037234  | 0.0522388 | 0.037234  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| total   | 0.0454545 | 0.0159236 | 0.0235849 | 0.0159236 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| company | 0.521739  | 0.521739  | 0.521739  | 0.521739  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| overall | 0.252747  | 0.146965  | 0.185859  | 0.146965  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "[2022-02-17 11:00:35,989 - trainer - INFO] - Train Epoch:[7/100] Step:[110/250] Total Loss: 71.865860 GL_Loss: 1.326678 CRF_Loss: 70.539185\n",
      "[2022-02-17 11:00:50,215 - trainer - INFO] - Train Epoch:[7/100] Step:[120/250] Total Loss: 377.712311 GL_Loss: 0.516267 CRF_Loss: 377.196045\n",
      "[2022-02-17 11:01:03,340 - trainer - INFO] - Train Epoch:[7/100] Step:[130/250] Total Loss: 149.675308 GL_Loss: 0.596321 CRF_Loss: 149.078979\n",
      "[2022-02-17 11:01:17,002 - trainer - INFO] - Train Epoch:[7/100] Step:[140/250] Total Loss: 65.044052 GL_Loss: 0.724592 CRF_Loss: 64.319458\n",
      "[2022-02-17 11:01:31,496 - trainer - INFO] - Train Epoch:[7/100] Step:[150/250] Total Loss: 112.818779 GL_Loss: 0.469290 CRF_Loss: 112.349487\n",
      "[2022-02-17 11:01:50,614 - trainer - INFO] - [Step Validation] Epoch:[7/100] Step:[150/250]  \n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| name    |      mEP |       mER |       mEF |       mEA |\n",
      "+=========+==========+===========+===========+===========+\n",
      "| date    | 0.504545 | 0.707006  | 0.588859  | 0.707006  |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| address | 0.115385 | 0.0398936 | 0.0592885 | 0.0398936 |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| total   | 0.15     | 0.0382166 | 0.0609137 | 0.0382166 |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| company | 0.375    | 0.228261  | 0.283784  | 0.228261  |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| overall | 0.32716  | 0.169329  | 0.223158  | 0.169329  |\n",
      "+---------+----------+-----------+-----------+-----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 11:02:06,123 - trainer - INFO] - Train Epoch:[7/100] Step:[160/250] Total Loss: 69.357567 GL_Loss: 0.471823 CRF_Loss: 68.885742\n",
      "[2022-02-17 11:02:20,422 - trainer - INFO] - Train Epoch:[7/100] Step:[170/250] Total Loss: 928.009949 GL_Loss: 1.015819 CRF_Loss: 926.994141\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 11:02:34,862 - trainer - INFO] - Train Epoch:[7/100] Step:[180/250] Total Loss: 132.055618 GL_Loss: 3.159741 CRF_Loss: 128.895874\n",
      "[2022-02-17 11:02:49,910 - trainer - INFO] - Train Epoch:[7/100] Step:[190/250] Total Loss: 198.253311 GL_Loss: 1.350961 CRF_Loss: 196.902344\n",
      "[2022-02-17 11:03:04,683 - trainer - INFO] - Train Epoch:[7/100] Step:[200/250] Total Loss: 143.489029 GL_Loss: 0.618054 CRF_Loss: 142.870972\n",
      "[2022-02-17 11:03:23,645 - trainer - INFO] - [Step Validation] Epoch:[7/100] Step:[200/250]  \n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| name    |       mEP |       mER |       mEF |       mEA |\n",
      "+=========+===========+===========+===========+===========+\n",
      "| date    | 0.0445545 | 0.0573248 | 0.0501393 | 0.0573248 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| address | 0.084507  | 0.0319149 | 0.046332  | 0.0319149 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| total   | 0         | 0         | 0         | 0         |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| company | 0.397849  | 0.402174  | 0.4       | 0.402174  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| overall | 0.124464  | 0.0617678 | 0.0825623 | 0.0617678 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "[2022-02-17 11:03:37,899 - trainer - INFO] - Train Epoch:[7/100] Step:[210/250] Total Loss: 94.008263 GL_Loss: 0.978115 CRF_Loss: 93.030151\n",
      "[2022-02-17 11:03:53,066 - trainer - INFO] - Train Epoch:[7/100] Step:[220/250] Total Loss: 111.034241 GL_Loss: 1.040098 CRF_Loss: 109.994141\n",
      "[2022-02-17 11:04:06,911 - trainer - INFO] - Train Epoch:[7/100] Step:[230/250] Total Loss: 93.117615 GL_Loss: 1.299742 CRF_Loss: 91.817871\n",
      "[2022-02-17 11:04:21,558 - trainer - INFO] - Train Epoch:[7/100] Step:[240/250] Total Loss: 56.251129 GL_Loss: 0.946684 CRF_Loss: 55.304443\n",
      "[2022-02-17 11:04:35,821 - trainer - INFO] - Train Epoch:[7/100] Step:[250/250] Total Loss: 85.454285 GL_Loss: 1.029477 CRF_Loss: 84.424805\n",
      "[2022-02-17 11:04:54,956 - trainer - INFO] - [Step Validation] Epoch:[7/100] Step:[250/250]  \n",
      "+---------+----------+----------+-----------+----------+\n",
      "| name    |      mEP |      mER |       mEF |      mEA |\n",
      "+=========+==========+==========+===========+==========+\n",
      "| date    | 0.133956 | 0.273885 | 0.179916  | 0.273885 |\n",
      "+---------+----------+----------+-----------+----------+\n",
      "| address | 0.0875   | 0.037234 | 0.0522388 | 0.037234 |\n",
      "+---------+----------+----------+-----------+----------+\n",
      "| total   | 0.38342  | 0.235669 | 0.291913  | 0.235669 |\n",
      "+---------+----------+----------+-----------+----------+\n",
      "| company | 0.454545 | 0.48913  | 0.471204  | 0.48913  |\n",
      "+---------+----------+----------+-----------+----------+\n",
      "| overall | 0.227684 | 0.187433 | 0.205607  | 0.187433 |\n",
      "+---------+----------+----------+-----------+----------+\n",
      "[2022-02-17 11:05:14,176 - trainer - INFO] - [Epoch Validation] Epoch:[7/100] Total Loss: 177.188628 GL_Loss: 0.015308 CRF_Loss: 175.657780 \n",
      "+---------+----------+----------+-----------+----------+\n",
      "| name    |      mEP |      mER |       mEF |      mEA |\n",
      "+=========+==========+==========+===========+==========+\n",
      "| date    | 0.133956 | 0.273885 | 0.179916  | 0.273885 |\n",
      "+---------+----------+----------+-----------+----------+\n",
      "| address | 0.0875   | 0.037234 | 0.0522388 | 0.037234 |\n",
      "+---------+----------+----------+-----------+----------+\n",
      "| total   | 0.38342  | 0.235669 | 0.291913  | 0.235669 |\n",
      "+---------+----------+----------+-----------+----------+\n",
      "| company | 0.454545 | 0.48913  | 0.471204  | 0.48913  |\n",
      "+---------+----------+----------+-----------+----------+\n",
      "| overall | 0.227684 | 0.187433 | 0.205607  | 0.187433 |\n",
      "+---------+----------+----------+-----------+----------+\n",
      "[2022-02-17 11:05:28,905 - trainer - INFO] - Train Epoch:[8/100] Step:[10/250] Total Loss: 112.465279 GL_Loss: 0.976268 CRF_Loss: 111.489014\n",
      "[2022-02-17 11:05:43,681 - trainer - INFO] - Train Epoch:[8/100] Step:[20/250] Total Loss: 157.052582 GL_Loss: 0.858666 CRF_Loss: 156.193909\n",
      "[2022-02-17 11:05:56,574 - trainer - INFO] - Train Epoch:[8/100] Step:[30/250] Total Loss: 117.101555 GL_Loss: 0.781733 CRF_Loss: 116.319824\n",
      "[2022-02-17 11:06:11,302 - trainer - INFO] - Train Epoch:[8/100] Step:[40/250] Total Loss: 145.421890 GL_Loss: 0.883200 CRF_Loss: 144.538696\n",
      "[2022-02-17 11:06:26,061 - trainer - INFO] - Train Epoch:[8/100] Step:[50/250] Total Loss: 51.119099 GL_Loss: 1.171711 CRF_Loss: 49.947388\n",
      "[2022-02-17 11:06:45,314 - trainer - INFO] - [Step Validation] Epoch:[8/100] Step:[50/250]  \n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| name    |      mEP |       mER |       mEF |       mEA |\n",
      "+=========+==========+===========+===========+===========+\n",
      "| date    | 0.323651 | 0.496815  | 0.39196   | 0.496815  |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| address | 0.133803 | 0.0505319 | 0.0733591 | 0.0505319 |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| total   | 0.27476  | 0.273885  | 0.274322  | 0.273885  |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| company | 0.542056 | 0.630435  | 0.582915  | 0.630435  |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| overall | 0.300125 | 0.256656  | 0.276693  | 0.256656  |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "[2022-02-17 11:06:47,600 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 11:07:01,243 - trainer - INFO] - Train Epoch:[8/100] Step:[60/250] Total Loss: 64.202744 GL_Loss: 1.912982 CRF_Loss: 62.289764\n",
      "[2022-02-17 11:07:15,870 - trainer - INFO] - Train Epoch:[8/100] Step:[70/250] Total Loss: 69.530045 GL_Loss: 0.476336 CRF_Loss: 69.053711\n",
      "[2022-02-17 11:07:29,144 - trainer - INFO] - Train Epoch:[8/100] Step:[80/250] Total Loss: 38.475479 GL_Loss: 0.960830 CRF_Loss: 37.514648\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 11:07:43,991 - trainer - INFO] - Train Epoch:[8/100] Step:[90/250] Total Loss: 61.141445 GL_Loss: 0.680262 CRF_Loss: 60.461182\n",
      "[2022-02-17 11:07:59,147 - trainer - INFO] - Train Epoch:[8/100] Step:[100/250] Total Loss: 78.237686 GL_Loss: 0.615002 CRF_Loss: 77.622681\n",
      "[2022-02-17 11:08:18,330 - trainer - INFO] - [Step Validation] Epoch:[8/100] Step:[100/250]  \n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| name    |      mEP |       mER |      mEF |       mEA |\n",
      "+=========+==========+===========+==========+===========+\n",
      "| date    | 0.367257 | 0.528662  | 0.43342  | 0.528662  |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| address | 0.10119  | 0.0452128 | 0.0625   | 0.0452128 |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| total   | 0.270451 | 0.515924  | 0.354874 | 0.515924  |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| company | 0.56701  | 0.597826  | 0.582011 | 0.597826  |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| overall | 0.290826 | 0.337593  | 0.312469 | 0.337593  |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "[2022-02-17 11:08:20,472 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 11:08:35,223 - trainer - INFO] - Train Epoch:[8/100] Step:[110/250] Total Loss: 94.593117 GL_Loss: 0.499123 CRF_Loss: 94.093994\n",
      "[2022-02-17 11:08:49,064 - trainer - INFO] - Train Epoch:[8/100] Step:[120/250] Total Loss: 767.900635 GL_Loss: 1.117619 CRF_Loss: 766.783020\n",
      "[2022-02-17 11:09:03,431 - trainer - INFO] - Train Epoch:[8/100] Step:[130/250] Total Loss: 257.177917 GL_Loss: 2.107371 CRF_Loss: 255.070557\n",
      "[2022-02-17 11:09:17,881 - trainer - INFO] - Train Epoch:[8/100] Step:[140/250] Total Loss: 126.287766 GL_Loss: 2.147749 CRF_Loss: 124.140015\n",
      "[2022-02-17 11:09:33,332 - trainer - INFO] - Train Epoch:[8/100] Step:[150/250] Total Loss: 147.610016 GL_Loss: 1.952184 CRF_Loss: 145.657837\n",
      "[2022-02-17 11:09:52,638 - trainer - INFO] - [Step Validation] Epoch:[8/100] Step:[150/250]  \n",
      "+---------+------------+------------+------------+------------+\n",
      "| name    |        mEP |        mER |        mEF |        mEA |\n",
      "+=========+============+============+============+============+\n",
      "| date    | 0.474576   | 0.535032   | 0.502994   | 0.535032   |\n",
      "+---------+------------+------------+------------+------------+\n",
      "| address | 0.00568182 | 0.00265957 | 0.00362319 | 0.00265957 |\n",
      "+---------+------------+------------+------------+------------+\n",
      "| total   | 0          | 0          | 0          | 0          |\n",
      "+---------+------------+------------+------------+------------+\n",
      "| company | 0.385321   | 0.456522   | 0.41791    | 0.456522   |\n",
      "+---------+------------+------------+------------+------------+\n",
      "| overall | 0.273118   | 0.13525    | 0.180912   | 0.13525    |\n",
      "+---------+------------+------------+------------+------------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 11:10:06,489 - trainer - INFO] - Train Epoch:[8/100] Step:[160/250] Total Loss: 201.804794 GL_Loss: 0.828966 CRF_Loss: 200.975830\n",
      "[2022-02-17 11:10:21,269 - trainer - INFO] - Train Epoch:[8/100] Step:[170/250] Total Loss: 77.618492 GL_Loss: 0.698814 CRF_Loss: 76.919678\n",
      "[2022-02-17 11:10:36,084 - trainer - INFO] - Train Epoch:[8/100] Step:[180/250] Total Loss: 105.579201 GL_Loss: 2.613140 CRF_Loss: 102.966064\n",
      "[2022-02-17 11:10:51,566 - trainer - INFO] - Train Epoch:[8/100] Step:[190/250] Total Loss: 101.333290 GL_Loss: 0.807408 CRF_Loss: 100.525879\n",
      "[2022-02-17 11:11:05,384 - trainer - INFO] - Train Epoch:[8/100] Step:[200/250] Total Loss: 84.754875 GL_Loss: 1.316398 CRF_Loss: 83.438477\n",
      "[2022-02-17 11:11:24,475 - trainer - INFO] - [Step Validation] Epoch:[8/100] Step:[200/250]  \n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| name    |      mEP |       mER |       mEF |       mEA |\n",
      "+=========+==========+===========+===========+===========+\n",
      "| date    | 0.571429 | 0.713376  | 0.634561  | 0.713376  |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| address | 0.14     | 0.0558511 | 0.0798479 | 0.0558511 |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| total   | 0.319588 | 0.0987261 | 0.150852  | 0.0987261 |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| company | 0.534653 | 0.586957  | 0.559585  | 0.586957  |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| overall | 0.400735 | 0.232162  | 0.293999  | 0.232162  |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "[2022-02-17 11:11:39,729 - trainer - INFO] - Train Epoch:[8/100] Step:[210/250] Total Loss: 58.646820 GL_Loss: 2.202118 CRF_Loss: 56.444702\n",
      "[2022-02-17 11:11:53,345 - trainer - INFO] - Train Epoch:[8/100] Step:[220/250] Total Loss: 161.930832 GL_Loss: 1.960856 CRF_Loss: 159.969971\n",
      "[2022-02-17 11:12:09,367 - trainer - INFO] - Train Epoch:[8/100] Step:[230/250] Total Loss: 125.647194 GL_Loss: 1.512796 CRF_Loss: 124.134399\n",
      "[2022-02-17 11:12:23,992 - trainer - INFO] - Train Epoch:[8/100] Step:[240/250] Total Loss: 108.677307 GL_Loss: 1.001160 CRF_Loss: 107.676147\n",
      "[2022-02-17 11:12:38,935 - trainer - INFO] - Train Epoch:[8/100] Step:[250/250] Total Loss: 92.218559 GL_Loss: 0.997734 CRF_Loss: 91.220825\n",
      "[2022-02-17 11:12:57,986 - trainer - INFO] - [Step Validation] Epoch:[8/100] Step:[250/250]  \n",
      "+---------+----------+------------+------------+------------+\n",
      "| name    |      mEP |        mER |        mEF |        mEA |\n",
      "+=========+==========+============+============+============+\n",
      "| date    | 0.597938 | 0.738854   | 0.660969   | 0.738854   |\n",
      "+---------+----------+------------+------------+------------+\n",
      "| address | 0.181818 | 0.0691489  | 0.100193   | 0.0691489  |\n",
      "+---------+----------+------------+------------+------------+\n",
      "| total   | 0.5      | 0.00318471 | 0.00632911 | 0.00318471 |\n",
      "+---------+----------+------------+------------+------------+\n",
      "| company | 0.472527 | 0.467391   | 0.469945   | 0.467391   |\n",
      "+---------+----------+------------+------------+------------+\n",
      "| overall | 0.432558 | 0.198083   | 0.271731   | 0.198083   |\n",
      "+---------+----------+------------+------------+------------+\n",
      "[2022-02-17 11:13:17,206 - trainer - INFO] - [Epoch Validation] Epoch:[8/100] Total Loss: 153.640040 GL_Loss: 0.013362 CRF_Loss: 152.303844 \n",
      "+---------+----------+------------+------------+------------+\n",
      "| name    |      mEP |        mER |        mEF |        mEA |\n",
      "+=========+==========+============+============+============+\n",
      "| date    | 0.597938 | 0.738854   | 0.660969   | 0.738854   |\n",
      "+---------+----------+------------+------------+------------+\n",
      "| address | 0.181818 | 0.0691489  | 0.100193   | 0.0691489  |\n",
      "+---------+----------+------------+------------+------------+\n",
      "| total   | 0.5      | 0.00318471 | 0.00632911 | 0.00318471 |\n",
      "+---------+----------+------------+------------+------------+\n",
      "| company | 0.472527 | 0.467391   | 0.469945   | 0.467391   |\n",
      "+---------+----------+------------+------------+------------+\n",
      "| overall | 0.432558 | 0.198083   | 0.271731   | 0.198083   |\n",
      "+---------+----------+------------+------------+------------+\n",
      "[2022-02-17 11:13:34,333 - trainer - INFO] - Train Epoch:[9/100] Step:[10/250] Total Loss: 61.271294 GL_Loss: 1.438774 CRF_Loss: 59.832520\n",
      "[2022-02-17 11:13:48,693 - trainer - INFO] - Train Epoch:[9/100] Step:[20/250] Total Loss: 45.674820 GL_Loss: 1.125992 CRF_Loss: 44.548828\n",
      "[2022-02-17 11:14:02,656 - trainer - INFO] - Train Epoch:[9/100] Step:[30/250] Total Loss: 261.502167 GL_Loss: 1.476895 CRF_Loss: 260.025269\n",
      "[2022-02-17 11:14:16,539 - trainer - INFO] - Train Epoch:[9/100] Step:[40/250] Total Loss: 100.709358 GL_Loss: 1.791020 CRF_Loss: 98.918335\n",
      "[2022-02-17 11:14:31,664 - trainer - INFO] - Train Epoch:[9/100] Step:[50/250] Total Loss: 57.722973 GL_Loss: 2.142284 CRF_Loss: 55.580688\n",
      "[2022-02-17 11:14:50,735 - trainer - INFO] - [Step Validation] Epoch:[9/100] Step:[50/250]  \n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| name    |      mEP |       mER |      mEF |       mEA |\n",
      "+=========+==========+===========+==========+===========+\n",
      "| date    | 0.589286 | 0.630573  | 0.609231 | 0.630573  |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| address | 0.270677 | 0.0957447 | 0.141454 | 0.0957447 |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| total   | 0        | 0         | 0        | 0         |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| company | 0.246154 | 0.173913  | 0.203822 | 0.173913  |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| overall | 0.403743 | 0.160809  | 0.230008 | 0.160809  |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "[2022-02-17 11:15:04,567 - trainer - INFO] - Train Epoch:[9/100] Step:[60/250] Total Loss: 67.301773 GL_Loss: 3.290541 CRF_Loss: 64.011230\n",
      "[2022-02-17 11:15:18,897 - trainer - INFO] - Train Epoch:[9/100] Step:[70/250] Total Loss: 126.347023 GL_Loss: 1.234351 CRF_Loss: 125.112671\n",
      "[2022-02-17 11:15:33,495 - trainer - INFO] - Train Epoch:[9/100] Step:[80/250] Total Loss: 94.491142 GL_Loss: 0.961842 CRF_Loss: 93.529297\n",
      "[2022-02-17 11:15:48,391 - trainer - INFO] - Train Epoch:[9/100] Step:[90/250] Total Loss: 94.346336 GL_Loss: 0.348415 CRF_Loss: 93.997925\n",
      "[2022-02-17 11:16:03,616 - trainer - INFO] - Train Epoch:[9/100] Step:[100/250] Total Loss: 44.763962 GL_Loss: 0.447555 CRF_Loss: 44.316406\n",
      "[2022-02-17 11:16:22,812 - trainer - INFO] - [Step Validation] Epoch:[9/100] Step:[100/250]  \n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| name    |      mEP |       mER |      mEF |       mEA |\n",
      "+=========+==========+===========+==========+===========+\n",
      "| date    | 0.757225 | 0.834395  | 0.793939 | 0.834395  |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| address | 0.210526 | 0.0851064 | 0.121212 | 0.0851064 |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| total   | 0.407407 | 0.280255  | 0.332075 | 0.280255  |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| company | 0.514851 | 0.565217  | 0.53886  | 0.565217  |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| overall | 0.471963 | 0.322684  | 0.383302 | 0.322684  |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "[2022-02-17 11:16:24,936 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 11:16:39,114 - trainer - INFO] - Train Epoch:[9/100] Step:[110/250] Total Loss: 97.672798 GL_Loss: 0.567449 CRF_Loss: 97.105347\n",
      "[2022-02-17 11:16:54,281 - trainer - INFO] - Train Epoch:[9/100] Step:[120/250] Total Loss: 54.783020 GL_Loss: 1.737488 CRF_Loss: 53.045532\n",
      "[2022-02-17 11:17:09,543 - trainer - INFO] - Train Epoch:[9/100] Step:[130/250] Total Loss: 119.005226 GL_Loss: 4.769018 CRF_Loss: 114.236206\n",
      "[2022-02-17 11:17:23,740 - trainer - INFO] - Train Epoch:[9/100] Step:[140/250] Total Loss: 43.877823 GL_Loss: 0.804824 CRF_Loss: 43.072998\n",
      "[2022-02-17 11:17:37,766 - trainer - INFO] - Train Epoch:[9/100] Step:[150/250] Total Loss: 221.197296 GL_Loss: 0.577427 CRF_Loss: 220.619873\n",
      "[2022-02-17 11:17:56,752 - trainer - INFO] - [Step Validation] Epoch:[9/100] Step:[150/250]  \n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| name    |       mEP |       mER |       mEF |       mEA |\n",
      "+=========+===========+===========+===========+===========+\n",
      "| date    | 0.466667  | 0.757962  | 0.57767   | 0.757962  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| address | 0.0949367 | 0.0398936 | 0.0561798 | 0.0398936 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| total   | 0.37469   | 0.480892  | 0.421199  | 0.480892  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| company | 0.509615  | 0.576087  | 0.540816  | 0.576087  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| overall | 0.367391  | 0.359957  | 0.363636  | 0.359957  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 11:18:12,532 - trainer - INFO] - Train Epoch:[9/100] Step:[160/250] Total Loss: 112.852440 GL_Loss: 0.420191 CRF_Loss: 112.432251\n",
      "[2022-02-17 11:18:26,965 - trainer - INFO] - Train Epoch:[9/100] Step:[170/250] Total Loss: 198.994690 GL_Loss: 0.663751 CRF_Loss: 198.330933\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 11:18:41,958 - trainer - INFO] - Train Epoch:[9/100] Step:[180/250] Total Loss: 199.008301 GL_Loss: 0.591680 CRF_Loss: 198.416626\n",
      "[2022-02-17 11:18:56,130 - trainer - INFO] - Train Epoch:[9/100] Step:[190/250] Total Loss: 260.668488 GL_Loss: 0.777361 CRF_Loss: 259.891113\n",
      "[2022-02-17 11:19:11,019 - trainer - INFO] - Train Epoch:[9/100] Step:[200/250] Total Loss: 89.407166 GL_Loss: 0.523008 CRF_Loss: 88.884155\n",
      "[2022-02-17 11:19:30,680 - trainer - INFO] - [Step Validation] Epoch:[9/100] Step:[200/250]  \n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| name    |       mEP |       mER |       mEF |       mEA |\n",
      "+=========+===========+===========+===========+===========+\n",
      "| date    | 0.639344  | 0.745223  | 0.688235  | 0.745223  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| address | 0.0457143 | 0.0212766 | 0.0290381 | 0.0212766 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| total   | 0.357466  | 0.251592  | 0.295327  | 0.251592  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| company | 0.577778  | 0.565217  | 0.571429  | 0.565217  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| overall | 0.382661  | 0.27263   | 0.318408  | 0.27263   |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "[2022-02-17 11:19:45,898 - trainer - INFO] - Train Epoch:[9/100] Step:[210/250] Total Loss: 119.197708 GL_Loss: 0.582778 CRF_Loss: 118.614929\n",
      "[2022-02-17 11:20:00,171 - trainer - INFO] - Train Epoch:[9/100] Step:[220/250] Total Loss: 102.915962 GL_Loss: 0.778511 CRF_Loss: 102.137451\n",
      "[2022-02-17 11:20:13,579 - trainer - INFO] - Train Epoch:[9/100] Step:[230/250] Total Loss: 219.296158 GL_Loss: 10.158892 CRF_Loss: 209.137268\n",
      "[2022-02-17 11:20:27,588 - trainer - INFO] - Train Epoch:[9/100] Step:[240/250] Total Loss: 54.215919 GL_Loss: 5.624001 CRF_Loss: 48.591919\n",
      "[2022-02-17 11:20:41,913 - trainer - INFO] - Train Epoch:[9/100] Step:[250/250] Total Loss: 104.412109 GL_Loss: 1.857304 CRF_Loss: 102.554810\n",
      "[2022-02-17 11:21:01,051 - trainer - INFO] - [Step Validation] Epoch:[9/100] Step:[250/250]  \n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| name    |      mEP |       mER |       mEF |       mEA |\n",
      "+=========+==========+===========+===========+===========+\n",
      "| date    | 0.597222 | 0.821656  | 0.691689  | 0.821656  |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| address | 0.272727 | 0.103723  | 0.150289  | 0.103723  |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| total   | 0.217391 | 0.0318471 | 0.0555556 | 0.0318471 |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| company | 0.564103 | 0.478261  | 0.517647  | 0.478261  |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| overall | 0.459627 | 0.236422  | 0.312236  | 0.236422  |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "[2022-02-17 11:21:20,088 - trainer - INFO] - [Epoch Validation] Epoch:[9/100] Total Loss: 136.970329 GL_Loss: 0.018633 CRF_Loss: 135.107041 \n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| name    |      mEP |       mER |       mEF |       mEA |\n",
      "+=========+==========+===========+===========+===========+\n",
      "| date    | 0.597222 | 0.821656  | 0.691689  | 0.821656  |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| address | 0.272727 | 0.103723  | 0.150289  | 0.103723  |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| total   | 0.217391 | 0.0318471 | 0.0555556 | 0.0318471 |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| company | 0.564103 | 0.478261  | 0.517647  | 0.478261  |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| overall | 0.459627 | 0.236422  | 0.312236  | 0.236422  |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "[2022-02-17 11:21:35,508 - trainer - INFO] - Train Epoch:[10/100] Step:[10/250] Total Loss: 58.738674 GL_Loss: 0.631619 CRF_Loss: 58.107056\n",
      "[2022-02-17 11:21:48,826 - trainer - INFO] - Train Epoch:[10/100] Step:[20/250] Total Loss: 74.884735 GL_Loss: 0.765964 CRF_Loss: 74.118774\n",
      "[2022-02-17 11:22:02,189 - trainer - INFO] - Train Epoch:[10/100] Step:[30/250] Total Loss: 36.670383 GL_Loss: 0.670138 CRF_Loss: 36.000244\n",
      "[2022-02-17 11:22:17,804 - trainer - INFO] - Train Epoch:[10/100] Step:[40/250] Total Loss: 54.118862 GL_Loss: 1.010465 CRF_Loss: 53.108398\n",
      "[2022-02-17 11:22:32,297 - trainer - INFO] - Train Epoch:[10/100] Step:[50/250] Total Loss: 39.650238 GL_Loss: 1.115083 CRF_Loss: 38.535156\n",
      "[2022-02-17 11:22:51,178 - trainer - INFO] - [Step Validation] Epoch:[10/100] Step:[50/250]  \n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| name    |      mEP |       mER |       mEF |       mEA |\n",
      "+=========+==========+===========+===========+===========+\n",
      "| date    | 0.509653 | 0.840764  | 0.634615  | 0.840764  |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| address | 0.127389 | 0.0531915 | 0.0750469 | 0.0531915 |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| total   | 0.495455 | 0.347134  | 0.40824   | 0.347134  |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| company | 0.461538 | 0.521739  | 0.489796  | 0.521739  |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| overall | 0.417568 | 0.329073  | 0.368076  | 0.329073  |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "[2022-02-17 11:23:04,054 - trainer - INFO] - Train Epoch:[10/100] Step:[60/250] Total Loss: 76.495064 GL_Loss: 0.420356 CRF_Loss: 76.074707\n",
      "[2022-02-17 11:23:18,488 - trainer - INFO] - Train Epoch:[10/100] Step:[70/250] Total Loss: 71.069756 GL_Loss: 0.428520 CRF_Loss: 70.641235\n",
      "[2022-02-17 11:23:32,665 - trainer - INFO] - Train Epoch:[10/100] Step:[80/250] Total Loss: 56.185959 GL_Loss: 0.579757 CRF_Loss: 55.606201\n",
      "[2022-02-17 11:23:46,200 - trainer - INFO] - Train Epoch:[10/100] Step:[90/250] Total Loss: 116.124207 GL_Loss: 1.277036 CRF_Loss: 114.847168\n",
      "[2022-02-17 11:23:59,625 - trainer - INFO] - Train Epoch:[10/100] Step:[100/250] Total Loss: 55.717106 GL_Loss: 0.958927 CRF_Loss: 54.758179\n",
      "[2022-02-17 11:24:18,902 - trainer - INFO] - [Step Validation] Epoch:[10/100] Step:[100/250]  \n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| name    |      mEP |       mER |      mEF |       mEA |\n",
      "+=========+==========+===========+==========+===========+\n",
      "| date    | 0.579646 | 0.834395  | 0.684073 | 0.834395  |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| address | 0.253623 | 0.0930851 | 0.136187 | 0.0930851 |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| total   | 0.460177 | 0.496815  | 0.477795 | 0.496815  |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| company | 0.623529 | 0.576087  | 0.59887  | 0.576087  |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| overall | 0.475888 | 0.399361  | 0.434279 | 0.399361  |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "[2022-02-17 11:24:21,000 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 11:24:34,212 - trainer - INFO] - Train Epoch:[10/100] Step:[110/250] Total Loss: 94.564438 GL_Loss: 0.709701 CRF_Loss: 93.854736\n",
      "[2022-02-17 11:24:48,019 - trainer - INFO] - Train Epoch:[10/100] Step:[120/250] Total Loss: 75.943436 GL_Loss: 0.537432 CRF_Loss: 75.406006\n",
      "[2022-02-17 11:25:02,311 - trainer - INFO] - Train Epoch:[10/100] Step:[130/250] Total Loss: 84.371239 GL_Loss: 0.507593 CRF_Loss: 83.863647\n",
      "[2022-02-17 11:25:17,413 - trainer - INFO] - Train Epoch:[10/100] Step:[140/250] Total Loss: 510.023865 GL_Loss: 3.482855 CRF_Loss: 506.541016\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 11:25:31,890 - trainer - INFO] - Train Epoch:[10/100] Step:[150/250] Total Loss: 53.822891 GL_Loss: 6.123304 CRF_Loss: 47.699585\n",
      "[2022-02-17 11:25:50,953 - trainer - INFO] - [Step Validation] Epoch:[10/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.58952  | 0.859873 | 0.699482 | 0.859873 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.286667 | 0.114362 | 0.163498 | 0.114362 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.38674  | 0.44586  | 0.414201 | 0.44586  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.521277 | 0.532609 | 0.526882 | 0.532609 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.439521 | 0.390841 | 0.413754 | 0.390841 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 11:26:06,004 - trainer - INFO] - Train Epoch:[10/100] Step:[160/250] Total Loss: 123.513885 GL_Loss: 0.694065 CRF_Loss: 122.819824\n",
      "[2022-02-17 11:26:21,171 - trainer - INFO] - Train Epoch:[10/100] Step:[170/250] Total Loss: 140.689667 GL_Loss: 23.364480 CRF_Loss: 117.325195\n",
      "[2022-02-17 11:26:36,613 - trainer - INFO] - Train Epoch:[10/100] Step:[180/250] Total Loss: 126.737198 GL_Loss: 1.939467 CRF_Loss: 124.797729\n",
      "[2022-02-17 11:26:50,518 - trainer - INFO] - Train Epoch:[10/100] Step:[190/250] Total Loss: 72.470261 GL_Loss: 0.658862 CRF_Loss: 71.811401\n",
      "[2022-02-17 11:27:04,389 - trainer - INFO] - Train Epoch:[10/100] Step:[200/250] Total Loss: 274.108917 GL_Loss: 0.289085 CRF_Loss: 273.819824\n",
      "[2022-02-17 11:27:23,419 - trainer - INFO] - [Step Validation] Epoch:[10/100] Step:[200/250]  \n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| name    |      mEP |       mER |       mEF |       mEA |\n",
      "+=========+==========+===========+===========+===========+\n",
      "| date    | 0.461538 | 0.802548  | 0.586047  | 0.802548  |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| address | 0.105769 | 0.0292553 | 0.0458333 | 0.0292553 |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| total   | 0.432177 | 0.436306  | 0.434231  | 0.436306  |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| company | 0.475248 | 0.521739  | 0.497409  | 0.521739  |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| overall | 0.405031 | 0.342918  | 0.371396  | 0.342918  |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "[2022-02-17 11:27:37,080 - trainer - INFO] - Train Epoch:[10/100] Step:[210/250] Total Loss: 93.911736 GL_Loss: 0.394527 CRF_Loss: 93.517212\n",
      "[2022-02-17 11:27:51,318 - trainer - INFO] - Train Epoch:[10/100] Step:[220/250] Total Loss: 138.704971 GL_Loss: 0.468280 CRF_Loss: 138.236694\n",
      "[2022-02-17 11:28:05,427 - trainer - INFO] - Train Epoch:[10/100] Step:[230/250] Total Loss: 346.511963 GL_Loss: 0.602670 CRF_Loss: 345.909302\n",
      "[2022-02-17 11:28:19,618 - trainer - INFO] - Train Epoch:[10/100] Step:[240/250] Total Loss: 77.947929 GL_Loss: 1.955255 CRF_Loss: 75.992676\n",
      "[2022-02-17 11:28:34,644 - trainer - INFO] - Train Epoch:[10/100] Step:[250/250] Total Loss: 264.267761 GL_Loss: 0.768871 CRF_Loss: 263.498901\n",
      "[2022-02-17 11:28:53,734 - trainer - INFO] - [Step Validation] Epoch:[10/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.632124 | 0.77707  | 0.697143 | 0.77707  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.307692 | 0.117021 | 0.169557 | 0.117021 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.483221 | 0.229299 | 0.311015 | 0.229299 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.583333 | 0.456522 | 0.512195 | 0.456522 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.502693 | 0.29819  | 0.374332 | 0.29819  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 11:29:12,990 - trainer - INFO] - [Epoch Validation] Epoch:[10/100] Total Loss: 138.761432 GL_Loss: 0.018237 CRF_Loss: 136.937743 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.632124 | 0.77707  | 0.697143 | 0.77707  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.307692 | 0.117021 | 0.169557 | 0.117021 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.483221 | 0.229299 | 0.311015 | 0.229299 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.583333 | 0.456522 | 0.512195 | 0.456522 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.502693 | 0.29819  | 0.374332 | 0.29819  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 11:29:28,035 - trainer - INFO] - Train Epoch:[11/100] Step:[10/250] Total Loss: 78.783432 GL_Loss: 1.322494 CRF_Loss: 77.460938\n",
      "[2022-02-17 11:29:42,392 - trainer - INFO] - Train Epoch:[11/100] Step:[20/250] Total Loss: 38.893803 GL_Loss: 1.524907 CRF_Loss: 37.368896\n",
      "[2022-02-17 11:29:57,824 - trainer - INFO] - Train Epoch:[11/100] Step:[30/250] Total Loss: 45.763641 GL_Loss: 1.011687 CRF_Loss: 44.751953\n",
      "[2022-02-17 11:30:11,542 - trainer - INFO] - Train Epoch:[11/100] Step:[40/250] Total Loss: 77.201866 GL_Loss: 2.098166 CRF_Loss: 75.103699\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 11:30:25,402 - trainer - INFO] - Train Epoch:[11/100] Step:[50/250] Total Loss: 37.186691 GL_Loss: 1.308764 CRF_Loss: 35.877930\n",
      "[2022-02-17 11:30:44,399 - trainer - INFO] - [Step Validation] Epoch:[11/100] Step:[50/250]  \n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| name    |      mEP |       mER |       mEF |       mEA |\n",
      "+=========+==========+===========+===========+===========+\n",
      "| date    | 0.697297 | 0.821656  | 0.754386  | 0.821656  |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| address | 0.100629 | 0.0425532 | 0.0598131 | 0.0425532 |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| total   | 0.42515  | 0.452229  | 0.438272  | 0.452229  |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| company | 0.597701 | 0.565217  | 0.581006  | 0.565217  |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| overall | 0.443137 | 0.361022  | 0.397887  | 0.361022  |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "[2022-02-17 11:30:59,489 - trainer - INFO] - Train Epoch:[11/100] Step:[60/250] Total Loss: 116.425362 GL_Loss: 0.736456 CRF_Loss: 115.688904\n",
      "[2022-02-17 11:31:13,767 - trainer - INFO] - Train Epoch:[11/100] Step:[70/250] Total Loss: 69.097878 GL_Loss: 1.012914 CRF_Loss: 68.084961\n",
      "[2022-02-17 11:31:27,301 - trainer - INFO] - Train Epoch:[11/100] Step:[80/250] Total Loss: 109.768692 GL_Loss: 2.044205 CRF_Loss: 107.724487\n",
      "[2022-02-17 11:31:42,193 - trainer - INFO] - Train Epoch:[11/100] Step:[90/250] Total Loss: 256.793091 GL_Loss: 1.016000 CRF_Loss: 255.777100\n",
      "[2022-02-17 11:31:56,173 - trainer - INFO] - Train Epoch:[11/100] Step:[100/250] Total Loss: 112.453949 GL_Loss: 2.741180 CRF_Loss: 109.712769\n",
      "[2022-02-17 11:32:15,235 - trainer - INFO] - [Step Validation] Epoch:[11/100] Step:[100/250]  \n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| name    |       mEP |       mER |       mEF |       mEA |\n",
      "+=========+===========+===========+===========+===========+\n",
      "| date    | 0.59375   | 0.726115  | 0.653295  | 0.726115  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| address | 0.0462428 | 0.0212766 | 0.0291439 | 0.0212766 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| total   | 0.498258  | 0.455414  | 0.475874  | 0.455414  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| company | 0.443299  | 0.467391  | 0.455026  | 0.467391  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| overall | 0.411215  | 0.328009  | 0.364929  | 0.328009  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "[2022-02-17 11:32:28,333 - trainer - INFO] - Train Epoch:[11/100] Step:[110/250] Total Loss: 81.602165 GL_Loss: 6.622426 CRF_Loss: 74.979736\n",
      "[2022-02-17 11:32:41,694 - trainer - INFO] - Train Epoch:[11/100] Step:[120/250] Total Loss: 50.241787 GL_Loss: 2.818446 CRF_Loss: 47.423340\n",
      "[2022-02-17 11:32:55,537 - trainer - INFO] - Train Epoch:[11/100] Step:[130/250] Total Loss: 46.978245 GL_Loss: 1.390354 CRF_Loss: 45.587891\n",
      "[2022-02-17 11:33:10,313 - trainer - INFO] - Train Epoch:[11/100] Step:[140/250] Total Loss: 114.944214 GL_Loss: 1.061033 CRF_Loss: 113.883179\n",
      "[2022-02-17 11:33:25,098 - trainer - INFO] - Train Epoch:[11/100] Step:[150/250] Total Loss: 123.426056 GL_Loss: 1.071072 CRF_Loss: 122.354980\n",
      "[2022-02-17 11:33:44,222 - trainer - INFO] - [Step Validation] Epoch:[11/100] Step:[150/250]  \n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| name    |       mEP |       mER |       mEF |       mEA |\n",
      "+=========+===========+===========+===========+===========+\n",
      "| date    | 0.563786  | 0.872611  | 0.685     | 0.872611  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| address | 0.0691489 | 0.0345745 | 0.0460993 | 0.0345745 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| total   | 0.435897  | 0.216561  | 0.289362  | 0.216561  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| company | 0.459184  | 0.48913   | 0.473684  | 0.48913   |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| overall | 0.383942  | 0.280085  | 0.323892  | 0.280085  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 11:33:57,580 - trainer - INFO] - Train Epoch:[11/100] Step:[160/250] Total Loss: 70.989594 GL_Loss: 2.040798 CRF_Loss: 68.948792\n",
      "[2022-02-17 11:34:12,580 - trainer - INFO] - Train Epoch:[11/100] Step:[170/250] Total Loss: 318.654907 GL_Loss: 0.930417 CRF_Loss: 317.724487\n",
      "[2022-02-17 11:34:26,995 - trainer - INFO] - Train Epoch:[11/100] Step:[180/250] Total Loss: 139.581680 GL_Loss: 7.703025 CRF_Loss: 131.878662\n",
      "[2022-02-17 11:34:41,066 - trainer - INFO] - Train Epoch:[11/100] Step:[190/250] Total Loss: 160.025604 GL_Loss: 0.836513 CRF_Loss: 159.189087\n",
      "[2022-02-17 11:34:56,149 - trainer - INFO] - Train Epoch:[11/100] Step:[200/250] Total Loss: 103.273743 GL_Loss: 0.506895 CRF_Loss: 102.766846\n",
      "[2022-02-17 11:35:16,564 - trainer - INFO] - [Step Validation] Epoch:[11/100] Step:[200/250]  \n",
      "+---------+------------+------------+------------+------------+\n",
      "| name    |        mEP |        mER |        mEF |        mEA |\n",
      "+=========+============+============+============+============+\n",
      "| date    | 0.00952381 | 0.00636943 | 0.00763359 | 0.00636943 |\n",
      "+---------+------------+------------+------------+------------+\n",
      "| address | 0.256757   | 0.101064   | 0.145038   | 0.101064   |\n",
      "+---------+------------+------------+------------+------------+\n",
      "| total   | 0.4        | 0.089172   | 0.145833   | 0.089172   |\n",
      "+---------+------------+------------+------------+------------+\n",
      "| company | 0.646154   | 0.456522   | 0.535032   | 0.456522   |\n",
      "+---------+------------+------------+------------+------------+\n",
      "| overall | 0.280928   | 0.116081   | 0.16428    | 0.116081   |\n",
      "+---------+------------+------------+------------+------------+\n",
      "[2022-02-17 11:35:30,776 - trainer - INFO] - Train Epoch:[11/100] Step:[210/250] Total Loss: 299.975525 GL_Loss: 0.523864 CRF_Loss: 299.451660\n",
      "[2022-02-17 11:35:44,705 - trainer - INFO] - Train Epoch:[11/100] Step:[220/250] Total Loss: 131.132980 GL_Loss: 0.501200 CRF_Loss: 130.631775\n",
      "[2022-02-17 11:35:59,783 - trainer - INFO] - Train Epoch:[11/100] Step:[230/250] Total Loss: 62.904449 GL_Loss: 0.579744 CRF_Loss: 62.324707\n",
      "[2022-02-17 11:36:14,415 - trainer - INFO] - Train Epoch:[11/100] Step:[240/250] Total Loss: 48.652706 GL_Loss: 0.578608 CRF_Loss: 48.074097\n",
      "[2022-02-17 11:36:28,248 - trainer - INFO] - Train Epoch:[11/100] Step:[250/250] Total Loss: 589.358276 GL_Loss: 0.517967 CRF_Loss: 588.840332\n",
      "[2022-02-17 11:36:47,505 - trainer - INFO] - [Step Validation] Epoch:[11/100] Step:[250/250]  \n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| name    |       mEP |       mER |       mEF |       mEA |\n",
      "+=========+===========+===========+===========+===========+\n",
      "| date    | 0.201183  | 0.216561  | 0.208589  | 0.216561  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| address | 0.0888889 | 0.0319149 | 0.0469667 | 0.0319149 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| total   | 0.527972  | 0.480892  | 0.503333  | 0.480892  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| company | 0.57      | 0.619565  | 0.59375   | 0.619565  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| overall | 0.368116  | 0.270501  | 0.311848  | 0.270501  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "[2022-02-17 11:37:07,005 - trainer - INFO] - [Epoch Validation] Epoch:[11/100] Total Loss: 139.598532 GL_Loss: 0.024723 CRF_Loss: 137.126251 \n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| name    |       mEP |       mER |       mEF |       mEA |\n",
      "+=========+===========+===========+===========+===========+\n",
      "| date    | 0.201183  | 0.216561  | 0.208589  | 0.216561  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| address | 0.0888889 | 0.0319149 | 0.0469667 | 0.0319149 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| total   | 0.527972  | 0.480892  | 0.503333  | 0.480892  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| company | 0.57      | 0.619565  | 0.59375   | 0.619565  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| overall | 0.368116  | 0.270501  | 0.311848  | 0.270501  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "[2022-02-17 11:37:21,675 - trainer - INFO] - Train Epoch:[12/100] Step:[10/250] Total Loss: 52.090691 GL_Loss: 0.972893 CRF_Loss: 51.117798\n",
      "[2022-02-17 11:37:35,965 - trainer - INFO] - Train Epoch:[12/100] Step:[20/250] Total Loss: 238.536362 GL_Loss: 0.657095 CRF_Loss: 237.879272\n",
      "[2022-02-17 11:37:50,285 - trainer - INFO] - Train Epoch:[12/100] Step:[30/250] Total Loss: 181.857422 GL_Loss: 0.488285 CRF_Loss: 181.369141\n",
      "[2022-02-17 11:38:04,977 - trainer - INFO] - Train Epoch:[12/100] Step:[40/250] Total Loss: 161.360229 GL_Loss: 1.916141 CRF_Loss: 159.444092\n",
      "[2022-02-17 11:38:19,784 - trainer - INFO] - Train Epoch:[12/100] Step:[50/250] Total Loss: 124.109642 GL_Loss: 1.102805 CRF_Loss: 123.006836\n",
      "[2022-02-17 11:38:38,778 - trainer - INFO] - [Step Validation] Epoch:[12/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.709184 | 0.88535  | 0.787535 | 0.88535  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.248408 | 0.103723 | 0.146341 | 0.103723 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.59434  | 0.401274 | 0.479087 | 0.401274 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.604167 | 0.630435 | 0.617021 | 0.630435 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.547655 | 0.385517 | 0.4525   | 0.385517 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 11:38:40,887 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 11:38:55,178 - trainer - INFO] - Train Epoch:[12/100] Step:[60/250] Total Loss: 246.763901 GL_Loss: 2.645865 CRF_Loss: 244.118042\n",
      "[2022-02-17 11:39:09,284 - trainer - INFO] - Train Epoch:[12/100] Step:[70/250] Total Loss: 67.249588 GL_Loss: 4.238476 CRF_Loss: 63.011108\n",
      "[2022-02-17 11:39:23,669 - trainer - INFO] - Train Epoch:[12/100] Step:[80/250] Total Loss: 64.647186 GL_Loss: 2.993135 CRF_Loss: 61.654053\n",
      "[2022-02-17 11:39:37,661 - trainer - INFO] - Train Epoch:[12/100] Step:[90/250] Total Loss: 1656.636963 GL_Loss: 2.076147 CRF_Loss: 1654.560791\n",
      "[2022-02-17 11:39:52,188 - trainer - INFO] - Train Epoch:[12/100] Step:[100/250] Total Loss: 69.547630 GL_Loss: 1.305080 CRF_Loss: 68.242554\n",
      "[2022-02-17 11:40:11,256 - trainer - INFO] - [Step Validation] Epoch:[12/100] Step:[100/250]  \n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| name    |      mEP |       mER |      mEF |       mEA |\n",
      "+=========+==========+===========+==========+===========+\n",
      "| date    | 0.691489 | 0.828025  | 0.753623 | 0.828025  |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| address | 0.198718 | 0.0824468 | 0.116541 | 0.0824468 |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| total   | 0.50495  | 0.487261  | 0.495948 | 0.487261  |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| company | 0.623656 | 0.630435  | 0.627027 | 0.630435  |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| overall | 0.502703 | 0.396166  | 0.443121 | 0.396166  |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "[2022-02-17 11:40:26,884 - trainer - INFO] - Train Epoch:[12/100] Step:[110/250] Total Loss: 116.150841 GL_Loss: 1.057093 CRF_Loss: 115.093750\n",
      "[2022-02-17 11:40:40,862 - trainer - INFO] - Train Epoch:[12/100] Step:[120/250] Total Loss: 477.437775 GL_Loss: 1.975977 CRF_Loss: 475.461792\n",
      "[2022-02-17 11:40:54,967 - trainer - INFO] - Train Epoch:[12/100] Step:[130/250] Total Loss: 147.766235 GL_Loss: 0.629146 CRF_Loss: 147.137085\n",
      "[2022-02-17 11:41:09,268 - trainer - INFO] - Train Epoch:[12/100] Step:[140/250] Total Loss: 42.559418 GL_Loss: 1.760591 CRF_Loss: 40.798828\n",
      "[2022-02-17 11:41:23,160 - trainer - INFO] - Train Epoch:[12/100] Step:[150/250] Total Loss: 100.209984 GL_Loss: 1.072534 CRF_Loss: 99.137451\n",
      "[2022-02-17 11:41:42,116 - trainer - INFO] - [Step Validation] Epoch:[12/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.851429 | 0.949045 | 0.89759  | 0.949045 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.306667 | 0.12234  | 0.174905 | 0.12234  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.616883 | 0.302548 | 0.405983 | 0.302548 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.568421 | 0.586957 | 0.57754  | 0.586957 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.599303 | 0.366347 | 0.454726 | 0.366347 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 11:41:44,205 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 11:41:58,615 - trainer - INFO] - Train Epoch:[12/100] Step:[160/250] Total Loss: 46.588379 GL_Loss: 1.225708 CRF_Loss: 45.362671\n",
      "[2022-02-17 11:42:12,515 - trainer - INFO] - Train Epoch:[12/100] Step:[170/250] Total Loss: 44.737190 GL_Loss: 0.907358 CRF_Loss: 43.829834\n",
      "[2022-02-17 11:42:26,578 - trainer - INFO] - Train Epoch:[12/100] Step:[180/250] Total Loss: 111.628998 GL_Loss: 0.699556 CRF_Loss: 110.929443\n",
      "[2022-02-17 11:42:41,130 - trainer - INFO] - Train Epoch:[12/100] Step:[190/250] Total Loss: 57.731606 GL_Loss: 0.902624 CRF_Loss: 56.828979\n",
      "[2022-02-17 11:42:56,099 - trainer - INFO] - Train Epoch:[12/100] Step:[200/250] Total Loss: 83.133484 GL_Loss: 1.222958 CRF_Loss: 81.910522\n",
      "[2022-02-17 11:43:15,297 - trainer - INFO] - [Step Validation] Epoch:[12/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.830409 | 0.904459 | 0.865854 | 0.904459 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.310811 | 0.12234  | 0.175573 | 0.12234  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.528053 | 0.509554 | 0.518639 | 0.509554 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.584158 | 0.641304 | 0.611399 | 0.641304 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.562932 | 0.43344  | 0.489771 | 0.43344  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 11:43:17,371 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 11:43:30,674 - trainer - INFO] - Train Epoch:[12/100] Step:[210/250] Total Loss: 139.109787 GL_Loss: 1.201216 CRF_Loss: 137.908569\n",
      "[2022-02-17 11:43:44,522 - trainer - INFO] - Train Epoch:[12/100] Step:[220/250] Total Loss: 231.155411 GL_Loss: 0.581925 CRF_Loss: 230.573486\n",
      "[2022-02-17 11:43:58,419 - trainer - INFO] - Train Epoch:[12/100] Step:[230/250] Total Loss: 69.870705 GL_Loss: 0.831034 CRF_Loss: 69.039673\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 11:44:12,151 - trainer - INFO] - Train Epoch:[12/100] Step:[240/250] Total Loss: 166.589920 GL_Loss: 0.830644 CRF_Loss: 165.759277\n",
      "[2022-02-17 11:44:27,338 - trainer - INFO] - Train Epoch:[12/100] Step:[250/250] Total Loss: 48.300800 GL_Loss: 0.820086 CRF_Loss: 47.480713\n",
      "[2022-02-17 11:44:47,844 - trainer - INFO] - [Step Validation] Epoch:[12/100] Step:[250/250]  \n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| name    |      mEP |       mER |       mEF |       mEA |\n",
      "+=========+==========+===========+===========+===========+\n",
      "| date    | 0.830409 | 0.904459  | 0.865854  | 0.904459  |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| address | 0.213873 | 0.0984043 | 0.134791  | 0.0984043 |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| total   | 0.714286 | 0.0159236 | 0.0311526 | 0.0159236 |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| company | 0.597561 | 0.532609  | 0.563218  | 0.532609  |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| overall | 0.538106 | 0.248136  | 0.33965   | 0.248136  |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "[2022-02-17 11:45:07,017 - trainer - INFO] - [Epoch Validation] Epoch:[12/100] Total Loss: 127.196826 GL_Loss: 0.014518 CRF_Loss: 125.745041 \n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| name    |      mEP |       mER |       mEF |       mEA |\n",
      "+=========+==========+===========+===========+===========+\n",
      "| date    | 0.830409 | 0.904459  | 0.865854  | 0.904459  |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| address | 0.213873 | 0.0984043 | 0.134791  | 0.0984043 |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| total   | 0.714286 | 0.0159236 | 0.0311526 | 0.0159236 |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| company | 0.597561 | 0.532609  | 0.563218  | 0.532609  |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| overall | 0.538106 | 0.248136  | 0.33965   | 0.248136  |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 11:45:21,597 - trainer - INFO] - Train Epoch:[13/100] Step:[10/250] Total Loss: 46.357849 GL_Loss: 1.825133 CRF_Loss: 44.532715\n",
      "[2022-02-17 11:45:35,697 - trainer - INFO] - Train Epoch:[13/100] Step:[20/250] Total Loss: 191.703415 GL_Loss: 2.005785 CRF_Loss: 189.697632\n",
      "[2022-02-17 11:45:50,304 - trainer - INFO] - Train Epoch:[13/100] Step:[30/250] Total Loss: 61.069939 GL_Loss: 1.617425 CRF_Loss: 59.452515\n",
      "[2022-02-17 11:46:03,689 - trainer - INFO] - Train Epoch:[13/100] Step:[40/250] Total Loss: 57.757435 GL_Loss: 1.215198 CRF_Loss: 56.542236\n",
      "[2022-02-17 11:46:17,794 - trainer - INFO] - Train Epoch:[13/100] Step:[50/250] Total Loss: 195.448914 GL_Loss: 0.831719 CRF_Loss: 194.617188\n",
      "[2022-02-17 11:46:37,052 - trainer - INFO] - [Step Validation] Epoch:[13/100] Step:[50/250]  \n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| name    |      mEP |       mER |      mEF |       mEA |\n",
      "+=========+==========+===========+==========+===========+\n",
      "| date    | 0.842105 | 0.917197  | 0.878049 | 0.917197  |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| address | 0.188679 | 0.0797872 | 0.11215  | 0.0797872 |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| total   | 0.508671 | 0.56051   | 0.533333 | 0.56051   |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| company | 0.59596  | 0.641304  | 0.617801 | 0.641304  |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| overall | 0.527742 | 0.43557   | 0.477246 | 0.43557   |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "[2022-02-17 11:46:52,322 - trainer - INFO] - Train Epoch:[13/100] Step:[60/250] Total Loss: 63.782467 GL_Loss: 0.572140 CRF_Loss: 63.210327\n",
      "[2022-02-17 11:47:06,749 - trainer - INFO] - Train Epoch:[13/100] Step:[70/250] Total Loss: 75.029129 GL_Loss: 0.626418 CRF_Loss: 74.402710\n",
      "[2022-02-17 11:47:21,506 - trainer - INFO] - Train Epoch:[13/100] Step:[80/250] Total Loss: 98.100006 GL_Loss: 0.433744 CRF_Loss: 97.666260\n",
      "[2022-02-17 11:47:35,665 - trainer - INFO] - Train Epoch:[13/100] Step:[90/250] Total Loss: 76.699028 GL_Loss: 1.003533 CRF_Loss: 75.695496\n",
      "[2022-02-17 11:47:49,391 - trainer - INFO] - Train Epoch:[13/100] Step:[100/250] Total Loss: 92.947052 GL_Loss: 0.955532 CRF_Loss: 91.991516\n",
      "[2022-02-17 11:48:08,505 - trainer - INFO] - [Step Validation] Epoch:[13/100] Step:[100/250]  \n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| name    |      mEP |       mER |      mEF |       mEA |\n",
      "+=========+==========+===========+==========+===========+\n",
      "| date    | 0.363636 | 0.229299  | 0.28125  | 0.229299  |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| address | 0.268657 | 0.0957447 | 0.141176 | 0.0957447 |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| total   | 0.566667 | 0.10828   | 0.181818 | 0.10828   |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| company | 0.462264 | 0.532609  | 0.494949 | 0.532609  |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| overall | 0.388471 | 0.165069  | 0.231689 | 0.165069  |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "[2022-02-17 11:48:22,838 - trainer - INFO] - Train Epoch:[13/100] Step:[110/250] Total Loss: 127.863388 GL_Loss: 2.180774 CRF_Loss: 125.682617\n",
      "[2022-02-17 11:48:37,894 - trainer - INFO] - Train Epoch:[13/100] Step:[120/250] Total Loss: 72.088699 GL_Loss: 5.695264 CRF_Loss: 66.393433\n",
      "[2022-02-17 11:48:51,303 - trainer - INFO] - Train Epoch:[13/100] Step:[130/250] Total Loss: 84.551086 GL_Loss: 2.312439 CRF_Loss: 82.238647\n",
      "[2022-02-17 11:49:04,993 - trainer - INFO] - Train Epoch:[13/100] Step:[140/250] Total Loss: 166.549606 GL_Loss: 0.976737 CRF_Loss: 165.572876\n",
      "[2022-02-17 11:49:19,104 - trainer - INFO] - Train Epoch:[13/100] Step:[150/250] Total Loss: 131.079910 GL_Loss: 2.009483 CRF_Loss: 129.070435\n",
      "[2022-02-17 11:49:38,083 - trainer - INFO] - [Step Validation] Epoch:[13/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.675978 | 0.770701 | 0.720238 | 0.770701 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.25     | 0.101064 | 0.143939 | 0.101064 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.574257 | 0.369427 | 0.449612 | 0.369427 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.543689 | 0.608696 | 0.574359 | 0.608696 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.52044  | 0.352503 | 0.420317 | 0.352503 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 11:49:52,979 - trainer - INFO] - Train Epoch:[13/100] Step:[160/250] Total Loss: 105.175949 GL_Loss: 0.939742 CRF_Loss: 104.236206\n",
      "[2022-02-17 11:50:07,107 - trainer - INFO] - Train Epoch:[13/100] Step:[170/250] Total Loss: 122.291527 GL_Loss: 2.490625 CRF_Loss: 119.800903\n",
      "[2022-02-17 11:50:21,727 - trainer - INFO] - Train Epoch:[13/100] Step:[180/250] Total Loss: 80.323021 GL_Loss: 6.755641 CRF_Loss: 73.567383\n",
      "[2022-02-17 11:50:35,323 - trainer - INFO] - Train Epoch:[13/100] Step:[190/250] Total Loss: 146.492783 GL_Loss: 3.882798 CRF_Loss: 142.609985\n",
      "[2022-02-17 11:50:49,207 - trainer - INFO] - Train Epoch:[13/100] Step:[200/250] Total Loss: 549.745117 GL_Loss: 1.414808 CRF_Loss: 548.330322\n",
      "[2022-02-17 11:51:08,175 - trainer - INFO] - [Step Validation] Epoch:[13/100] Step:[200/250]  \n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| name    |      mEP |       mER |      mEF |       mEA |\n",
      "+=========+==========+===========+==========+===========+\n",
      "| date    | 0.52381  | 0.770701  | 0.623711 | 0.770701  |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| address | 0.192857 | 0.0718085 | 0.104651 | 0.0718085 |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| total   | 0.522167 | 0.33758   | 0.410058 | 0.33758   |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| company | 0.585106 | 0.597826  | 0.591398 | 0.597826  |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| overall | 0.462575 | 0.329073  | 0.384568 | 0.329073  |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "[2022-02-17 11:51:22,932 - trainer - INFO] - Train Epoch:[13/100] Step:[210/250] Total Loss: 51.190907 GL_Loss: 0.756826 CRF_Loss: 50.434082\n",
      "[2022-02-17 11:51:37,641 - trainer - INFO] - Train Epoch:[13/100] Step:[220/250] Total Loss: 155.150772 GL_Loss: 0.849374 CRF_Loss: 154.301392\n",
      "[2022-02-17 11:51:52,091 - trainer - INFO] - Train Epoch:[13/100] Step:[230/250] Total Loss: 508.318604 GL_Loss: 1.164303 CRF_Loss: 507.154297\n",
      "[2022-02-17 11:52:06,011 - trainer - INFO] - Train Epoch:[13/100] Step:[240/250] Total Loss: 94.659981 GL_Loss: 0.581737 CRF_Loss: 94.078247\n",
      "[2022-02-17 11:52:19,988 - trainer - INFO] - Train Epoch:[13/100] Step:[250/250] Total Loss: 117.681290 GL_Loss: 0.750383 CRF_Loss: 116.930908\n",
      "[2022-02-17 11:52:39,186 - trainer - INFO] - [Step Validation] Epoch:[13/100] Step:[250/250]  \n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| name    |      mEP |       mER |      mEF |       mEA |\n",
      "+=========+==========+===========+==========+===========+\n",
      "| date    | 0.705882 | 0.764331  | 0.733945 | 0.764331  |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| address | 0.239726 | 0.0930851 | 0.1341   | 0.0930851 |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| total   | 0.503185 | 0.503185  | 0.503185 | 0.503185  |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| company | 0.641026 | 0.543478  | 0.588235 | 0.543478  |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| overall | 0.512712 | 0.386581  | 0.440801 | 0.386581  |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "[2022-02-17 11:52:58,360 - trainer - INFO] - [Epoch Validation] Epoch:[13/100] Total Loss: 132.034041 GL_Loss: 0.018977 CRF_Loss: 130.136292 \n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| name    |      mEP |       mER |      mEF |       mEA |\n",
      "+=========+==========+===========+==========+===========+\n",
      "| date    | 0.705882 | 0.764331  | 0.733945 | 0.764331  |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| address | 0.239726 | 0.0930851 | 0.1341   | 0.0930851 |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| total   | 0.503185 | 0.503185  | 0.503185 | 0.503185  |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| company | 0.641026 | 0.543478  | 0.588235 | 0.543478  |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| overall | 0.512712 | 0.386581  | 0.440801 | 0.386581  |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "[2022-02-17 11:53:13,744 - trainer - INFO] - Train Epoch:[14/100] Step:[10/250] Total Loss: 72.199783 GL_Loss: 0.808673 CRF_Loss: 71.391113\n",
      "[2022-02-17 11:53:28,196 - trainer - INFO] - Train Epoch:[14/100] Step:[20/250] Total Loss: 45.073326 GL_Loss: 0.690637 CRF_Loss: 44.382690\n",
      "[2022-02-17 11:53:41,437 - trainer - INFO] - Train Epoch:[14/100] Step:[30/250] Total Loss: 86.223206 GL_Loss: 0.541930 CRF_Loss: 85.681274\n",
      "[2022-02-17 11:53:55,909 - trainer - INFO] - Train Epoch:[14/100] Step:[40/250] Total Loss: 97.787781 GL_Loss: 0.358825 CRF_Loss: 97.428955\n",
      "[2022-02-17 11:54:09,587 - trainer - INFO] - Train Epoch:[14/100] Step:[50/250] Total Loss: 39.992588 GL_Loss: 1.225254 CRF_Loss: 38.767334\n",
      "[2022-02-17 11:54:28,781 - trainer - INFO] - [Step Validation] Epoch:[14/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.57767  | 0.757962 | 0.655647 | 0.757962 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.405405 | 0.159574 | 0.229008 | 0.159574 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.531746 | 0.426752 | 0.473498 | 0.426752 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.532609 | 0.532609 | 0.532609 | 0.532609 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.518625 | 0.385517 | 0.442272 | 0.385517 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 11:54:43,282 - trainer - INFO] - Train Epoch:[14/100] Step:[60/250] Total Loss: 96.925835 GL_Loss: 1.674733 CRF_Loss: 95.251099\n",
      "[2022-02-17 11:54:57,571 - trainer - INFO] - Train Epoch:[14/100] Step:[70/250] Total Loss: 117.007126 GL_Loss: 2.722214 CRF_Loss: 114.284912\n",
      "[2022-02-17 11:55:12,759 - trainer - INFO] - Train Epoch:[14/100] Step:[80/250] Total Loss: 133.862839 GL_Loss: 1.419118 CRF_Loss: 132.443726\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 11:55:27,337 - trainer - INFO] - Train Epoch:[14/100] Step:[90/250] Total Loss: 72.187164 GL_Loss: 1.362210 CRF_Loss: 70.824951\n",
      "[2022-02-17 11:55:43,265 - trainer - INFO] - Train Epoch:[14/100] Step:[100/250] Total Loss: 54.778336 GL_Loss: 0.847304 CRF_Loss: 53.931030\n",
      "[2022-02-17 11:56:02,360 - trainer - INFO] - [Step Validation] Epoch:[14/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.69     | 0.878981 | 0.773109 | 0.878981 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.313725 | 0.12766  | 0.181474 | 0.12766  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.623256 | 0.426752 | 0.506616 | 0.426752 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.589474 | 0.608696 | 0.59893  | 0.608696 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.567119 | 0.400426 | 0.469413 | 0.400426 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 11:56:16,998 - trainer - INFO] - Train Epoch:[14/100] Step:[110/250] Total Loss: 39.403595 GL_Loss: 0.525422 CRF_Loss: 38.878174\n",
      "[2022-02-17 11:56:31,134 - trainer - INFO] - Train Epoch:[14/100] Step:[120/250] Total Loss: 24.732546 GL_Loss: 1.195070 CRF_Loss: 23.537476\n",
      "[2022-02-17 11:56:45,589 - trainer - INFO] - Train Epoch:[14/100] Step:[130/250] Total Loss: 29.999695 GL_Loss: 0.832580 CRF_Loss: 29.167114\n",
      "[2022-02-17 11:56:59,225 - trainer - INFO] - Train Epoch:[14/100] Step:[140/250] Total Loss: 96.776436 GL_Loss: 1.051827 CRF_Loss: 95.724609\n",
      "[2022-02-17 11:57:13,172 - trainer - INFO] - Train Epoch:[14/100] Step:[150/250] Total Loss: 43.761749 GL_Loss: 0.959014 CRF_Loss: 42.802734\n",
      "[2022-02-17 11:57:32,212 - trainer - INFO] - [Step Validation] Epoch:[14/100] Step:[150/250]  \n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| name    |      mEP |       mER |      mEF |       mEA |\n",
      "+=========+==========+===========+==========+===========+\n",
      "| date    | 0.517241 | 0.764331  | 0.616967 | 0.764331  |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| address | 0.196319 | 0.0851064 | 0.118738 | 0.0851064 |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| total   | 0.382409 | 0.636943  | 0.477897 | 0.636943  |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| company | 0.529412 | 0.48913   | 0.508475 | 0.48913   |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| overall | 0.395813 | 0.42279   | 0.408857 | 0.42279   |\n",
      "+---------+----------+-----------+----------+-----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 11:57:47,023 - trainer - INFO] - Train Epoch:[14/100] Step:[160/250] Total Loss: 343.336273 GL_Loss: 0.631438 CRF_Loss: 342.704834\n",
      "[2022-02-17 11:58:01,691 - trainer - INFO] - Train Epoch:[14/100] Step:[170/250] Total Loss: 114.091667 GL_Loss: 0.636959 CRF_Loss: 113.454712\n",
      "[2022-02-17 11:58:16,480 - trainer - INFO] - Train Epoch:[14/100] Step:[180/250] Total Loss: 49.944443 GL_Loss: 0.939438 CRF_Loss: 49.005005\n",
      "[2022-02-17 11:58:31,105 - trainer - INFO] - Train Epoch:[14/100] Step:[190/250] Total Loss: 38.576015 GL_Loss: 0.565638 CRF_Loss: 38.010376\n",
      "[2022-02-17 11:58:46,474 - trainer - INFO] - Train Epoch:[14/100] Step:[200/250] Total Loss: 112.610115 GL_Loss: 1.474131 CRF_Loss: 111.135986\n",
      "[2022-02-17 11:59:05,960 - trainer - INFO] - [Step Validation] Epoch:[14/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.673913 | 0.789809 | 0.727273 | 0.789809 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.324675 | 0.132979 | 0.188679 | 0.132979 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.606796 | 0.398089 | 0.480769 | 0.398089 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.6375   | 0.554348 | 0.593023 | 0.554348 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.560897 | 0.372737 | 0.447857 | 0.372737 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 11:59:20,114 - trainer - INFO] - Train Epoch:[14/100] Step:[210/250] Total Loss: 49.561752 GL_Loss: 3.398420 CRF_Loss: 46.163330\n",
      "[2022-02-17 11:59:35,842 - trainer - INFO] - Train Epoch:[14/100] Step:[220/250] Total Loss: 215.268875 GL_Loss: 1.743970 CRF_Loss: 213.524902\n",
      "[2022-02-17 11:59:51,973 - trainer - INFO] - Train Epoch:[14/100] Step:[230/250] Total Loss: 85.920609 GL_Loss: 1.210035 CRF_Loss: 84.710571\n",
      "[2022-02-17 12:00:06,890 - trainer - INFO] - Train Epoch:[14/100] Step:[240/250] Total Loss: 223.097687 GL_Loss: 1.264430 CRF_Loss: 221.833252\n",
      "[2022-02-17 12:00:21,791 - trainer - INFO] - Train Epoch:[14/100] Step:[250/250] Total Loss: 72.387619 GL_Loss: 1.184859 CRF_Loss: 71.202759\n",
      "[2022-02-17 12:00:40,911 - trainer - INFO] - [Step Validation] Epoch:[14/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.734463 | 0.828025 | 0.778443 | 0.828025 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.339744 | 0.140957 | 0.199248 | 0.140957 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.631868 | 0.366242 | 0.46371  | 0.366242 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.535354 | 0.576087 | 0.554974 | 0.576087 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.571661 | 0.373802 | 0.452028 | 0.373802 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 12:01:00,082 - trainer - INFO] - [Epoch Validation] Epoch:[14/100] Total Loss: 125.265423 GL_Loss: 0.011933 CRF_Loss: 124.072083 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.734463 | 0.828025 | 0.778443 | 0.828025 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.339744 | 0.140957 | 0.199248 | 0.140957 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.631868 | 0.366242 | 0.46371  | 0.366242 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.535354 | 0.576087 | 0.554974 | 0.576087 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.571661 | 0.373802 | 0.452028 | 0.373802 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 12:01:16,072 - trainer - INFO] - Train Epoch:[15/100] Step:[10/250] Total Loss: 67.002312 GL_Loss: 1.493400 CRF_Loss: 65.508911\n",
      "[2022-02-17 12:01:32,014 - trainer - INFO] - Train Epoch:[15/100] Step:[20/250] Total Loss: 413.334808 GL_Loss: 0.982882 CRF_Loss: 412.351929\n",
      "[2022-02-17 12:01:48,641 - trainer - INFO] - Train Epoch:[15/100] Step:[30/250] Total Loss: 155.618668 GL_Loss: 1.599378 CRF_Loss: 154.019287\n",
      "[2022-02-17 12:02:03,572 - trainer - INFO] - Train Epoch:[15/100] Step:[40/250] Total Loss: 57.673424 GL_Loss: 2.456872 CRF_Loss: 55.216553\n",
      "[2022-02-17 12:02:18,456 - trainer - INFO] - Train Epoch:[15/100] Step:[50/250] Total Loss: 41.415001 GL_Loss: 3.687217 CRF_Loss: 37.727783\n",
      "[2022-02-17 12:02:37,513 - trainer - INFO] - [Step Validation] Epoch:[15/100] Step:[50/250]  \n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| name    |      mEP |       mER |      mEF |       mEA |\n",
      "+=========+==========+===========+==========+===========+\n",
      "| date    | 0.732558 | 0.802548  | 0.765957 | 0.802548  |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| address | 0.21875  | 0.0930851 | 0.130597 | 0.0930851 |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| total   | 0.6375   | 0.16242   | 0.258883 | 0.16242   |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| company | 0.504202 | 0.652174  | 0.56872  | 0.652174  |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "| overall | 0.512241 | 0.28967   | 0.370068 | 0.28967   |\n",
      "+---------+----------+-----------+----------+-----------+\n",
      "[2022-02-17 12:02:51,556 - trainer - INFO] - Train Epoch:[15/100] Step:[60/250] Total Loss: 56.781326 GL_Loss: 2.446854 CRF_Loss: 54.334473\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 12:03:06,755 - trainer - INFO] - Train Epoch:[15/100] Step:[70/250] Total Loss: 111.807335 GL_Loss: 1.617269 CRF_Loss: 110.190063\n",
      "[2022-02-17 12:03:22,221 - trainer - INFO] - Train Epoch:[15/100] Step:[80/250] Total Loss: 98.958931 GL_Loss: 1.297797 CRF_Loss: 97.661133\n",
      "[2022-02-17 12:03:39,483 - trainer - INFO] - Train Epoch:[15/100] Step:[90/250] Total Loss: 22.984287 GL_Loss: 1.354648 CRF_Loss: 21.629639\n",
      "[2022-02-17 12:03:54,637 - trainer - INFO] - Train Epoch:[15/100] Step:[100/250] Total Loss: 212.516006 GL_Loss: 1.253440 CRF_Loss: 211.262573\n",
      "[2022-02-17 12:04:13,745 - trainer - INFO] - [Step Validation] Epoch:[15/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.679144 | 0.808917 | 0.738372 | 0.808917 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.351515 | 0.154255 | 0.214418 | 0.154255 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.659218 | 0.375796 | 0.478702 | 0.375796 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.6      | 0.619565 | 0.609626 | 0.619565 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.57508  | 0.383387 | 0.460064 | 0.383387 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 12:04:28,772 - trainer - INFO] - Train Epoch:[15/100] Step:[110/250] Total Loss: 43.897713 GL_Loss: 0.993170 CRF_Loss: 42.904541\n",
      "[2022-02-17 12:04:44,247 - trainer - INFO] - Train Epoch:[15/100] Step:[120/250] Total Loss: 68.216270 GL_Loss: 1.761927 CRF_Loss: 66.454346\n",
      "[2022-02-17 12:04:59,875 - trainer - INFO] - Train Epoch:[15/100] Step:[130/250] Total Loss: 101.514549 GL_Loss: 0.995625 CRF_Loss: 100.518921\n",
      "[2022-02-17 12:05:14,953 - trainer - INFO] - Train Epoch:[15/100] Step:[140/250] Total Loss: 393.985077 GL_Loss: 0.604957 CRF_Loss: 393.380127\n",
      "[2022-02-17 12:05:29,761 - trainer - INFO] - Train Epoch:[15/100] Step:[150/250] Total Loss: 279.401306 GL_Loss: 1.583567 CRF_Loss: 277.817749\n",
      "[2022-02-17 12:05:48,826 - trainer - INFO] - [Step Validation] Epoch:[15/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.62     | 0.789809 | 0.694678 | 0.789809 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.397516 | 0.170213 | 0.238361 | 0.170213 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.685567 | 0.423567 | 0.523622 | 0.423567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.591398 | 0.597826 | 0.594595 | 0.597826 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.580247 | 0.400426 | 0.47385  | 0.400426 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 12:06:03,141 - trainer - INFO] - Train Epoch:[15/100] Step:[160/250] Total Loss: 61.948193 GL_Loss: 3.362742 CRF_Loss: 58.585449\n",
      "[2022-02-17 12:06:17,996 - trainer - INFO] - Train Epoch:[15/100] Step:[170/250] Total Loss: 46.139370 GL_Loss: 2.949794 CRF_Loss: 43.189575\n",
      "[2022-02-17 12:06:32,749 - trainer - INFO] - Train Epoch:[15/100] Step:[180/250] Total Loss: 45.544353 GL_Loss: 1.351847 CRF_Loss: 44.192505\n",
      "[2022-02-17 12:06:47,221 - trainer - INFO] - Train Epoch:[15/100] Step:[190/250] Total Loss: 35.894646 GL_Loss: 1.139031 CRF_Loss: 34.755615\n",
      "[2022-02-17 12:07:00,412 - trainer - INFO] - Train Epoch:[15/100] Step:[200/250] Total Loss: 51.681858 GL_Loss: 1.299656 CRF_Loss: 50.382202\n",
      "[2022-02-17 12:07:19,632 - trainer - INFO] - [Step Validation] Epoch:[15/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.86875  | 0.88535  | 0.876972 | 0.88535  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.320988 | 0.138298 | 0.193309 | 0.138298 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.696133 | 0.401274 | 0.509091 | 0.401274 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.579439 | 0.673913 | 0.623116 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.621311 | 0.403621 | 0.489348 | 0.403621 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 12:07:32,919 - trainer - INFO] - Train Epoch:[15/100] Step:[210/250] Total Loss: 45.948708 GL_Loss: 1.368754 CRF_Loss: 44.579956\n",
      "[2022-02-17 12:07:46,655 - trainer - INFO] - Train Epoch:[15/100] Step:[220/250] Total Loss: 76.632904 GL_Loss: 0.914029 CRF_Loss: 75.718872\n",
      "[2022-02-17 12:08:00,816 - trainer - INFO] - Train Epoch:[15/100] Step:[230/250] Total Loss: 64.654259 GL_Loss: 1.586387 CRF_Loss: 63.067871\n",
      "[2022-02-17 12:08:14,254 - trainer - INFO] - Train Epoch:[15/100] Step:[240/250] Total Loss: 103.360756 GL_Loss: 1.699255 CRF_Loss: 101.661499\n",
      "[2022-02-17 12:08:27,743 - trainer - INFO] - Train Epoch:[15/100] Step:[250/250] Total Loss: 63.387760 GL_Loss: 1.116642 CRF_Loss: 62.271118\n",
      "[2022-02-17 12:08:46,816 - trainer - INFO] - [Step Validation] Epoch:[15/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.866242 | 0.866242 | 0.866242 | 0.866242 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.287356 | 0.132979 | 0.181818 | 0.132979 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.635922 | 0.417197 | 0.503846 | 0.417197 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.487179 | 0.619565 | 0.545455 | 0.619565 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.571865 | 0.398296 | 0.469554 | 0.398296 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 12:09:06,014 - trainer - INFO] - [Epoch Validation] Epoch:[15/100] Total Loss: 112.750029 GL_Loss: 0.016740 CRF_Loss: 111.076015 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.866242 | 0.866242 | 0.866242 | 0.866242 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.287356 | 0.132979 | 0.181818 | 0.132979 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.635922 | 0.417197 | 0.503846 | 0.417197 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.487179 | 0.619565 | 0.545455 | 0.619565 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.571865 | 0.398296 | 0.469554 | 0.398296 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 12:09:22,106 - trainer - INFO] - Train Epoch:[16/100] Step:[10/250] Total Loss: 47.150726 GL_Loss: 1.441130 CRF_Loss: 45.709595\n",
      "[2022-02-17 12:09:35,664 - trainer - INFO] - Train Epoch:[16/100] Step:[20/250] Total Loss: 54.815105 GL_Loss: 1.573896 CRF_Loss: 53.241211\n",
      "[2022-02-17 12:09:50,033 - trainer - INFO] - Train Epoch:[16/100] Step:[30/250] Total Loss: 34.374809 GL_Loss: 1.207329 CRF_Loss: 33.167480\n",
      "[2022-02-17 12:10:03,798 - trainer - INFO] - Train Epoch:[16/100] Step:[40/250] Total Loss: 80.955597 GL_Loss: 1.097196 CRF_Loss: 79.858398\n",
      "[2022-02-17 12:10:17,795 - trainer - INFO] - Train Epoch:[16/100] Step:[50/250] Total Loss: 59.854721 GL_Loss: 1.772690 CRF_Loss: 58.082031\n",
      "[2022-02-17 12:10:36,889 - trainer - INFO] - [Step Validation] Epoch:[16/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.822485 | 0.88535  | 0.852761 | 0.88535  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.333333 | 0.154255 | 0.210909 | 0.154255 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.632    | 0.503185 | 0.560284 | 0.503185 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.633333 | 0.619565 | 0.626374 | 0.619565 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.603221 | 0.438765 | 0.508015 | 0.438765 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 12:10:39,082 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 12:10:53,266 - trainer - INFO] - Train Epoch:[16/100] Step:[60/250] Total Loss: 141.386261 GL_Loss: 0.963897 CRF_Loss: 140.422363\n",
      "[2022-02-17 12:11:06,969 - trainer - INFO] - Train Epoch:[16/100] Step:[70/250] Total Loss: 102.404991 GL_Loss: 0.527553 CRF_Loss: 101.877441\n",
      "[2022-02-17 12:11:20,641 - trainer - INFO] - Train Epoch:[16/100] Step:[80/250] Total Loss: 63.951317 GL_Loss: 0.712427 CRF_Loss: 63.238892\n",
      "[2022-02-17 12:11:35,306 - trainer - INFO] - Train Epoch:[16/100] Step:[90/250] Total Loss: 34.121536 GL_Loss: 0.631791 CRF_Loss: 33.489746\n",
      "[2022-02-17 12:11:49,565 - trainer - INFO] - Train Epoch:[16/100] Step:[100/250] Total Loss: 160.575943 GL_Loss: 0.597432 CRF_Loss: 159.978516\n",
      "[2022-02-17 12:12:08,589 - trainer - INFO] - [Step Validation] Epoch:[16/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.844311 | 0.898089 | 0.87037  | 0.898089 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.329609 | 0.156915 | 0.212613 | 0.156915 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.731707 | 0.382166 | 0.502092 | 0.382166 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.583333 | 0.608696 | 0.595745 | 0.608696 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.620462 | 0.400426 | 0.486731 | 0.400426 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 12:12:24,238 - trainer - INFO] - Train Epoch:[16/100] Step:[110/250] Total Loss: 26.839973 GL_Loss: 0.751594 CRF_Loss: 26.088379\n",
      "[2022-02-17 12:12:38,236 - trainer - INFO] - Train Epoch:[16/100] Step:[120/250] Total Loss: 305.943848 GL_Loss: 1.155162 CRF_Loss: 304.788696\n",
      "[2022-02-17 12:12:52,019 - trainer - INFO] - Train Epoch:[16/100] Step:[130/250] Total Loss: 371.049561 GL_Loss: 0.681770 CRF_Loss: 370.367798\n",
      "[2022-02-17 12:13:06,788 - trainer - INFO] - Train Epoch:[16/100] Step:[140/250] Total Loss: 186.601318 GL_Loss: 0.936150 CRF_Loss: 185.665161\n",
      "[2022-02-17 12:13:20,344 - trainer - INFO] - Train Epoch:[16/100] Step:[150/250] Total Loss: 45.342281 GL_Loss: 1.305292 CRF_Loss: 44.036987\n",
      "[2022-02-17 12:13:39,368 - trainer - INFO] - [Step Validation] Epoch:[16/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.79661  | 0.898089 | 0.844311 | 0.898089 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.260116 | 0.119681 | 0.163934 | 0.119681 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.495913 | 0.579618 | 0.534508 | 0.579618 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.589474 | 0.608696 | 0.59893  | 0.608696 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.522167 | 0.451544 | 0.484295 | 0.451544 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 12:13:53,273 - trainer - INFO] - Train Epoch:[16/100] Step:[160/250] Total Loss: 56.615204 GL_Loss: 1.319306 CRF_Loss: 55.295898\n",
      "[2022-02-17 12:14:08,093 - trainer - INFO] - Train Epoch:[16/100] Step:[170/250] Total Loss: 33.453552 GL_Loss: 1.234437 CRF_Loss: 32.219116\n",
      "[2022-02-17 12:14:22,379 - trainer - INFO] - Train Epoch:[16/100] Step:[180/250] Total Loss: 1619.954102 GL_Loss: 1.395192 CRF_Loss: 1618.558960\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 12:14:35,794 - trainer - INFO] - Train Epoch:[16/100] Step:[190/250] Total Loss: 137.237289 GL_Loss: 0.634991 CRF_Loss: 136.602295\n",
      "[2022-02-17 12:14:49,925 - trainer - INFO] - Train Epoch:[16/100] Step:[200/250] Total Loss: 34.596035 GL_Loss: 0.780238 CRF_Loss: 33.815796\n",
      "[2022-02-17 12:15:08,894 - trainer - INFO] - [Step Validation] Epoch:[16/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.817073 | 0.853503 | 0.834891 | 0.853503 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.395349 | 0.180851 | 0.248175 | 0.180851 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.618677 | 0.506369 | 0.556918 | 0.506369 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.576087 | 0.576087 | 0.576087 | 0.576087 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.60438  | 0.440895 | 0.509852 | 0.440895 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 12:15:11,025 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 12:15:25,415 - trainer - INFO] - Train Epoch:[16/100] Step:[210/250] Total Loss: 80.775093 GL_Loss: 1.073310 CRF_Loss: 79.701782\n",
      "[2022-02-17 12:15:39,674 - trainer - INFO] - Train Epoch:[16/100] Step:[220/250] Total Loss: 28.776628 GL_Loss: 1.067156 CRF_Loss: 27.709473\n",
      "[2022-02-17 12:15:54,984 - trainer - INFO] - Train Epoch:[16/100] Step:[230/250] Total Loss: 35.756935 GL_Loss: 1.400979 CRF_Loss: 34.355957\n",
      "[2022-02-17 12:16:09,665 - trainer - INFO] - Train Epoch:[16/100] Step:[240/250] Total Loss: 93.349434 GL_Loss: 1.548653 CRF_Loss: 91.800781\n",
      "[2022-02-17 12:16:24,624 - trainer - INFO] - Train Epoch:[16/100] Step:[250/250] Total Loss: 42.300022 GL_Loss: 1.529758 CRF_Loss: 40.770264\n",
      "[2022-02-17 12:16:45,001 - trainer - INFO] - [Step Validation] Epoch:[16/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.815029 | 0.898089 | 0.854545 | 0.898089 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.39548  | 0.18617  | 0.253165 | 0.18617  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.711538 | 0.353503 | 0.47234  | 0.353503 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.648936 | 0.663043 | 0.655914 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.638333 | 0.407881 | 0.497726 | 0.407881 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 12:17:04,067 - trainer - INFO] - [Epoch Validation] Epoch:[16/100] Total Loss: 95.946984 GL_Loss: 0.010868 CRF_Loss: 94.860203 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.815029 | 0.898089 | 0.854545 | 0.898089 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.39548  | 0.18617  | 0.253165 | 0.18617  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.711538 | 0.353503 | 0.47234  | 0.353503 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.648936 | 0.663043 | 0.655914 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.638333 | 0.407881 | 0.497726 | 0.407881 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 12:17:18,933 - trainer - INFO] - Train Epoch:[17/100] Step:[10/250] Total Loss: 35.766197 GL_Loss: 1.282066 CRF_Loss: 34.484131\n",
      "[2022-02-17 12:17:33,666 - trainer - INFO] - Train Epoch:[17/100] Step:[20/250] Total Loss: 33.719017 GL_Loss: 0.842796 CRF_Loss: 32.876221\n",
      "[2022-02-17 12:17:47,389 - trainer - INFO] - Train Epoch:[17/100] Step:[30/250] Total Loss: 96.881905 GL_Loss: 0.890330 CRF_Loss: 95.991577\n",
      "[2022-02-17 12:18:02,169 - trainer - INFO] - Train Epoch:[17/100] Step:[40/250] Total Loss: 64.524666 GL_Loss: 0.595224 CRF_Loss: 63.929443\n",
      "[2022-02-17 12:18:15,819 - trainer - INFO] - Train Epoch:[17/100] Step:[50/250] Total Loss: 48.182098 GL_Loss: 0.989714 CRF_Loss: 47.192383\n",
      "[2022-02-17 12:18:34,748 - trainer - INFO] - [Step Validation] Epoch:[17/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.865031 | 0.898089 | 0.88125  | 0.898089 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.369318 | 0.172872 | 0.235507 | 0.172872 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.757009 | 0.257962 | 0.384798 | 0.257962 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.586957 | 0.586957 | 0.586957 | 0.586957 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.633829 | 0.363152 | 0.461747 | 0.363152 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 12:18:48,332 - trainer - INFO] - Train Epoch:[17/100] Step:[60/250] Total Loss: 234.692505 GL_Loss: 0.738646 CRF_Loss: 233.953857\n",
      "[2022-02-17 12:19:03,069 - trainer - INFO] - Train Epoch:[17/100] Step:[70/250] Total Loss: 30.346205 GL_Loss: 0.855727 CRF_Loss: 29.490479\n",
      "[2022-02-17 12:19:16,905 - trainer - INFO] - Train Epoch:[17/100] Step:[80/250] Total Loss: 70.603256 GL_Loss: 0.822739 CRF_Loss: 69.780518\n",
      "[2022-02-17 12:19:32,655 - trainer - INFO] - Train Epoch:[17/100] Step:[90/250] Total Loss: 50.962639 GL_Loss: 1.452874 CRF_Loss: 49.509766\n",
      "[2022-02-17 12:19:47,398 - trainer - INFO] - Train Epoch:[17/100] Step:[100/250] Total Loss: 105.061302 GL_Loss: 0.922019 CRF_Loss: 104.139282\n",
      "[2022-02-17 12:20:06,416 - trainer - INFO] - [Step Validation] Epoch:[17/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.877301 | 0.910828 | 0.89375  | 0.910828 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.261438 | 0.106383 | 0.151229 | 0.106383 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.71066  | 0.44586  | 0.547945 | 0.44586  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.641304 | 0.641304 | 0.641304 | 0.641304 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.631405 | 0.406816 | 0.494819 | 0.406816 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 12:20:21,437 - trainer - INFO] - Train Epoch:[17/100] Step:[110/250] Total Loss: 1661.466553 GL_Loss: 0.914935 CRF_Loss: 1660.551636\n",
      "[2022-02-17 12:20:35,735 - trainer - INFO] - Train Epoch:[17/100] Step:[120/250] Total Loss: 39.116947 GL_Loss: 0.521856 CRF_Loss: 38.595093\n",
      "[2022-02-17 12:20:49,896 - trainer - INFO] - Train Epoch:[17/100] Step:[130/250] Total Loss: 46.048580 GL_Loss: 0.568964 CRF_Loss: 45.479614\n",
      "[2022-02-17 12:21:04,852 - trainer - INFO] - Train Epoch:[17/100] Step:[140/250] Total Loss: 254.568741 GL_Loss: 0.400837 CRF_Loss: 254.167908\n",
      "[2022-02-17 12:21:19,770 - trainer - INFO] - Train Epoch:[17/100] Step:[150/250] Total Loss: 68.200012 GL_Loss: 4.788882 CRF_Loss: 63.411133\n",
      "[2022-02-17 12:21:38,967 - trainer - INFO] - [Step Validation] Epoch:[17/100] Step:[150/250]  \n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| name    |       mEP |       mER |       mEF |       mEA |\n",
      "+=========+===========+===========+===========+===========+\n",
      "| date    | 0.363914  | 0.757962  | 0.491736  | 0.757962  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| address | 0.0786517 | 0.0558511 | 0.0653188 | 0.0558511 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| total   | 0.467213  | 0.181529  | 0.261468  | 0.181529  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| company | 0.44      | 0.358696  | 0.39521   | 0.358696  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| overall | 0.290771  | 0.244941  | 0.265896  | 0.244941  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 12:21:53,854 - trainer - INFO] - Train Epoch:[17/100] Step:[160/250] Total Loss: 144.206924 GL_Loss: 2.102865 CRF_Loss: 142.104065\n",
      "[2022-02-17 12:22:07,590 - trainer - INFO] - Train Epoch:[17/100] Step:[170/250] Total Loss: 161.079254 GL_Loss: 0.909327 CRF_Loss: 160.169922\n",
      "[2022-02-17 12:22:21,952 - trainer - INFO] - Train Epoch:[17/100] Step:[180/250] Total Loss: 469.968048 GL_Loss: 0.390414 CRF_Loss: 469.577637\n",
      "[2022-02-17 12:22:35,826 - trainer - INFO] - Train Epoch:[17/100] Step:[190/250] Total Loss: 139.193893 GL_Loss: 1.282152 CRF_Loss: 137.911743\n",
      "[2022-02-17 12:22:49,133 - trainer - INFO] - Train Epoch:[17/100] Step:[200/250] Total Loss: 51.195423 GL_Loss: 1.608386 CRF_Loss: 49.587036\n",
      "[2022-02-17 12:23:08,099 - trainer - INFO] - [Step Validation] Epoch:[17/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.804598 | 0.89172  | 0.845921 | 0.89172  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.343373 | 0.151596 | 0.210332 | 0.151596 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.587591 | 0.512739 | 0.547619 | 0.512739 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.551282 | 0.467391 | 0.505882 | 0.467391 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.57948  | 0.42705  | 0.491723 | 0.42705  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 12:23:21,660 - trainer - INFO] - Train Epoch:[17/100] Step:[210/250] Total Loss: 74.917259 GL_Loss: 0.728661 CRF_Loss: 74.188599\n",
      "[2022-02-17 12:23:36,203 - trainer - INFO] - Train Epoch:[17/100] Step:[220/250] Total Loss: 101.849556 GL_Loss: 0.863103 CRF_Loss: 100.986450\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 12:23:50,952 - trainer - INFO] - Train Epoch:[17/100] Step:[230/250] Total Loss: 29.685856 GL_Loss: 0.979802 CRF_Loss: 28.706055\n",
      "[2022-02-17 12:24:05,754 - trainer - INFO] - Train Epoch:[17/100] Step:[240/250] Total Loss: 147.716400 GL_Loss: 0.501559 CRF_Loss: 147.214844\n",
      "[2022-02-17 12:24:19,211 - trainer - INFO] - Train Epoch:[17/100] Step:[250/250] Total Loss: 50.794350 GL_Loss: 0.601114 CRF_Loss: 50.193237\n",
      "[2022-02-17 12:24:38,319 - trainer - INFO] - [Step Validation] Epoch:[17/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.873494 | 0.923567 | 0.897833 | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.362573 | 0.164894 | 0.226691 | 0.164894 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.604502 | 0.598726 | 0.6016   | 0.598726 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.623529 | 0.576087 | 0.59887  | 0.576087 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.611187 | 0.477103 | 0.535885 | 0.477103 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 12:24:40,439 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 12:24:59,687 - trainer - INFO] - [Epoch Validation] Epoch:[17/100] Total Loss: 106.787332 GL_Loss: 0.012225 CRF_Loss: 105.564801 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.873494 | 0.923567 | 0.897833 | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.362573 | 0.164894 | 0.226691 | 0.164894 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.604502 | 0.598726 | 0.6016   | 0.598726 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.623529 | 0.576087 | 0.59887  | 0.576087 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.611187 | 0.477103 | 0.535885 | 0.477103 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 12:25:14,798 - trainer - INFO] - Train Epoch:[18/100] Step:[10/250] Total Loss: 26.653194 GL_Loss: 0.855099 CRF_Loss: 25.798096\n",
      "[2022-02-17 12:25:29,259 - trainer - INFO] - Train Epoch:[18/100] Step:[20/250] Total Loss: 36.163647 GL_Loss: 0.517651 CRF_Loss: 35.645996\n",
      "[2022-02-17 12:25:43,634 - trainer - INFO] - Train Epoch:[18/100] Step:[30/250] Total Loss: 67.610413 GL_Loss: 0.675233 CRF_Loss: 66.935181\n",
      "[2022-02-17 12:25:58,198 - trainer - INFO] - Train Epoch:[18/100] Step:[40/250] Total Loss: 98.072731 GL_Loss: 0.395362 CRF_Loss: 97.677368\n",
      "[2022-02-17 12:26:12,643 - trainer - INFO] - Train Epoch:[18/100] Step:[50/250] Total Loss: 27.602253 GL_Loss: 0.535237 CRF_Loss: 27.067017\n",
      "[2022-02-17 12:26:31,698 - trainer - INFO] - [Step Validation] Epoch:[18/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.902439 | 0.942675 | 0.922118 | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.323699 | 0.148936 | 0.204007 | 0.148936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.6      | 0.573248 | 0.586319 | 0.573248 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.593407 | 0.586957 | 0.590164 | 0.586957 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.601648 | 0.466454 | 0.525495 | 0.466454 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 12:26:45,621 - trainer - INFO] - Train Epoch:[18/100] Step:[60/250] Total Loss: 43.411205 GL_Loss: 0.622019 CRF_Loss: 42.789185\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 12:26:59,701 - trainer - INFO] - Train Epoch:[18/100] Step:[70/250] Total Loss: 51.877758 GL_Loss: 0.794017 CRF_Loss: 51.083740\n",
      "[2022-02-17 12:27:13,439 - trainer - INFO] - Train Epoch:[18/100] Step:[80/250] Total Loss: 90.490326 GL_Loss: 0.513032 CRF_Loss: 89.977295\n",
      "[2022-02-17 12:27:28,848 - trainer - INFO] - Train Epoch:[18/100] Step:[90/250] Total Loss: 57.452469 GL_Loss: 0.629470 CRF_Loss: 56.822998\n",
      "[2022-02-17 12:27:43,993 - trainer - INFO] - Train Epoch:[18/100] Step:[100/250] Total Loss: 44.436001 GL_Loss: 0.545924 CRF_Loss: 43.890076\n",
      "[2022-02-17 12:28:02,986 - trainer - INFO] - [Step Validation] Epoch:[18/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.819277 | 0.866242 | 0.842105 | 0.866242 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.350575 | 0.162234 | 0.221818 | 0.162234 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.72973  | 0.429936 | 0.541082 | 0.429936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.549451 | 0.543478 | 0.546448 | 0.543478 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.62013  | 0.406816 | 0.491318 | 0.406816 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 12:28:17,139 - trainer - INFO] - Train Epoch:[18/100] Step:[110/250] Total Loss: 67.757164 GL_Loss: 21.509238 CRF_Loss: 46.247925\n",
      "[2022-02-17 12:28:31,765 - trainer - INFO] - Train Epoch:[18/100] Step:[120/250] Total Loss: 211.026520 GL_Loss: 3.608305 CRF_Loss: 207.418213\n",
      "[2022-02-17 12:28:45,400 - trainer - INFO] - Train Epoch:[18/100] Step:[130/250] Total Loss: 185.688278 GL_Loss: 2.003335 CRF_Loss: 183.684937\n",
      "[2022-02-17 12:29:00,696 - trainer - INFO] - Train Epoch:[18/100] Step:[140/250] Total Loss: 80.240738 GL_Loss: 3.358289 CRF_Loss: 76.882446\n",
      "[2022-02-17 12:29:14,525 - trainer - INFO] - Train Epoch:[18/100] Step:[150/250] Total Loss: 120.237419 GL_Loss: 4.606863 CRF_Loss: 115.630554\n",
      "[2022-02-17 12:29:33,799 - trainer - INFO] - [Step Validation] Epoch:[18/100] Step:[150/250]  \n",
      "+---------+-----------+----------+----------+----------+\n",
      "| name    |       mEP |      mER |      mEF |      mEA |\n",
      "+=========+===========+==========+==========+==========+\n",
      "| date    | 0.397436  | 0.592357 | 0.475703 | 0.592357 |\n",
      "+---------+-----------+----------+----------+----------+\n",
      "| address | 0.0338983 | 0.037234 | 0.035488 | 0.037234 |\n",
      "+---------+-----------+----------+----------+----------+\n",
      "| total   | 0.310502  | 0.433121 | 0.361702 | 0.433121 |\n",
      "+---------+-----------+----------+----------+----------+\n",
      "| company | 0.490566  | 0.565217 | 0.525253 | 0.565217 |\n",
      "+---------+-----------+----------+----------+----------+\n",
      "| overall | 0.247691  | 0.314164 | 0.276995 | 0.314164 |\n",
      "+---------+-----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 12:29:47,747 - trainer - INFO] - Train Epoch:[18/100] Step:[160/250] Total Loss: 116.874954 GL_Loss: 2.133135 CRF_Loss: 114.741821\n",
      "[2022-02-17 12:30:02,955 - trainer - INFO] - Train Epoch:[18/100] Step:[170/250] Total Loss: 100.868690 GL_Loss: 1.895423 CRF_Loss: 98.973267\n",
      "[2022-02-17 12:30:17,548 - trainer - INFO] - Train Epoch:[18/100] Step:[180/250] Total Loss: 130.223328 GL_Loss: 1.529300 CRF_Loss: 128.694031\n",
      "[2022-02-17 12:30:31,738 - trainer - INFO] - Train Epoch:[18/100] Step:[190/250] Total Loss: 65.701195 GL_Loss: 2.234767 CRF_Loss: 63.466431\n",
      "[2022-02-17 12:30:46,350 - trainer - INFO] - Train Epoch:[18/100] Step:[200/250] Total Loss: 53.868660 GL_Loss: 2.288093 CRF_Loss: 51.580566\n",
      "[2022-02-17 12:31:05,459 - trainer - INFO] - [Step Validation] Epoch:[18/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.763736 | 0.88535  | 0.820059 | 0.88535  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.30102  | 0.156915 | 0.206294 | 0.156915 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.606335 | 0.426752 | 0.500935 | 0.426752 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.596154 | 0.673913 | 0.632653 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.560455 | 0.419595 | 0.479903 | 0.419595 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 12:31:19,339 - trainer - INFO] - Train Epoch:[18/100] Step:[210/250] Total Loss: 66.532661 GL_Loss: 1.573497 CRF_Loss: 64.959167\n",
      "[2022-02-17 12:31:32,923 - trainer - INFO] - Train Epoch:[18/100] Step:[220/250] Total Loss: 53.947056 GL_Loss: 1.187900 CRF_Loss: 52.759155\n",
      "[2022-02-17 12:31:47,666 - trainer - INFO] - Train Epoch:[18/100] Step:[230/250] Total Loss: 185.078979 GL_Loss: 0.754033 CRF_Loss: 184.324951\n",
      "[2022-02-17 12:32:01,324 - trainer - INFO] - Train Epoch:[18/100] Step:[240/250] Total Loss: 63.144497 GL_Loss: 2.264613 CRF_Loss: 60.879883\n",
      "[2022-02-17 12:32:16,028 - trainer - INFO] - Train Epoch:[18/100] Step:[250/250] Total Loss: 53.992279 GL_Loss: 2.049287 CRF_Loss: 51.942993\n",
      "[2022-02-17 12:32:35,073 - trainer - INFO] - [Step Validation] Epoch:[18/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.789474 | 0.859873 | 0.823171 | 0.859873 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.27673  | 0.117021 | 0.164486 | 0.117021 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.601399 | 0.547771 | 0.573333 | 0.547771 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.673913 | 0.673913 | 0.673913 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.583333 | 0.43983  | 0.501518 | 0.43983  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 12:32:54,239 - trainer - INFO] - [Epoch Validation] Epoch:[18/100] Total Loss: 115.438834 GL_Loss: 0.021257 CRF_Loss: 113.313164 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.789474 | 0.859873 | 0.823171 | 0.859873 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.27673  | 0.117021 | 0.164486 | 0.117021 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.601399 | 0.547771 | 0.573333 | 0.547771 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.673913 | 0.673913 | 0.673913 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.583333 | 0.43983  | 0.501518 | 0.43983  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 12:33:09,683 - trainer - INFO] - Train Epoch:[19/100] Step:[10/250] Total Loss: 42.252724 GL_Loss: 1.134314 CRF_Loss: 41.118408\n",
      "[2022-02-17 12:33:23,547 - trainer - INFO] - Train Epoch:[19/100] Step:[20/250] Total Loss: 48.489258 GL_Loss: 1.191042 CRF_Loss: 47.298218\n",
      "[2022-02-17 12:33:37,437 - trainer - INFO] - Train Epoch:[19/100] Step:[30/250] Total Loss: 59.228409 GL_Loss: 0.844680 CRF_Loss: 58.383728\n",
      "[2022-02-17 12:33:51,169 - trainer - INFO] - Train Epoch:[19/100] Step:[40/250] Total Loss: 391.857391 GL_Loss: 0.632284 CRF_Loss: 391.225098\n",
      "[2022-02-17 12:34:05,058 - trainer - INFO] - Train Epoch:[19/100] Step:[50/250] Total Loss: 37.002304 GL_Loss: 0.668929 CRF_Loss: 36.333374\n",
      "[2022-02-17 12:34:24,203 - trainer - INFO] - [Step Validation] Epoch:[19/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.79096  | 0.89172  | 0.838323 | 0.89172  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.290155 | 0.148936 | 0.196837 | 0.148936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.598485 | 0.503185 | 0.546713 | 0.503185 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.628866 | 0.663043 | 0.645503 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.567715 | 0.44196  | 0.497006 | 0.44196  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 12:34:38,160 - trainer - INFO] - Train Epoch:[19/100] Step:[60/250] Total Loss: 47.586620 GL_Loss: 1.019727 CRF_Loss: 46.566895\n",
      "[2022-02-17 12:34:52,441 - trainer - INFO] - Train Epoch:[19/100] Step:[70/250] Total Loss: 25.858124 GL_Loss: 1.248383 CRF_Loss: 24.609741\n",
      "[2022-02-17 12:35:07,500 - trainer - INFO] - Train Epoch:[19/100] Step:[80/250] Total Loss: 62.858875 GL_Loss: 2.394641 CRF_Loss: 60.464233\n",
      "[2022-02-17 12:35:21,067 - trainer - INFO] - Train Epoch:[19/100] Step:[90/250] Total Loss: 70.658379 GL_Loss: 1.870173 CRF_Loss: 68.788208\n",
      "[2022-02-17 12:35:35,318 - trainer - INFO] - Train Epoch:[19/100] Step:[100/250] Total Loss: 44.008820 GL_Loss: 0.850616 CRF_Loss: 43.158203\n",
      "[2022-02-17 12:35:54,292 - trainer - INFO] - [Step Validation] Epoch:[19/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.845238 | 0.904459 | 0.873846 | 0.904459 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.340102 | 0.178191 | 0.233857 | 0.178191 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.597902 | 0.544586 | 0.57     | 0.544586 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.630435 | 0.630435 | 0.630435 | 0.630435 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.589502 | 0.466454 | 0.520809 | 0.466454 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 12:36:09,676 - trainer - INFO] - Train Epoch:[19/100] Step:[110/250] Total Loss: 651.349121 GL_Loss: 1.981110 CRF_Loss: 649.367981\n",
      "[2022-02-17 12:36:23,765 - trainer - INFO] - Train Epoch:[19/100] Step:[120/250] Total Loss: 66.342232 GL_Loss: 0.630807 CRF_Loss: 65.711426\n",
      "[2022-02-17 12:36:37,068 - trainer - INFO] - Train Epoch:[19/100] Step:[130/250] Total Loss: 81.892509 GL_Loss: 1.727961 CRF_Loss: 80.164551\n",
      "[2022-02-17 12:36:51,039 - trainer - INFO] - Train Epoch:[19/100] Step:[140/250] Total Loss: 668.625061 GL_Loss: 1.071039 CRF_Loss: 667.554016\n",
      "[2022-02-17 12:37:05,443 - trainer - INFO] - Train Epoch:[19/100] Step:[150/250] Total Loss: 61.804508 GL_Loss: 0.953188 CRF_Loss: 60.851318\n",
      "[2022-02-17 12:37:24,824 - trainer - INFO] - [Step Validation] Epoch:[19/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.807018 | 0.878981 | 0.841463 | 0.878981 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.362069 | 0.167553 | 0.229091 | 0.167553 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.7375   | 0.375796 | 0.49789  | 0.375796 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.659574 | 0.673913 | 0.666667 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.63606  | 0.405751 | 0.495449 | 0.405751 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 12:37:40,862 - trainer - INFO] - Train Epoch:[19/100] Step:[160/250] Total Loss: 27.332218 GL_Loss: 1.094303 CRF_Loss: 26.237915\n",
      "[2022-02-17 12:37:55,142 - trainer - INFO] - Train Epoch:[19/100] Step:[170/250] Total Loss: 199.253204 GL_Loss: 0.751500 CRF_Loss: 198.501709\n",
      "[2022-02-17 12:38:09,703 - trainer - INFO] - Train Epoch:[19/100] Step:[180/250] Total Loss: 49.314529 GL_Loss: 1.187700 CRF_Loss: 48.126831\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 12:38:24,730 - trainer - INFO] - Train Epoch:[19/100] Step:[190/250] Total Loss: 43.721676 GL_Loss: 0.652341 CRF_Loss: 43.069336\n",
      "[2022-02-17 12:38:41,306 - trainer - INFO] - Train Epoch:[19/100] Step:[200/250] Total Loss: 64.196785 GL_Loss: 1.438242 CRF_Loss: 62.758545\n",
      "[2022-02-17 12:39:00,338 - trainer - INFO] - [Step Validation] Epoch:[19/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.822857 | 0.917197 | 0.86747  | 0.917197 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.387435 | 0.196809 | 0.261023 | 0.196809 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.65098  | 0.528662 | 0.58348  | 0.528662 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.612903 | 0.619565 | 0.616216 | 0.619565 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.617647 | 0.469649 | 0.533575 | 0.469649 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 12:39:15,310 - trainer - INFO] - Train Epoch:[19/100] Step:[210/250] Total Loss: 81.255112 GL_Loss: 0.923934 CRF_Loss: 80.331177\n",
      "[2022-02-17 12:39:32,066 - trainer - INFO] - Train Epoch:[19/100] Step:[220/250] Total Loss: 100.708359 GL_Loss: 0.804852 CRF_Loss: 99.903503\n",
      "[2022-02-17 12:39:48,515 - trainer - INFO] - Train Epoch:[19/100] Step:[230/250] Total Loss: 36.502338 GL_Loss: 1.817647 CRF_Loss: 34.684692\n",
      "[2022-02-17 12:40:04,785 - trainer - INFO] - Train Epoch:[19/100] Step:[240/250] Total Loss: 70.912079 GL_Loss: 1.825532 CRF_Loss: 69.086548\n",
      "[2022-02-17 12:40:18,904 - trainer - INFO] - Train Epoch:[19/100] Step:[250/250] Total Loss: 32.528835 GL_Loss: 1.869900 CRF_Loss: 30.658936\n",
      "[2022-02-17 12:40:38,104 - trainer - INFO] - [Step Validation] Epoch:[19/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.864198 | 0.89172  | 0.877743 | 0.89172  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.47619  | 0.239362 | 0.318584 | 0.239362 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.613419 | 0.611465 | 0.61244  | 0.611465 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.677778 | 0.663043 | 0.67033  | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.640584 | 0.514377 | 0.570585 | 0.514377 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 12:40:40,263 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 12:40:59,478 - trainer - INFO] - [Epoch Validation] Epoch:[19/100] Total Loss: 92.650618 GL_Loss: 0.012053 CRF_Loss: 91.445272 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.864198 | 0.89172  | 0.877743 | 0.89172  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.47619  | 0.239362 | 0.318584 | 0.239362 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.613419 | 0.611465 | 0.61244  | 0.611465 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.677778 | 0.663043 | 0.67033  | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.640584 | 0.514377 | 0.570585 | 0.514377 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 12:41:16,138 - trainer - INFO] - Train Epoch:[20/100] Step:[10/250] Total Loss: 27.783428 GL_Loss: 1.313214 CRF_Loss: 26.470215\n",
      "[2022-02-17 12:41:33,486 - trainer - INFO] - Train Epoch:[20/100] Step:[20/250] Total Loss: 35.893906 GL_Loss: 1.111923 CRF_Loss: 34.781982\n",
      "[2022-02-17 12:41:48,786 - trainer - INFO] - Train Epoch:[20/100] Step:[30/250] Total Loss: 31.309883 GL_Loss: 1.189888 CRF_Loss: 30.119995\n",
      "[2022-02-17 12:42:03,558 - trainer - INFO] - Train Epoch:[20/100] Step:[40/250] Total Loss: 37.728619 GL_Loss: 0.910381 CRF_Loss: 36.818237\n",
      "[2022-02-17 12:42:18,110 - trainer - INFO] - Train Epoch:[20/100] Step:[50/250] Total Loss: 44.801502 GL_Loss: 0.804676 CRF_Loss: 43.996826\n",
      "[2022-02-17 12:42:37,091 - trainer - INFO] - [Step Validation] Epoch:[20/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.845238 | 0.904459 | 0.873846 | 0.904459 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.494898 | 0.257979 | 0.339161 | 0.257979 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.754098 | 0.43949  | 0.555332 | 0.43949  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.723404 | 0.73913  | 0.731183 | 0.73913  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.694228 | 0.473908 | 0.563291 | 0.473908 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 12:42:51,550 - trainer - INFO] - Train Epoch:[20/100] Step:[60/250] Total Loss: 1469.203979 GL_Loss: 0.788643 CRF_Loss: 1468.415283\n",
      "[2022-02-17 12:43:04,763 - trainer - INFO] - Train Epoch:[20/100] Step:[70/250] Total Loss: 65.480652 GL_Loss: 0.454892 CRF_Loss: 65.025757\n",
      "[2022-02-17 12:43:18,833 - trainer - INFO] - Train Epoch:[20/100] Step:[80/250] Total Loss: 48.354446 GL_Loss: 0.645340 CRF_Loss: 47.709106\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 12:43:32,920 - trainer - INFO] - Train Epoch:[20/100] Step:[90/250] Total Loss: 30.544594 GL_Loss: 0.987831 CRF_Loss: 29.556763\n",
      "[2022-02-17 12:43:47,512 - trainer - INFO] - Train Epoch:[20/100] Step:[100/250] Total Loss: 22.169476 GL_Loss: 1.012859 CRF_Loss: 21.156616\n",
      "[2022-02-17 12:44:06,744 - trainer - INFO] - [Step Validation] Epoch:[20/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.835294 | 0.904459 | 0.868502 | 0.904459 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.482587 | 0.257979 | 0.336222 | 0.257979 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.65704  | 0.579618 | 0.615905 | 0.579618 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.758242 | 0.75     | 0.754098 | 0.75     |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.663058 | 0.521832 | 0.584029 | 0.521832 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 12:44:08,884 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 12:44:23,892 - trainer - INFO] - Train Epoch:[20/100] Step:[110/250] Total Loss: 21.617783 GL_Loss: 0.952133 CRF_Loss: 20.665649\n",
      "[2022-02-17 12:44:37,686 - trainer - INFO] - Train Epoch:[20/100] Step:[120/250] Total Loss: 68.448334 GL_Loss: 0.728850 CRF_Loss: 67.719482\n",
      "[2022-02-17 12:44:51,241 - trainer - INFO] - Train Epoch:[20/100] Step:[130/250] Total Loss: 58.605923 GL_Loss: 0.732388 CRF_Loss: 57.873535\n",
      "[2022-02-17 12:45:06,304 - trainer - INFO] - Train Epoch:[20/100] Step:[140/250] Total Loss: 53.263096 GL_Loss: 0.933629 CRF_Loss: 52.329468\n",
      "[2022-02-17 12:45:19,558 - trainer - INFO] - Train Epoch:[20/100] Step:[150/250] Total Loss: 99.792183 GL_Loss: 0.367378 CRF_Loss: 99.424805\n",
      "[2022-02-17 12:45:38,908 - trainer - INFO] - [Step Validation] Epoch:[20/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.852071 | 0.917197 | 0.883436 | 0.917197 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.247012 | 0.164894 | 0.197767 | 0.164894 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.660584 | 0.576433 | 0.615646 | 0.576433 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.656566 | 0.706522 | 0.680628 | 0.706522 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.569987 | 0.481363 | 0.52194  | 0.481363 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 12:45:53,468 - trainer - INFO] - Train Epoch:[20/100] Step:[160/250] Total Loss: 59.882637 GL_Loss: 0.603095 CRF_Loss: 59.279541\n",
      "[2022-02-17 12:46:06,940 - trainer - INFO] - Train Epoch:[20/100] Step:[170/250] Total Loss: 62.835663 GL_Loss: 0.468110 CRF_Loss: 62.367554\n",
      "[2022-02-17 12:46:22,403 - trainer - INFO] - Train Epoch:[20/100] Step:[180/250] Total Loss: 26.146908 GL_Loss: 0.519100 CRF_Loss: 25.627808\n",
      "[2022-02-17 12:46:36,940 - trainer - INFO] - Train Epoch:[20/100] Step:[190/250] Total Loss: 94.675644 GL_Loss: 0.475326 CRF_Loss: 94.200317\n",
      "[2022-02-17 12:46:52,186 - trainer - INFO] - Train Epoch:[20/100] Step:[200/250] Total Loss: 66.844894 GL_Loss: 0.485766 CRF_Loss: 66.359131\n",
      "[2022-02-17 12:47:11,279 - trainer - INFO] - [Step Validation] Epoch:[20/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.865854 | 0.904459 | 0.884735 | 0.904459 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.373272 | 0.215426 | 0.273187 | 0.215426 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.761364 | 0.426752 | 0.546939 | 0.426752 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.666667 | 0.695652 | 0.680851 | 0.695652 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.644717 | 0.448349 | 0.528894 | 0.448349 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 12:47:26,342 - trainer - INFO] - Train Epoch:[20/100] Step:[210/250] Total Loss: 39.852489 GL_Loss: 0.598462 CRF_Loss: 39.254028\n",
      "[2022-02-17 12:47:40,323 - trainer - INFO] - Train Epoch:[20/100] Step:[220/250] Total Loss: 151.794083 GL_Loss: 0.506119 CRF_Loss: 151.287964\n",
      "[2022-02-17 12:47:55,238 - trainer - INFO] - Train Epoch:[20/100] Step:[230/250] Total Loss: 463.108246 GL_Loss: 0.811608 CRF_Loss: 462.296631\n",
      "[2022-02-17 12:48:10,171 - trainer - INFO] - Train Epoch:[20/100] Step:[240/250] Total Loss: 45.347595 GL_Loss: 1.138977 CRF_Loss: 44.208618\n",
      "[2022-02-17 12:48:24,828 - trainer - INFO] - Train Epoch:[20/100] Step:[250/250] Total Loss: 45.574627 GL_Loss: 0.567059 CRF_Loss: 45.007568\n",
      "[2022-02-17 12:48:44,108 - trainer - INFO] - [Step Validation] Epoch:[20/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.856287 | 0.910828 | 0.882716 | 0.910828 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.397849 | 0.196809 | 0.263345 | 0.196809 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.692308 | 0.372611 | 0.484472 | 0.372611 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.65625  | 0.684783 | 0.670213 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.642395 | 0.42279  | 0.509955 | 0.42279  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 12:49:03,407 - trainer - INFO] - [Epoch Validation] Epoch:[20/100] Total Loss: 81.769248 GL_Loss: 0.008490 CRF_Loss: 80.920297 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.856287 | 0.910828 | 0.882716 | 0.910828 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.397849 | 0.196809 | 0.263345 | 0.196809 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.692308 | 0.372611 | 0.484472 | 0.372611 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.65625  | 0.684783 | 0.670213 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.642395 | 0.42279  | 0.509955 | 0.42279  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 12:49:05,327 - trainer - INFO] - Saving checkpoint: saved/models/PICK_Default/test_0217_100852/checkpoint-epoch20.pth ...\n",
      "[2022-02-17 12:49:20,768 - trainer - INFO] - Train Epoch:[21/100] Step:[10/250] Total Loss: 93.168900 GL_Loss: 0.519607 CRF_Loss: 92.649292\n",
      "[2022-02-17 12:49:34,004 - trainer - INFO] - Train Epoch:[21/100] Step:[20/250] Total Loss: 47.923653 GL_Loss: 1.021673 CRF_Loss: 46.901978\n",
      "[2022-02-17 12:49:48,690 - trainer - INFO] - Train Epoch:[21/100] Step:[30/250] Total Loss: 25.630152 GL_Loss: 1.052270 CRF_Loss: 24.577881\n",
      "[2022-02-17 12:50:04,626 - trainer - INFO] - Train Epoch:[21/100] Step:[40/250] Total Loss: 15.887918 GL_Loss: 0.923197 CRF_Loss: 14.964722\n",
      "[2022-02-17 12:50:18,539 - trainer - INFO] - Train Epoch:[21/100] Step:[50/250] Total Loss: 27.173046 GL_Loss: 0.908154 CRF_Loss: 26.264893\n",
      "[2022-02-17 12:50:37,532 - trainer - INFO] - [Step Validation] Epoch:[21/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.840237 | 0.904459 | 0.871166 | 0.904459 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.445161 | 0.183511 | 0.259887 | 0.183511 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.598684 | 0.579618 | 0.588997 | 0.579618 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.586957 | 0.586957 | 0.586957 | 0.586957 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.620833 | 0.476038 | 0.538879 | 0.476038 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 12:50:51,950 - trainer - INFO] - Train Epoch:[21/100] Step:[60/250] Total Loss: 552.124695 GL_Loss: 0.907065 CRF_Loss: 551.217651\n",
      "[2022-02-17 12:51:07,082 - trainer - INFO] - Train Epoch:[21/100] Step:[70/250] Total Loss: 29.694824 GL_Loss: 0.657471 CRF_Loss: 29.037354\n",
      "[2022-02-17 12:51:20,733 - trainer - INFO] - Train Epoch:[21/100] Step:[80/250] Total Loss: 55.875404 GL_Loss: 0.756997 CRF_Loss: 55.118408\n",
      "[2022-02-17 12:51:34,995 - trainer - INFO] - Train Epoch:[21/100] Step:[90/250] Total Loss: 67.954987 GL_Loss: 0.588164 CRF_Loss: 67.366821\n",
      "[2022-02-17 12:51:48,463 - trainer - INFO] - Train Epoch:[21/100] Step:[100/250] Total Loss: 88.677116 GL_Loss: 1.042475 CRF_Loss: 87.634644\n",
      "[2022-02-17 12:52:07,522 - trainer - INFO] - [Step Validation] Epoch:[21/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.849398 | 0.898089 | 0.873065 | 0.898089 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.436735 | 0.284574 | 0.344605 | 0.284574 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.645631 | 0.423567 | 0.511538 | 0.423567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.568807 | 0.673913 | 0.616915 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.610193 | 0.471778 | 0.532132 | 0.471778 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 12:52:20,735 - trainer - INFO] - Train Epoch:[21/100] Step:[110/250] Total Loss: 208.078613 GL_Loss: 1.186888 CRF_Loss: 206.891724\n",
      "[2022-02-17 12:52:34,395 - trainer - INFO] - Train Epoch:[21/100] Step:[120/250] Total Loss: 82.586746 GL_Loss: 1.160476 CRF_Loss: 81.426270\n",
      "[2022-02-17 12:52:48,841 - trainer - INFO] - Train Epoch:[21/100] Step:[130/250] Total Loss: 110.801727 GL_Loss: 0.670743 CRF_Loss: 110.130981\n",
      "[2022-02-17 12:53:02,932 - trainer - INFO] - Train Epoch:[21/100] Step:[140/250] Total Loss: 21.600365 GL_Loss: 0.847923 CRF_Loss: 20.752441\n",
      "[2022-02-17 12:53:18,166 - trainer - INFO] - Train Epoch:[21/100] Step:[150/250] Total Loss: 50.176666 GL_Loss: 0.625031 CRF_Loss: 49.551636\n",
      "[2022-02-17 12:53:37,364 - trainer - INFO] - [Step Validation] Epoch:[21/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.862275 | 0.917197 | 0.888889 | 0.917197 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.583333 | 0.335106 | 0.425676 | 0.335106 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.725926 | 0.312102 | 0.436526 | 0.312102 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.65     | 0.706522 | 0.677083 | 0.706522 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.700647 | 0.461129 | 0.556198 | 0.461129 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 12:53:51,264 - trainer - INFO] - Train Epoch:[21/100] Step:[160/250] Total Loss: 127.545387 GL_Loss: 0.729103 CRF_Loss: 126.816284\n",
      "[2022-02-17 12:54:05,827 - trainer - INFO] - Train Epoch:[21/100] Step:[170/250] Total Loss: 57.341198 GL_Loss: 0.578013 CRF_Loss: 56.763184\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 12:54:21,311 - trainer - INFO] - Train Epoch:[21/100] Step:[180/250] Total Loss: 24.476028 GL_Loss: 0.640091 CRF_Loss: 23.835938\n",
      "[2022-02-17 12:54:35,946 - trainer - INFO] - Train Epoch:[21/100] Step:[190/250] Total Loss: 50.051838 GL_Loss: 0.612507 CRF_Loss: 49.439331\n",
      "[2022-02-17 12:54:50,624 - trainer - INFO] - Train Epoch:[21/100] Step:[200/250] Total Loss: 101.895386 GL_Loss: 0.810304 CRF_Loss: 101.085083\n",
      "[2022-02-17 12:55:09,793 - trainer - INFO] - [Step Validation] Epoch:[21/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.843023 | 0.923567 | 0.881459 | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.57619  | 0.321809 | 0.412969 | 0.321809 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.697368 | 0.506369 | 0.586716 | 0.506369 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.648352 | 0.641304 | 0.644809 | 0.641304 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.690442 | 0.515442 | 0.590244 | 0.515442 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 12:55:11,931 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 12:55:26,278 - trainer - INFO] - Train Epoch:[21/100] Step:[210/250] Total Loss: 39.229534 GL_Loss: 0.685344 CRF_Loss: 38.544189\n",
      "[2022-02-17 12:55:39,863 - trainer - INFO] - Train Epoch:[21/100] Step:[220/250] Total Loss: 81.087570 GL_Loss: 0.718921 CRF_Loss: 80.368652\n",
      "[2022-02-17 12:55:53,724 - trainer - INFO] - Train Epoch:[21/100] Step:[230/250] Total Loss: 37.360806 GL_Loss: 0.477260 CRF_Loss: 36.883545\n",
      "[2022-02-17 12:56:07,455 - trainer - INFO] - Train Epoch:[21/100] Step:[240/250] Total Loss: 38.635178 GL_Loss: 0.854174 CRF_Loss: 37.781006\n",
      "[2022-02-17 12:56:21,949 - trainer - INFO] - Train Epoch:[21/100] Step:[250/250] Total Loss: 93.688248 GL_Loss: 0.495867 CRF_Loss: 93.192383\n",
      "[2022-02-17 12:56:41,005 - trainer - INFO] - [Step Validation] Epoch:[21/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.855491 | 0.942675 | 0.89697  | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.543779 | 0.31383  | 0.397976 | 0.31383  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.679537 | 0.56051  | 0.614311 | 0.56051  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.648936 | 0.663043 | 0.655914 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.676985 | 0.535676 | 0.598098 | 0.535676 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 12:56:43,122 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 12:57:02,495 - trainer - INFO] - [Epoch Validation] Epoch:[21/100] Total Loss: 85.026383 GL_Loss: 0.008081 CRF_Loss: 84.218265 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.855491 | 0.942675 | 0.89697  | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.543779 | 0.31383  | 0.397976 | 0.31383  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.679537 | 0.56051  | 0.614311 | 0.56051  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.648936 | 0.663043 | 0.655914 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.676985 | 0.535676 | 0.598098 | 0.535676 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 12:57:17,887 - trainer - INFO] - Train Epoch:[22/100] Step:[10/250] Total Loss: 34.015518 GL_Loss: 0.668229 CRF_Loss: 33.347290\n",
      "[2022-02-17 12:57:31,844 - trainer - INFO] - Train Epoch:[22/100] Step:[20/250] Total Loss: 94.173988 GL_Loss: 0.571690 CRF_Loss: 93.602295\n",
      "[2022-02-17 12:57:45,115 - trainer - INFO] - Train Epoch:[22/100] Step:[30/250] Total Loss: 16.555082 GL_Loss: 0.671050 CRF_Loss: 15.884033\n",
      "[2022-02-17 12:58:00,380 - trainer - INFO] - Train Epoch:[22/100] Step:[40/250] Total Loss: 46.679432 GL_Loss: 0.530384 CRF_Loss: 46.149048\n",
      "[2022-02-17 12:58:14,900 - trainer - INFO] - Train Epoch:[22/100] Step:[50/250] Total Loss: 17.563726 GL_Loss: 0.748663 CRF_Loss: 16.815063\n",
      "[2022-02-17 12:58:33,970 - trainer - INFO] - [Step Validation] Epoch:[22/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.863905 | 0.929936 | 0.895706 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.453704 | 0.260638 | 0.331081 | 0.260638 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.670732 | 0.525478 | 0.589286 | 0.525478 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.677419 | 0.684783 | 0.681081 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.651934 | 0.502662 | 0.567649 | 0.502662 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 12:58:49,730 - trainer - INFO] - Train Epoch:[22/100] Step:[60/250] Total Loss: 41.502602 GL_Loss: 0.463051 CRF_Loss: 41.039551\n",
      "[2022-02-17 12:59:02,983 - trainer - INFO] - Train Epoch:[22/100] Step:[70/250] Total Loss: 46.396481 GL_Loss: 0.428096 CRF_Loss: 45.968384\n",
      "[2022-02-17 12:59:17,245 - trainer - INFO] - Train Epoch:[22/100] Step:[80/250] Total Loss: 46.784836 GL_Loss: 0.510055 CRF_Loss: 46.274780\n",
      "[2022-02-17 12:59:31,382 - trainer - INFO] - Train Epoch:[22/100] Step:[90/250] Total Loss: 25.972475 GL_Loss: 0.509341 CRF_Loss: 25.463135\n",
      "[2022-02-17 12:59:46,968 - trainer - INFO] - Train Epoch:[22/100] Step:[100/250] Total Loss: 38.077736 GL_Loss: 0.556374 CRF_Loss: 37.521362\n",
      "[2022-02-17 13:00:06,230 - trainer - INFO] - [Step Validation] Epoch:[22/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.884848 | 0.929936 | 0.906832 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.497608 | 0.276596 | 0.355556 | 0.276596 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.787671 | 0.366242 | 0.5      | 0.366242 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.702128 | 0.717391 | 0.709677 | 0.717391 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.701954 | 0.458999 | 0.555055 | 0.458999 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 13:00:19,501 - trainer - INFO] - Train Epoch:[22/100] Step:[110/250] Total Loss: 27.223658 GL_Loss: 0.381251 CRF_Loss: 26.842407\n",
      "[2022-02-17 13:00:33,247 - trainer - INFO] - Train Epoch:[22/100] Step:[120/250] Total Loss: 100.994797 GL_Loss: 0.457202 CRF_Loss: 100.537598\n",
      "[2022-02-17 13:00:48,266 - trainer - INFO] - Train Epoch:[22/100] Step:[130/250] Total Loss: 19.006910 GL_Loss: 0.455397 CRF_Loss: 18.551514\n",
      "[2022-02-17 13:01:02,485 - trainer - INFO] - Train Epoch:[22/100] Step:[140/250] Total Loss: 80.907066 GL_Loss: 0.473472 CRF_Loss: 80.433594\n",
      "[2022-02-17 13:01:15,977 - trainer - INFO] - Train Epoch:[22/100] Step:[150/250] Total Loss: 113.092003 GL_Loss: 0.349568 CRF_Loss: 112.742432\n",
      "[2022-02-17 13:01:35,189 - trainer - INFO] - [Step Validation] Epoch:[22/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.776536 | 0.88535  | 0.827381 | 0.88535  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.511416 | 0.297872 | 0.376471 | 0.297872 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.704918 | 0.547771 | 0.616487 | 0.547771 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.673913 | 0.673913 | 0.673913 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.660763 | 0.516507 | 0.579797 | 0.516507 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 13:01:49,815 - trainer - INFO] - Train Epoch:[22/100] Step:[160/250] Total Loss: 48.010246 GL_Loss: 0.681267 CRF_Loss: 47.328979\n",
      "[2022-02-17 13:02:03,526 - trainer - INFO] - Train Epoch:[22/100] Step:[170/250] Total Loss: 122.591949 GL_Loss: 1.321688 CRF_Loss: 121.270264\n",
      "[2022-02-17 13:02:18,094 - trainer - INFO] - Train Epoch:[22/100] Step:[180/250] Total Loss: 39.584885 GL_Loss: 1.591356 CRF_Loss: 37.993530\n",
      "[2022-02-17 13:02:32,869 - trainer - INFO] - Train Epoch:[22/100] Step:[190/250] Total Loss: 135.725143 GL_Loss: 0.814254 CRF_Loss: 134.910889\n",
      "[2022-02-17 13:02:48,831 - trainer - INFO] - Train Epoch:[22/100] Step:[200/250] Total Loss: 38.557163 GL_Loss: 0.933383 CRF_Loss: 37.623779\n",
      "[2022-02-17 13:03:07,965 - trainer - INFO] - [Step Validation] Epoch:[22/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.818713 | 0.89172  | 0.853659 | 0.89172  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.542601 | 0.321809 | 0.404007 | 0.321809 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.681818 | 0.382166 | 0.489796 | 0.382166 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.520661 | 0.684783 | 0.591549 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.642547 | 0.472843 | 0.544785 | 0.472843 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 13:03:22,230 - trainer - INFO] - Train Epoch:[22/100] Step:[210/250] Total Loss: 51.831112 GL_Loss: 0.960016 CRF_Loss: 50.871094\n",
      "[2022-02-17 13:03:38,290 - trainer - INFO] - Train Epoch:[22/100] Step:[220/250] Total Loss: 447.150391 GL_Loss: 0.965806 CRF_Loss: 446.184570\n",
      "[2022-02-17 13:03:52,883 - trainer - INFO] - Train Epoch:[22/100] Step:[230/250] Total Loss: 28.292416 GL_Loss: 0.986141 CRF_Loss: 27.306274\n",
      "[2022-02-17 13:04:06,720 - trainer - INFO] - Train Epoch:[22/100] Step:[240/250] Total Loss: 66.183350 GL_Loss: 0.838012 CRF_Loss: 65.345337\n",
      "[2022-02-17 13:04:22,309 - trainer - INFO] - Train Epoch:[22/100] Step:[250/250] Total Loss: 17.609240 GL_Loss: 0.943468 CRF_Loss: 16.665771\n",
      "[2022-02-17 13:04:41,498 - trainer - INFO] - [Step Validation] Epoch:[22/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.863095 | 0.923567 | 0.892308 | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.565022 | 0.335106 | 0.420701 | 0.335106 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.686275 | 0.44586  | 0.540541 | 0.44586  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.705882 | 0.652174 | 0.677966 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.692647 | 0.501597 | 0.581841 | 0.501597 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 13:05:00,651 - trainer - INFO] - [Epoch Validation] Epoch:[22/100] Total Loss: 74.043468 GL_Loss: 0.006571 CRF_Loss: 73.386386 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.863095 | 0.923567 | 0.892308 | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.565022 | 0.335106 | 0.420701 | 0.335106 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.686275 | 0.44586  | 0.540541 | 0.44586  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.705882 | 0.652174 | 0.677966 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.692647 | 0.501597 | 0.581841 | 0.501597 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 13:05:14,079 - trainer - INFO] - Train Epoch:[23/100] Step:[10/250] Total Loss: 57.742409 GL_Loss: 0.901956 CRF_Loss: 56.840454\n",
      "[2022-02-17 13:05:29,149 - trainer - INFO] - Train Epoch:[23/100] Step:[20/250] Total Loss: 24.226122 GL_Loss: 0.801561 CRF_Loss: 23.424561\n",
      "[2022-02-17 13:05:43,358 - trainer - INFO] - Train Epoch:[23/100] Step:[30/250] Total Loss: 31.756598 GL_Loss: 0.990729 CRF_Loss: 30.765869\n",
      "[2022-02-17 13:05:57,779 - trainer - INFO] - Train Epoch:[23/100] Step:[40/250] Total Loss: 60.716019 GL_Loss: 0.763381 CRF_Loss: 59.952637\n",
      "[2022-02-17 13:06:11,648 - trainer - INFO] - Train Epoch:[23/100] Step:[50/250] Total Loss: 560.183228 GL_Loss: 0.478554 CRF_Loss: 559.704651\n",
      "[2022-02-17 13:06:30,621 - trainer - INFO] - [Step Validation] Epoch:[23/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.882716 | 0.910828 | 0.896552 | 0.910828 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.523148 | 0.300532 | 0.381757 | 0.300532 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.643636 | 0.563694 | 0.601019 | 0.563694 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.655914 | 0.663043 | 0.659459 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.662198 | 0.526092 | 0.58635  | 0.526092 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 13:06:46,437 - trainer - INFO] - Train Epoch:[23/100] Step:[60/250] Total Loss: 26.791548 GL_Loss: 0.741499 CRF_Loss: 26.050049\n",
      "[2022-02-17 13:07:00,992 - trainer - INFO] - Train Epoch:[23/100] Step:[70/250] Total Loss: 68.750717 GL_Loss: 0.815049 CRF_Loss: 67.935669\n",
      "[2022-02-17 13:07:15,428 - trainer - INFO] - Train Epoch:[23/100] Step:[80/250] Total Loss: 55.437813 GL_Loss: 0.691110 CRF_Loss: 54.746704\n",
      "[2022-02-17 13:07:29,389 - trainer - INFO] - Train Epoch:[23/100] Step:[90/250] Total Loss: 42.393089 GL_Loss: 1.500266 CRF_Loss: 40.892822\n",
      "[2022-02-17 13:07:43,536 - trainer - INFO] - Train Epoch:[23/100] Step:[100/250] Total Loss: 49.942078 GL_Loss: 1.537903 CRF_Loss: 48.404175\n",
      "[2022-02-17 13:08:02,565 - trainer - INFO] - [Step Validation] Epoch:[23/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.618357 | 0.340426 | 0.439108 | 0.340426 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.743902 | 0.388535 | 0.51046  | 0.388535 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.637363 | 0.630435 | 0.63388  | 0.630435 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.7264   | 0.483493 | 0.580563 | 0.483493 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 13:08:16,847 - trainer - INFO] - Train Epoch:[23/100] Step:[110/250] Total Loss: 17.917599 GL_Loss: 1.079586 CRF_Loss: 16.838013\n",
      "[2022-02-17 13:08:32,005 - trainer - INFO] - Train Epoch:[23/100] Step:[120/250] Total Loss: 23.143288 GL_Loss: 0.858010 CRF_Loss: 22.285278\n",
      "[2022-02-17 13:08:46,107 - trainer - INFO] - Train Epoch:[23/100] Step:[130/250] Total Loss: 59.639324 GL_Loss: 0.747845 CRF_Loss: 58.891479\n",
      "[2022-02-17 13:08:59,372 - trainer - INFO] - Train Epoch:[23/100] Step:[140/250] Total Loss: 55.768169 GL_Loss: 0.538434 CRF_Loss: 55.229736\n",
      "[2022-02-17 13:09:13,830 - trainer - INFO] - Train Epoch:[23/100] Step:[150/250] Total Loss: 41.189934 GL_Loss: 0.763541 CRF_Loss: 40.426392\n",
      "[2022-02-17 13:09:32,845 - trainer - INFO] - [Step Validation] Epoch:[23/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.873494 | 0.923567 | 0.897833 | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.592233 | 0.324468 | 0.419244 | 0.324468 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.720183 | 0.5      | 0.590226 | 0.5      |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.634409 | 0.641304 | 0.637838 | 0.641304 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.707174 | 0.514377 | 0.595561 | 0.514377 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 13:09:47,652 - trainer - INFO] - Train Epoch:[23/100] Step:[160/250] Total Loss: 125.085068 GL_Loss: 0.645857 CRF_Loss: 124.439209\n",
      "[2022-02-17 13:10:02,290 - trainer - INFO] - Train Epoch:[23/100] Step:[170/250] Total Loss: 59.459522 GL_Loss: 0.601613 CRF_Loss: 58.857910\n",
      "[2022-02-17 13:10:15,874 - trainer - INFO] - Train Epoch:[23/100] Step:[180/250] Total Loss: 30.128010 GL_Loss: 0.556781 CRF_Loss: 29.571228\n",
      "[2022-02-17 13:10:30,229 - trainer - INFO] - Train Epoch:[23/100] Step:[190/250] Total Loss: 97.654221 GL_Loss: 0.746384 CRF_Loss: 96.907837\n",
      "[2022-02-17 13:10:45,642 - trainer - INFO] - Train Epoch:[23/100] Step:[200/250] Total Loss: 43.415081 GL_Loss: 0.554118 CRF_Loss: 42.860962\n",
      "[2022-02-17 13:11:04,775 - trainer - INFO] - [Step Validation] Epoch:[23/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.860606 | 0.904459 | 0.881988 | 0.904459 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.525862 | 0.324468 | 0.401316 | 0.324468 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.724444 | 0.519108 | 0.604824 | 0.519108 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.655914 | 0.663043 | 0.659459 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.682517 | 0.519702 | 0.590085 | 0.519702 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 13:11:18,961 - trainer - INFO] - Train Epoch:[23/100] Step:[210/250] Total Loss: 84.247086 GL_Loss: 0.476699 CRF_Loss: 83.770386\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 13:11:32,988 - trainer - INFO] - Train Epoch:[23/100] Step:[220/250] Total Loss: 118.551117 GL_Loss: 0.386320 CRF_Loss: 118.164795\n",
      "[2022-02-17 13:11:46,662 - trainer - INFO] - Train Epoch:[23/100] Step:[230/250] Total Loss: 66.151260 GL_Loss: 0.679093 CRF_Loss: 65.472168\n",
      "[2022-02-17 13:12:01,027 - trainer - INFO] - Train Epoch:[23/100] Step:[240/250] Total Loss: 14.332478 GL_Loss: 0.991047 CRF_Loss: 13.341431\n",
      "[2022-02-17 13:12:14,944 - trainer - INFO] - Train Epoch:[23/100] Step:[250/250] Total Loss: 62.853970 GL_Loss: 0.647916 CRF_Loss: 62.206055\n",
      "[2022-02-17 13:12:34,231 - trainer - INFO] - [Step Validation] Epoch:[23/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.883436 | 0.917197 | 0.9      | 0.917197 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.518349 | 0.300532 | 0.380471 | 0.300532 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.686992 | 0.538217 | 0.603571 | 0.538217 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.626374 | 0.619565 | 0.622951 | 0.619565 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.672702 | 0.514377 | 0.582981 | 0.514377 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 13:12:53,426 - trainer - INFO] - [Epoch Validation] Epoch:[23/100] Total Loss: 67.893444 GL_Loss: 0.007707 CRF_Loss: 67.122725 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.883436 | 0.917197 | 0.9      | 0.917197 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.518349 | 0.300532 | 0.380471 | 0.300532 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.686992 | 0.538217 | 0.603571 | 0.538217 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.626374 | 0.619565 | 0.622951 | 0.619565 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.672702 | 0.514377 | 0.582981 | 0.514377 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 13:13:08,409 - trainer - INFO] - Train Epoch:[24/100] Step:[10/250] Total Loss: 34.029655 GL_Loss: 0.611688 CRF_Loss: 33.417969\n",
      "[2022-02-17 13:13:21,986 - trainer - INFO] - Train Epoch:[24/100] Step:[20/250] Total Loss: 15.684216 GL_Loss: 0.589977 CRF_Loss: 15.094238\n",
      "[2022-02-17 13:13:36,148 - trainer - INFO] - Train Epoch:[24/100] Step:[30/250] Total Loss: 17.593672 GL_Loss: 0.861494 CRF_Loss: 16.732178\n",
      "[2022-02-17 13:13:51,331 - trainer - INFO] - Train Epoch:[24/100] Step:[40/250] Total Loss: 32.274090 GL_Loss: 0.927166 CRF_Loss: 31.346924\n",
      "[2022-02-17 13:14:05,387 - trainer - INFO] - Train Epoch:[24/100] Step:[50/250] Total Loss: 52.889439 GL_Loss: 0.939977 CRF_Loss: 51.949463\n",
      "[2022-02-17 13:14:24,468 - trainer - INFO] - [Step Validation] Epoch:[24/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.852071 | 0.917197 | 0.883436 | 0.917197 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.570796 | 0.343085 | 0.428571 | 0.343085 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.627986 | 0.585987 | 0.60626  | 0.585987 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.641304 | 0.641304 | 0.641304 | 0.641304 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.661538 | 0.549521 | 0.600349 | 0.549521 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 13:14:26,553 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 13:14:40,051 - trainer - INFO] - Train Epoch:[24/100] Step:[60/250] Total Loss: 20.675552 GL_Loss: 0.461807 CRF_Loss: 20.213745\n",
      "[2022-02-17 13:14:53,745 - trainer - INFO] - Train Epoch:[24/100] Step:[70/250] Total Loss: 50.033108 GL_Loss: 0.569607 CRF_Loss: 49.463501\n",
      "[2022-02-17 13:15:08,429 - trainer - INFO] - Train Epoch:[24/100] Step:[80/250] Total Loss: 22.049648 GL_Loss: 0.725064 CRF_Loss: 21.324585\n",
      "[2022-02-17 13:15:23,493 - trainer - INFO] - Train Epoch:[24/100] Step:[90/250] Total Loss: 26.433561 GL_Loss: 0.580413 CRF_Loss: 25.853149\n",
      "[2022-02-17 13:15:37,721 - trainer - INFO] - Train Epoch:[24/100] Step:[100/250] Total Loss: 118.398834 GL_Loss: 1.089632 CRF_Loss: 117.309204\n",
      "[2022-02-17 13:15:56,970 - trainer - INFO] - [Step Validation] Epoch:[24/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.820809 | 0.904459 | 0.860606 | 0.904459 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.566964 | 0.337766 | 0.423333 | 0.337766 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.61753  | 0.493631 | 0.548673 | 0.493631 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.6875   | 0.597826 | 0.639535 | 0.597826 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.657967 | 0.510117 | 0.574685 | 0.510117 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 13:16:11,831 - trainer - INFO] - Train Epoch:[24/100] Step:[110/250] Total Loss: 35.804203 GL_Loss: 4.158207 CRF_Loss: 31.645996\n",
      "[2022-02-17 13:16:26,378 - trainer - INFO] - Train Epoch:[24/100] Step:[120/250] Total Loss: 83.728577 GL_Loss: 2.777529 CRF_Loss: 80.951050\n",
      "[2022-02-17 13:16:40,884 - trainer - INFO] - Train Epoch:[24/100] Step:[130/250] Total Loss: 62.953678 GL_Loss: 3.658147 CRF_Loss: 59.295532\n",
      "[2022-02-17 13:16:54,247 - trainer - INFO] - Train Epoch:[24/100] Step:[140/250] Total Loss: 92.431007 GL_Loss: 5.545023 CRF_Loss: 86.885986\n",
      "[2022-02-17 13:17:08,958 - trainer - INFO] - Train Epoch:[24/100] Step:[150/250] Total Loss: 58.728600 GL_Loss: 3.327722 CRF_Loss: 55.400879\n",
      "[2022-02-17 13:17:27,990 - trainer - INFO] - [Step Validation] Epoch:[24/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.801205 | 0.847134 | 0.823529 | 0.847134 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.657895 | 0.332447 | 0.441696 | 0.332447 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.608527 | 0.5      | 0.548951 | 0.5      |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.581633 | 0.619565 | 0.6      | 0.619565 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.662921 | 0.502662 | 0.571775 | 0.502662 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 13:17:42,140 - trainer - INFO] - Train Epoch:[24/100] Step:[160/250] Total Loss: 220.509171 GL_Loss: 1.235248 CRF_Loss: 219.273926\n",
      "[2022-02-17 13:17:55,798 - trainer - INFO] - Train Epoch:[24/100] Step:[170/250] Total Loss: 331.326721 GL_Loss: 0.429555 CRF_Loss: 330.897156\n",
      "[2022-02-17 13:18:10,186 - trainer - INFO] - Train Epoch:[24/100] Step:[180/250] Total Loss: 113.202911 GL_Loss: 1.127041 CRF_Loss: 112.075867\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 13:18:24,499 - trainer - INFO] - Train Epoch:[24/100] Step:[190/250] Total Loss: 80.636826 GL_Loss: 0.817308 CRF_Loss: 79.819519\n",
      "[2022-02-17 13:18:39,666 - trainer - INFO] - Train Epoch:[24/100] Step:[200/250] Total Loss: 165.137344 GL_Loss: 11.006479 CRF_Loss: 154.130859\n",
      "[2022-02-17 13:18:58,837 - trainer - INFO] - [Step Validation] Epoch:[24/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.238095 | 0.318471 | 0.27248  | 0.318471 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.234513 | 0.140957 | 0.17608  | 0.140957 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.550388 | 0.226115 | 0.320542 | 0.226115 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.5      | 0.576087 | 0.535354 | 0.576087 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.338301 | 0.241747 | 0.281988 | 0.241747 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 13:19:11,216 - trainer - INFO] - Train Epoch:[24/100] Step:[210/250] Total Loss: 68.580231 GL_Loss: 8.498141 CRF_Loss: 60.082092\n",
      "[2022-02-17 13:19:26,581 - trainer - INFO] - Train Epoch:[24/100] Step:[220/250] Total Loss: 87.035912 GL_Loss: 5.183130 CRF_Loss: 81.852783\n",
      "[2022-02-17 13:19:40,661 - trainer - INFO] - Train Epoch:[24/100] Step:[230/250] Total Loss: 98.010162 GL_Loss: 1.999054 CRF_Loss: 96.011108\n",
      "[2022-02-17 13:19:54,610 - trainer - INFO] - Train Epoch:[24/100] Step:[240/250] Total Loss: 350.054138 GL_Loss: 1.067576 CRF_Loss: 348.986572\n",
      "[2022-02-17 13:20:08,925 - trainer - INFO] - Train Epoch:[24/100] Step:[250/250] Total Loss: 74.043312 GL_Loss: 1.268652 CRF_Loss: 72.774658\n",
      "[2022-02-17 13:20:28,118 - trainer - INFO] - [Step Validation] Epoch:[24/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.720238 | 0.770701 | 0.744615 | 0.770701 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.418269 | 0.231383 | 0.297945 | 0.231383 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.674528 | 0.455414 | 0.543726 | 0.455414 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.578947 | 0.597826 | 0.588235 | 0.597826 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.594436 | 0.432375 | 0.500617 | 0.432375 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 13:20:47,466 - trainer - INFO] - [Epoch Validation] Epoch:[24/100] Total Loss: 103.813287 GL_Loss: 0.022571 CRF_Loss: 101.556190 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.720238 | 0.770701 | 0.744615 | 0.770701 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.418269 | 0.231383 | 0.297945 | 0.231383 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.674528 | 0.455414 | 0.543726 | 0.455414 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.578947 | 0.597826 | 0.588235 | 0.597826 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.594436 | 0.432375 | 0.500617 | 0.432375 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 13:21:03,038 - trainer - INFO] - Train Epoch:[25/100] Step:[10/250] Total Loss: 26.245701 GL_Loss: 2.481541 CRF_Loss: 23.764160\n",
      "[2022-02-17 13:21:17,626 - trainer - INFO] - Train Epoch:[25/100] Step:[20/250] Total Loss: 44.872765 GL_Loss: 0.599326 CRF_Loss: 44.273438\n",
      "[2022-02-17 13:21:31,703 - trainer - INFO] - Train Epoch:[25/100] Step:[30/250] Total Loss: 67.218086 GL_Loss: 0.551151 CRF_Loss: 66.666931\n",
      "[2022-02-17 13:21:46,478 - trainer - INFO] - Train Epoch:[25/100] Step:[40/250] Total Loss: 122.050148 GL_Loss: 1.354837 CRF_Loss: 120.695312\n",
      "[2022-02-17 13:22:00,198 - trainer - INFO] - Train Epoch:[25/100] Step:[50/250] Total Loss: 129.919189 GL_Loss: 1.036864 CRF_Loss: 128.882324\n",
      "[2022-02-17 13:22:19,270 - trainer - INFO] - [Step Validation] Epoch:[25/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.785714 | 0.840764 | 0.812308 | 0.840764 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.438095 | 0.244681 | 0.313993 | 0.244681 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.658009 | 0.484076 | 0.557798 | 0.484076 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.54717  | 0.630435 | 0.585859 | 0.630435 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.606993 | 0.462194 | 0.524788 | 0.462194 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 13:22:33,369 - trainer - INFO] - Train Epoch:[25/100] Step:[60/250] Total Loss: 52.681160 GL_Loss: 0.620125 CRF_Loss: 52.061035\n",
      "[2022-02-17 13:22:46,871 - trainer - INFO] - Train Epoch:[25/100] Step:[70/250] Total Loss: 187.463272 GL_Loss: 1.590714 CRF_Loss: 185.872559\n",
      "[2022-02-17 13:23:01,283 - trainer - INFO] - Train Epoch:[25/100] Step:[80/250] Total Loss: 85.727707 GL_Loss: 1.545336 CRF_Loss: 84.182373\n",
      "[2022-02-17 13:23:15,058 - trainer - INFO] - Train Epoch:[25/100] Step:[90/250] Total Loss: 54.543098 GL_Loss: 1.162118 CRF_Loss: 53.380981\n",
      "[2022-02-17 13:23:28,980 - trainer - INFO] - Train Epoch:[25/100] Step:[100/250] Total Loss: 80.026459 GL_Loss: 1.658908 CRF_Loss: 78.367554\n",
      "[2022-02-17 13:23:47,970 - trainer - INFO] - [Step Validation] Epoch:[25/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.725714 | 0.808917 | 0.76506  | 0.808917 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.606061 | 0.319149 | 0.418118 | 0.319149 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.732824 | 0.305732 | 0.431461 | 0.305732 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.704545 | 0.673913 | 0.688889 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.684122 | 0.43131  | 0.529066 | 0.43131  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 13:24:03,428 - trainer - INFO] - Train Epoch:[25/100] Step:[110/250] Total Loss: 41.743710 GL_Loss: 0.891415 CRF_Loss: 40.852295\n",
      "[2022-02-17 13:24:17,834 - trainer - INFO] - Train Epoch:[25/100] Step:[120/250] Total Loss: 53.257668 GL_Loss: 0.963965 CRF_Loss: 52.293701\n",
      "[2022-02-17 13:24:32,437 - trainer - INFO] - Train Epoch:[25/100] Step:[130/250] Total Loss: 31.302349 GL_Loss: 0.558209 CRF_Loss: 30.744141\n",
      "[2022-02-17 13:24:45,965 - trainer - INFO] - Train Epoch:[25/100] Step:[140/250] Total Loss: 44.865623 GL_Loss: 0.783835 CRF_Loss: 44.081787\n",
      "[2022-02-17 13:25:00,424 - trainer - INFO] - Train Epoch:[25/100] Step:[150/250] Total Loss: 71.868118 GL_Loss: 1.316788 CRF_Loss: 70.551331\n",
      "[2022-02-17 13:25:19,486 - trainer - INFO] - [Step Validation] Epoch:[25/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.838509 | 0.859873 | 0.849057 | 0.859873 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.509804 | 0.345745 | 0.412044 | 0.345745 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.655039 | 0.538217 | 0.590909 | 0.538217 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.7      | 0.684783 | 0.692308 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.650524 | 0.529286 | 0.583676 | 0.529286 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 13:25:33,960 - trainer - INFO] - Train Epoch:[25/100] Step:[160/250] Total Loss: 412.796265 GL_Loss: 0.629948 CRF_Loss: 412.166321\n",
      "[2022-02-17 13:25:48,159 - trainer - INFO] - Train Epoch:[25/100] Step:[170/250] Total Loss: 128.850128 GL_Loss: 0.606721 CRF_Loss: 128.243408\n",
      "[2022-02-17 13:26:02,828 - trainer - INFO] - Train Epoch:[25/100] Step:[180/250] Total Loss: 107.001213 GL_Loss: 0.653556 CRF_Loss: 106.347656\n",
      "[2022-02-17 13:26:16,917 - trainer - INFO] - Train Epoch:[25/100] Step:[190/250] Total Loss: 41.935074 GL_Loss: 0.544573 CRF_Loss: 41.390503\n",
      "[2022-02-17 13:26:31,440 - trainer - INFO] - Train Epoch:[25/100] Step:[200/250] Total Loss: 77.179611 GL_Loss: 0.640426 CRF_Loss: 76.539185\n",
      "[2022-02-17 13:26:52,291 - trainer - INFO] - [Step Validation] Epoch:[25/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.831395 | 0.910828 | 0.869301 | 0.910828 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.534884 | 0.305851 | 0.389171 | 0.305851 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.632302 | 0.585987 | 0.608264 | 0.585987 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.707865 | 0.684783 | 0.696133 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.658409 | 0.537806 | 0.592028 | 0.537806 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 13:27:07,164 - trainer - INFO] - Train Epoch:[25/100] Step:[210/250] Total Loss: 64.162971 GL_Loss: 0.610969 CRF_Loss: 63.552002\n",
      "[2022-02-17 13:27:22,073 - trainer - INFO] - Train Epoch:[25/100] Step:[220/250] Total Loss: 18.480665 GL_Loss: 0.744704 CRF_Loss: 17.735962\n",
      "[2022-02-17 13:27:36,825 - trainer - INFO] - Train Epoch:[25/100] Step:[230/250] Total Loss: 67.527657 GL_Loss: 0.688791 CRF_Loss: 66.838867\n",
      "[2022-02-17 13:27:52,232 - trainer - INFO] - Train Epoch:[25/100] Step:[240/250] Total Loss: 49.574402 GL_Loss: 0.530702 CRF_Loss: 49.043701\n",
      "[2022-02-17 13:28:06,583 - trainer - INFO] - Train Epoch:[25/100] Step:[250/250] Total Loss: 51.353737 GL_Loss: 0.538309 CRF_Loss: 50.815430\n",
      "[2022-02-17 13:28:25,626 - trainer - INFO] - [Step Validation] Epoch:[25/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.73743  | 0.840764 | 0.785714 | 0.840764 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.542986 | 0.319149 | 0.40201  | 0.319149 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.678571 | 0.544586 | 0.60424  | 0.544586 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.709302 | 0.663043 | 0.685393 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.655827 | 0.515442 | 0.577221 | 0.515442 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 13:28:44,695 - trainer - INFO] - [Epoch Validation] Epoch:[25/100] Total Loss: 89.629144 GL_Loss: 0.009446 CRF_Loss: 88.684527 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.73743  | 0.840764 | 0.785714 | 0.840764 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.542986 | 0.319149 | 0.40201  | 0.319149 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.678571 | 0.544586 | 0.60424  | 0.544586 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.709302 | 0.663043 | 0.685393 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.655827 | 0.515442 | 0.577221 | 0.515442 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 13:28:58,567 - trainer - INFO] - Train Epoch:[26/100] Step:[10/250] Total Loss: 59.463024 GL_Loss: 0.479869 CRF_Loss: 58.983154\n",
      "[2022-02-17 13:29:13,366 - trainer - INFO] - Train Epoch:[26/100] Step:[20/250] Total Loss: 47.210342 GL_Loss: 0.467179 CRF_Loss: 46.743164\n",
      "[2022-02-17 13:29:27,152 - trainer - INFO] - Train Epoch:[26/100] Step:[30/250] Total Loss: 24.684015 GL_Loss: 1.153010 CRF_Loss: 23.531006\n",
      "[2022-02-17 13:29:41,518 - trainer - INFO] - Train Epoch:[26/100] Step:[40/250] Total Loss: 40.038559 GL_Loss: 1.189560 CRF_Loss: 38.848999\n",
      "[2022-02-17 13:29:55,736 - trainer - INFO] - Train Epoch:[26/100] Step:[50/250] Total Loss: 30.112076 GL_Loss: 0.729263 CRF_Loss: 29.382812\n",
      "[2022-02-17 13:30:16,401 - trainer - INFO] - [Step Validation] Epoch:[26/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.836257 | 0.910828 | 0.871951 | 0.910828 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.55157  | 0.327128 | 0.410684 | 0.327128 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.669291 | 0.541401 | 0.598592 | 0.541401 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.645833 | 0.673913 | 0.659574 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.669355 | 0.530351 | 0.5918   | 0.530351 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 13:30:30,681 - trainer - INFO] - Train Epoch:[26/100] Step:[60/250] Total Loss: 68.497696 GL_Loss: 0.399304 CRF_Loss: 68.098389\n",
      "[2022-02-17 13:30:44,872 - trainer - INFO] - Train Epoch:[26/100] Step:[70/250] Total Loss: 32.709328 GL_Loss: 0.452860 CRF_Loss: 32.256470\n",
      "[2022-02-17 13:30:59,305 - trainer - INFO] - Train Epoch:[26/100] Step:[80/250] Total Loss: 67.369057 GL_Loss: 0.522132 CRF_Loss: 66.846924\n",
      "[2022-02-17 13:31:13,227 - trainer - INFO] - Train Epoch:[26/100] Step:[90/250] Total Loss: 74.596680 GL_Loss: 0.478269 CRF_Loss: 74.118408\n",
      "[2022-02-17 13:31:27,522 - trainer - INFO] - Train Epoch:[26/100] Step:[100/250] Total Loss: 34.324120 GL_Loss: 0.399314 CRF_Loss: 33.924805\n",
      "[2022-02-17 13:31:46,775 - trainer - INFO] - [Step Validation] Epoch:[26/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.862275 | 0.917197 | 0.888889 | 0.917197 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.572727 | 0.335106 | 0.422819 | 0.335106 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.660448 | 0.563694 | 0.608247 | 0.563694 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.625    | 0.652174 | 0.638298 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.6751   | 0.539936 | 0.6      | 0.539936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 13:32:01,274 - trainer - INFO] - Train Epoch:[26/100] Step:[110/250] Total Loss: 53.182705 GL_Loss: 0.297940 CRF_Loss: 52.884766\n",
      "[2022-02-17 13:32:15,565 - trainer - INFO] - Train Epoch:[26/100] Step:[120/250] Total Loss: 36.689598 GL_Loss: 0.374902 CRF_Loss: 36.314697\n",
      "[2022-02-17 13:32:30,521 - trainer - INFO] - Train Epoch:[26/100] Step:[130/250] Total Loss: 29.711649 GL_Loss: 0.506815 CRF_Loss: 29.204834\n",
      "[2022-02-17 13:32:44,703 - trainer - INFO] - Train Epoch:[26/100] Step:[140/250] Total Loss: 100.509697 GL_Loss: 0.555595 CRF_Loss: 99.954102\n",
      "[2022-02-17 13:32:59,454 - trainer - INFO] - Train Epoch:[26/100] Step:[150/250] Total Loss: 86.386635 GL_Loss: 0.556804 CRF_Loss: 85.829834\n",
      "[2022-02-17 13:33:18,523 - trainer - INFO] - [Step Validation] Epoch:[26/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.852071 | 0.917197 | 0.883436 | 0.917197 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.509091 | 0.297872 | 0.375839 | 0.297872 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.742857 | 0.414013 | 0.531697 | 0.414013 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.635417 | 0.663043 | 0.648936 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.677273 | 0.476038 | 0.559099 | 0.476038 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 13:33:32,196 - trainer - INFO] - Train Epoch:[26/100] Step:[160/250] Total Loss: 606.255554 GL_Loss: 0.725851 CRF_Loss: 605.529724\n",
      "[2022-02-17 13:33:46,601 - trainer - INFO] - Train Epoch:[26/100] Step:[170/250] Total Loss: 25.039913 GL_Loss: 0.573971 CRF_Loss: 24.465942\n",
      "[2022-02-17 13:34:03,174 - trainer - INFO] - Train Epoch:[26/100] Step:[180/250] Total Loss: 49.618999 GL_Loss: 0.531354 CRF_Loss: 49.087646\n",
      "[2022-02-17 13:34:18,155 - trainer - INFO] - Train Epoch:[26/100] Step:[190/250] Total Loss: 56.374935 GL_Loss: 1.268978 CRF_Loss: 55.105957\n",
      "[2022-02-17 13:34:32,339 - trainer - INFO] - Train Epoch:[26/100] Step:[200/250] Total Loss: 99.123596 GL_Loss: 7.505189 CRF_Loss: 91.618408\n",
      "[2022-02-17 13:34:51,415 - trainer - INFO] - [Step Validation] Epoch:[26/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.79661  | 0.898089 | 0.844311 | 0.898089 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.473077 | 0.327128 | 0.386792 | 0.327128 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.713115 | 0.27707  | 0.399083 | 0.27707  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.610526 | 0.630435 | 0.620321 | 0.630435 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.625382 | 0.43557  | 0.513497 | 0.43557  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 13:35:05,953 - trainer - INFO] - Train Epoch:[26/100] Step:[210/250] Total Loss: 34.468285 GL_Loss: 5.563621 CRF_Loss: 28.904663\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 13:35:20,254 - trainer - INFO] - Train Epoch:[26/100] Step:[220/250] Total Loss: 50.246758 GL_Loss: 1.546074 CRF_Loss: 48.700684\n",
      "[2022-02-17 13:35:37,510 - trainer - INFO] - Train Epoch:[26/100] Step:[230/250] Total Loss: 91.750374 GL_Loss: 1.871470 CRF_Loss: 89.878906\n",
      "[2022-02-17 13:35:52,247 - trainer - INFO] - Train Epoch:[26/100] Step:[240/250] Total Loss: 43.307201 GL_Loss: 0.835154 CRF_Loss: 42.472046\n",
      "[2022-02-17 13:36:06,946 - trainer - INFO] - Train Epoch:[26/100] Step:[250/250] Total Loss: 84.739494 GL_Loss: 1.450062 CRF_Loss: 83.289429\n",
      "[2022-02-17 13:36:26,155 - trainer - INFO] - [Step Validation] Epoch:[26/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.80814  | 0.88535  | 0.844985 | 0.88535  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.592437 | 0.375    | 0.459283 | 0.375    |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.586207 | 0.595541 | 0.590837 | 0.595541 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.733333 | 0.717391 | 0.725275 | 0.717391 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.650794 | 0.567625 | 0.606371 | 0.567625 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 13:36:28,271 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 13:36:47,471 - trainer - INFO] - [Epoch Validation] Epoch:[26/100] Total Loss: 82.361053 GL_Loss: 0.012686 CRF_Loss: 81.092465 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.80814  | 0.88535  | 0.844985 | 0.88535  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.592437 | 0.375    | 0.459283 | 0.375    |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.586207 | 0.595541 | 0.590837 | 0.595541 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.733333 | 0.717391 | 0.725275 | 0.717391 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.650794 | 0.567625 | 0.606371 | 0.567625 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 13:37:02,867 - trainer - INFO] - Train Epoch:[27/100] Step:[10/250] Total Loss: 76.706276 GL_Loss: 1.689305 CRF_Loss: 75.016968\n",
      "[2022-02-17 13:37:18,136 - trainer - INFO] - Train Epoch:[27/100] Step:[20/250] Total Loss: 28.352169 GL_Loss: 0.520503 CRF_Loss: 27.831665\n",
      "[2022-02-17 13:37:33,690 - trainer - INFO] - Train Epoch:[27/100] Step:[30/250] Total Loss: 64.655861 GL_Loss: 1.178933 CRF_Loss: 63.476929\n",
      "[2022-02-17 13:37:49,409 - trainer - INFO] - Train Epoch:[27/100] Step:[40/250] Total Loss: 51.201107 GL_Loss: 2.911068 CRF_Loss: 48.290039\n",
      "[2022-02-17 13:38:05,422 - trainer - INFO] - Train Epoch:[27/100] Step:[50/250] Total Loss: 54.990593 GL_Loss: 0.942558 CRF_Loss: 54.048035\n",
      "[2022-02-17 13:38:24,460 - trainer - INFO] - [Step Validation] Epoch:[27/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.837349 | 0.88535  | 0.860681 | 0.88535  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.60262  | 0.367021 | 0.456198 | 0.367021 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.631387 | 0.550955 | 0.588435 | 0.550955 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.6      | 0.652174 | 0.625    | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.663199 | 0.543131 | 0.59719  | 0.543131 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 13:38:39,995 - trainer - INFO] - Train Epoch:[27/100] Step:[60/250] Total Loss: 26.430933 GL_Loss: 0.616357 CRF_Loss: 25.814575\n",
      "[2022-02-17 13:38:55,171 - trainer - INFO] - Train Epoch:[27/100] Step:[70/250] Total Loss: 16.336493 GL_Loss: 0.559515 CRF_Loss: 15.776978\n",
      "[2022-02-17 13:39:09,833 - trainer - INFO] - Train Epoch:[27/100] Step:[80/250] Total Loss: 17.438383 GL_Loss: 0.612211 CRF_Loss: 16.826172\n",
      "[2022-02-17 13:39:24,352 - trainer - INFO] - Train Epoch:[27/100] Step:[90/250] Total Loss: 140.667557 GL_Loss: 0.638499 CRF_Loss: 140.029053\n",
      "[2022-02-17 13:39:38,592 - trainer - INFO] - Train Epoch:[27/100] Step:[100/250] Total Loss: 44.649368 GL_Loss: 0.504716 CRF_Loss: 44.144653\n",
      "[2022-02-17 13:39:57,849 - trainer - INFO] - [Step Validation] Epoch:[27/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.84472  | 0.866242 | 0.855346 | 0.866242 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.562771 | 0.345745 | 0.428336 | 0.345745 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.522788 | 0.621019 | 0.567686 | 0.621019 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.642105 | 0.663043 | 0.652406 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.606977 | 0.555911 | 0.580322 | 0.555911 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 13:40:11,810 - trainer - INFO] - Train Epoch:[27/100] Step:[110/250] Total Loss: 42.716873 GL_Loss: 1.588456 CRF_Loss: 41.128418\n",
      "[2022-02-17 13:40:26,330 - trainer - INFO] - Train Epoch:[27/100] Step:[120/250] Total Loss: 23.721964 GL_Loss: 0.711099 CRF_Loss: 23.010864\n",
      "[2022-02-17 13:40:41,673 - trainer - INFO] - Train Epoch:[27/100] Step:[130/250] Total Loss: 34.075314 GL_Loss: 0.458736 CRF_Loss: 33.616577\n",
      "[2022-02-17 13:40:56,332 - trainer - INFO] - Train Epoch:[27/100] Step:[140/250] Total Loss: 22.920485 GL_Loss: 0.382033 CRF_Loss: 22.538452\n",
      "[2022-02-17 13:41:10,258 - trainer - INFO] - Train Epoch:[27/100] Step:[150/250] Total Loss: 25.713146 GL_Loss: 0.396740 CRF_Loss: 25.316406\n",
      "[2022-02-17 13:41:29,200 - trainer - INFO] - [Step Validation] Epoch:[27/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.786127 | 0.866242 | 0.824242 | 0.866242 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.535971 | 0.396277 | 0.455657 | 0.396277 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.70892  | 0.480892 | 0.573055 | 0.480892 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.625    | 0.652174 | 0.638298 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.652632 | 0.528222 | 0.583873 | 0.528222 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 13:41:43,322 - trainer - INFO] - Train Epoch:[27/100] Step:[160/250] Total Loss: 17.953194 GL_Loss: 0.492866 CRF_Loss: 17.460327\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 13:41:58,808 - trainer - INFO] - Train Epoch:[27/100] Step:[170/250] Total Loss: 19.750315 GL_Loss: 0.913279 CRF_Loss: 18.837036\n",
      "[2022-02-17 13:42:14,400 - trainer - INFO] - Train Epoch:[27/100] Step:[180/250] Total Loss: 49.233006 GL_Loss: 1.201999 CRF_Loss: 48.031006\n",
      "[2022-02-17 13:42:29,135 - trainer - INFO] - Train Epoch:[27/100] Step:[190/250] Total Loss: 20.781570 GL_Loss: 1.076125 CRF_Loss: 19.705444\n",
      "[2022-02-17 13:42:43,357 - trainer - INFO] - Train Epoch:[27/100] Step:[200/250] Total Loss: 62.053349 GL_Loss: 0.966433 CRF_Loss: 61.086914\n",
      "[2022-02-17 13:43:02,482 - trainer - INFO] - [Step Validation] Epoch:[27/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.823171 | 0.859873 | 0.841121 | 0.859873 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.626728 | 0.361702 | 0.458685 | 0.361702 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.838095 | 0.280255 | 0.420048 | 0.280255 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.651685 | 0.630435 | 0.640884 | 0.630435 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.725217 | 0.444089 | 0.550859 | 0.444089 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 13:43:16,364 - trainer - INFO] - Train Epoch:[27/100] Step:[210/250] Total Loss: 25.890457 GL_Loss: 1.384842 CRF_Loss: 24.505615\n",
      "[2022-02-17 13:43:30,648 - trainer - INFO] - Train Epoch:[27/100] Step:[220/250] Total Loss: 35.925358 GL_Loss: 0.502628 CRF_Loss: 35.422729\n",
      "[2022-02-17 13:43:45,327 - trainer - INFO] - Train Epoch:[27/100] Step:[230/250] Total Loss: 43.525459 GL_Loss: 0.636545 CRF_Loss: 42.888916\n",
      "[2022-02-17 13:43:59,771 - trainer - INFO] - Train Epoch:[27/100] Step:[240/250] Total Loss: 64.352173 GL_Loss: 0.642582 CRF_Loss: 63.709595\n",
      "[2022-02-17 13:44:13,575 - trainer - INFO] - Train Epoch:[27/100] Step:[250/250] Total Loss: 48.017349 GL_Loss: 1.141862 CRF_Loss: 46.875488\n",
      "[2022-02-17 13:44:32,621 - trainer - INFO] - [Step Validation] Epoch:[27/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.871951 | 0.910828 | 0.890966 | 0.910828 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.563107 | 0.308511 | 0.398625 | 0.308511 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.556291 | 0.535032 | 0.545455 | 0.535032 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.735632 | 0.695652 | 0.715084 | 0.695652 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.646904 | 0.522897 | 0.578327 | 0.522897 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 13:44:51,805 - trainer - INFO] - [Epoch Validation] Epoch:[27/100] Total Loss: 72.951993 GL_Loss: 0.008767 CRF_Loss: 72.075309 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.871951 | 0.910828 | 0.890966 | 0.910828 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.563107 | 0.308511 | 0.398625 | 0.308511 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.556291 | 0.535032 | 0.545455 | 0.535032 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.735632 | 0.695652 | 0.715084 | 0.695652 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.646904 | 0.522897 | 0.578327 | 0.522897 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 13:45:06,883 - trainer - INFO] - Train Epoch:[28/100] Step:[10/250] Total Loss: 253.021927 GL_Loss: 1.255820 CRF_Loss: 251.766113\n",
      "[2022-02-17 13:45:21,408 - trainer - INFO] - Train Epoch:[28/100] Step:[20/250] Total Loss: 45.299335 GL_Loss: 0.870502 CRF_Loss: 44.428833\n",
      "[2022-02-17 13:45:34,658 - trainer - INFO] - Train Epoch:[28/100] Step:[30/250] Total Loss: 44.089214 GL_Loss: 0.307841 CRF_Loss: 43.781372\n",
      "[2022-02-17 13:45:48,381 - trainer - INFO] - Train Epoch:[28/100] Step:[40/250] Total Loss: 26.884916 GL_Loss: 0.601713 CRF_Loss: 26.283203\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 13:46:02,339 - trainer - INFO] - Train Epoch:[28/100] Step:[50/250] Total Loss: 39.526047 GL_Loss: 0.365768 CRF_Loss: 39.160278\n",
      "[2022-02-17 13:46:21,343 - trainer - INFO] - [Step Validation] Epoch:[28/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.850299 | 0.904459 | 0.876543 | 0.904459 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.622881 | 0.390957 | 0.480392 | 0.390957 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.641026 | 0.477707 | 0.547445 | 0.477707 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.666667 | 0.652174 | 0.659341 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.686382 | 0.531416 | 0.59904  | 0.531416 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 13:46:37,777 - trainer - INFO] - Train Epoch:[28/100] Step:[60/250] Total Loss: 26.807505 GL_Loss: 0.459848 CRF_Loss: 26.347656\n",
      "[2022-02-17 13:46:51,613 - trainer - INFO] - Train Epoch:[28/100] Step:[70/250] Total Loss: 30.697760 GL_Loss: 0.386479 CRF_Loss: 30.311279\n",
      "[2022-02-17 13:47:05,757 - trainer - INFO] - Train Epoch:[28/100] Step:[80/250] Total Loss: 18.462349 GL_Loss: 0.614449 CRF_Loss: 17.847900\n",
      "[2022-02-17 13:47:20,418 - trainer - INFO] - Train Epoch:[28/100] Step:[90/250] Total Loss: 30.189577 GL_Loss: 0.639894 CRF_Loss: 29.549683\n",
      "[2022-02-17 13:47:34,824 - trainer - INFO] - Train Epoch:[28/100] Step:[100/250] Total Loss: 68.878799 GL_Loss: 0.502826 CRF_Loss: 68.375977\n",
      "[2022-02-17 13:47:53,952 - trainer - INFO] - [Step Validation] Epoch:[28/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.86747  | 0.917197 | 0.891641 | 0.917197 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.588235 | 0.345745 | 0.435511 | 0.345745 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.716418 | 0.458599 | 0.559223 | 0.458599 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.623656 | 0.630435 | 0.627027 | 0.630435 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.698972 | 0.506922 | 0.587654 | 0.506922 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 13:48:09,093 - trainer - INFO] - Train Epoch:[28/100] Step:[110/250] Total Loss: 80.974251 GL_Loss: 0.373540 CRF_Loss: 80.600708\n",
      "[2022-02-17 13:48:23,256 - trainer - INFO] - Train Epoch:[28/100] Step:[120/250] Total Loss: 27.552755 GL_Loss: 0.302634 CRF_Loss: 27.250122\n",
      "[2022-02-17 13:48:37,613 - trainer - INFO] - Train Epoch:[28/100] Step:[130/250] Total Loss: 28.710173 GL_Loss: 0.772307 CRF_Loss: 27.937866\n",
      "[2022-02-17 13:48:51,092 - trainer - INFO] - Train Epoch:[28/100] Step:[140/250] Total Loss: 52.482609 GL_Loss: 0.733098 CRF_Loss: 51.749512\n",
      "[2022-02-17 13:49:04,421 - trainer - INFO] - Train Epoch:[28/100] Step:[150/250] Total Loss: 63.875809 GL_Loss: 1.660355 CRF_Loss: 62.215454\n",
      "[2022-02-17 13:49:23,573 - trainer - INFO] - [Step Validation] Epoch:[28/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.842424 | 0.88535  | 0.863354 | 0.88535  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.649123 | 0.393617 | 0.490066 | 0.393617 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.597523 | 0.61465  | 0.605965 | 0.61465  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.569892 | 0.576087 | 0.572973 | 0.576087 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.658838 | 0.567625 | 0.60984  | 0.567625 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 13:49:25,765 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 13:49:39,957 - trainer - INFO] - Train Epoch:[28/100] Step:[160/250] Total Loss: 73.136749 GL_Loss: 2.296658 CRF_Loss: 70.840088\n",
      "[2022-02-17 13:49:53,924 - trainer - INFO] - Train Epoch:[28/100] Step:[170/250] Total Loss: 67.092369 GL_Loss: 1.321861 CRF_Loss: 65.770508\n",
      "[2022-02-17 13:50:08,400 - trainer - INFO] - Train Epoch:[28/100] Step:[180/250] Total Loss: 101.310646 GL_Loss: 1.186378 CRF_Loss: 100.124268\n",
      "[2022-02-17 13:50:23,735 - trainer - INFO] - Train Epoch:[28/100] Step:[190/250] Total Loss: 524.085815 GL_Loss: 2.089124 CRF_Loss: 521.996704\n",
      "[2022-02-17 13:50:37,605 - trainer - INFO] - Train Epoch:[28/100] Step:[200/250] Total Loss: 105.052963 GL_Loss: 2.910267 CRF_Loss: 102.142700\n",
      "[2022-02-17 13:50:56,765 - trainer - INFO] - [Step Validation] Epoch:[28/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.679739 | 0.66242  | 0.670968 | 0.66242  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.319527 | 0.143617 | 0.198165 | 0.143617 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.622318 | 0.461783 | 0.530165 | 0.461783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.415929 | 0.51087  | 0.458537 | 0.51087  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.523952 | 0.372737 | 0.435594 | 0.372737 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 13:51:11,415 - trainer - INFO] - Train Epoch:[28/100] Step:[210/250] Total Loss: 39.846634 GL_Loss: 1.902052 CRF_Loss: 37.944580\n",
      "[2022-02-17 13:51:25,152 - trainer - INFO] - Train Epoch:[28/100] Step:[220/250] Total Loss: 44.484913 GL_Loss: 1.047534 CRF_Loss: 43.437378\n",
      "[2022-02-17 13:51:40,514 - trainer - INFO] - Train Epoch:[28/100] Step:[230/250] Total Loss: 131.139420 GL_Loss: 1.773576 CRF_Loss: 129.365845\n",
      "[2022-02-17 13:51:54,454 - trainer - INFO] - Train Epoch:[28/100] Step:[240/250] Total Loss: 47.481056 GL_Loss: 2.561255 CRF_Loss: 44.919800\n",
      "[2022-02-17 13:52:08,731 - trainer - INFO] - Train Epoch:[28/100] Step:[250/250] Total Loss: 141.715591 GL_Loss: 2.035411 CRF_Loss: 139.680176\n",
      "[2022-02-17 13:52:27,910 - trainer - INFO] - [Step Validation] Epoch:[28/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.755682 | 0.847134 | 0.798799 | 0.847134 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.467391 | 0.228723 | 0.307143 | 0.228723 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.560656 | 0.544586 | 0.552504 | 0.544586 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.514851 | 0.565217 | 0.53886  | 0.565217 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.577023 | 0.470714 | 0.518475 | 0.470714 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 13:52:47,108 - trainer - INFO] - [Epoch Validation] Epoch:[28/100] Total Loss: 86.115432 GL_Loss: 0.014580 CRF_Loss: 84.657441 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.755682 | 0.847134 | 0.798799 | 0.847134 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.467391 | 0.228723 | 0.307143 | 0.228723 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.560656 | 0.544586 | 0.552504 | 0.544586 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.514851 | 0.565217 | 0.53886  | 0.565217 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.577023 | 0.470714 | 0.518475 | 0.470714 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 13:53:01,860 - trainer - INFO] - Train Epoch:[29/100] Step:[10/250] Total Loss: 53.461594 GL_Loss: 1.672408 CRF_Loss: 51.789185\n",
      "[2022-02-17 13:53:16,145 - trainer - INFO] - Train Epoch:[29/100] Step:[20/250] Total Loss: 43.280876 GL_Loss: 2.155510 CRF_Loss: 41.125366\n",
      "[2022-02-17 13:53:30,241 - trainer - INFO] - Train Epoch:[29/100] Step:[30/250] Total Loss: 76.854828 GL_Loss: 1.220547 CRF_Loss: 75.634277\n",
      "[2022-02-17 13:53:45,321 - trainer - INFO] - Train Epoch:[29/100] Step:[40/250] Total Loss: 31.666702 GL_Loss: 0.830520 CRF_Loss: 30.836182\n",
      "[2022-02-17 13:53:59,615 - trainer - INFO] - Train Epoch:[29/100] Step:[50/250] Total Loss: 178.672806 GL_Loss: 0.902422 CRF_Loss: 177.770386\n",
      "[2022-02-17 13:54:18,909 - trainer - INFO] - [Step Validation] Epoch:[29/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.812865 | 0.88535  | 0.847561 | 0.88535  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.504132 | 0.324468 | 0.394822 | 0.324468 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.656489 | 0.547771 | 0.597222 | 0.547771 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.645161 | 0.652174 | 0.648649 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.641927 | 0.525027 | 0.577622 | 0.525027 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 13:54:34,070 - trainer - INFO] - Train Epoch:[29/100] Step:[60/250] Total Loss: 24.301832 GL_Loss: 0.879347 CRF_Loss: 23.422485\n",
      "[2022-02-17 13:54:48,606 - trainer - INFO] - Train Epoch:[29/100] Step:[70/250] Total Loss: 28.218109 GL_Loss: 1.349946 CRF_Loss: 26.868164\n",
      "[2022-02-17 13:55:03,046 - trainer - INFO] - Train Epoch:[29/100] Step:[80/250] Total Loss: 168.277328 GL_Loss: 1.442971 CRF_Loss: 166.834351\n",
      "[2022-02-17 13:55:16,336 - trainer - INFO] - Train Epoch:[29/100] Step:[90/250] Total Loss: 43.627197 GL_Loss: 1.503417 CRF_Loss: 42.123779\n",
      "[2022-02-17 13:55:30,920 - trainer - INFO] - Train Epoch:[29/100] Step:[100/250] Total Loss: 23.914190 GL_Loss: 1.162114 CRF_Loss: 22.752075\n",
      "[2022-02-17 13:55:49,969 - trainer - INFO] - [Step Validation] Epoch:[29/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.822485 | 0.88535  | 0.852761 | 0.88535  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.524444 | 0.31383  | 0.392679 | 0.31383  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.645522 | 0.550955 | 0.594502 | 0.550955 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.56     | 0.608696 | 0.583333 | 0.608696 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.637795 | 0.517572 | 0.571429 | 0.517572 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 13:56:03,516 - trainer - INFO] - Train Epoch:[29/100] Step:[110/250] Total Loss: 64.848587 GL_Loss: 0.543471 CRF_Loss: 64.305115\n",
      "[2022-02-17 13:56:17,124 - trainer - INFO] - Train Epoch:[29/100] Step:[120/250] Total Loss: 88.066063 GL_Loss: 0.995629 CRF_Loss: 87.070435\n",
      "[2022-02-17 13:56:31,863 - trainer - INFO] - Train Epoch:[29/100] Step:[130/250] Total Loss: 25.109158 GL_Loss: 0.854641 CRF_Loss: 24.254517\n",
      "[2022-02-17 13:56:46,667 - trainer - INFO] - Train Epoch:[29/100] Step:[140/250] Total Loss: 46.202923 GL_Loss: 0.759563 CRF_Loss: 45.443359\n",
      "[2022-02-17 13:57:00,665 - trainer - INFO] - Train Epoch:[29/100] Step:[150/250] Total Loss: 200.630798 GL_Loss: 0.568295 CRF_Loss: 200.062500\n",
      "[2022-02-17 13:57:19,585 - trainer - INFO] - [Step Validation] Epoch:[29/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.831325 | 0.878981 | 0.854489 | 0.878981 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.595455 | 0.348404 | 0.439597 | 0.348404 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.669323 | 0.535032 | 0.59469  | 0.535032 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.59     | 0.641304 | 0.614583 | 0.641304 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.672999 | 0.528222 | 0.591885 | 0.528222 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 13:57:34,155 - trainer - INFO] - Train Epoch:[29/100] Step:[160/250] Total Loss: 53.292473 GL_Loss: 0.556266 CRF_Loss: 52.736206\n",
      "[2022-02-17 13:57:48,274 - trainer - INFO] - Train Epoch:[29/100] Step:[170/250] Total Loss: 16.972317 GL_Loss: 0.939968 CRF_Loss: 16.032349\n",
      "[2022-02-17 13:58:02,987 - trainer - INFO] - Train Epoch:[29/100] Step:[180/250] Total Loss: 26.891876 GL_Loss: 0.693756 CRF_Loss: 26.198120\n",
      "[2022-02-17 13:58:17,067 - trainer - INFO] - Train Epoch:[29/100] Step:[190/250] Total Loss: 123.927582 GL_Loss: 0.647920 CRF_Loss: 123.279663\n",
      "[2022-02-17 13:58:30,545 - trainer - INFO] - Train Epoch:[29/100] Step:[200/250] Total Loss: 76.824692 GL_Loss: 0.457989 CRF_Loss: 76.366699\n",
      "[2022-02-17 13:58:49,403 - trainer - INFO] - [Step Validation] Epoch:[29/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.700599 | 0.745223 | 0.722222 | 0.745223 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.565401 | 0.356383 | 0.437194 | 0.356383 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.8      | 0.216561 | 0.340852 | 0.216561 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.604167 | 0.630435 | 0.617021 | 0.630435 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.644444 | 0.401491 | 0.494751 | 0.401491 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 13:59:03,570 - trainer - INFO] - Train Epoch:[29/100] Step:[210/250] Total Loss: 43.594280 GL_Loss: 1.969647 CRF_Loss: 41.624634\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 13:59:17,679 - trainer - INFO] - Train Epoch:[29/100] Step:[220/250] Total Loss: 815.568054 GL_Loss: 16.413036 CRF_Loss: 799.155029\n",
      "[2022-02-17 13:59:32,888 - trainer - INFO] - Train Epoch:[29/100] Step:[230/250] Total Loss: 122.127190 GL_Loss: 4.551750 CRF_Loss: 117.575439\n",
      "[2022-02-17 13:59:47,758 - trainer - INFO] - Train Epoch:[29/100] Step:[240/250] Total Loss: 170.412415 GL_Loss: 8.092833 CRF_Loss: 162.319580\n",
      "[2022-02-17 14:00:01,193 - trainer - INFO] - Train Epoch:[29/100] Step:[250/250] Total Loss: 65.087364 GL_Loss: 6.709071 CRF_Loss: 58.378296\n",
      "[2022-02-17 14:00:22,180 - trainer - INFO] - [Step Validation] Epoch:[29/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.816568 | 0.878981 | 0.846626 | 0.878981 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.477912 | 0.316489 | 0.3808   | 0.316489 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.673387 | 0.531847 | 0.594306 | 0.531847 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.522124 | 0.641304 | 0.57561  | 0.641304 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.620026 | 0.514377 | 0.562282 | 0.514377 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 14:00:41,235 - trainer - INFO] - [Epoch Validation] Epoch:[29/100] Total Loss: 93.742743 GL_Loss: 0.020689 CRF_Loss: 91.673809 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.816568 | 0.878981 | 0.846626 | 0.878981 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.477912 | 0.316489 | 0.3808   | 0.316489 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.673387 | 0.531847 | 0.594306 | 0.531847 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.522124 | 0.641304 | 0.57561  | 0.641304 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.620026 | 0.514377 | 0.562282 | 0.514377 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 14:00:55,660 - trainer - INFO] - Train Epoch:[30/100] Step:[10/250] Total Loss: 80.724365 GL_Loss: 1.107055 CRF_Loss: 79.617310\n",
      "[2022-02-17 14:01:10,416 - trainer - INFO] - Train Epoch:[30/100] Step:[20/250] Total Loss: 24.421890 GL_Loss: 1.209854 CRF_Loss: 23.212036\n",
      "[2022-02-17 14:01:24,205 - trainer - INFO] - Train Epoch:[30/100] Step:[30/250] Total Loss: 34.440155 GL_Loss: 0.738251 CRF_Loss: 33.701904\n",
      "[2022-02-17 14:01:38,487 - trainer - INFO] - Train Epoch:[30/100] Step:[40/250] Total Loss: 85.107590 GL_Loss: 0.669361 CRF_Loss: 84.438232\n",
      "[2022-02-17 14:01:53,080 - trainer - INFO] - Train Epoch:[30/100] Step:[50/250] Total Loss: 47.655830 GL_Loss: 2.141672 CRF_Loss: 45.514160\n",
      "[2022-02-17 14:02:12,065 - trainer - INFO] - [Step Validation] Epoch:[30/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.775758 | 0.815287 | 0.795031 | 0.815287 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.530702 | 0.321809 | 0.400662 | 0.321809 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.653333 | 0.468153 | 0.545455 | 0.468153 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.508475 | 0.652174 | 0.571429 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.619565 | 0.485623 | 0.544478 | 0.485623 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 14:02:25,423 - trainer - INFO] - Train Epoch:[30/100] Step:[60/250] Total Loss: 37.323971 GL_Loss: 0.991940 CRF_Loss: 36.332031\n",
      "[2022-02-17 14:02:40,633 - trainer - INFO] - Train Epoch:[30/100] Step:[70/250] Total Loss: 60.260376 GL_Loss: 5.272825 CRF_Loss: 54.987549\n",
      "[2022-02-17 14:02:54,454 - trainer - INFO] - Train Epoch:[30/100] Step:[80/250] Total Loss: 78.556824 GL_Loss: 0.534851 CRF_Loss: 78.021973\n",
      "[2022-02-17 14:03:08,325 - trainer - INFO] - Train Epoch:[30/100] Step:[90/250] Total Loss: 53.614014 GL_Loss: 0.568971 CRF_Loss: 53.045044\n",
      "[2022-02-17 14:03:22,656 - trainer - INFO] - Train Epoch:[30/100] Step:[100/250] Total Loss: 164.277222 GL_Loss: 0.881653 CRF_Loss: 163.395569\n",
      "[2022-02-17 14:03:42,007 - trainer - INFO] - [Step Validation] Epoch:[30/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.742515 | 0.789809 | 0.765432 | 0.789809 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.572052 | 0.348404 | 0.433058 | 0.348404 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.695853 | 0.480892 | 0.568738 | 0.480892 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.644444 | 0.630435 | 0.637363 | 0.630435 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.660028 | 0.494143 | 0.565164 | 0.494143 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 14:03:56,106 - trainer - INFO] - Train Epoch:[30/100] Step:[110/250] Total Loss: 30.139572 GL_Loss: 0.484177 CRF_Loss: 29.655396\n",
      "[2022-02-17 14:04:10,957 - trainer - INFO] - Train Epoch:[30/100] Step:[120/250] Total Loss: 41.904457 GL_Loss: 0.535926 CRF_Loss: 41.368530\n",
      "[2022-02-17 14:04:25,319 - trainer - INFO] - Train Epoch:[30/100] Step:[130/250] Total Loss: 18.958042 GL_Loss: 0.496738 CRF_Loss: 18.461304\n",
      "[2022-02-17 14:04:38,864 - trainer - INFO] - Train Epoch:[30/100] Step:[140/250] Total Loss: 21.997736 GL_Loss: 0.363215 CRF_Loss: 21.634521\n",
      "[2022-02-17 14:04:53,458 - trainer - INFO] - Train Epoch:[30/100] Step:[150/250] Total Loss: 132.896576 GL_Loss: 0.391334 CRF_Loss: 132.505249\n",
      "[2022-02-17 14:05:12,611 - trainer - INFO] - [Step Validation] Epoch:[30/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.779762 | 0.834395 | 0.806154 | 0.834395 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.466887 | 0.375    | 0.415929 | 0.375    |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.619048 | 0.579618 | 0.598684 | 0.579618 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.604167 | 0.630435 | 0.617021 | 0.630435 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.595349 | 0.545261 | 0.569205 | 0.545261 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 14:05:26,442 - trainer - INFO] - Train Epoch:[30/100] Step:[160/250] Total Loss: 84.662453 GL_Loss: 0.667583 CRF_Loss: 83.994873\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 14:05:41,151 - trainer - INFO] - Train Epoch:[30/100] Step:[170/250] Total Loss: 67.629745 GL_Loss: 1.607038 CRF_Loss: 66.022705\n",
      "[2022-02-17 14:05:55,871 - trainer - INFO] - Train Epoch:[30/100] Step:[180/250] Total Loss: 59.127953 GL_Loss: 1.535851 CRF_Loss: 57.592102\n",
      "[2022-02-17 14:06:09,717 - trainer - INFO] - Train Epoch:[30/100] Step:[190/250] Total Loss: 50.405556 GL_Loss: 2.453590 CRF_Loss: 47.951965\n",
      "[2022-02-17 14:06:23,584 - trainer - INFO] - Train Epoch:[30/100] Step:[200/250] Total Loss: 49.297668 GL_Loss: 7.810728 CRF_Loss: 41.486938\n",
      "[2022-02-17 14:06:42,674 - trainer - INFO] - [Step Validation] Epoch:[30/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.785276 | 0.815287 | 0.8      | 0.815287 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.531401 | 0.292553 | 0.377358 | 0.292553 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.598706 | 0.589172 | 0.5939   | 0.589172 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.61165  | 0.684783 | 0.646154 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.621483 | 0.517572 | 0.564788 | 0.517572 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 14:06:57,299 - trainer - INFO] - Train Epoch:[30/100] Step:[210/250] Total Loss: 37.837006 GL_Loss: 1.927583 CRF_Loss: 35.909424\n",
      "[2022-02-17 14:07:11,249 - trainer - INFO] - Train Epoch:[30/100] Step:[220/250] Total Loss: 67.084702 GL_Loss: 0.520981 CRF_Loss: 66.563721\n",
      "[2022-02-17 14:07:25,784 - trainer - INFO] - Train Epoch:[30/100] Step:[230/250] Total Loss: 77.480331 GL_Loss: 0.409411 CRF_Loss: 77.070923\n",
      "[2022-02-17 14:07:40,928 - trainer - INFO] - Train Epoch:[30/100] Step:[240/250] Total Loss: 388.320435 GL_Loss: 0.299694 CRF_Loss: 388.020752\n",
      "[2022-02-17 14:07:55,005 - trainer - INFO] - Train Epoch:[30/100] Step:[250/250] Total Loss: 144.461731 GL_Loss: 0.501521 CRF_Loss: 143.960205\n",
      "[2022-02-17 14:08:14,054 - trainer - INFO] - [Step Validation] Epoch:[30/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.77095  | 0.878981 | 0.821429 | 0.878981 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.572052 | 0.348404 | 0.433058 | 0.348404 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.786517 | 0.44586  | 0.569106 | 0.44586  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.59     | 0.641304 | 0.614583 | 0.641304 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.682216 | 0.498403 | 0.576    | 0.498403 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 14:08:33,412 - trainer - INFO] - [Epoch Validation] Epoch:[30/100] Total Loss: 87.222768 GL_Loss: 0.016210 CRF_Loss: 85.601790 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.77095  | 0.878981 | 0.821429 | 0.878981 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.572052 | 0.348404 | 0.433058 | 0.348404 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.786517 | 0.44586  | 0.569106 | 0.44586  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.59     | 0.641304 | 0.614583 | 0.641304 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.682216 | 0.498403 | 0.576    | 0.498403 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 14:08:49,605 - trainer - INFO] - Train Epoch:[31/100] Step:[10/250] Total Loss: 41.335140 GL_Loss: 3.050472 CRF_Loss: 38.284668\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 14:09:04,926 - trainer - INFO] - Train Epoch:[31/100] Step:[20/250] Total Loss: 44.819248 GL_Loss: 0.973666 CRF_Loss: 43.845581\n",
      "[2022-02-17 14:09:19,517 - trainer - INFO] - Train Epoch:[31/100] Step:[30/250] Total Loss: 159.153244 GL_Loss: 0.791556 CRF_Loss: 158.361694\n",
      "[2022-02-17 14:09:34,885 - trainer - INFO] - Train Epoch:[31/100] Step:[40/250] Total Loss: 85.156075 GL_Loss: 0.427071 CRF_Loss: 84.729004\n",
      "[2022-02-17 14:09:48,918 - trainer - INFO] - Train Epoch:[31/100] Step:[50/250] Total Loss: 28.663288 GL_Loss: 0.366657 CRF_Loss: 28.296631\n",
      "[2022-02-17 14:10:07,956 - trainer - INFO] - [Step Validation] Epoch:[31/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.737705 | 0.859873 | 0.794118 | 0.859873 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.557018 | 0.337766 | 0.42053  | 0.337766 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.677291 | 0.541401 | 0.60177  | 0.541401 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.59     | 0.641304 | 0.614583 | 0.641304 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.644357 | 0.522897 | 0.577307 | 0.522897 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 14:10:23,284 - trainer - INFO] - Train Epoch:[31/100] Step:[60/250] Total Loss: 38.429169 GL_Loss: 1.427338 CRF_Loss: 37.001831\n",
      "[2022-02-17 14:10:40,126 - trainer - INFO] - Train Epoch:[31/100] Step:[70/250] Total Loss: 40.675102 GL_Loss: 0.613211 CRF_Loss: 40.061890\n",
      "[2022-02-17 14:10:54,971 - trainer - INFO] - Train Epoch:[31/100] Step:[80/250] Total Loss: 61.150047 GL_Loss: 1.231225 CRF_Loss: 59.918823\n",
      "[2022-02-17 14:11:12,571 - trainer - INFO] - Train Epoch:[31/100] Step:[90/250] Total Loss: 118.032158 GL_Loss: 0.682057 CRF_Loss: 117.350098\n",
      "[2022-02-17 14:11:27,239 - trainer - INFO] - Train Epoch:[31/100] Step:[100/250] Total Loss: 25.891680 GL_Loss: 0.461260 CRF_Loss: 25.430420\n",
      "[2022-02-17 14:11:46,311 - trainer - INFO] - [Step Validation] Epoch:[31/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.804469 | 0.917197 | 0.857143 | 0.917197 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.589286 | 0.351064 | 0.44     | 0.351064 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.698347 | 0.538217 | 0.607914 | 0.538217 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.614583 | 0.641304 | 0.62766  | 0.641304 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.680162 | 0.536741 | 0.6      | 0.536741 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 14:12:01,426 - trainer - INFO] - Train Epoch:[31/100] Step:[110/250] Total Loss: 31.256601 GL_Loss: 0.687753 CRF_Loss: 30.568848\n",
      "[2022-02-17 14:12:15,981 - trainer - INFO] - Train Epoch:[31/100] Step:[120/250] Total Loss: 68.132492 GL_Loss: 0.425098 CRF_Loss: 67.707397\n",
      "[2022-02-17 14:12:30,557 - trainer - INFO] - Train Epoch:[31/100] Step:[130/250] Total Loss: 227.372635 GL_Loss: 0.484764 CRF_Loss: 226.887878\n",
      "[2022-02-17 14:12:45,708 - trainer - INFO] - Train Epoch:[31/100] Step:[140/250] Total Loss: 53.884808 GL_Loss: 0.788859 CRF_Loss: 53.095947\n",
      "[2022-02-17 14:12:59,352 - trainer - INFO] - Train Epoch:[31/100] Step:[150/250] Total Loss: 36.077770 GL_Loss: 0.555796 CRF_Loss: 35.521973\n",
      "[2022-02-17 14:13:18,564 - trainer - INFO] - [Step Validation] Epoch:[31/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.796512 | 0.872611 | 0.832827 | 0.872611 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.568889 | 0.340426 | 0.425957 | 0.340426 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.70155  | 0.576433 | 0.632867 | 0.576433 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.614583 | 0.641304 | 0.62766  | 0.641304 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.672437 | 0.537806 | 0.597633 | 0.537806 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 14:13:33,248 - trainer - INFO] - Train Epoch:[31/100] Step:[160/250] Total Loss: 87.309288 GL_Loss: 0.309774 CRF_Loss: 86.999512\n",
      "[2022-02-17 14:13:47,623 - trainer - INFO] - Train Epoch:[31/100] Step:[170/250] Total Loss: 30.506384 GL_Loss: 0.838538 CRF_Loss: 29.667847\n",
      "[2022-02-17 14:14:02,077 - trainer - INFO] - Train Epoch:[31/100] Step:[180/250] Total Loss: 48.579674 GL_Loss: 0.388880 CRF_Loss: 48.190796\n",
      "[2022-02-17 14:14:15,180 - trainer - INFO] - Train Epoch:[31/100] Step:[190/250] Total Loss: 56.490105 GL_Loss: 0.407950 CRF_Loss: 56.082153\n",
      "[2022-02-17 14:14:30,593 - trainer - INFO] - Train Epoch:[31/100] Step:[200/250] Total Loss: 53.767647 GL_Loss: 0.803414 CRF_Loss: 52.964233\n",
      "[2022-02-17 14:14:49,724 - trainer - INFO] - [Step Validation] Epoch:[31/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.843023 | 0.923567 | 0.881459 | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.596413 | 0.353723 | 0.444073 | 0.353723 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.7251   | 0.579618 | 0.644248 | 0.579618 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.621053 | 0.641304 | 0.631016 | 0.641304 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.700405 | 0.552716 | 0.617857 | 0.552716 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 14:14:51,904 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 14:15:05,928 - trainer - INFO] - Train Epoch:[31/100] Step:[210/250] Total Loss: 49.467354 GL_Loss: 1.170357 CRF_Loss: 48.296997\n",
      "[2022-02-17 14:15:19,498 - trainer - INFO] - Train Epoch:[31/100] Step:[220/250] Total Loss: 17.613564 GL_Loss: 0.616248 CRF_Loss: 16.997314\n",
      "[2022-02-17 14:15:32,915 - trainer - INFO] - Train Epoch:[31/100] Step:[230/250] Total Loss: 36.218311 GL_Loss: 0.668018 CRF_Loss: 35.550293\n",
      "[2022-02-17 14:15:47,959 - trainer - INFO] - Train Epoch:[31/100] Step:[240/250] Total Loss: 26.909321 GL_Loss: 0.707782 CRF_Loss: 26.201538\n",
      "[2022-02-17 14:16:02,154 - trainer - INFO] - Train Epoch:[31/100] Step:[250/250] Total Loss: 26.390270 GL_Loss: 0.481335 CRF_Loss: 25.908936\n",
      "[2022-02-17 14:16:21,107 - trainer - INFO] - [Step Validation] Epoch:[31/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.807229 | 0.853503 | 0.829721 | 0.853503 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.571429 | 0.340426 | 0.426667 | 0.340426 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.684211 | 0.579618 | 0.627586 | 0.579618 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.628866 | 0.663043 | 0.645503 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.670651 | 0.537806 | 0.596927 | 0.537806 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 14:16:40,164 - trainer - INFO] - [Epoch Validation] Epoch:[31/100] Total Loss: 69.618684 GL_Loss: 0.007924 CRF_Loss: 68.826304 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.807229 | 0.853503 | 0.829721 | 0.853503 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.571429 | 0.340426 | 0.426667 | 0.340426 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.684211 | 0.579618 | 0.627586 | 0.579618 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.628866 | 0.663043 | 0.645503 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.670651 | 0.537806 | 0.596927 | 0.537806 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 14:16:54,903 - trainer - INFO] - Train Epoch:[32/100] Step:[10/250] Total Loss: 314.389679 GL_Loss: 0.403965 CRF_Loss: 313.985718\n",
      "[2022-02-17 14:17:09,068 - trainer - INFO] - Train Epoch:[32/100] Step:[20/250] Total Loss: 55.940693 GL_Loss: 0.630208 CRF_Loss: 55.310486\n",
      "[2022-02-17 14:17:23,249 - trainer - INFO] - Train Epoch:[32/100] Step:[30/250] Total Loss: 32.154560 GL_Loss: 0.501363 CRF_Loss: 31.653198\n",
      "[2022-02-17 14:17:37,763 - trainer - INFO] - Train Epoch:[32/100] Step:[40/250] Total Loss: 69.163910 GL_Loss: 0.823088 CRF_Loss: 68.340820\n",
      "[2022-02-17 14:17:52,175 - trainer - INFO] - Train Epoch:[32/100] Step:[50/250] Total Loss: 405.759094 GL_Loss: 0.685969 CRF_Loss: 405.073120\n",
      "[2022-02-17 14:18:11,381 - trainer - INFO] - [Step Validation] Epoch:[32/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.783626 | 0.853503 | 0.817073 | 0.853503 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.580357 | 0.345745 | 0.433333 | 0.345745 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.661922 | 0.592357 | 0.62521  | 0.592357 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.634409 | 0.641304 | 0.637838 | 0.641304 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.661899 | 0.542066 | 0.596019 | 0.542066 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 14:18:25,970 - trainer - INFO] - Train Epoch:[32/100] Step:[60/250] Total Loss: 19.775133 GL_Loss: 0.315295 CRF_Loss: 19.459839\n",
      "[2022-02-17 14:18:41,497 - trainer - INFO] - Train Epoch:[32/100] Step:[70/250] Total Loss: 33.430229 GL_Loss: 0.859793 CRF_Loss: 32.570435\n",
      "[2022-02-17 14:18:55,605 - trainer - INFO] - Train Epoch:[32/100] Step:[80/250] Total Loss: 42.419357 GL_Loss: 0.815964 CRF_Loss: 41.603394\n",
      "[2022-02-17 14:19:09,947 - trainer - INFO] - Train Epoch:[32/100] Step:[90/250] Total Loss: 26.310066 GL_Loss: 0.678597 CRF_Loss: 25.631470\n",
      "[2022-02-17 14:19:24,006 - trainer - INFO] - Train Epoch:[32/100] Step:[100/250] Total Loss: 40.534191 GL_Loss: 0.338146 CRF_Loss: 40.196045\n",
      "[2022-02-17 14:19:43,090 - trainer - INFO] - [Step Validation] Epoch:[32/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.8      | 0.89172  | 0.843373 | 0.89172  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.587444 | 0.348404 | 0.437396 | 0.348404 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.714829 | 0.598726 | 0.651646 | 0.598726 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.610526 | 0.630435 | 0.620321 | 0.630435 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.683862 | 0.550586 | 0.610029 | 0.550586 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 14:19:57,691 - trainer - INFO] - Train Epoch:[32/100] Step:[110/250] Total Loss: 22.340939 GL_Loss: 0.581538 CRF_Loss: 21.759399\n",
      "[2022-02-17 14:20:12,065 - trainer - INFO] - Train Epoch:[32/100] Step:[120/250] Total Loss: 50.623638 GL_Loss: 1.531476 CRF_Loss: 49.092163\n",
      "[2022-02-17 14:20:26,665 - trainer - INFO] - Train Epoch:[32/100] Step:[130/250] Total Loss: 77.232681 GL_Loss: 0.402845 CRF_Loss: 76.829834\n",
      "[2022-02-17 14:20:42,838 - trainer - INFO] - Train Epoch:[32/100] Step:[140/250] Total Loss: 45.847084 GL_Loss: 0.452308 CRF_Loss: 45.394775\n",
      "[2022-02-17 14:20:57,603 - trainer - INFO] - Train Epoch:[32/100] Step:[150/250] Total Loss: 46.449219 GL_Loss: 0.777344 CRF_Loss: 45.671875\n",
      "[2022-02-17 14:21:16,594 - trainer - INFO] - [Step Validation] Epoch:[32/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.831395 | 0.910828 | 0.869301 | 0.910828 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.61435  | 0.364362 | 0.457429 | 0.364362 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.721116 | 0.576433 | 0.640708 | 0.576433 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.62766  | 0.641304 | 0.634409 | 0.641304 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.702703 | 0.553781 | 0.619416 | 0.553781 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 14:21:18,748 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 14:21:33,332 - trainer - INFO] - Train Epoch:[32/100] Step:[160/250] Total Loss: 40.870937 GL_Loss: 0.477139 CRF_Loss: 40.393799\n",
      "[2022-02-17 14:21:47,039 - trainer - INFO] - Train Epoch:[32/100] Step:[170/250] Total Loss: 17.413109 GL_Loss: 0.594138 CRF_Loss: 16.818970\n",
      "[2022-02-17 14:22:01,523 - trainer - INFO] - Train Epoch:[32/100] Step:[180/250] Total Loss: 43.827698 GL_Loss: 0.432312 CRF_Loss: 43.395386\n",
      "[2022-02-17 14:22:15,242 - trainer - INFO] - Train Epoch:[32/100] Step:[190/250] Total Loss: 41.926430 GL_Loss: 0.556921 CRF_Loss: 41.369507\n",
      "[2022-02-17 14:22:28,535 - trainer - INFO] - Train Epoch:[32/100] Step:[200/250] Total Loss: 65.660378 GL_Loss: 0.539530 CRF_Loss: 65.120850\n",
      "[2022-02-17 14:22:47,655 - trainer - INFO] - [Step Validation] Epoch:[32/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.861446 | 0.910828 | 0.885449 | 0.910828 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.595556 | 0.356383 | 0.445923 | 0.356383 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.648829 | 0.617834 | 0.632953 | 0.617834 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.604167 | 0.630435 | 0.617021 | 0.630435 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.673028 | 0.563365 | 0.613333 | 0.563365 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 14:23:01,891 - trainer - INFO] - Train Epoch:[32/100] Step:[210/250] Total Loss: 62.071369 GL_Loss: 0.504476 CRF_Loss: 61.566895\n",
      "[2022-02-17 14:23:16,334 - trainer - INFO] - Train Epoch:[32/100] Step:[220/250] Total Loss: 23.376408 GL_Loss: 0.490543 CRF_Loss: 22.885864\n",
      "[2022-02-17 14:23:29,593 - trainer - INFO] - Train Epoch:[32/100] Step:[230/250] Total Loss: 24.359934 GL_Loss: 0.535226 CRF_Loss: 23.824707\n",
      "[2022-02-17 14:23:43,476 - trainer - INFO] - Train Epoch:[32/100] Step:[240/250] Total Loss: 25.157875 GL_Loss: 0.418373 CRF_Loss: 24.739502\n",
      "[2022-02-17 14:23:57,955 - trainer - INFO] - Train Epoch:[32/100] Step:[250/250] Total Loss: 143.755066 GL_Loss: 0.339903 CRF_Loss: 143.415161\n",
      "[2022-02-17 14:24:17,037 - trainer - INFO] - [Step Validation] Epoch:[32/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.86747  | 0.917197 | 0.891641 | 0.917197 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.581897 | 0.359043 | 0.444079 | 0.359043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.73617  | 0.550955 | 0.630237 | 0.550955 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.604167 | 0.630435 | 0.617021 | 0.630435 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.699588 | 0.543131 | 0.611511 | 0.543131 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 14:24:36,247 - trainer - INFO] - [Epoch Validation] Epoch:[32/100] Total Loss: 63.462517 GL_Loss: 0.006134 CRF_Loss: 62.849098 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.86747  | 0.917197 | 0.891641 | 0.917197 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.581897 | 0.359043 | 0.444079 | 0.359043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.73617  | 0.550955 | 0.630237 | 0.550955 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.604167 | 0.630435 | 0.617021 | 0.630435 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.699588 | 0.543131 | 0.611511 | 0.543131 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 14:24:50,674 - trainer - INFO] - Train Epoch:[33/100] Step:[10/250] Total Loss: 20.688253 GL_Loss: 0.495504 CRF_Loss: 20.192749\n",
      "[2022-02-17 14:25:04,792 - trainer - INFO] - Train Epoch:[33/100] Step:[20/250] Total Loss: 34.803593 GL_Loss: 0.470950 CRF_Loss: 34.332642\n",
      "[2022-02-17 14:25:18,785 - trainer - INFO] - Train Epoch:[33/100] Step:[30/250] Total Loss: 38.556511 GL_Loss: 0.465447 CRF_Loss: 38.091064\n",
      "[2022-02-17 14:25:33,521 - trainer - INFO] - Train Epoch:[33/100] Step:[40/250] Total Loss: 25.106022 GL_Loss: 0.424137 CRF_Loss: 24.681885\n",
      "[2022-02-17 14:25:47,461 - trainer - INFO] - Train Epoch:[33/100] Step:[50/250] Total Loss: 54.086262 GL_Loss: 0.415853 CRF_Loss: 53.670410\n",
      "[2022-02-17 14:26:06,564 - trainer - INFO] - [Step Validation] Epoch:[33/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.830303 | 0.872611 | 0.850932 | 0.872611 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.582609 | 0.356383 | 0.442244 | 0.356383 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.685185 | 0.589172 | 0.633562 | 0.589172 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.604167 | 0.630435 | 0.617021 | 0.630435 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.675427 | 0.547391 | 0.604706 | 0.547391 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 14:26:21,918 - trainer - INFO] - Train Epoch:[33/100] Step:[60/250] Total Loss: 34.030128 GL_Loss: 0.575049 CRF_Loss: 33.455078\n",
      "[2022-02-17 14:26:37,373 - trainer - INFO] - Train Epoch:[33/100] Step:[70/250] Total Loss: 106.433380 GL_Loss: 0.561189 CRF_Loss: 105.872192\n",
      "[2022-02-17 14:26:50,852 - trainer - INFO] - Train Epoch:[33/100] Step:[80/250] Total Loss: 43.311916 GL_Loss: 0.933375 CRF_Loss: 42.378540\n",
      "[2022-02-17 14:27:04,667 - trainer - INFO] - Train Epoch:[33/100] Step:[90/250] Total Loss: 38.136791 GL_Loss: 0.784739 CRF_Loss: 37.352051\n",
      "[2022-02-17 14:27:19,682 - trainer - INFO] - Train Epoch:[33/100] Step:[100/250] Total Loss: 19.758499 GL_Loss: 0.351151 CRF_Loss: 19.407349\n",
      "[2022-02-17 14:27:38,762 - trainer - INFO] - [Step Validation] Epoch:[33/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.818713 | 0.89172  | 0.853659 | 0.89172  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.584416 | 0.359043 | 0.444811 | 0.359043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.694981 | 0.573248 | 0.628272 | 0.573248 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.614583 | 0.641304 | 0.62766  | 0.641304 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.678996 | 0.547391 | 0.606132 | 0.547391 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 14:27:54,076 - trainer - INFO] - Train Epoch:[33/100] Step:[110/250] Total Loss: 26.203362 GL_Loss: 0.488884 CRF_Loss: 25.714478\n",
      "[2022-02-17 14:28:08,605 - trainer - INFO] - Train Epoch:[33/100] Step:[120/250] Total Loss: 40.297600 GL_Loss: 0.453363 CRF_Loss: 39.844238\n",
      "[2022-02-17 14:28:21,649 - trainer - INFO] - Train Epoch:[33/100] Step:[130/250] Total Loss: 65.946182 GL_Loss: 0.838397 CRF_Loss: 65.107788\n",
      "[2022-02-17 14:28:35,566 - trainer - INFO] - Train Epoch:[33/100] Step:[140/250] Total Loss: 155.605087 GL_Loss: 0.366440 CRF_Loss: 155.238647\n",
      "[2022-02-17 14:28:49,468 - trainer - INFO] - Train Epoch:[33/100] Step:[150/250] Total Loss: 34.690392 GL_Loss: 1.710776 CRF_Loss: 32.979614\n",
      "[2022-02-17 14:29:08,461 - trainer - INFO] - [Step Validation] Epoch:[33/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.837349 | 0.88535  | 0.860681 | 0.88535  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.582609 | 0.356383 | 0.442244 | 0.356383 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.69685  | 0.563694 | 0.623239 | 0.563694 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.630435 | 0.630435 | 0.630435 | 0.630435 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.684636 | 0.541001 | 0.604402 | 0.541001 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 14:29:22,253 - trainer - INFO] - Train Epoch:[33/100] Step:[160/250] Total Loss: 30.109890 GL_Loss: 0.617458 CRF_Loss: 29.492432\n",
      "[2022-02-17 14:29:36,564 - trainer - INFO] - Train Epoch:[33/100] Step:[170/250] Total Loss: 118.456528 GL_Loss: 0.527331 CRF_Loss: 117.929199\n",
      "[2022-02-17 14:29:50,813 - trainer - INFO] - Train Epoch:[33/100] Step:[180/250] Total Loss: 113.491249 GL_Loss: 0.357097 CRF_Loss: 113.134155\n",
      "[2022-02-17 14:30:05,106 - trainer - INFO] - Train Epoch:[33/100] Step:[190/250] Total Loss: 53.281136 GL_Loss: 0.515997 CRF_Loss: 52.765137\n",
      "[2022-02-17 14:30:18,796 - trainer - INFO] - Train Epoch:[33/100] Step:[200/250] Total Loss: 78.374069 GL_Loss: 0.463668 CRF_Loss: 77.910400\n",
      "[2022-02-17 14:30:38,390 - trainer - INFO] - [Step Validation] Epoch:[33/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.86747  | 0.917197 | 0.891641 | 0.917197 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.597403 | 0.367021 | 0.454695 | 0.367021 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.675    | 0.601911 | 0.636364 | 0.601911 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.614583 | 0.641304 | 0.62766  | 0.641304 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.68564  | 0.56443  | 0.619159 | 0.56443  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 14:30:52,291 - trainer - INFO] - Train Epoch:[33/100] Step:[210/250] Total Loss: 62.092304 GL_Loss: 0.732928 CRF_Loss: 61.359375\n",
      "[2022-02-17 14:31:07,011 - trainer - INFO] - Train Epoch:[33/100] Step:[220/250] Total Loss: 54.990734 GL_Loss: 0.809705 CRF_Loss: 54.181030\n",
      "[2022-02-17 14:31:21,607 - trainer - INFO] - Train Epoch:[33/100] Step:[230/250] Total Loss: 16.657051 GL_Loss: 0.620431 CRF_Loss: 16.036621\n",
      "[2022-02-17 14:31:36,230 - trainer - INFO] - Train Epoch:[33/100] Step:[240/250] Total Loss: 68.862831 GL_Loss: 0.896765 CRF_Loss: 67.966064\n",
      "[2022-02-17 14:31:50,748 - trainer - INFO] - Train Epoch:[33/100] Step:[250/250] Total Loss: 34.708370 GL_Loss: 0.393063 CRF_Loss: 34.315308\n",
      "[2022-02-17 14:32:09,991 - trainer - INFO] - [Step Validation] Epoch:[33/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.883436 | 0.917197 | 0.9      | 0.917197 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.610619 | 0.367021 | 0.458472 | 0.367021 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.713147 | 0.570064 | 0.633628 | 0.570064 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.621053 | 0.641304 | 0.631016 | 0.641304 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.707483 | 0.553781 | 0.621266 | 0.553781 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 14:32:12,145 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 14:32:31,273 - trainer - INFO] - [Epoch Validation] Epoch:[33/100] Total Loss: 62.077301 GL_Loss: 0.006048 CRF_Loss: 61.472452 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.883436 | 0.917197 | 0.9      | 0.917197 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.610619 | 0.367021 | 0.458472 | 0.367021 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.713147 | 0.570064 | 0.633628 | 0.570064 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.621053 | 0.641304 | 0.631016 | 0.641304 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.707483 | 0.553781 | 0.621266 | 0.553781 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 14:32:46,608 - trainer - INFO] - Train Epoch:[34/100] Step:[10/250] Total Loss: 120.745987 GL_Loss: 0.391373 CRF_Loss: 120.354614\n",
      "[2022-02-17 14:33:00,507 - trainer - INFO] - Train Epoch:[34/100] Step:[20/250] Total Loss: 91.020332 GL_Loss: 0.471259 CRF_Loss: 90.549072\n",
      "[2022-02-17 14:33:14,662 - trainer - INFO] - Train Epoch:[34/100] Step:[30/250] Total Loss: 31.852781 GL_Loss: 0.733030 CRF_Loss: 31.119751\n",
      "[2022-02-17 14:33:28,998 - trainer - INFO] - Train Epoch:[34/100] Step:[40/250] Total Loss: 25.938890 GL_Loss: 0.497973 CRF_Loss: 25.440918\n",
      "[2022-02-17 14:33:43,548 - trainer - INFO] - Train Epoch:[34/100] Step:[50/250] Total Loss: 14.794726 GL_Loss: 0.500293 CRF_Loss: 14.294434\n",
      "[2022-02-17 14:34:04,356 - trainer - INFO] - [Step Validation] Epoch:[34/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.878788 | 0.923567 | 0.900621 | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.596491 | 0.361702 | 0.450331 | 0.361702 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.677656 | 0.589172 | 0.630324 | 0.589172 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.614583 | 0.641304 | 0.62766  | 0.641304 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.688976 | 0.559105 | 0.617284 | 0.559105 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 14:34:20,113 - trainer - INFO] - Train Epoch:[34/100] Step:[60/250] Total Loss: 13.581491 GL_Loss: 0.620737 CRF_Loss: 12.960754\n",
      "[2022-02-17 14:34:33,964 - trainer - INFO] - Train Epoch:[34/100] Step:[70/250] Total Loss: 107.834793 GL_Loss: 0.387525 CRF_Loss: 107.447266\n",
      "[2022-02-17 14:34:49,012 - trainer - INFO] - Train Epoch:[34/100] Step:[80/250] Total Loss: 111.254265 GL_Loss: 0.644887 CRF_Loss: 110.609375\n",
      "[2022-02-17 14:35:04,040 - trainer - INFO] - Train Epoch:[34/100] Step:[90/250] Total Loss: 37.329098 GL_Loss: 0.413815 CRF_Loss: 36.915283\n",
      "[2022-02-17 14:35:17,771 - trainer - INFO] - Train Epoch:[34/100] Step:[100/250] Total Loss: 163.070572 GL_Loss: 0.460707 CRF_Loss: 162.609863\n",
      "[2022-02-17 14:35:37,040 - trainer - INFO] - [Step Validation] Epoch:[34/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.856287 | 0.910828 | 0.882716 | 0.910828 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.61674  | 0.37234  | 0.464345 | 0.37234  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.670213 | 0.601911 | 0.634228 | 0.601911 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.631579 | 0.652174 | 0.641711 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.690013 | 0.56656  | 0.622222 | 0.56656  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 14:35:39,174 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 14:35:53,911 - trainer - INFO] - Train Epoch:[34/100] Step:[110/250] Total Loss: 28.721962 GL_Loss: 0.783729 CRF_Loss: 27.938232\n",
      "[2022-02-17 14:36:07,601 - trainer - INFO] - Train Epoch:[34/100] Step:[120/250] Total Loss: 31.620699 GL_Loss: 1.165193 CRF_Loss: 30.455505\n",
      "[2022-02-17 14:36:21,321 - trainer - INFO] - Train Epoch:[34/100] Step:[130/250] Total Loss: 123.460564 GL_Loss: 0.331047 CRF_Loss: 123.129517\n",
      "[2022-02-17 14:36:36,155 - trainer - INFO] - Train Epoch:[34/100] Step:[140/250] Total Loss: 24.434347 GL_Loss: 0.734763 CRF_Loss: 23.699585\n",
      "[2022-02-17 14:36:50,025 - trainer - INFO] - Train Epoch:[34/100] Step:[150/250] Total Loss: 16.647713 GL_Loss: 1.342170 CRF_Loss: 15.305542\n",
      "[2022-02-17 14:37:08,824 - trainer - INFO] - [Step Validation] Epoch:[34/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.848485 | 0.89172  | 0.869565 | 0.89172  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.584416 | 0.359043 | 0.444811 | 0.359043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.725664 | 0.522293 | 0.607407 | 0.522293 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.614583 | 0.641304 | 0.62766  | 0.641304 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.693593 | 0.530351 | 0.601086 | 0.530351 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 14:37:22,495 - trainer - INFO] - Train Epoch:[34/100] Step:[160/250] Total Loss: 52.908428 GL_Loss: 0.559552 CRF_Loss: 52.348877\n",
      "[2022-02-17 14:37:36,797 - trainer - INFO] - Train Epoch:[34/100] Step:[170/250] Total Loss: 20.410898 GL_Loss: 0.458994 CRF_Loss: 19.951904\n",
      "[2022-02-17 14:37:50,489 - trainer - INFO] - Train Epoch:[34/100] Step:[180/250] Total Loss: 143.740631 GL_Loss: 0.694001 CRF_Loss: 143.046631\n",
      "[2022-02-17 14:38:03,764 - trainer - INFO] - Train Epoch:[34/100] Step:[190/250] Total Loss: 22.487421 GL_Loss: 0.614131 CRF_Loss: 21.873291\n",
      "[2022-02-17 14:38:18,336 - trainer - INFO] - Train Epoch:[34/100] Step:[200/250] Total Loss: 68.030869 GL_Loss: 0.432970 CRF_Loss: 67.597900\n",
      "[2022-02-17 14:38:37,381 - trainer - INFO] - [Step Validation] Epoch:[34/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.852071 | 0.917197 | 0.883436 | 0.917197 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.603448 | 0.37234  | 0.460526 | 0.37234  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.673759 | 0.605096 | 0.637584 | 0.605096 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.617021 | 0.630435 | 0.623656 | 0.630435 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.684685 | 0.56656  | 0.620047 | 0.56656  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 14:38:51,760 - trainer - INFO] - Train Epoch:[34/100] Step:[210/250] Total Loss: 74.583160 GL_Loss: 0.362576 CRF_Loss: 74.220581\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 14:39:05,056 - trainer - INFO] - Train Epoch:[34/100] Step:[220/250] Total Loss: 21.784821 GL_Loss: 0.631255 CRF_Loss: 21.153564\n",
      "[2022-02-17 14:39:19,641 - trainer - INFO] - Train Epoch:[34/100] Step:[230/250] Total Loss: 70.200188 GL_Loss: 0.896351 CRF_Loss: 69.303833\n",
      "[2022-02-17 14:39:33,717 - trainer - INFO] - Train Epoch:[34/100] Step:[240/250] Total Loss: 81.526192 GL_Loss: 0.710029 CRF_Loss: 80.816162\n",
      "[2022-02-17 14:39:49,334 - trainer - INFO] - Train Epoch:[34/100] Step:[250/250] Total Loss: 22.612991 GL_Loss: 0.827712 CRF_Loss: 21.785278\n",
      "[2022-02-17 14:40:08,451 - trainer - INFO] - [Step Validation] Epoch:[34/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.856287 | 0.910828 | 0.882716 | 0.910828 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.594828 | 0.367021 | 0.453947 | 0.367021 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.67474  | 0.621019 | 0.646766 | 0.621019 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.638298 | 0.652174 | 0.645161 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.685422 | 0.57082  | 0.622894 | 0.57082  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 14:40:10,592 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 14:40:29,896 - trainer - INFO] - [Epoch Validation] Epoch:[34/100] Total Loss: 59.972717 GL_Loss: 0.006312 CRF_Loss: 59.341521 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.856287 | 0.910828 | 0.882716 | 0.910828 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.594828 | 0.367021 | 0.453947 | 0.367021 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.67474  | 0.621019 | 0.646766 | 0.621019 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.638298 | 0.652174 | 0.645161 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.685422 | 0.57082  | 0.622894 | 0.57082  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 14:40:44,780 - trainer - INFO] - Train Epoch:[35/100] Step:[10/250] Total Loss: 103.497169 GL_Loss: 0.564921 CRF_Loss: 102.932251\n",
      "[2022-02-17 14:40:59,596 - trainer - INFO] - Train Epoch:[35/100] Step:[20/250] Total Loss: 18.571983 GL_Loss: 0.719323 CRF_Loss: 17.852661\n",
      "[2022-02-17 14:41:13,727 - trainer - INFO] - Train Epoch:[35/100] Step:[30/250] Total Loss: 54.624367 GL_Loss: 0.454874 CRF_Loss: 54.169495\n",
      "[2022-02-17 14:41:28,121 - trainer - INFO] - Train Epoch:[35/100] Step:[40/250] Total Loss: 120.436386 GL_Loss: 0.732465 CRF_Loss: 119.703918\n",
      "[2022-02-17 14:41:42,596 - trainer - INFO] - Train Epoch:[35/100] Step:[50/250] Total Loss: 83.068115 GL_Loss: 0.371829 CRF_Loss: 82.696289\n",
      "[2022-02-17 14:42:01,714 - trainer - INFO] - [Step Validation] Epoch:[35/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.85119  | 0.910828 | 0.88     | 0.910828 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.597403 | 0.367021 | 0.454695 | 0.367021 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.685512 | 0.617834 | 0.649916 | 0.617834 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.638298 | 0.652174 | 0.645161 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.689433 | 0.569755 | 0.623907 | 0.569755 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 14:42:03,921 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 14:42:17,683 - trainer - INFO] - Train Epoch:[35/100] Step:[60/250] Total Loss: 20.552254 GL_Loss: 0.596809 CRF_Loss: 19.955444\n",
      "[2022-02-17 14:42:31,661 - trainer - INFO] - Train Epoch:[35/100] Step:[70/250] Total Loss: 29.975855 GL_Loss: 0.363549 CRF_Loss: 29.612305\n",
      "[2022-02-17 14:42:46,717 - trainer - INFO] - Train Epoch:[35/100] Step:[80/250] Total Loss: 29.683424 GL_Loss: 0.571730 CRF_Loss: 29.111694\n",
      "[2022-02-17 14:43:00,475 - trainer - INFO] - Train Epoch:[35/100] Step:[90/250] Total Loss: 36.986134 GL_Loss: 0.658129 CRF_Loss: 36.328003\n",
      "[2022-02-17 14:43:14,289 - trainer - INFO] - Train Epoch:[35/100] Step:[100/250] Total Loss: 23.747143 GL_Loss: 0.367871 CRF_Loss: 23.379272\n",
      "[2022-02-17 14:43:33,452 - trainer - INFO] - [Step Validation] Epoch:[35/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.835294 | 0.904459 | 0.868502 | 0.904459 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.587983 | 0.364362 | 0.449918 | 0.364362 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.655629 | 0.630573 | 0.642857 | 0.630573 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.634409 | 0.641304 | 0.637838 | 0.641304 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.671679 | 0.57082  | 0.617156 | 0.57082  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 14:43:48,296 - trainer - INFO] - Train Epoch:[35/100] Step:[110/250] Total Loss: 46.446228 GL_Loss: 0.968324 CRF_Loss: 45.477905\n",
      "[2022-02-17 14:44:01,686 - trainer - INFO] - Train Epoch:[35/100] Step:[120/250] Total Loss: 14.509714 GL_Loss: 0.534128 CRF_Loss: 13.975586\n",
      "[2022-02-17 14:44:16,429 - trainer - INFO] - Train Epoch:[35/100] Step:[130/250] Total Loss: 18.953495 GL_Loss: 0.578984 CRF_Loss: 18.374512\n",
      "[2022-02-17 14:44:31,203 - trainer - INFO] - Train Epoch:[35/100] Step:[140/250] Total Loss: 24.954308 GL_Loss: 0.655358 CRF_Loss: 24.298950\n",
      "[2022-02-17 14:44:46,065 - trainer - INFO] - Train Epoch:[35/100] Step:[150/250] Total Loss: 127.692375 GL_Loss: 0.731435 CRF_Loss: 126.960938\n",
      "[2022-02-17 14:45:05,276 - trainer - INFO] - [Step Validation] Epoch:[35/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.845238 | 0.904459 | 0.873846 | 0.904459 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.596567 | 0.369681 | 0.456486 | 0.369681 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.702703 | 0.579618 | 0.635253 | 0.579618 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.642105 | 0.663043 | 0.652406 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.69404  | 0.55804  | 0.618654 | 0.55804  |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 14:45:18,863 - trainer - INFO] - Train Epoch:[35/100] Step:[160/250] Total Loss: 39.377968 GL_Loss: 0.558022 CRF_Loss: 38.819946\n",
      "[2022-02-17 14:45:33,061 - trainer - INFO] - Train Epoch:[35/100] Step:[170/250] Total Loss: 20.015995 GL_Loss: 0.337285 CRF_Loss: 19.678711\n",
      "[2022-02-17 14:45:46,974 - trainer - INFO] - Train Epoch:[35/100] Step:[180/250] Total Loss: 66.474892 GL_Loss: 0.682288 CRF_Loss: 65.792603\n",
      "[2022-02-17 14:46:02,063 - trainer - INFO] - Train Epoch:[35/100] Step:[190/250] Total Loss: 16.620607 GL_Loss: 0.655520 CRF_Loss: 15.965088\n",
      "[2022-02-17 14:46:16,201 - trainer - INFO] - Train Epoch:[35/100] Step:[200/250] Total Loss: 24.700493 GL_Loss: 0.636955 CRF_Loss: 24.063538\n",
      "[2022-02-17 14:46:35,283 - trainer - INFO] - [Step Validation] Epoch:[35/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.855422 | 0.904459 | 0.879257 | 0.904459 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.598291 | 0.37234  | 0.459016 | 0.37234  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.690141 | 0.624204 | 0.655518 | 0.624204 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.637363 | 0.630435 | 0.63388  | 0.630435 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.691613 | 0.57082  | 0.625438 | 0.57082  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 14:46:37,478 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 14:46:52,556 - trainer - INFO] - Train Epoch:[35/100] Step:[210/250] Total Loss: 20.125387 GL_Loss: 0.738057 CRF_Loss: 19.387329\n",
      "[2022-02-17 14:47:07,055 - trainer - INFO] - Train Epoch:[35/100] Step:[220/250] Total Loss: 103.599327 GL_Loss: 0.655356 CRF_Loss: 102.943970\n",
      "[2022-02-17 14:47:21,514 - trainer - INFO] - Train Epoch:[35/100] Step:[230/250] Total Loss: 64.335320 GL_Loss: 0.469474 CRF_Loss: 63.865845\n",
      "[2022-02-17 14:47:35,834 - trainer - INFO] - Train Epoch:[35/100] Step:[240/250] Total Loss: 31.012888 GL_Loss: 0.586251 CRF_Loss: 30.426636\n",
      "[2022-02-17 14:47:50,221 - trainer - INFO] - Train Epoch:[35/100] Step:[250/250] Total Loss: 22.632822 GL_Loss: 0.749888 CRF_Loss: 21.882935\n",
      "[2022-02-17 14:48:09,269 - trainer - INFO] - [Step Validation] Epoch:[35/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.85119  | 0.910828 | 0.88     | 0.910828 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.602564 | 0.375    | 0.462295 | 0.375    |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.660959 | 0.61465  | 0.636964 | 0.61465  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.642105 | 0.663043 | 0.652406 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.681876 | 0.57295  | 0.622685 | 0.57295  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 14:48:28,367 - trainer - INFO] - [Epoch Validation] Epoch:[35/100] Total Loss: 57.949839 GL_Loss: 0.006408 CRF_Loss: 57.309042 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.85119  | 0.910828 | 0.88     | 0.910828 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.602564 | 0.375    | 0.462295 | 0.375    |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.660959 | 0.61465  | 0.636964 | 0.61465  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.642105 | 0.663043 | 0.652406 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.681876 | 0.57295  | 0.622685 | 0.57295  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 14:48:43,705 - trainer - INFO] - Train Epoch:[36/100] Step:[10/250] Total Loss: 28.868616 GL_Loss: 0.655481 CRF_Loss: 28.213135\n",
      "[2022-02-17 14:48:57,875 - trainer - INFO] - Train Epoch:[36/100] Step:[20/250] Total Loss: 33.475025 GL_Loss: 0.534716 CRF_Loss: 32.940308\n",
      "[2022-02-17 14:49:11,225 - trainer - INFO] - Train Epoch:[36/100] Step:[30/250] Total Loss: 26.433685 GL_Loss: 0.491912 CRF_Loss: 25.941772\n",
      "[2022-02-17 14:49:25,708 - trainer - INFO] - Train Epoch:[36/100] Step:[40/250] Total Loss: 17.714121 GL_Loss: 0.318735 CRF_Loss: 17.395386\n",
      "[2022-02-17 14:49:39,222 - trainer - INFO] - Train Epoch:[36/100] Step:[50/250] Total Loss: 26.025990 GL_Loss: 0.421742 CRF_Loss: 25.604248\n",
      "[2022-02-17 14:49:58,330 - trainer - INFO] - [Step Validation] Epoch:[36/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.868263 | 0.923567 | 0.895062 | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.599138 | 0.369681 | 0.457237 | 0.369681 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.662069 | 0.611465 | 0.635762 | 0.611465 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.638298 | 0.652174 | 0.645161 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.684547 | 0.57082  | 0.622532 | 0.57082  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 14:50:12,695 - trainer - INFO] - Train Epoch:[36/100] Step:[60/250] Total Loss: 160.557846 GL_Loss: 0.640847 CRF_Loss: 159.916992\n",
      "[2022-02-17 14:50:27,779 - trainer - INFO] - Train Epoch:[36/100] Step:[70/250] Total Loss: 34.747578 GL_Loss: 0.987812 CRF_Loss: 33.759766\n",
      "[2022-02-17 14:50:41,707 - trainer - INFO] - Train Epoch:[36/100] Step:[80/250] Total Loss: 15.263667 GL_Loss: 0.909175 CRF_Loss: 14.354492\n",
      "[2022-02-17 14:50:55,756 - trainer - INFO] - Train Epoch:[36/100] Step:[90/250] Total Loss: 88.194168 GL_Loss: 0.421098 CRF_Loss: 87.773071\n",
      "[2022-02-17 14:51:09,240 - trainer - INFO] - Train Epoch:[36/100] Step:[100/250] Total Loss: 28.352602 GL_Loss: 0.435854 CRF_Loss: 27.916748\n",
      "[2022-02-17 14:51:28,146 - trainer - INFO] - [Step Validation] Epoch:[36/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.850299 | 0.904459 | 0.876543 | 0.904459 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.596567 | 0.369681 | 0.456486 | 0.369681 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.69145  | 0.592357 | 0.638079 | 0.592357 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.621053 | 0.641304 | 0.631016 | 0.641304 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.688482 | 0.56017  | 0.617733 | 0.56017  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 14:51:41,688 - trainer - INFO] - Train Epoch:[36/100] Step:[110/250] Total Loss: 44.379013 GL_Loss: 0.788559 CRF_Loss: 43.590454\n",
      "[2022-02-17 14:51:56,173 - trainer - INFO] - Train Epoch:[36/100] Step:[120/250] Total Loss: 47.358253 GL_Loss: 0.515723 CRF_Loss: 46.842529\n",
      "[2022-02-17 14:52:10,881 - trainer - INFO] - Train Epoch:[36/100] Step:[130/250] Total Loss: 26.000029 GL_Loss: 0.686918 CRF_Loss: 25.313110\n",
      "[2022-02-17 14:52:25,194 - trainer - INFO] - Train Epoch:[36/100] Step:[140/250] Total Loss: 29.797348 GL_Loss: 0.377792 CRF_Loss: 29.419556\n",
      "[2022-02-17 14:52:39,837 - trainer - INFO] - Train Epoch:[36/100] Step:[150/250] Total Loss: 27.562183 GL_Loss: 0.388722 CRF_Loss: 27.173462\n",
      "[2022-02-17 14:52:58,967 - trainer - INFO] - [Step Validation] Epoch:[36/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.862275 | 0.917197 | 0.888889 | 0.917197 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.60515  | 0.375    | 0.463054 | 0.375    |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.670175 | 0.60828  | 0.63773  | 0.60828  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.628866 | 0.663043 | 0.645503 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.686701 | 0.571885 | 0.624056 | 0.571885 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 14:53:12,637 - trainer - INFO] - Train Epoch:[36/100] Step:[160/250] Total Loss: 29.515026 GL_Loss: 0.635632 CRF_Loss: 28.879395\n",
      "[2022-02-17 14:53:27,427 - trainer - INFO] - Train Epoch:[36/100] Step:[170/250] Total Loss: 58.119610 GL_Loss: 0.710187 CRF_Loss: 57.409424\n",
      "[2022-02-17 14:53:42,256 - trainer - INFO] - Train Epoch:[36/100] Step:[180/250] Total Loss: 39.430012 GL_Loss: 0.544879 CRF_Loss: 38.885132\n",
      "[2022-02-17 14:53:56,353 - trainer - INFO] - Train Epoch:[36/100] Step:[190/250] Total Loss: 21.351673 GL_Loss: 0.490039 CRF_Loss: 20.861633\n",
      "[2022-02-17 14:54:10,782 - trainer - INFO] - Train Epoch:[36/100] Step:[200/250] Total Loss: 29.020010 GL_Loss: 0.567129 CRF_Loss: 28.452881\n",
      "[2022-02-17 14:54:29,932 - trainer - INFO] - [Step Validation] Epoch:[36/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.85119  | 0.910828 | 0.88     | 0.910828 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.588745 | 0.361702 | 0.448105 | 0.361702 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.658621 | 0.60828  | 0.63245  | 0.60828  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.638298 | 0.652174 | 0.645161 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.676884 | 0.56443  | 0.615563 | 0.56443  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 14:54:43,618 - trainer - INFO] - Train Epoch:[36/100] Step:[210/250] Total Loss: 39.119663 GL_Loss: 0.508456 CRF_Loss: 38.611206\n",
      "[2022-02-17 14:54:57,857 - trainer - INFO] - Train Epoch:[36/100] Step:[220/250] Total Loss: 21.646717 GL_Loss: 0.531727 CRF_Loss: 21.114990\n",
      "[2022-02-17 14:55:12,001 - trainer - INFO] - Train Epoch:[36/100] Step:[230/250] Total Loss: 146.242493 GL_Loss: 0.506168 CRF_Loss: 145.736328\n",
      "[2022-02-17 14:55:26,641 - trainer - INFO] - Train Epoch:[36/100] Step:[240/250] Total Loss: 74.812897 GL_Loss: 0.536774 CRF_Loss: 74.276123\n",
      "[2022-02-17 14:55:40,279 - trainer - INFO] - Train Epoch:[36/100] Step:[250/250] Total Loss: 35.096687 GL_Loss: 0.418832 CRF_Loss: 34.677856\n",
      "[2022-02-17 14:56:00,781 - trainer - INFO] - [Step Validation] Epoch:[36/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.847059 | 0.917197 | 0.880734 | 0.917197 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.614719 | 0.37766  | 0.467875 | 0.37766  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.684982 | 0.595541 | 0.637138 | 0.595541 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.642105 | 0.663043 | 0.652406 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.694408 | 0.56869  | 0.625293 | 0.56869  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 14:56:19,997 - trainer - INFO] - [Epoch Validation] Epoch:[36/100] Total Loss: 58.481853 GL_Loss: 0.005818 CRF_Loss: 57.900065 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.847059 | 0.917197 | 0.880734 | 0.917197 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.614719 | 0.37766  | 0.467875 | 0.37766  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.684982 | 0.595541 | 0.637138 | 0.595541 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.642105 | 0.663043 | 0.652406 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.694408 | 0.56869  | 0.625293 | 0.56869  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 14:56:35,114 - trainer - INFO] - Train Epoch:[37/100] Step:[10/250] Total Loss: 19.134052 GL_Loss: 0.603535 CRF_Loss: 18.530518\n",
      "[2022-02-17 14:56:48,476 - trainer - INFO] - Train Epoch:[37/100] Step:[20/250] Total Loss: 57.129204 GL_Loss: 0.649345 CRF_Loss: 56.479858\n",
      "[2022-02-17 14:57:01,780 - trainer - INFO] - Train Epoch:[37/100] Step:[30/250] Total Loss: 33.306671 GL_Loss: 0.784087 CRF_Loss: 32.522583\n",
      "[2022-02-17 14:57:15,680 - trainer - INFO] - Train Epoch:[37/100] Step:[40/250] Total Loss: 54.020462 GL_Loss: 0.763381 CRF_Loss: 53.257080\n",
      "[2022-02-17 14:57:30,480 - trainer - INFO] - Train Epoch:[37/100] Step:[50/250] Total Loss: 63.025177 GL_Loss: 0.540435 CRF_Loss: 62.484741\n",
      "[2022-02-17 14:57:49,617 - trainer - INFO] - [Step Validation] Epoch:[37/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.85119  | 0.910828 | 0.88     | 0.910828 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.596491 | 0.361702 | 0.450331 | 0.361702 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.690037 | 0.595541 | 0.639316 | 0.595541 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.642105 | 0.663043 | 0.652406 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.691601 | 0.561235 | 0.619636 | 0.561235 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 14:58:04,743 - trainer - INFO] - Train Epoch:[37/100] Step:[60/250] Total Loss: 158.534958 GL_Loss: 0.678262 CRF_Loss: 157.856689\n",
      "[2022-02-17 14:58:19,488 - trainer - INFO] - Train Epoch:[37/100] Step:[70/250] Total Loss: 35.273094 GL_Loss: 0.544580 CRF_Loss: 34.728516\n",
      "[2022-02-17 14:58:34,803 - trainer - INFO] - Train Epoch:[37/100] Step:[80/250] Total Loss: 41.540649 GL_Loss: 0.434937 CRF_Loss: 41.105713\n",
      "[2022-02-17 14:58:49,844 - trainer - INFO] - Train Epoch:[37/100] Step:[90/250] Total Loss: 34.495667 GL_Loss: 0.405335 CRF_Loss: 34.090332\n",
      "[2022-02-17 14:59:03,670 - trainer - INFO] - Train Epoch:[37/100] Step:[100/250] Total Loss: 55.056572 GL_Loss: 0.685235 CRF_Loss: 54.371338\n",
      "[2022-02-17 14:59:22,827 - trainer - INFO] - [Step Validation] Epoch:[37/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.839286 | 0.898089 | 0.867692 | 0.898089 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.587719 | 0.356383 | 0.443709 | 0.356383 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.729167 | 0.557325 | 0.631769 | 0.557325 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.634409 | 0.641304 | 0.637838 | 0.641304 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.698217 | 0.542066 | 0.610312 | 0.542066 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 14:59:37,806 - trainer - INFO] - Train Epoch:[37/100] Step:[110/250] Total Loss: 18.967365 GL_Loss: 0.623126 CRF_Loss: 18.344238\n",
      "[2022-02-17 14:59:52,197 - trainer - INFO] - Train Epoch:[37/100] Step:[120/250] Total Loss: 21.176649 GL_Loss: 0.558851 CRF_Loss: 20.617798\n",
      "[2022-02-17 15:00:05,866 - trainer - INFO] - Train Epoch:[37/100] Step:[130/250] Total Loss: 93.783691 GL_Loss: 0.476926 CRF_Loss: 93.306763\n",
      "[2022-02-17 15:00:19,570 - trainer - INFO] - Train Epoch:[37/100] Step:[140/250] Total Loss: 29.289948 GL_Loss: 0.692170 CRF_Loss: 28.597778\n",
      "[2022-02-17 15:00:34,267 - trainer - INFO] - Train Epoch:[37/100] Step:[150/250] Total Loss: 28.144751 GL_Loss: 0.840307 CRF_Loss: 27.304443\n",
      "[2022-02-17 15:00:53,515 - trainer - INFO] - [Step Validation] Epoch:[37/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.856287 | 0.910828 | 0.882716 | 0.910828 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.591304 | 0.361702 | 0.448845 | 0.361702 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.673611 | 0.617834 | 0.644518 | 0.617834 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.648936 | 0.663043 | 0.655914 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.685494 | 0.56869  | 0.621653 | 0.56869  |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 15:01:06,543 - trainer - INFO] - Train Epoch:[37/100] Step:[160/250] Total Loss: 24.576899 GL_Loss: 0.496576 CRF_Loss: 24.080322\n",
      "[2022-02-17 15:01:20,877 - trainer - INFO] - Train Epoch:[37/100] Step:[170/250] Total Loss: 38.100918 GL_Loss: 0.613430 CRF_Loss: 37.487488\n",
      "[2022-02-17 15:01:35,506 - trainer - INFO] - Train Epoch:[37/100] Step:[180/250] Total Loss: 30.414711 GL_Loss: 0.585122 CRF_Loss: 29.829590\n",
      "[2022-02-17 15:01:50,733 - trainer - INFO] - Train Epoch:[37/100] Step:[190/250] Total Loss: 31.922071 GL_Loss: 1.047925 CRF_Loss: 30.874146\n",
      "[2022-02-17 15:02:05,513 - trainer - INFO] - Train Epoch:[37/100] Step:[200/250] Total Loss: 118.178154 GL_Loss: 0.440971 CRF_Loss: 117.737183\n",
      "[2022-02-17 15:02:24,571 - trainer - INFO] - [Step Validation] Epoch:[37/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.85119  | 0.910828 | 0.88     | 0.910828 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.601732 | 0.369681 | 0.45799  | 0.369681 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.68705  | 0.60828  | 0.64527  | 0.60828  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.634409 | 0.641304 | 0.637838 | 0.641304 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.690909 | 0.56656  | 0.622586 | 0.56656  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 15:02:38,480 - trainer - INFO] - Train Epoch:[37/100] Step:[210/250] Total Loss: 23.499054 GL_Loss: 0.417632 CRF_Loss: 23.081421\n",
      "[2022-02-17 15:02:53,358 - trainer - INFO] - Train Epoch:[37/100] Step:[220/250] Total Loss: 91.375847 GL_Loss: 0.540519 CRF_Loss: 90.835327\n",
      "[2022-02-17 15:03:07,757 - trainer - INFO] - Train Epoch:[37/100] Step:[230/250] Total Loss: 58.295948 GL_Loss: 0.457934 CRF_Loss: 57.838013\n",
      "[2022-02-17 15:03:22,027 - trainer - INFO] - Train Epoch:[37/100] Step:[240/250] Total Loss: 60.667160 GL_Loss: 0.877855 CRF_Loss: 59.789307\n",
      "[2022-02-17 15:03:36,418 - trainer - INFO] - Train Epoch:[37/100] Step:[250/250] Total Loss: 25.534468 GL_Loss: 0.729292 CRF_Loss: 24.805176\n",
      "[2022-02-17 15:03:55,679 - trainer - INFO] - [Step Validation] Epoch:[37/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.861446 | 0.910828 | 0.885449 | 0.910828 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.62069  | 0.382979 | 0.473684 | 0.382979 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.630225 | 0.624204 | 0.6272   | 0.624204 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.642105 | 0.663043 | 0.652406 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.676617 | 0.57934  | 0.624211 | 0.57934  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 15:04:14,857 - trainer - INFO] - [Epoch Validation] Epoch:[37/100] Total Loss: 57.301930 GL_Loss: 0.006207 CRF_Loss: 56.681230 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.861446 | 0.910828 | 0.885449 | 0.910828 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.62069  | 0.382979 | 0.473684 | 0.382979 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.630225 | 0.624204 | 0.6272   | 0.624204 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.642105 | 0.663043 | 0.652406 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.676617 | 0.57934  | 0.624211 | 0.57934  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 15:04:28,829 - trainer - INFO] - Train Epoch:[38/100] Step:[10/250] Total Loss: 12.200851 GL_Loss: 0.362351 CRF_Loss: 11.838501\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 15:04:43,349 - trainer - INFO] - Train Epoch:[38/100] Step:[20/250] Total Loss: 48.653503 GL_Loss: 0.813049 CRF_Loss: 47.840454\n",
      "[2022-02-17 15:04:58,108 - trainer - INFO] - Train Epoch:[38/100] Step:[30/250] Total Loss: 18.938000 GL_Loss: 0.452525 CRF_Loss: 18.485474\n",
      "[2022-02-17 15:05:12,668 - trainer - INFO] - Train Epoch:[38/100] Step:[40/250] Total Loss: 99.532997 GL_Loss: 0.383215 CRF_Loss: 99.149780\n",
      "[2022-02-17 15:05:27,887 - trainer - INFO] - Train Epoch:[38/100] Step:[50/250] Total Loss: 12.336627 GL_Loss: 0.621295 CRF_Loss: 11.715332\n",
      "[2022-02-17 15:05:47,117 - trainer - INFO] - [Step Validation] Epoch:[38/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.862275 | 0.917197 | 0.888889 | 0.917197 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.607759 | 0.375    | 0.463816 | 0.375    |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.720648 | 0.566879 | 0.634581 | 0.566879 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.625    | 0.652174 | 0.638298 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.704852 | 0.556976 | 0.622249 | 0.556976 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 15:06:03,548 - trainer - INFO] - Train Epoch:[38/100] Step:[60/250] Total Loss: 41.258606 GL_Loss: 0.666076 CRF_Loss: 40.592529\n",
      "[2022-02-17 15:06:18,524 - trainer - INFO] - Train Epoch:[38/100] Step:[70/250] Total Loss: 30.793701 GL_Loss: 0.440674 CRF_Loss: 30.353027\n",
      "[2022-02-17 15:06:33,066 - trainer - INFO] - Train Epoch:[38/100] Step:[80/250] Total Loss: 48.509384 GL_Loss: 0.465562 CRF_Loss: 48.043823\n",
      "[2022-02-17 15:06:47,602 - trainer - INFO] - Train Epoch:[38/100] Step:[90/250] Total Loss: 47.791088 GL_Loss: 0.547558 CRF_Loss: 47.243530\n",
      "[2022-02-17 15:07:01,935 - trainer - INFO] - Train Epoch:[38/100] Step:[100/250] Total Loss: 59.141838 GL_Loss: 0.520866 CRF_Loss: 58.620972\n",
      "[2022-02-17 15:07:20,928 - trainer - INFO] - [Step Validation] Epoch:[38/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.862275 | 0.917197 | 0.888889 | 0.917197 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.615385 | 0.382979 | 0.472131 | 0.382979 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.616099 | 0.633758 | 0.624804 | 0.633758 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.62766  | 0.641304 | 0.634409 | 0.641304 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.667482 | 0.58147  | 0.621514 | 0.58147  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 15:07:34,648 - trainer - INFO] - Train Epoch:[38/100] Step:[110/250] Total Loss: 13.495669 GL_Loss: 0.455752 CRF_Loss: 13.039917\n",
      "[2022-02-17 15:07:49,543 - trainer - INFO] - Train Epoch:[38/100] Step:[120/250] Total Loss: 34.097229 GL_Loss: 0.418884 CRF_Loss: 33.678345\n",
      "[2022-02-17 15:08:04,511 - trainer - INFO] - Train Epoch:[38/100] Step:[130/250] Total Loss: 41.374012 GL_Loss: 1.022207 CRF_Loss: 40.351807\n",
      "[2022-02-17 15:08:19,998 - trainer - INFO] - Train Epoch:[38/100] Step:[140/250] Total Loss: 45.730202 GL_Loss: 0.475077 CRF_Loss: 45.255127\n",
      "[2022-02-17 15:08:35,203 - trainer - INFO] - Train Epoch:[38/100] Step:[150/250] Total Loss: 87.734627 GL_Loss: 0.443979 CRF_Loss: 87.290649\n",
      "[2022-02-17 15:08:54,486 - trainer - INFO] - [Step Validation] Epoch:[38/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.857988 | 0.923567 | 0.889571 | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.615385 | 0.382979 | 0.472131 | 0.382979 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.706107 | 0.589172 | 0.642361 | 0.589172 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.648936 | 0.663043 | 0.655914 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.704875 | 0.569755 | 0.630153 | 0.569755 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 15:08:56,666 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 15:09:10,398 - trainer - INFO] - Train Epoch:[38/100] Step:[160/250] Total Loss: 25.372194 GL_Loss: 0.593385 CRF_Loss: 24.778809\n",
      "[2022-02-17 15:09:24,173 - trainer - INFO] - Train Epoch:[38/100] Step:[170/250] Total Loss: 19.956741 GL_Loss: 0.520218 CRF_Loss: 19.436523\n",
      "[2022-02-17 15:09:37,692 - trainer - INFO] - Train Epoch:[38/100] Step:[180/250] Total Loss: 33.187763 GL_Loss: 0.687640 CRF_Loss: 32.500122\n",
      "[2022-02-17 15:09:51,815 - trainer - INFO] - Train Epoch:[38/100] Step:[190/250] Total Loss: 26.163246 GL_Loss: 0.448525 CRF_Loss: 25.714722\n",
      "[2022-02-17 15:10:05,827 - trainer - INFO] - Train Epoch:[38/100] Step:[200/250] Total Loss: 54.957211 GL_Loss: 0.378596 CRF_Loss: 54.578613\n",
      "[2022-02-17 15:10:25,053 - trainer - INFO] - [Step Validation] Epoch:[38/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.806061 | 0.847134 | 0.826087 | 0.847134 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.575221 | 0.345745 | 0.431894 | 0.345745 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.7343   | 0.484076 | 0.583493 | 0.484076 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.659574 | 0.673913 | 0.666667 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.689306 | 0.507987 | 0.584917 | 0.507987 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 15:10:39,970 - trainer - INFO] - Train Epoch:[38/100] Step:[210/250] Total Loss: 111.301529 GL_Loss: 0.585100 CRF_Loss: 110.716431\n",
      "[2022-02-17 15:10:54,801 - trainer - INFO] - Train Epoch:[38/100] Step:[220/250] Total Loss: 87.301826 GL_Loss: 0.387278 CRF_Loss: 86.914551\n",
      "[2022-02-17 15:11:07,645 - trainer - INFO] - Train Epoch:[38/100] Step:[230/250] Total Loss: 25.955830 GL_Loss: 0.740132 CRF_Loss: 25.215698\n",
      "[2022-02-17 15:11:22,101 - trainer - INFO] - Train Epoch:[38/100] Step:[240/250] Total Loss: 142.655640 GL_Loss: 0.604973 CRF_Loss: 142.050659\n",
      "[2022-02-17 15:11:36,716 - trainer - INFO] - Train Epoch:[38/100] Step:[250/250] Total Loss: 29.044432 GL_Loss: 0.451293 CRF_Loss: 28.593140\n",
      "[2022-02-17 15:11:55,841 - trainer - INFO] - [Step Validation] Epoch:[38/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.878049 | 0.917197 | 0.897196 | 0.917197 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.64135  | 0.404255 | 0.495922 | 0.404255 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.683453 | 0.605096 | 0.641892 | 0.605096 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.635417 | 0.663043 | 0.648936 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.705806 | 0.582535 | 0.638273 | 0.582535 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 15:11:58,003 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 15:12:17,169 - trainer - INFO] - [Epoch Validation] Epoch:[38/100] Total Loss: 55.662847 GL_Loss: 0.005801 CRF_Loss: 55.082758 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.878049 | 0.917197 | 0.897196 | 0.917197 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.64135  | 0.404255 | 0.495922 | 0.404255 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.683453 | 0.605096 | 0.641892 | 0.605096 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.635417 | 0.663043 | 0.648936 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.705806 | 0.582535 | 0.638273 | 0.582535 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 15:12:32,025 - trainer - INFO] - Train Epoch:[39/100] Step:[10/250] Total Loss: 21.493277 GL_Loss: 0.972525 CRF_Loss: 20.520752\n",
      "[2022-02-17 15:12:46,823 - trainer - INFO] - Train Epoch:[39/100] Step:[20/250] Total Loss: 146.344864 GL_Loss: 0.586325 CRF_Loss: 145.758545\n",
      "[2022-02-17 15:13:00,262 - trainer - INFO] - Train Epoch:[39/100] Step:[30/250] Total Loss: 34.197639 GL_Loss: 0.712959 CRF_Loss: 33.484680\n",
      "[2022-02-17 15:13:14,299 - trainer - INFO] - Train Epoch:[39/100] Step:[40/250] Total Loss: 31.094288 GL_Loss: 0.691212 CRF_Loss: 30.403076\n",
      "[2022-02-17 15:13:28,238 - trainer - INFO] - Train Epoch:[39/100] Step:[50/250] Total Loss: 41.121162 GL_Loss: 0.694769 CRF_Loss: 40.426392\n",
      "[2022-02-17 15:13:47,374 - trainer - INFO] - [Step Validation] Epoch:[39/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.830303 | 0.872611 | 0.850932 | 0.872611 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.635593 | 0.398936 | 0.490196 | 0.398936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.67037  | 0.576433 | 0.619863 | 0.576433 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.645161 | 0.652174 | 0.648649 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.691099 | 0.5623   | 0.620082 | 0.5623   |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 15:14:01,387 - trainer - INFO] - Train Epoch:[39/100] Step:[60/250] Total Loss: 27.932339 GL_Loss: 0.927701 CRF_Loss: 27.004639\n",
      "[2022-02-17 15:14:16,336 - trainer - INFO] - Train Epoch:[39/100] Step:[70/250] Total Loss: 42.056339 GL_Loss: 0.726260 CRF_Loss: 41.330078\n",
      "[2022-02-17 15:14:30,276 - trainer - INFO] - Train Epoch:[39/100] Step:[80/250] Total Loss: 21.528685 GL_Loss: 0.454711 CRF_Loss: 21.073975\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 15:14:44,162 - trainer - INFO] - Train Epoch:[39/100] Step:[90/250] Total Loss: 61.158192 GL_Loss: 0.899891 CRF_Loss: 60.258301\n",
      "[2022-02-17 15:14:57,491 - trainer - INFO] - Train Epoch:[39/100] Step:[100/250] Total Loss: 21.923584 GL_Loss: 0.328125 CRF_Loss: 21.595459\n",
      "[2022-02-17 15:15:16,544 - trainer - INFO] - [Step Validation] Epoch:[39/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.859756 | 0.898089 | 0.878505 | 0.898089 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.629787 | 0.393617 | 0.484452 | 0.393617 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.687732 | 0.589172 | 0.634648 | 0.589172 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.641304 | 0.641304 | 0.641304 | 0.641304 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.701316 | 0.567625 | 0.627428 | 0.567625 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 15:15:30,788 - trainer - INFO] - Train Epoch:[39/100] Step:[110/250] Total Loss: 18.985975 GL_Loss: 1.020766 CRF_Loss: 17.965210\n",
      "[2022-02-17 15:15:44,721 - trainer - INFO] - Train Epoch:[39/100] Step:[120/250] Total Loss: 35.871048 GL_Loss: 0.380082 CRF_Loss: 35.490967\n",
      "[2022-02-17 15:15:58,999 - trainer - INFO] - Train Epoch:[39/100] Step:[130/250] Total Loss: 35.379982 GL_Loss: 0.433691 CRF_Loss: 34.946289\n",
      "[2022-02-17 15:16:12,762 - trainer - INFO] - Train Epoch:[39/100] Step:[140/250] Total Loss: 72.665520 GL_Loss: 0.351918 CRF_Loss: 72.313599\n",
      "[2022-02-17 15:16:27,260 - trainer - INFO] - Train Epoch:[39/100] Step:[150/250] Total Loss: 49.847401 GL_Loss: 0.501331 CRF_Loss: 49.346069\n",
      "[2022-02-17 15:16:46,233 - trainer - INFO] - [Step Validation] Epoch:[39/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.855422 | 0.904459 | 0.879257 | 0.904459 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.599138 | 0.369681 | 0.457237 | 0.369681 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.653846 | 0.595541 | 0.623333 | 0.595541 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.631579 | 0.652174 | 0.641711 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.677792 | 0.5623   | 0.614668 | 0.5623   |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 15:17:00,270 - trainer - INFO] - Train Epoch:[39/100] Step:[160/250] Total Loss: 32.374207 GL_Loss: 0.731141 CRF_Loss: 31.643066\n",
      "[2022-02-17 15:17:14,086 - trainer - INFO] - Train Epoch:[39/100] Step:[170/250] Total Loss: 57.000355 GL_Loss: 0.553945 CRF_Loss: 56.446411\n",
      "[2022-02-17 15:17:28,445 - trainer - INFO] - Train Epoch:[39/100] Step:[180/250] Total Loss: 41.333508 GL_Loss: 0.378916 CRF_Loss: 40.954590\n",
      "[2022-02-17 15:17:43,196 - trainer - INFO] - Train Epoch:[39/100] Step:[190/250] Total Loss: 54.996231 GL_Loss: 0.504044 CRF_Loss: 54.492188\n",
      "[2022-02-17 15:17:57,547 - trainer - INFO] - Train Epoch:[39/100] Step:[200/250] Total Loss: 13.055114 GL_Loss: 0.460509 CRF_Loss: 12.594604\n",
      "[2022-02-17 15:18:16,856 - trainer - INFO] - [Step Validation] Epoch:[39/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.879518 | 0.929936 | 0.904025 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.617391 | 0.37766  | 0.468647 | 0.37766  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.69708  | 0.60828  | 0.64966  | 0.60828  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.652174 | 0.652174 | 0.652174 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.707349 | 0.574015 | 0.633745 | 0.574015 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 15:18:31,632 - trainer - INFO] - Train Epoch:[39/100] Step:[210/250] Total Loss: 36.625900 GL_Loss: 0.897873 CRF_Loss: 35.728027\n",
      "[2022-02-17 15:18:45,825 - trainer - INFO] - Train Epoch:[39/100] Step:[220/250] Total Loss: 28.200146 GL_Loss: 0.810742 CRF_Loss: 27.389404\n",
      "[2022-02-17 15:19:00,295 - trainer - INFO] - Train Epoch:[39/100] Step:[230/250] Total Loss: 18.297903 GL_Loss: 0.389455 CRF_Loss: 17.908447\n",
      "[2022-02-17 15:19:13,881 - trainer - INFO] - Train Epoch:[39/100] Step:[240/250] Total Loss: 50.842510 GL_Loss: 0.417338 CRF_Loss: 50.425171\n",
      "[2022-02-17 15:19:29,200 - trainer - INFO] - Train Epoch:[39/100] Step:[250/250] Total Loss: 81.730896 GL_Loss: 0.378604 CRF_Loss: 81.352295\n",
      "[2022-02-17 15:19:48,311 - trainer - INFO] - [Step Validation] Epoch:[39/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.878788 | 0.923567 | 0.900621 | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.607759 | 0.375    | 0.463816 | 0.375    |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.714829 | 0.598726 | 0.651646 | 0.598726 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.645161 | 0.652174 | 0.648649 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.709163 | 0.56869  | 0.631206 | 0.56869  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 15:20:07,527 - trainer - INFO] - [Epoch Validation] Epoch:[39/100] Total Loss: 54.780628 GL_Loss: 0.005510 CRF_Loss: 54.229593 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.878788 | 0.923567 | 0.900621 | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.607759 | 0.375    | 0.463816 | 0.375    |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.714829 | 0.598726 | 0.651646 | 0.598726 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.645161 | 0.652174 | 0.648649 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.709163 | 0.56869  | 0.631206 | 0.56869  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 15:20:22,529 - trainer - INFO] - Train Epoch:[40/100] Step:[10/250] Total Loss: 13.846278 GL_Loss: 0.509120 CRF_Loss: 13.337158\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 15:20:36,769 - trainer - INFO] - Train Epoch:[40/100] Step:[20/250] Total Loss: 55.137245 GL_Loss: 0.569254 CRF_Loss: 54.567993\n",
      "[2022-02-17 15:20:51,269 - trainer - INFO] - Train Epoch:[40/100] Step:[30/250] Total Loss: 16.278168 GL_Loss: 0.540985 CRF_Loss: 15.737183\n",
      "[2022-02-17 15:21:05,619 - trainer - INFO] - Train Epoch:[40/100] Step:[40/250] Total Loss: 26.873964 GL_Loss: 0.615420 CRF_Loss: 26.258545\n",
      "[2022-02-17 15:21:20,507 - trainer - INFO] - Train Epoch:[40/100] Step:[50/250] Total Loss: 16.021704 GL_Loss: 0.548925 CRF_Loss: 15.472778\n",
      "[2022-02-17 15:21:39,502 - trainer - INFO] - [Step Validation] Epoch:[40/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.884146 | 0.923567 | 0.903427 | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.599138 | 0.369681 | 0.457237 | 0.369681 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.699248 | 0.592357 | 0.641379 | 0.592357 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.630435 | 0.630435 | 0.630435 | 0.630435 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.700265 | 0.5623   | 0.623745 | 0.5623   |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 15:21:52,810 - trainer - INFO] - Train Epoch:[40/100] Step:[60/250] Total Loss: 66.564224 GL_Loss: 1.293229 CRF_Loss: 65.270996\n",
      "[2022-02-17 15:22:07,975 - trainer - INFO] - Train Epoch:[40/100] Step:[70/250] Total Loss: 35.920956 GL_Loss: 0.365415 CRF_Loss: 35.555542\n",
      "[2022-02-17 15:22:23,479 - trainer - INFO] - Train Epoch:[40/100] Step:[80/250] Total Loss: 62.632965 GL_Loss: 0.408113 CRF_Loss: 62.224854\n",
      "[2022-02-17 15:22:38,852 - trainer - INFO] - Train Epoch:[40/100] Step:[90/250] Total Loss: 27.575308 GL_Loss: 0.782949 CRF_Loss: 26.792358\n",
      "[2022-02-17 15:22:54,341 - trainer - INFO] - Train Epoch:[40/100] Step:[100/250] Total Loss: 20.266714 GL_Loss: 0.543325 CRF_Loss: 19.723389\n",
      "[2022-02-17 15:23:13,665 - trainer - INFO] - [Step Validation] Epoch:[40/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.836364 | 0.878981 | 0.857143 | 0.878981 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.599138 | 0.369681 | 0.457237 | 0.369681 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.694118 | 0.563694 | 0.622144 | 0.563694 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.652174 | 0.652174 | 0.652174 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.69086  | 0.547391 | 0.610814 | 0.547391 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 15:23:27,610 - trainer - INFO] - Train Epoch:[40/100] Step:[110/250] Total Loss: 36.034538 GL_Loss: 0.493280 CRF_Loss: 35.541260\n",
      "[2022-02-17 15:23:42,155 - trainer - INFO] - Train Epoch:[40/100] Step:[120/250] Total Loss: 20.304676 GL_Loss: 0.726673 CRF_Loss: 19.578003\n",
      "[2022-02-17 15:23:55,983 - trainer - INFO] - Train Epoch:[40/100] Step:[130/250] Total Loss: 387.563385 GL_Loss: 0.548244 CRF_Loss: 387.015137\n",
      "[2022-02-17 15:24:09,715 - trainer - INFO] - Train Epoch:[40/100] Step:[140/250] Total Loss: 16.176598 GL_Loss: 0.587242 CRF_Loss: 15.589355\n",
      "[2022-02-17 15:24:24,883 - trainer - INFO] - Train Epoch:[40/100] Step:[150/250] Total Loss: 13.057622 GL_Loss: 0.712041 CRF_Loss: 12.345581\n",
      "[2022-02-17 15:24:44,139 - trainer - INFO] - [Step Validation] Epoch:[40/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.878788 | 0.923567 | 0.900621 | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.621849 | 0.393617 | 0.482085 | 0.393617 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.640264 | 0.617834 | 0.628849 | 0.617834 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.663043 | 0.663043 | 0.663043 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.686717 | 0.5836   | 0.630973 | 0.5836   |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 15:24:57,998 - trainer - INFO] - Train Epoch:[40/100] Step:[160/250] Total Loss: 55.949612 GL_Loss: 1.183620 CRF_Loss: 54.765991\n",
      "[2022-02-17 15:25:12,587 - trainer - INFO] - Train Epoch:[40/100] Step:[170/250] Total Loss: 31.042864 GL_Loss: 0.535784 CRF_Loss: 30.507080\n",
      "[2022-02-17 15:25:26,183 - trainer - INFO] - Train Epoch:[40/100] Step:[180/250] Total Loss: 34.736542 GL_Loss: 0.509856 CRF_Loss: 34.226685\n",
      "[2022-02-17 15:25:40,464 - trainer - INFO] - Train Epoch:[40/100] Step:[190/250] Total Loss: 23.043068 GL_Loss: 0.713355 CRF_Loss: 22.329712\n",
      "[2022-02-17 15:25:54,550 - trainer - INFO] - Train Epoch:[40/100] Step:[200/250] Total Loss: 67.033600 GL_Loss: 0.414764 CRF_Loss: 66.618835\n",
      "[2022-02-17 15:26:13,631 - trainer - INFO] - [Step Validation] Epoch:[40/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.885542 | 0.936306 | 0.910217 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.631356 | 0.396277 | 0.486928 | 0.396277 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.673684 | 0.611465 | 0.641068 | 0.611465 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688172 | 0.695652 | 0.691892 | 0.695652 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.707692 | 0.587859 | 0.642234 | 0.587859 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 15:26:15,753 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 15:26:30,251 - trainer - INFO] - Train Epoch:[40/100] Step:[210/250] Total Loss: 38.592541 GL_Loss: 0.542248 CRF_Loss: 38.050293\n",
      "[2022-02-17 15:26:44,867 - trainer - INFO] - Train Epoch:[40/100] Step:[220/250] Total Loss: 38.191521 GL_Loss: 0.724968 CRF_Loss: 37.466553\n",
      "[2022-02-17 15:26:59,241 - trainer - INFO] - Train Epoch:[40/100] Step:[230/250] Total Loss: 64.150558 GL_Loss: 0.634930 CRF_Loss: 63.515625\n",
      "[2022-02-17 15:27:13,717 - trainer - INFO] - Train Epoch:[40/100] Step:[240/250] Total Loss: 17.030304 GL_Loss: 0.732575 CRF_Loss: 16.297729\n",
      "[2022-02-17 15:27:28,023 - trainer - INFO] - Train Epoch:[40/100] Step:[250/250] Total Loss: 14.265877 GL_Loss: 0.731208 CRF_Loss: 13.534668\n",
      "[2022-02-17 15:27:47,387 - trainer - INFO] - [Step Validation] Epoch:[40/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.884146 | 0.923567 | 0.903427 | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.619048 | 0.380319 | 0.47117  | 0.380319 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.722656 | 0.589172 | 0.649123 | 0.589172 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.635417 | 0.663043 | 0.648936 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.714859 | 0.56869  | 0.633452 | 0.56869  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 15:28:07,566 - trainer - INFO] - [Epoch Validation] Epoch:[40/100] Total Loss: 54.891056 GL_Loss: 0.006009 CRF_Loss: 54.290175 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.884146 | 0.923567 | 0.903427 | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.619048 | 0.380319 | 0.47117  | 0.380319 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.722656 | 0.589172 | 0.649123 | 0.589172 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.635417 | 0.663043 | 0.648936 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.714859 | 0.56869  | 0.633452 | 0.56869  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 15:28:09,299 - trainer - INFO] - Saving checkpoint: saved/models/PICK_Default/test_0217_100852/checkpoint-epoch40.pth ...\n",
      "[2022-02-17 15:28:23,104 - trainer - INFO] - Train Epoch:[41/100] Step:[10/250] Total Loss: 14.611844 GL_Loss: 0.780301 CRF_Loss: 13.831543\n",
      "[2022-02-17 15:28:38,035 - trainer - INFO] - Train Epoch:[41/100] Step:[20/250] Total Loss: 21.186832 GL_Loss: 0.505437 CRF_Loss: 20.681396\n",
      "[2022-02-17 15:28:52,726 - trainer - INFO] - Train Epoch:[41/100] Step:[30/250] Total Loss: 98.120651 GL_Loss: 0.496021 CRF_Loss: 97.624634\n",
      "[2022-02-17 15:29:05,934 - trainer - INFO] - Train Epoch:[41/100] Step:[40/250] Total Loss: 101.933739 GL_Loss: 0.541038 CRF_Loss: 101.392700\n",
      "[2022-02-17 15:29:20,939 - trainer - INFO] - Train Epoch:[41/100] Step:[50/250] Total Loss: 72.615051 GL_Loss: 0.448062 CRF_Loss: 72.166992\n",
      "[2022-02-17 15:29:40,086 - trainer - INFO] - [Step Validation] Epoch:[41/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.888889 | 0.917197 | 0.902821 | 0.917197 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.619658 | 0.385638 | 0.47541  | 0.385638 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.662116 | 0.617834 | 0.639209 | 0.617834 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.625    | 0.652174 | 0.638298 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.69172  | 0.578275 | 0.62993  | 0.578275 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 15:29:53,795 - trainer - INFO] - Train Epoch:[41/100] Step:[60/250] Total Loss: 23.600849 GL_Loss: 0.732929 CRF_Loss: 22.867920\n",
      "[2022-02-17 15:30:07,913 - trainer - INFO] - Train Epoch:[41/100] Step:[70/250] Total Loss: 31.037956 GL_Loss: 0.335808 CRF_Loss: 30.702148\n",
      "[2022-02-17 15:30:22,576 - trainer - INFO] - Train Epoch:[41/100] Step:[80/250] Total Loss: 38.420406 GL_Loss: 0.476802 CRF_Loss: 37.943604\n",
      "[2022-02-17 15:30:36,722 - trainer - INFO] - Train Epoch:[41/100] Step:[90/250] Total Loss: 30.965406 GL_Loss: 0.392286 CRF_Loss: 30.573120\n",
      "[2022-02-17 15:30:50,956 - trainer - INFO] - Train Epoch:[41/100] Step:[100/250] Total Loss: 21.320238 GL_Loss: 0.525927 CRF_Loss: 20.794312\n",
      "[2022-02-17 15:31:10,104 - trainer - INFO] - [Step Validation] Epoch:[41/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.883436 | 0.917197 | 0.9      | 0.917197 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.64135  | 0.404255 | 0.495922 | 0.404255 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.635484 | 0.627389 | 0.63141  | 0.627389 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.652174 | 0.652174 | 0.652174 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.689526 | 0.588924 | 0.635267 | 0.588924 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 15:31:23,677 - trainer - INFO] - Train Epoch:[41/100] Step:[110/250] Total Loss: 160.003494 GL_Loss: 0.413531 CRF_Loss: 159.589966\n",
      "[2022-02-17 15:31:39,075 - trainer - INFO] - Train Epoch:[41/100] Step:[120/250] Total Loss: 30.598122 GL_Loss: 0.452247 CRF_Loss: 30.145874\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 15:31:53,110 - trainer - INFO] - Train Epoch:[41/100] Step:[130/250] Total Loss: 52.983727 GL_Loss: 0.385095 CRF_Loss: 52.598633\n",
      "[2022-02-17 15:32:06,265 - trainer - INFO] - Train Epoch:[41/100] Step:[140/250] Total Loss: 63.200890 GL_Loss: 0.420493 CRF_Loss: 62.780396\n",
      "[2022-02-17 15:32:20,814 - trainer - INFO] - Train Epoch:[41/100] Step:[150/250] Total Loss: 17.792082 GL_Loss: 0.365934 CRF_Loss: 17.426147\n",
      "[2022-02-17 15:32:41,312 - trainer - INFO] - [Step Validation] Epoch:[41/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.873494 | 0.923567 | 0.897833 | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.634454 | 0.401596 | 0.491857 | 0.401596 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.666667 | 0.617834 | 0.641322 | 0.617834 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.663043 | 0.663043 | 0.663043 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.700127 | 0.586794 | 0.63847  | 0.586794 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 15:32:55,912 - trainer - INFO] - Train Epoch:[41/100] Step:[160/250] Total Loss: 11.303017 GL_Loss: 0.623085 CRF_Loss: 10.679932\n",
      "[2022-02-17 15:33:10,898 - trainer - INFO] - Train Epoch:[41/100] Step:[170/250] Total Loss: 23.800543 GL_Loss: 0.487188 CRF_Loss: 23.313354\n",
      "[2022-02-17 15:33:25,911 - trainer - INFO] - Train Epoch:[41/100] Step:[180/250] Total Loss: 23.028849 GL_Loss: 0.524943 CRF_Loss: 22.503906\n",
      "[2022-02-17 15:33:40,606 - trainer - INFO] - Train Epoch:[41/100] Step:[190/250] Total Loss: 49.159664 GL_Loss: 0.418331 CRF_Loss: 48.741333\n",
      "[2022-02-17 15:33:55,640 - trainer - INFO] - Train Epoch:[41/100] Step:[200/250] Total Loss: 39.964092 GL_Loss: 0.514386 CRF_Loss: 39.449707\n",
      "[2022-02-17 15:34:14,701 - trainer - INFO] - [Step Validation] Epoch:[41/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.873494 | 0.923567 | 0.897833 | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.636752 | 0.396277 | 0.488525 | 0.396277 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.702602 | 0.601911 | 0.64837  | 0.601911 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.670213 | 0.684783 | 0.677419 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.715596 | 0.58147  | 0.641598 | 0.58147  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 15:34:28,287 - trainer - INFO] - Train Epoch:[41/100] Step:[210/250] Total Loss: 17.933208 GL_Loss: 0.679301 CRF_Loss: 17.253906\n",
      "[2022-02-17 15:34:42,154 - trainer - INFO] - Train Epoch:[41/100] Step:[220/250] Total Loss: 35.187325 GL_Loss: 0.528876 CRF_Loss: 34.658447\n",
      "[2022-02-17 15:34:57,434 - trainer - INFO] - Train Epoch:[41/100] Step:[230/250] Total Loss: 42.042984 GL_Loss: 0.651018 CRF_Loss: 41.391968\n",
      "[2022-02-17 15:35:12,301 - trainer - INFO] - Train Epoch:[41/100] Step:[240/250] Total Loss: 31.595184 GL_Loss: 0.532195 CRF_Loss: 31.062988\n",
      "[2022-02-17 15:35:26,543 - trainer - INFO] - Train Epoch:[41/100] Step:[250/250] Total Loss: 18.907043 GL_Loss: 0.411193 CRF_Loss: 18.495850\n",
      "[2022-02-17 15:35:45,581 - trainer - INFO] - [Step Validation] Epoch:[41/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.869048 | 0.929936 | 0.898462 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.632479 | 0.393617 | 0.485246 | 0.393617 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.693727 | 0.598726 | 0.642735 | 0.598726 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.645833 | 0.673913 | 0.659574 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.707412 | 0.57934  | 0.637002 | 0.57934  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 15:36:04,878 - trainer - INFO] - [Epoch Validation] Epoch:[41/100] Total Loss: 52.870207 GL_Loss: 0.005611 CRF_Loss: 52.309061 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.869048 | 0.929936 | 0.898462 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.632479 | 0.393617 | 0.485246 | 0.393617 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.693727 | 0.598726 | 0.642735 | 0.598726 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.645833 | 0.673913 | 0.659574 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.707412 | 0.57934  | 0.637002 | 0.57934  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 15:36:20,272 - trainer - INFO] - Train Epoch:[42/100] Step:[10/250] Total Loss: 38.928211 GL_Loss: 0.436266 CRF_Loss: 38.491943\n",
      "[2022-02-17 15:36:34,131 - trainer - INFO] - Train Epoch:[42/100] Step:[20/250] Total Loss: 31.947546 GL_Loss: 0.765051 CRF_Loss: 31.182495\n",
      "[2022-02-17 15:36:49,119 - trainer - INFO] - Train Epoch:[42/100] Step:[30/250] Total Loss: 42.272732 GL_Loss: 0.892482 CRF_Loss: 41.380249\n",
      "[2022-02-17 15:37:02,426 - trainer - INFO] - Train Epoch:[42/100] Step:[40/250] Total Loss: 19.730175 GL_Loss: 0.386426 CRF_Loss: 19.343750\n",
      "[2022-02-17 15:37:16,155 - trainer - INFO] - Train Epoch:[42/100] Step:[50/250] Total Loss: 24.996431 GL_Loss: 0.801485 CRF_Loss: 24.194946\n",
      "[2022-02-17 15:37:35,401 - trainer - INFO] - [Step Validation] Epoch:[42/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.878788 | 0.923567 | 0.900621 | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.625    | 0.398936 | 0.487013 | 0.398936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.645695 | 0.621019 | 0.633117 | 0.621019 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.652632 | 0.673913 | 0.663102 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.688279 | 0.587859 | 0.634118 | 0.587859 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 15:37:49,530 - trainer - INFO] - Train Epoch:[42/100] Step:[60/250] Total Loss: 12.123486 GL_Loss: 0.459790 CRF_Loss: 11.663696\n",
      "[2022-02-17 15:38:03,834 - trainer - INFO] - Train Epoch:[42/100] Step:[70/250] Total Loss: 12.280557 GL_Loss: 0.505410 CRF_Loss: 11.775146\n",
      "[2022-02-17 15:38:18,410 - trainer - INFO] - Train Epoch:[42/100] Step:[80/250] Total Loss: 35.051395 GL_Loss: 0.481693 CRF_Loss: 34.569702\n",
      "[2022-02-17 15:38:33,495 - trainer - INFO] - Train Epoch:[42/100] Step:[90/250] Total Loss: 23.751091 GL_Loss: 0.432121 CRF_Loss: 23.318970\n",
      "[2022-02-17 15:38:47,631 - trainer - INFO] - Train Epoch:[42/100] Step:[100/250] Total Loss: 36.337872 GL_Loss: 0.407819 CRF_Loss: 35.930054\n",
      "[2022-02-17 15:39:06,705 - trainer - INFO] - [Step Validation] Epoch:[42/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.869048 | 0.929936 | 0.898462 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.627706 | 0.385638 | 0.477759 | 0.385638 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.672414 | 0.621019 | 0.645695 | 0.621019 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.666667 | 0.673913 | 0.67027  | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.700767 | 0.5836   | 0.636839 | 0.5836   |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 15:39:20,816 - trainer - INFO] - Train Epoch:[42/100] Step:[110/250] Total Loss: 25.081514 GL_Loss: 0.588106 CRF_Loss: 24.493408\n",
      "[2022-02-17 15:39:34,975 - trainer - INFO] - Train Epoch:[42/100] Step:[120/250] Total Loss: 49.686630 GL_Loss: 0.531723 CRF_Loss: 49.154907\n",
      "[2022-02-17 15:39:49,631 - trainer - INFO] - Train Epoch:[42/100] Step:[130/250] Total Loss: 28.962536 GL_Loss: 0.938610 CRF_Loss: 28.023926\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 15:40:03,706 - trainer - INFO] - Train Epoch:[42/100] Step:[140/250] Total Loss: 18.133493 GL_Loss: 0.592599 CRF_Loss: 17.540894\n",
      "[2022-02-17 15:40:18,698 - trainer - INFO] - Train Epoch:[42/100] Step:[150/250] Total Loss: 22.880217 GL_Loss: 0.393889 CRF_Loss: 22.486328\n",
      "[2022-02-17 15:40:37,929 - trainer - INFO] - [Step Validation] Epoch:[42/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.874251 | 0.929936 | 0.901235 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.630901 | 0.390957 | 0.482759 | 0.390957 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.687719 | 0.624204 | 0.654424 | 0.624204 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.659574 | 0.673913 | 0.666667 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.707317 | 0.586794 | 0.641444 | 0.586794 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 15:40:52,093 - trainer - INFO] - Train Epoch:[42/100] Step:[160/250] Total Loss: 100.394615 GL_Loss: 0.709920 CRF_Loss: 99.684692\n",
      "[2022-02-17 15:41:06,759 - trainer - INFO] - Train Epoch:[42/100] Step:[170/250] Total Loss: 19.425688 GL_Loss: 0.498686 CRF_Loss: 18.927002\n",
      "[2022-02-17 15:41:21,560 - trainer - INFO] - Train Epoch:[42/100] Step:[180/250] Total Loss: 192.381897 GL_Loss: 0.570372 CRF_Loss: 191.811523\n",
      "[2022-02-17 15:41:35,828 - trainer - INFO] - Train Epoch:[42/100] Step:[190/250] Total Loss: 170.962173 GL_Loss: 0.641374 CRF_Loss: 170.320801\n",
      "[2022-02-17 15:41:50,241 - trainer - INFO] - Train Epoch:[42/100] Step:[200/250] Total Loss: 10.781182 GL_Loss: 0.517999 CRF_Loss: 10.263184\n",
      "[2022-02-17 15:42:09,345 - trainer - INFO] - [Step Validation] Epoch:[42/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.837349 | 0.88535  | 0.860681 | 0.88535  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.614719 | 0.37766  | 0.467875 | 0.37766  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.690566 | 0.582803 | 0.632124 | 0.582803 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.663043 | 0.663043 | 0.663043 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.696286 | 0.559105 | 0.620201 | 0.559105 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 15:42:23,428 - trainer - INFO] - Train Epoch:[42/100] Step:[210/250] Total Loss: 28.472034 GL_Loss: 0.493519 CRF_Loss: 27.978516\n",
      "[2022-02-17 15:42:37,862 - trainer - INFO] - Train Epoch:[42/100] Step:[220/250] Total Loss: 29.415211 GL_Loss: 0.582570 CRF_Loss: 28.832642\n",
      "[2022-02-17 15:42:52,156 - trainer - INFO] - Train Epoch:[42/100] Step:[230/250] Total Loss: 64.202583 GL_Loss: 0.434276 CRF_Loss: 63.768311\n",
      "[2022-02-17 15:43:06,479 - trainer - INFO] - Train Epoch:[42/100] Step:[240/250] Total Loss: 34.095062 GL_Loss: 0.935883 CRF_Loss: 33.159180\n",
      "[2022-02-17 15:43:19,404 - trainer - INFO] - Train Epoch:[42/100] Step:[250/250] Total Loss: 23.378960 GL_Loss: 0.352715 CRF_Loss: 23.026245\n",
      "[2022-02-17 15:43:39,381 - trainer - INFO] - [Step Validation] Epoch:[42/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.879518 | 0.929936 | 0.904025 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.622318 | 0.385638 | 0.47619  | 0.385638 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.649351 | 0.636943 | 0.643087 | 0.636943 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.648936 | 0.663043 | 0.655914 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.689139 | 0.587859 | 0.634483 | 0.587859 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 15:43:58,469 - trainer - INFO] - [Epoch Validation] Epoch:[42/100] Total Loss: 52.575757 GL_Loss: 0.005650 CRF_Loss: 52.010781 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.879518 | 0.929936 | 0.904025 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.622318 | 0.385638 | 0.47619  | 0.385638 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.649351 | 0.636943 | 0.643087 | 0.636943 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.648936 | 0.663043 | 0.655914 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.689139 | 0.587859 | 0.634483 | 0.587859 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 15:44:12,911 - trainer - INFO] - Train Epoch:[43/100] Step:[10/250] Total Loss: 68.951859 GL_Loss: 0.419507 CRF_Loss: 68.532349\n",
      "[2022-02-17 15:44:27,922 - trainer - INFO] - Train Epoch:[43/100] Step:[20/250] Total Loss: 48.142822 GL_Loss: 0.370482 CRF_Loss: 47.772339\n",
      "[2022-02-17 15:44:42,795 - trainer - INFO] - Train Epoch:[43/100] Step:[30/250] Total Loss: 31.266270 GL_Loss: 0.547886 CRF_Loss: 30.718384\n",
      "[2022-02-17 15:44:57,123 - trainer - INFO] - Train Epoch:[43/100] Step:[40/250] Total Loss: 68.733589 GL_Loss: 0.355050 CRF_Loss: 68.378540\n",
      "[2022-02-17 15:45:12,647 - trainer - INFO] - Train Epoch:[43/100] Step:[50/250] Total Loss: 21.651939 GL_Loss: 0.790977 CRF_Loss: 20.860962\n",
      "[2022-02-17 15:45:31,882 - trainer - INFO] - [Step Validation] Epoch:[43/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.848101 | 0.853503 | 0.850794 | 0.853503 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.613445 | 0.388298 | 0.47557  | 0.388298 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.684825 | 0.56051  | 0.616462 | 0.56051  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.67033  | 0.663043 | 0.666667 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.694892 | 0.550586 | 0.614379 | 0.550586 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 15:45:45,748 - trainer - INFO] - Train Epoch:[43/100] Step:[60/250] Total Loss: 157.871078 GL_Loss: 0.469952 CRF_Loss: 157.401123\n",
      "[2022-02-17 15:45:59,887 - trainer - INFO] - Train Epoch:[43/100] Step:[70/250] Total Loss: 12.924005 GL_Loss: 0.359064 CRF_Loss: 12.564941\n",
      "[2022-02-17 15:46:13,806 - trainer - INFO] - Train Epoch:[43/100] Step:[80/250] Total Loss: 13.358816 GL_Loss: 0.425466 CRF_Loss: 12.933350\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 15:46:28,577 - trainer - INFO] - Train Epoch:[43/100] Step:[90/250] Total Loss: 38.952377 GL_Loss: 0.968246 CRF_Loss: 37.984131\n",
      "[2022-02-17 15:46:42,030 - trainer - INFO] - Train Epoch:[43/100] Step:[100/250] Total Loss: 110.299835 GL_Loss: 0.398957 CRF_Loss: 109.900879\n",
      "[2022-02-17 15:47:01,155 - trainer - INFO] - [Step Validation] Epoch:[43/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.822086 | 0.853503 | 0.8375   | 0.853503 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.606838 | 0.37766  | 0.465574 | 0.37766  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.707113 | 0.538217 | 0.611212 | 0.538217 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.684783 | 0.684783 | 0.684783 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.697802 | 0.541001 | 0.609478 | 0.541001 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 15:47:16,154 - trainer - INFO] - Train Epoch:[43/100] Step:[110/250] Total Loss: 18.150167 GL_Loss: 0.498800 CRF_Loss: 17.651367\n",
      "[2022-02-17 15:47:30,190 - trainer - INFO] - Train Epoch:[43/100] Step:[120/250] Total Loss: 36.509388 GL_Loss: 0.430529 CRF_Loss: 36.078857\n",
      "[2022-02-17 15:47:44,438 - trainer - INFO] - Train Epoch:[43/100] Step:[130/250] Total Loss: 21.358379 GL_Loss: 0.359112 CRF_Loss: 20.999268\n",
      "[2022-02-17 15:47:57,910 - trainer - INFO] - Train Epoch:[43/100] Step:[140/250] Total Loss: 71.987869 GL_Loss: 0.425125 CRF_Loss: 71.562744\n",
      "[2022-02-17 15:48:11,946 - trainer - INFO] - Train Epoch:[43/100] Step:[150/250] Total Loss: 36.542309 GL_Loss: 0.591868 CRF_Loss: 35.950439\n",
      "[2022-02-17 15:48:30,968 - trainer - INFO] - [Step Validation] Epoch:[43/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.868263 | 0.923567 | 0.895062 | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.622407 | 0.398936 | 0.486224 | 0.398936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.696751 | 0.61465  | 0.65313  | 0.61465  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.666667 | 0.673913 | 0.67027  | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.706941 | 0.585729 | 0.640652 | 0.585729 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 15:48:45,223 - trainer - INFO] - Train Epoch:[43/100] Step:[160/250] Total Loss: 248.629669 GL_Loss: 0.529566 CRF_Loss: 248.100098\n",
      "[2022-02-17 15:49:00,074 - trainer - INFO] - Train Epoch:[43/100] Step:[170/250] Total Loss: 20.426844 GL_Loss: 0.492273 CRF_Loss: 19.934570\n",
      "[2022-02-17 15:49:14,639 - trainer - INFO] - Train Epoch:[43/100] Step:[180/250] Total Loss: 27.057644 GL_Loss: 0.412502 CRF_Loss: 26.645142\n",
      "[2022-02-17 15:49:28,357 - trainer - INFO] - Train Epoch:[43/100] Step:[190/250] Total Loss: 38.115448 GL_Loss: 0.573699 CRF_Loss: 37.541748\n",
      "[2022-02-17 15:49:43,369 - trainer - INFO] - Train Epoch:[43/100] Step:[200/250] Total Loss: 68.923424 GL_Loss: 0.443323 CRF_Loss: 68.480103\n",
      "[2022-02-17 15:50:02,579 - trainer - INFO] - [Step Validation] Epoch:[43/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.88024  | 0.936306 | 0.907407 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.622318 | 0.385638 | 0.47619  | 0.385638 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.708812 | 0.589172 | 0.643478 | 0.589172 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.673913 | 0.673913 | 0.673913 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.715803 | 0.574015 | 0.637116 | 0.574015 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 15:50:16,982 - trainer - INFO] - Train Epoch:[43/100] Step:[210/250] Total Loss: 17.619070 GL_Loss: 0.881887 CRF_Loss: 16.737183\n",
      "[2022-02-17 15:50:30,301 - trainer - INFO] - Train Epoch:[43/100] Step:[220/250] Total Loss: 35.734444 GL_Loss: 0.473334 CRF_Loss: 35.261108\n",
      "[2022-02-17 15:50:43,125 - trainer - INFO] - Train Epoch:[43/100] Step:[230/250] Total Loss: 89.315460 GL_Loss: 0.438015 CRF_Loss: 88.877441\n",
      "[2022-02-17 15:50:57,654 - trainer - INFO] - Train Epoch:[43/100] Step:[240/250] Total Loss: 23.080524 GL_Loss: 0.510333 CRF_Loss: 22.570190\n",
      "[2022-02-17 15:51:11,533 - trainer - INFO] - Train Epoch:[43/100] Step:[250/250] Total Loss: 47.716461 GL_Loss: 0.602934 CRF_Loss: 47.113525\n",
      "[2022-02-17 15:51:30,726 - trainer - INFO] - [Step Validation] Epoch:[43/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.832335 | 0.88535  | 0.858025 | 0.88535  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.600858 | 0.37234  | 0.45977  | 0.37234  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.6609   | 0.60828  | 0.633499 | 0.60828  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.666667 | 0.673913 | 0.67027  | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.680307 | 0.56656  | 0.618245 | 0.56656  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 15:51:49,918 - trainer - INFO] - [Epoch Validation] Epoch:[43/100] Total Loss: 52.191421 GL_Loss: 0.005278 CRF_Loss: 51.663620 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.832335 | 0.88535  | 0.858025 | 0.88535  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.600858 | 0.37234  | 0.45977  | 0.37234  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.6609   | 0.60828  | 0.633499 | 0.60828  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.666667 | 0.673913 | 0.67027  | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.680307 | 0.56656  | 0.618245 | 0.56656  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 15:52:04,906 - trainer - INFO] - Train Epoch:[44/100] Step:[10/250] Total Loss: 28.794554 GL_Loss: 0.433470 CRF_Loss: 28.361084\n",
      "[2022-02-17 15:52:18,483 - trainer - INFO] - Train Epoch:[44/100] Step:[20/250] Total Loss: 34.214237 GL_Loss: 0.397587 CRF_Loss: 33.816650\n",
      "[2022-02-17 15:52:31,346 - trainer - INFO] - Train Epoch:[44/100] Step:[30/250] Total Loss: 15.852599 GL_Loss: 0.730041 CRF_Loss: 15.122559\n",
      "[2022-02-17 15:52:45,236 - trainer - INFO] - Train Epoch:[44/100] Step:[40/250] Total Loss: 23.813334 GL_Loss: 0.546609 CRF_Loss: 23.266724\n",
      "[2022-02-17 15:52:59,205 - trainer - INFO] - Train Epoch:[44/100] Step:[50/250] Total Loss: 66.327782 GL_Loss: 0.336207 CRF_Loss: 65.991577\n",
      "[2022-02-17 15:53:18,324 - trainer - INFO] - [Step Validation] Epoch:[44/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.884146 | 0.923567 | 0.903427 | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.642241 | 0.396277 | 0.490132 | 0.396277 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.673611 | 0.617834 | 0.644518 | 0.617834 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.663158 | 0.684783 | 0.673797 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.707317 | 0.586794 | 0.641444 | 0.586794 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 15:53:31,774 - trainer - INFO] - Train Epoch:[44/100] Step:[60/250] Total Loss: 47.306206 GL_Loss: 0.475516 CRF_Loss: 46.830688\n",
      "[2022-02-17 15:53:45,916 - trainer - INFO] - Train Epoch:[44/100] Step:[70/250] Total Loss: 27.772980 GL_Loss: 0.468781 CRF_Loss: 27.304199\n",
      "[2022-02-17 15:54:00,343 - trainer - INFO] - Train Epoch:[44/100] Step:[80/250] Total Loss: 37.445015 GL_Loss: 0.737740 CRF_Loss: 36.707275\n",
      "[2022-02-17 15:54:15,585 - trainer - INFO] - Train Epoch:[44/100] Step:[90/250] Total Loss: 53.257664 GL_Loss: 0.663303 CRF_Loss: 52.594360\n",
      "[2022-02-17 15:54:30,951 - trainer - INFO] - Train Epoch:[44/100] Step:[100/250] Total Loss: 14.382404 GL_Loss: 1.144733 CRF_Loss: 13.237671\n",
      "[2022-02-17 15:54:50,383 - trainer - INFO] - [Step Validation] Epoch:[44/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.872727 | 0.917197 | 0.89441  | 0.917197 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.659574 | 0.412234 | 0.507365 | 0.412234 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.670103 | 0.621019 | 0.644628 | 0.621019 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.634409 | 0.641304 | 0.637838 | 0.641304 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.705357 | 0.588924 | 0.641904 | 0.588924 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 15:55:04,548 - trainer - INFO] - Train Epoch:[44/100] Step:[110/250] Total Loss: 26.391209 GL_Loss: 0.718723 CRF_Loss: 25.672485\n",
      "[2022-02-17 15:55:19,167 - trainer - INFO] - Train Epoch:[44/100] Step:[120/250] Total Loss: 112.636940 GL_Loss: 0.414772 CRF_Loss: 112.222168\n",
      "[2022-02-17 15:55:32,852 - trainer - INFO] - Train Epoch:[44/100] Step:[130/250] Total Loss: 20.061434 GL_Loss: 0.634309 CRF_Loss: 19.427124\n",
      "[2022-02-17 15:55:47,684 - trainer - INFO] - Train Epoch:[44/100] Step:[140/250] Total Loss: 25.172340 GL_Loss: 1.299537 CRF_Loss: 23.872803\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 15:56:03,224 - trainer - INFO] - Train Epoch:[44/100] Step:[150/250] Total Loss: 16.233824 GL_Loss: 0.549863 CRF_Loss: 15.683960\n",
      "[2022-02-17 15:56:22,295 - trainer - INFO] - [Step Validation] Epoch:[44/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.879518 | 0.929936 | 0.904025 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.649789 | 0.409574 | 0.502447 | 0.409574 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.665517 | 0.61465  | 0.639073 | 0.61465  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.631579 | 0.652174 | 0.641711 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.701777 | 0.588924 | 0.640417 | 0.588924 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 15:56:36,783 - trainer - INFO] - Train Epoch:[44/100] Step:[160/250] Total Loss: 32.735573 GL_Loss: 0.643835 CRF_Loss: 32.091736\n",
      "[2022-02-17 15:56:51,965 - trainer - INFO] - Train Epoch:[44/100] Step:[170/250] Total Loss: 169.436981 GL_Loss: 0.922334 CRF_Loss: 168.514648\n",
      "[2022-02-17 15:57:05,869 - trainer - INFO] - Train Epoch:[44/100] Step:[180/250] Total Loss: 39.008446 GL_Loss: 0.748191 CRF_Loss: 38.260254\n",
      "[2022-02-17 15:57:19,591 - trainer - INFO] - Train Epoch:[44/100] Step:[190/250] Total Loss: 61.057922 GL_Loss: 0.425966 CRF_Loss: 60.631958\n",
      "[2022-02-17 15:57:33,981 - trainer - INFO] - Train Epoch:[44/100] Step:[200/250] Total Loss: 10.268922 GL_Loss: 0.320801 CRF_Loss: 9.948120\n",
      "[2022-02-17 15:57:52,977 - trainer - INFO] - [Step Validation] Epoch:[44/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.857143 | 0.878981 | 0.867925 | 0.878981 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.662447 | 0.417553 | 0.512235 | 0.417553 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.741784 | 0.503185 | 0.59962  | 0.503185 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.655914 | 0.663043 | 0.659459 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.730114 | 0.547391 | 0.625685 | 0.547391 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 15:58:06,286 - trainer - INFO] - Train Epoch:[44/100] Step:[210/250] Total Loss: 29.059843 GL_Loss: 0.828519 CRF_Loss: 28.231323\n",
      "[2022-02-17 15:58:20,290 - trainer - INFO] - Train Epoch:[44/100] Step:[220/250] Total Loss: 25.921400 GL_Loss: 0.888686 CRF_Loss: 25.032715\n",
      "[2022-02-17 15:58:34,222 - trainer - INFO] - Train Epoch:[44/100] Step:[230/250] Total Loss: 52.107033 GL_Loss: 0.557351 CRF_Loss: 51.549683\n",
      "[2022-02-17 15:58:49,467 - trainer - INFO] - Train Epoch:[44/100] Step:[240/250] Total Loss: 38.253513 GL_Loss: 0.474828 CRF_Loss: 37.778687\n",
      "[2022-02-17 15:59:05,304 - trainer - INFO] - Train Epoch:[44/100] Step:[250/250] Total Loss: 29.638151 GL_Loss: 0.480069 CRF_Loss: 29.158081\n",
      "[2022-02-17 15:59:24,555 - trainer - INFO] - [Step Validation] Epoch:[44/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.845679 | 0.872611 | 0.858934 | 0.872611 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.617021 | 0.385638 | 0.474632 | 0.385638 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.636364 | 0.601911 | 0.618658 | 0.601911 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.652174 | 0.652174 | 0.652174 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.675573 | 0.565495 | 0.615652 | 0.565495 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 15:59:43,769 - trainer - INFO] - [Epoch Validation] Epoch:[44/100] Total Loss: 51.927540 GL_Loss: 0.005560 CRF_Loss: 51.371492 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.845679 | 0.872611 | 0.858934 | 0.872611 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.617021 | 0.385638 | 0.474632 | 0.385638 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.636364 | 0.601911 | 0.618658 | 0.601911 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.652174 | 0.652174 | 0.652174 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.675573 | 0.565495 | 0.615652 | 0.565495 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 15:59:58,145 - trainer - INFO] - Train Epoch:[45/100] Step:[10/250] Total Loss: 35.600525 GL_Loss: 0.591127 CRF_Loss: 35.009399\n",
      "[2022-02-17 16:00:13,060 - trainer - INFO] - Train Epoch:[45/100] Step:[20/250] Total Loss: 561.403809 GL_Loss: 0.551183 CRF_Loss: 560.852600\n",
      "[2022-02-17 16:00:27,606 - trainer - INFO] - Train Epoch:[45/100] Step:[30/250] Total Loss: 55.303963 GL_Loss: 0.324350 CRF_Loss: 54.979614\n",
      "[2022-02-17 16:00:41,801 - trainer - INFO] - Train Epoch:[45/100] Step:[40/250] Total Loss: 19.554447 GL_Loss: 0.625493 CRF_Loss: 18.928955\n",
      "[2022-02-17 16:00:56,111 - trainer - INFO] - Train Epoch:[45/100] Step:[50/250] Total Loss: 27.378960 GL_Loss: 0.421197 CRF_Loss: 26.957764\n",
      "[2022-02-17 16:01:15,109 - trainer - INFO] - [Step Validation] Epoch:[45/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.879518 | 0.929936 | 0.904025 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.692623 | 0.449468 | 0.545161 | 0.449468 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.673759 | 0.605096 | 0.637584 | 0.605096 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.648936 | 0.663043 | 0.655914 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.720102 | 0.602769 | 0.656232 | 0.602769 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 16:01:17,279 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 16:01:31,679 - trainer - INFO] - Train Epoch:[45/100] Step:[60/250] Total Loss: 79.131767 GL_Loss: 0.409229 CRF_Loss: 78.722534\n",
      "[2022-02-17 16:01:45,458 - trainer - INFO] - Train Epoch:[45/100] Step:[70/250] Total Loss: 43.940266 GL_Loss: 0.483966 CRF_Loss: 43.456299\n",
      "[2022-02-17 16:01:59,003 - trainer - INFO] - Train Epoch:[45/100] Step:[80/250] Total Loss: 40.016041 GL_Loss: 0.533130 CRF_Loss: 39.482910\n",
      "[2022-02-17 16:02:12,339 - trainer - INFO] - Train Epoch:[45/100] Step:[90/250] Total Loss: 75.807396 GL_Loss: 0.395040 CRF_Loss: 75.412354\n",
      "[2022-02-17 16:02:27,532 - trainer - INFO] - Train Epoch:[45/100] Step:[100/250] Total Loss: 9.122959 GL_Loss: 0.481602 CRF_Loss: 8.641357\n",
      "[2022-02-17 16:02:46,484 - trainer - INFO] - [Step Validation] Epoch:[45/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.885542 | 0.936306 | 0.910217 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.660944 | 0.409574 | 0.505747 | 0.409574 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.700389 | 0.573248 | 0.630473 | 0.573248 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.655914 | 0.663043 | 0.659459 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.723632 | 0.57721  | 0.64218  | 0.57721  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 16:03:01,738 - trainer - INFO] - Train Epoch:[45/100] Step:[110/250] Total Loss: 41.595451 GL_Loss: 0.467521 CRF_Loss: 41.127930\n",
      "[2022-02-17 16:03:15,741 - trainer - INFO] - Train Epoch:[45/100] Step:[120/250] Total Loss: 56.953949 GL_Loss: 0.525970 CRF_Loss: 56.427979\n",
      "[2022-02-17 16:03:29,483 - trainer - INFO] - Train Epoch:[45/100] Step:[130/250] Total Loss: 132.338196 GL_Loss: 0.552434 CRF_Loss: 131.785767\n",
      "[2022-02-17 16:03:43,689 - trainer - INFO] - Train Epoch:[45/100] Step:[140/250] Total Loss: 14.435116 GL_Loss: 0.451596 CRF_Loss: 13.983521\n",
      "[2022-02-17 16:03:59,037 - trainer - INFO] - Train Epoch:[45/100] Step:[150/250] Total Loss: 33.242413 GL_Loss: 0.824442 CRF_Loss: 32.417969\n",
      "[2022-02-17 16:04:18,240 - trainer - INFO] - [Step Validation] Epoch:[45/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.884848 | 0.929936 | 0.906832 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.630435 | 0.385638 | 0.478548 | 0.385638 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.661972 | 0.598726 | 0.628763 | 0.598726 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.652174 | 0.652174 | 0.652174 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.699092 | 0.574015 | 0.630409 | 0.574015 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 16:04:32,943 - trainer - INFO] - Train Epoch:[45/100] Step:[160/250] Total Loss: 19.101814 GL_Loss: 0.634652 CRF_Loss: 18.467163\n",
      "[2022-02-17 16:04:47,076 - trainer - INFO] - Train Epoch:[45/100] Step:[170/250] Total Loss: 40.109608 GL_Loss: 0.660388 CRF_Loss: 39.449219\n",
      "[2022-02-17 16:05:00,976 - trainer - INFO] - Train Epoch:[45/100] Step:[180/250] Total Loss: 73.026184 GL_Loss: 0.622741 CRF_Loss: 72.403442\n",
      "[2022-02-17 16:05:15,555 - trainer - INFO] - Train Epoch:[45/100] Step:[190/250] Total Loss: 39.449924 GL_Loss: 0.875827 CRF_Loss: 38.574097\n",
      "[2022-02-17 16:05:31,519 - trainer - INFO] - Train Epoch:[45/100] Step:[200/250] Total Loss: 13.521193 GL_Loss: 0.387891 CRF_Loss: 13.133301\n",
      "[2022-02-17 16:05:50,558 - trainer - INFO] - [Step Validation] Epoch:[45/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.867925 | 0.878981 | 0.873418 | 0.878981 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.630705 | 0.404255 | 0.492707 | 0.404255 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.647841 | 0.621019 | 0.634146 | 0.621019 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.659341 | 0.652174 | 0.655738 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.688131 | 0.580405 | 0.629694 | 0.580405 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 16:06:04,567 - trainer - INFO] - Train Epoch:[45/100] Step:[210/250] Total Loss: 33.046082 GL_Loss: 0.401061 CRF_Loss: 32.645020\n",
      "[2022-02-17 16:06:18,613 - trainer - INFO] - Train Epoch:[45/100] Step:[220/250] Total Loss: 19.973343 GL_Loss: 0.513139 CRF_Loss: 19.460205\n",
      "[2022-02-17 16:06:32,186 - trainer - INFO] - Train Epoch:[45/100] Step:[230/250] Total Loss: 110.648521 GL_Loss: 0.757650 CRF_Loss: 109.890869\n",
      "[2022-02-17 16:06:46,304 - trainer - INFO] - Train Epoch:[45/100] Step:[240/250] Total Loss: 22.275143 GL_Loss: 0.373959 CRF_Loss: 21.901184\n",
      "[2022-02-17 16:07:01,294 - trainer - INFO] - Train Epoch:[45/100] Step:[250/250] Total Loss: 11.196599 GL_Loss: 0.463445 CRF_Loss: 10.733154\n",
      "[2022-02-17 16:07:20,390 - trainer - INFO] - [Step Validation] Epoch:[45/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.849398 | 0.898089 | 0.873065 | 0.898089 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.601695 | 0.37766  | 0.464052 | 0.37766  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.694981 | 0.573248 | 0.628272 | 0.573248 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.673913 | 0.673913 | 0.673913 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.697211 | 0.559105 | 0.620567 | 0.559105 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 16:07:39,570 - trainer - INFO] - [Epoch Validation] Epoch:[45/100] Total Loss: 50.841754 GL_Loss: 0.005397 CRF_Loss: 50.302069 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.849398 | 0.898089 | 0.873065 | 0.898089 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.601695 | 0.37766  | 0.464052 | 0.37766  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.694981 | 0.573248 | 0.628272 | 0.573248 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.673913 | 0.673913 | 0.673913 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.697211 | 0.559105 | 0.620567 | 0.559105 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 16:07:54,452 - trainer - INFO] - Train Epoch:[46/100] Step:[10/250] Total Loss: 24.738428 GL_Loss: 0.566674 CRF_Loss: 24.171753\n",
      "[2022-02-17 16:08:09,286 - trainer - INFO] - Train Epoch:[46/100] Step:[20/250] Total Loss: 21.193113 GL_Loss: 0.389158 CRF_Loss: 20.803955\n",
      "[2022-02-17 16:08:22,961 - trainer - INFO] - Train Epoch:[46/100] Step:[30/250] Total Loss: 28.271528 GL_Loss: 0.331220 CRF_Loss: 27.940308\n",
      "[2022-02-17 16:08:36,001 - trainer - INFO] - Train Epoch:[46/100] Step:[40/250] Total Loss: 21.738018 GL_Loss: 0.483257 CRF_Loss: 21.254761\n",
      "[2022-02-17 16:08:49,480 - trainer - INFO] - Train Epoch:[46/100] Step:[50/250] Total Loss: 81.771957 GL_Loss: 1.178697 CRF_Loss: 80.593262\n",
      "[2022-02-17 16:09:08,688 - trainer - INFO] - [Step Validation] Epoch:[46/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.890909 | 0.936306 | 0.913043 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.62931  | 0.388298 | 0.480263 | 0.388298 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.671329 | 0.611465 | 0.64     | 0.611465 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.652632 | 0.673913 | 0.663102 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.703085 | 0.582535 | 0.637158 | 0.582535 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 16:09:23,361 - trainer - INFO] - Train Epoch:[46/100] Step:[60/250] Total Loss: 117.194695 GL_Loss: 0.365719 CRF_Loss: 116.828979\n",
      "[2022-02-17 16:09:38,080 - trainer - INFO] - Train Epoch:[46/100] Step:[70/250] Total Loss: 40.679344 GL_Loss: 0.634301 CRF_Loss: 40.045044\n",
      "[2022-02-17 16:09:52,215 - trainer - INFO] - Train Epoch:[46/100] Step:[80/250] Total Loss: 27.608559 GL_Loss: 1.035317 CRF_Loss: 26.573242\n",
      "[2022-02-17 16:10:05,712 - trainer - INFO] - Train Epoch:[46/100] Step:[90/250] Total Loss: 92.754250 GL_Loss: 0.338477 CRF_Loss: 92.415771\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 16:10:18,900 - trainer - INFO] - Train Epoch:[46/100] Step:[100/250] Total Loss: 1049.115356 GL_Loss: 0.300352 CRF_Loss: 1048.815063\n",
      "[2022-02-17 16:10:37,887 - trainer - INFO] - [Step Validation] Epoch:[46/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.902439 | 0.942675 | 0.922118 | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.688797 | 0.441489 | 0.538088 | 0.441489 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.649832 | 0.61465  | 0.631751 | 0.61465  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.638298 | 0.652174 | 0.645161 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.712312 | 0.603834 | 0.653602 | 0.603834 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 16:10:52,237 - trainer - INFO] - Train Epoch:[46/100] Step:[110/250] Total Loss: 47.810600 GL_Loss: 0.395683 CRF_Loss: 47.414917\n",
      "[2022-02-17 16:11:08,240 - trainer - INFO] - Train Epoch:[46/100] Step:[120/250] Total Loss: 19.135435 GL_Loss: 0.577940 CRF_Loss: 18.557495\n",
      "[2022-02-17 16:11:24,078 - trainer - INFO] - Train Epoch:[46/100] Step:[130/250] Total Loss: 46.469601 GL_Loss: 0.446894 CRF_Loss: 46.022705\n",
      "[2022-02-17 16:11:39,369 - trainer - INFO] - Train Epoch:[46/100] Step:[140/250] Total Loss: 26.619036 GL_Loss: 0.616106 CRF_Loss: 26.002930\n",
      "[2022-02-17 16:11:55,488 - trainer - INFO] - Train Epoch:[46/100] Step:[150/250] Total Loss: 50.723816 GL_Loss: 0.550352 CRF_Loss: 50.173462\n",
      "[2022-02-17 16:12:14,456 - trainer - INFO] - [Step Validation] Epoch:[46/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.868263 | 0.923567 | 0.895062 | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.632479 | 0.393617 | 0.485246 | 0.393617 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.677305 | 0.60828  | 0.64094  | 0.60828  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.645161 | 0.652174 | 0.648649 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.701031 | 0.57934  | 0.634402 | 0.57934  |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 16:12:30,659 - trainer - INFO] - Train Epoch:[46/100] Step:[160/250] Total Loss: 17.168032 GL_Loss: 0.584779 CRF_Loss: 16.583252\n",
      "[2022-02-17 16:12:46,225 - trainer - INFO] - Train Epoch:[46/100] Step:[170/250] Total Loss: 19.003929 GL_Loss: 0.321191 CRF_Loss: 18.682739\n",
      "[2022-02-17 16:13:02,528 - trainer - INFO] - Train Epoch:[46/100] Step:[180/250] Total Loss: 53.497959 GL_Loss: 0.514071 CRF_Loss: 52.983887\n",
      "[2022-02-17 16:13:16,670 - trainer - INFO] - Train Epoch:[46/100] Step:[190/250] Total Loss: 60.568348 GL_Loss: 0.714712 CRF_Loss: 59.853638\n",
      "[2022-02-17 16:13:31,704 - trainer - INFO] - Train Epoch:[46/100] Step:[200/250] Total Loss: 14.624918 GL_Loss: 0.456949 CRF_Loss: 14.167969\n",
      "[2022-02-17 16:13:50,956 - trainer - INFO] - [Step Validation] Epoch:[46/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.874251 | 0.929936 | 0.901235 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.669421 | 0.430851 | 0.524272 | 0.430851 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.678967 | 0.585987 | 0.62906  | 0.585987 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.663043 | 0.663043 | 0.663043 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.716321 | 0.588924 | 0.646406 | 0.588924 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 16:14:04,497 - trainer - INFO] - Train Epoch:[46/100] Step:[210/250] Total Loss: 565.241211 GL_Loss: 1.140764 CRF_Loss: 564.100464\n",
      "[2022-02-17 16:14:18,315 - trainer - INFO] - Train Epoch:[46/100] Step:[220/250] Total Loss: 78.637878 GL_Loss: 0.439513 CRF_Loss: 78.198364\n",
      "[2022-02-17 16:14:33,472 - trainer - INFO] - Train Epoch:[46/100] Step:[230/250] Total Loss: 25.514978 GL_Loss: 0.368005 CRF_Loss: 25.146973\n",
      "[2022-02-17 16:14:47,599 - trainer - INFO] - Train Epoch:[46/100] Step:[240/250] Total Loss: 23.479231 GL_Loss: 0.523786 CRF_Loss: 22.955444\n",
      "[2022-02-17 16:15:01,921 - trainer - INFO] - Train Epoch:[46/100] Step:[250/250] Total Loss: 13.754976 GL_Loss: 0.368502 CRF_Loss: 13.386475\n",
      "[2022-02-17 16:15:20,934 - trainer - INFO] - [Step Validation] Epoch:[46/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.879518 | 0.929936 | 0.904025 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.6625   | 0.422872 | 0.516234 | 0.422872 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.687273 | 0.601911 | 0.641766 | 0.601911 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.666667 | 0.673913 | 0.67027  | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.718346 | 0.592119 | 0.649154 | 0.592119 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 16:15:40,108 - trainer - INFO] - [Epoch Validation] Epoch:[46/100] Total Loss: 50.054646 GL_Loss: 0.005278 CRF_Loss: 49.526839 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.879518 | 0.929936 | 0.904025 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.6625   | 0.422872 | 0.516234 | 0.422872 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.687273 | 0.601911 | 0.641766 | 0.601911 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.666667 | 0.673913 | 0.67027  | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.718346 | 0.592119 | 0.649154 | 0.592119 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 16:15:54,734 - trainer - INFO] - Train Epoch:[47/100] Step:[10/250] Total Loss: 56.457211 GL_Loss: 1.267023 CRF_Loss: 55.190186\n",
      "[2022-02-17 16:16:09,273 - trainer - INFO] - Train Epoch:[47/100] Step:[20/250] Total Loss: 21.693249 GL_Loss: 0.525036 CRF_Loss: 21.168213\n",
      "[2022-02-17 16:16:23,458 - trainer - INFO] - Train Epoch:[47/100] Step:[30/250] Total Loss: 15.029662 GL_Loss: 0.608153 CRF_Loss: 14.421509\n",
      "[2022-02-17 16:16:37,428 - trainer - INFO] - Train Epoch:[47/100] Step:[40/250] Total Loss: 22.196320 GL_Loss: 0.484162 CRF_Loss: 21.712158\n",
      "[2022-02-17 16:16:51,252 - trainer - INFO] - Train Epoch:[47/100] Step:[50/250] Total Loss: 43.742439 GL_Loss: 0.366217 CRF_Loss: 43.376221\n",
      "[2022-02-17 16:17:10,313 - trainer - INFO] - [Step Validation] Epoch:[47/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.862275 | 0.917197 | 0.888889 | 0.917197 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.649789 | 0.409574 | 0.502447 | 0.409574 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.639871 | 0.633758 | 0.6368   | 0.633758 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.652174 | 0.652174 | 0.652174 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.690211 | 0.593184 | 0.63803  | 0.593184 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 16:17:23,813 - trainer - INFO] - Train Epoch:[47/100] Step:[60/250] Total Loss: 57.859600 GL_Loss: 0.419049 CRF_Loss: 57.440552\n",
      "[2022-02-17 16:17:39,170 - trainer - INFO] - Train Epoch:[47/100] Step:[70/250] Total Loss: 13.060766 GL_Loss: 0.664892 CRF_Loss: 12.395874\n",
      "[2022-02-17 16:17:52,927 - trainer - INFO] - Train Epoch:[47/100] Step:[80/250] Total Loss: 38.103424 GL_Loss: 0.451204 CRF_Loss: 37.652222\n",
      "[2022-02-17 16:18:06,774 - trainer - INFO] - Train Epoch:[47/100] Step:[90/250] Total Loss: 29.329765 GL_Loss: 0.488700 CRF_Loss: 28.841064\n",
      "[2022-02-17 16:18:21,516 - trainer - INFO] - Train Epoch:[47/100] Step:[100/250] Total Loss: 70.634361 GL_Loss: 0.377651 CRF_Loss: 70.256714\n",
      "[2022-02-17 16:18:40,672 - trainer - INFO] - [Step Validation] Epoch:[47/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.88024  | 0.936306 | 0.907407 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.677686 | 0.43617  | 0.530744 | 0.43617  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.694656 | 0.579618 | 0.631944 | 0.579618 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.655914 | 0.663043 | 0.659459 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.725131 | 0.589989 | 0.650617 | 0.589989 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 16:18:55,093 - trainer - INFO] - Train Epoch:[47/100] Step:[110/250] Total Loss: 16.561985 GL_Loss: 0.396091 CRF_Loss: 16.165894\n",
      "[2022-02-17 16:19:09,032 - trainer - INFO] - Train Epoch:[47/100] Step:[120/250] Total Loss: 24.237125 GL_Loss: 0.718570 CRF_Loss: 23.518555\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 16:19:23,166 - trainer - INFO] - Train Epoch:[47/100] Step:[130/250] Total Loss: 57.676750 GL_Loss: 0.583490 CRF_Loss: 57.093262\n",
      "[2022-02-17 16:19:38,404 - trainer - INFO] - Train Epoch:[47/100] Step:[140/250] Total Loss: 16.847729 GL_Loss: 0.503979 CRF_Loss: 16.343750\n",
      "[2022-02-17 16:19:52,277 - trainer - INFO] - Train Epoch:[47/100] Step:[150/250] Total Loss: 13.264304 GL_Loss: 0.796774 CRF_Loss: 12.467529\n",
      "[2022-02-17 16:20:11,330 - trainer - INFO] - [Step Validation] Epoch:[47/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.884848 | 0.929936 | 0.906832 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.652361 | 0.404255 | 0.499179 | 0.404255 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.676056 | 0.611465 | 0.64214  | 0.611465 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.670213 | 0.684783 | 0.677419 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.712629 | 0.588924 | 0.644898 | 0.588924 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 16:20:25,351 - trainer - INFO] - Train Epoch:[47/100] Step:[160/250] Total Loss: 45.729156 GL_Loss: 0.674836 CRF_Loss: 45.054321\n",
      "[2022-02-17 16:20:39,713 - trainer - INFO] - Train Epoch:[47/100] Step:[170/250] Total Loss: 61.650669 GL_Loss: 0.313511 CRF_Loss: 61.337158\n",
      "[2022-02-17 16:20:54,973 - trainer - INFO] - Train Epoch:[47/100] Step:[180/250] Total Loss: 37.877346 GL_Loss: 0.545804 CRF_Loss: 37.331543\n",
      "[2022-02-17 16:21:08,836 - trainer - INFO] - Train Epoch:[47/100] Step:[190/250] Total Loss: 31.722111 GL_Loss: 0.732610 CRF_Loss: 30.989502\n",
      "[2022-02-17 16:21:23,239 - trainer - INFO] - Train Epoch:[47/100] Step:[200/250] Total Loss: 55.215881 GL_Loss: 0.479431 CRF_Loss: 54.736450\n",
      "[2022-02-17 16:21:43,867 - trainer - INFO] - [Step Validation] Epoch:[47/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.879518 | 0.929936 | 0.904025 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.702479 | 0.452128 | 0.550162 | 0.452128 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.642173 | 0.640127 | 0.641148 | 0.640127 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.663043 | 0.663043 | 0.663043 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.710947 | 0.615548 | 0.659817 | 0.615548 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 16:21:46,062 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 16:22:00,652 - trainer - INFO] - Train Epoch:[47/100] Step:[210/250] Total Loss: 27.430998 GL_Loss: 0.557462 CRF_Loss: 26.873535\n",
      "[2022-02-17 16:22:14,842 - trainer - INFO] - Train Epoch:[47/100] Step:[220/250] Total Loss: 12.358989 GL_Loss: 0.339091 CRF_Loss: 12.019897\n",
      "[2022-02-17 16:22:28,706 - trainer - INFO] - Train Epoch:[47/100] Step:[230/250] Total Loss: 54.695778 GL_Loss: 0.343359 CRF_Loss: 54.352417\n",
      "[2022-02-17 16:22:43,464 - trainer - INFO] - Train Epoch:[47/100] Step:[240/250] Total Loss: 10.880748 GL_Loss: 0.575328 CRF_Loss: 10.305420\n",
      "[2022-02-17 16:22:58,055 - trainer - INFO] - Train Epoch:[47/100] Step:[250/250] Total Loss: 238.842850 GL_Loss: 0.679397 CRF_Loss: 238.163452\n",
      "[2022-02-17 16:23:17,519 - trainer - INFO] - [Step Validation] Epoch:[47/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.878788 | 0.923567 | 0.900621 | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.677551 | 0.441489 | 0.534622 | 0.441489 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.667797 | 0.627389 | 0.646962 | 0.627389 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.641304 | 0.641304 | 0.641304 | 0.641304 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.711418 | 0.603834 | 0.653226 | 0.603834 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 16:23:36,668 - trainer - INFO] - [Epoch Validation] Epoch:[47/100] Total Loss: 48.954497 GL_Loss: 0.005413 CRF_Loss: 48.413245 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.878788 | 0.923567 | 0.900621 | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.677551 | 0.441489 | 0.534622 | 0.441489 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.667797 | 0.627389 | 0.646962 | 0.627389 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.641304 | 0.641304 | 0.641304 | 0.641304 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.711418 | 0.603834 | 0.653226 | 0.603834 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 16:23:51,256 - trainer - INFO] - Train Epoch:[48/100] Step:[10/250] Total Loss: 25.245333 GL_Loss: 0.478120 CRF_Loss: 24.767212\n",
      "[2022-02-17 16:24:05,620 - trainer - INFO] - Train Epoch:[48/100] Step:[20/250] Total Loss: 11.333724 GL_Loss: 0.520248 CRF_Loss: 10.813477\n",
      "[2022-02-17 16:24:20,903 - trainer - INFO] - Train Epoch:[48/100] Step:[30/250] Total Loss: 51.652988 GL_Loss: 0.556064 CRF_Loss: 51.096924\n",
      "[2022-02-17 16:24:35,570 - trainer - INFO] - Train Epoch:[48/100] Step:[40/250] Total Loss: 14.916024 GL_Loss: 0.652108 CRF_Loss: 14.263916\n",
      "[2022-02-17 16:24:49,488 - trainer - INFO] - Train Epoch:[48/100] Step:[50/250] Total Loss: 27.548901 GL_Loss: 0.707837 CRF_Loss: 26.841064\n",
      "[2022-02-17 16:25:08,560 - trainer - INFO] - [Step Validation] Epoch:[48/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.891566 | 0.942675 | 0.916409 | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.654167 | 0.417553 | 0.50974  | 0.417553 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.686131 | 0.598726 | 0.639456 | 0.598726 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.645161 | 0.652174 | 0.648649 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.715395 | 0.588924 | 0.646028 | 0.588924 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 16:25:23,138 - trainer - INFO] - Train Epoch:[48/100] Step:[60/250] Total Loss: 39.567707 GL_Loss: 1.128497 CRF_Loss: 38.439209\n",
      "[2022-02-17 16:25:37,007 - trainer - INFO] - Train Epoch:[48/100] Step:[70/250] Total Loss: 54.557217 GL_Loss: 0.416349 CRF_Loss: 54.140869\n",
      "[2022-02-17 16:25:50,441 - trainer - INFO] - Train Epoch:[48/100] Step:[80/250] Total Loss: 29.645929 GL_Loss: 0.452569 CRF_Loss: 29.193359\n",
      "[2022-02-17 16:26:04,838 - trainer - INFO] - Train Epoch:[48/100] Step:[90/250] Total Loss: 22.973053 GL_Loss: 0.471954 CRF_Loss: 22.501099\n",
      "[2022-02-17 16:26:18,565 - trainer - INFO] - Train Epoch:[48/100] Step:[100/250] Total Loss: 93.479553 GL_Loss: 0.581479 CRF_Loss: 92.898071\n",
      "[2022-02-17 16:26:37,533 - trainer - INFO] - [Step Validation] Epoch:[48/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.875    | 0.936306 | 0.904615 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.679167 | 0.433511 | 0.529221 | 0.433511 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.679715 | 0.60828  | 0.642017 | 0.60828  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.645161 | 0.652174 | 0.648649 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.717391 | 0.597444 | 0.651947 | 0.597444 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 16:26:51,910 - trainer - INFO] - Train Epoch:[48/100] Step:[110/250] Total Loss: 20.757744 GL_Loss: 0.550712 CRF_Loss: 20.207031\n",
      "[2022-02-17 16:27:06,806 - trainer - INFO] - Train Epoch:[48/100] Step:[120/250] Total Loss: 26.011768 GL_Loss: 0.523732 CRF_Loss: 25.488037\n",
      "[2022-02-17 16:27:21,100 - trainer - INFO] - Train Epoch:[48/100] Step:[130/250] Total Loss: 25.539179 GL_Loss: 0.923761 CRF_Loss: 24.615417\n",
      "[2022-02-17 16:27:35,358 - trainer - INFO] - Train Epoch:[48/100] Step:[140/250] Total Loss: 18.339394 GL_Loss: 0.464760 CRF_Loss: 17.874634\n",
      "[2022-02-17 16:27:49,072 - trainer - INFO] - Train Epoch:[48/100] Step:[150/250] Total Loss: 21.720596 GL_Loss: 0.546769 CRF_Loss: 21.173828\n",
      "[2022-02-17 16:28:08,244 - trainer - INFO] - [Step Validation] Epoch:[48/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.89697  | 0.942675 | 0.919255 | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.679012 | 0.43883  | 0.533118 | 0.43883  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.682143 | 0.60828  | 0.643098 | 0.60828  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.663043 | 0.663043 | 0.663043 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.724359 | 0.601704 | 0.657359 | 0.601704 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 16:28:23,380 - trainer - INFO] - Train Epoch:[48/100] Step:[160/250] Total Loss: 25.144737 GL_Loss: 0.679039 CRF_Loss: 24.465698\n",
      "[2022-02-17 16:28:38,318 - trainer - INFO] - Train Epoch:[48/100] Step:[170/250] Total Loss: 545.231079 GL_Loss: 0.590343 CRF_Loss: 544.640747\n",
      "[2022-02-17 16:28:52,385 - trainer - INFO] - Train Epoch:[48/100] Step:[180/250] Total Loss: 50.506413 GL_Loss: 0.396487 CRF_Loss: 50.109924\n",
      "[2022-02-17 16:29:06,878 - trainer - INFO] - Train Epoch:[48/100] Step:[190/250] Total Loss: 74.111397 GL_Loss: 0.461980 CRF_Loss: 73.649414\n",
      "[2022-02-17 16:29:20,671 - trainer - INFO] - Train Epoch:[48/100] Step:[200/250] Total Loss: 30.340204 GL_Loss: 0.384638 CRF_Loss: 29.955566\n",
      "[2022-02-17 16:29:39,578 - trainer - INFO] - [Step Validation] Epoch:[48/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.691057 | 0.452128 | 0.546624 | 0.452128 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.689531 | 0.60828  | 0.646362 | 0.60828  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.652174 | 0.652174 | 0.652174 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.728792 | 0.603834 | 0.660454 | 0.603834 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 16:29:41,748 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 16:29:55,774 - trainer - INFO] - Train Epoch:[48/100] Step:[210/250] Total Loss: 25.237270 GL_Loss: 0.595669 CRF_Loss: 24.641602\n",
      "[2022-02-17 16:30:10,367 - trainer - INFO] - Train Epoch:[48/100] Step:[220/250] Total Loss: 1040.806885 GL_Loss: 0.458800 CRF_Loss: 1040.348145\n",
      "[2022-02-17 16:30:24,735 - trainer - INFO] - Train Epoch:[48/100] Step:[230/250] Total Loss: 33.481522 GL_Loss: 0.392409 CRF_Loss: 33.089111\n",
      "[2022-02-17 16:30:37,734 - trainer - INFO] - Train Epoch:[48/100] Step:[240/250] Total Loss: 40.227219 GL_Loss: 0.324630 CRF_Loss: 39.902588\n",
      "[2022-02-17 16:30:52,097 - trainer - INFO] - Train Epoch:[48/100] Step:[250/250] Total Loss: 30.465921 GL_Loss: 0.538920 CRF_Loss: 29.927002\n",
      "[2022-02-17 16:31:13,001 - trainer - INFO] - [Step Validation] Epoch:[48/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.708502 | 0.465426 | 0.561798 | 0.465426 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.636076 | 0.640127 | 0.638095 | 0.640127 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.62766  | 0.641304 | 0.634409 | 0.641304 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.708537 | 0.618743 | 0.660603 | 0.618743 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 16:31:15,157 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 16:31:34,483 - trainer - INFO] - [Epoch Validation] Epoch:[48/100] Total Loss: 48.787311 GL_Loss: 0.005375 CRF_Loss: 48.249811 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.708502 | 0.465426 | 0.561798 | 0.465426 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.636076 | 0.640127 | 0.638095 | 0.640127 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.62766  | 0.641304 | 0.634409 | 0.641304 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.708537 | 0.618743 | 0.660603 | 0.618743 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 16:31:49,769 - trainer - INFO] - Train Epoch:[49/100] Step:[10/250] Total Loss: 32.949131 GL_Loss: 0.732822 CRF_Loss: 32.216309\n",
      "[2022-02-17 16:32:04,456 - trainer - INFO] - Train Epoch:[49/100] Step:[20/250] Total Loss: 25.377069 GL_Loss: 0.466547 CRF_Loss: 24.910522\n",
      "[2022-02-17 16:32:19,131 - trainer - INFO] - Train Epoch:[49/100] Step:[30/250] Total Loss: 25.818956 GL_Loss: 0.442002 CRF_Loss: 25.376953\n",
      "[2022-02-17 16:32:33,303 - trainer - INFO] - Train Epoch:[49/100] Step:[40/250] Total Loss: 22.735807 GL_Loss: 0.491789 CRF_Loss: 22.244019\n",
      "[2022-02-17 16:32:47,895 - trainer - INFO] - Train Epoch:[49/100] Step:[50/250] Total Loss: 500.933685 GL_Loss: 0.530127 CRF_Loss: 500.403564\n",
      "[2022-02-17 16:33:07,054 - trainer - INFO] - [Step Validation] Epoch:[49/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.889571 | 0.923567 | 0.90625  | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.684211 | 0.449468 | 0.542536 | 0.449468 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.712598 | 0.576433 | 0.637324 | 0.576433 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.67033  | 0.663043 | 0.666667 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.736424 | 0.592119 | 0.656434 | 0.592119 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 16:33:22,569 - trainer - INFO] - Train Epoch:[49/100] Step:[60/250] Total Loss: 21.744884 GL_Loss: 0.435497 CRF_Loss: 21.309387\n",
      "[2022-02-17 16:33:37,366 - trainer - INFO] - Train Epoch:[49/100] Step:[70/250] Total Loss: 37.233444 GL_Loss: 0.440232 CRF_Loss: 36.793213\n",
      "[2022-02-17 16:33:52,243 - trainer - INFO] - Train Epoch:[49/100] Step:[80/250] Total Loss: 23.355633 GL_Loss: 0.588176 CRF_Loss: 22.767456\n",
      "[2022-02-17 16:34:07,847 - trainer - INFO] - Train Epoch:[49/100] Step:[90/250] Total Loss: 16.665953 GL_Loss: 0.705259 CRF_Loss: 15.960693\n",
      "[2022-02-17 16:34:21,992 - trainer - INFO] - Train Epoch:[49/100] Step:[100/250] Total Loss: 18.282080 GL_Loss: 0.465674 CRF_Loss: 17.816406\n",
      "[2022-02-17 16:34:41,053 - trainer - INFO] - [Step Validation] Epoch:[49/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.885542 | 0.936306 | 0.910217 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.677551 | 0.441489 | 0.534622 | 0.441489 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.660959 | 0.61465  | 0.636964 | 0.61465  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.645161 | 0.652174 | 0.648649 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.711055 | 0.602769 | 0.65245  | 0.602769 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 16:34:54,869 - trainer - INFO] - Train Epoch:[49/100] Step:[110/250] Total Loss: 18.204447 GL_Loss: 0.424295 CRF_Loss: 17.780151\n",
      "[2022-02-17 16:35:08,403 - trainer - INFO] - Train Epoch:[49/100] Step:[120/250] Total Loss: 19.669281 GL_Loss: 0.630096 CRF_Loss: 19.039185\n",
      "[2022-02-17 16:35:21,666 - trainer - INFO] - Train Epoch:[49/100] Step:[130/250] Total Loss: 171.727707 GL_Loss: 0.614546 CRF_Loss: 171.113159\n",
      "[2022-02-17 16:35:36,259 - trainer - INFO] - Train Epoch:[49/100] Step:[140/250] Total Loss: 16.542206 GL_Loss: 0.641571 CRF_Loss: 15.900635\n",
      "[2022-02-17 16:35:51,218 - trainer - INFO] - Train Epoch:[49/100] Step:[150/250] Total Loss: 84.573120 GL_Loss: 0.532833 CRF_Loss: 84.040283\n",
      "[2022-02-17 16:36:10,225 - trainer - INFO] - [Step Validation] Epoch:[49/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.891566 | 0.942675 | 0.916409 | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.682927 | 0.446809 | 0.540193 | 0.446809 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.707692 | 0.585987 | 0.641115 | 0.585987 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.655914 | 0.663043 | 0.659459 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.733333 | 0.597444 | 0.658451 | 0.597444 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 16:36:23,986 - trainer - INFO] - Train Epoch:[49/100] Step:[160/250] Total Loss: 39.568474 GL_Loss: 0.677240 CRF_Loss: 38.891235\n",
      "[2022-02-17 16:36:38,039 - trainer - INFO] - Train Epoch:[49/100] Step:[170/250] Total Loss: 18.300486 GL_Loss: 0.857859 CRF_Loss: 17.442627\n",
      "[2022-02-17 16:36:51,398 - trainer - INFO] - Train Epoch:[49/100] Step:[180/250] Total Loss: 15.732975 GL_Loss: 0.585270 CRF_Loss: 15.147705\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 16:37:05,164 - trainer - INFO] - Train Epoch:[49/100] Step:[190/250] Total Loss: 103.693108 GL_Loss: 0.545526 CRF_Loss: 103.147583\n",
      "[2022-02-17 16:37:19,568 - trainer - INFO] - Train Epoch:[49/100] Step:[200/250] Total Loss: 67.612381 GL_Loss: 0.308305 CRF_Loss: 67.304077\n",
      "[2022-02-17 16:37:38,724 - trainer - INFO] - [Step Validation] Epoch:[49/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.8625   | 0.878981 | 0.870662 | 0.878981 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.673469 | 0.43883  | 0.531401 | 0.43883  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.69962  | 0.585987 | 0.637782 | 0.585987 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.673913 | 0.673913 | 0.673913 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.722368 | 0.584665 | 0.646263 | 0.584665 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 16:37:53,058 - trainer - INFO] - Train Epoch:[49/100] Step:[210/250] Total Loss: 34.663631 GL_Loss: 1.277890 CRF_Loss: 33.385742\n",
      "[2022-02-17 16:38:08,153 - trainer - INFO] - Train Epoch:[49/100] Step:[220/250] Total Loss: 43.177181 GL_Loss: 0.931821 CRF_Loss: 42.245361\n",
      "[2022-02-17 16:38:22,772 - trainer - INFO] - Train Epoch:[49/100] Step:[230/250] Total Loss: 93.788162 GL_Loss: 0.484209 CRF_Loss: 93.303955\n",
      "[2022-02-17 16:38:36,625 - trainer - INFO] - Train Epoch:[49/100] Step:[240/250] Total Loss: 20.425604 GL_Loss: 0.398749 CRF_Loss: 20.026855\n",
      "[2022-02-17 16:38:50,559 - trainer - INFO] - Train Epoch:[49/100] Step:[250/250] Total Loss: 94.040604 GL_Loss: 0.311354 CRF_Loss: 93.729248\n",
      "[2022-02-17 16:39:09,485 - trainer - INFO] - [Step Validation] Epoch:[49/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.90184  | 0.936306 | 0.91875  | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.688525 | 0.446809 | 0.541935 | 0.446809 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.702602 | 0.601911 | 0.64837  | 0.601911 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.641304 | 0.641304 | 0.641304 | 0.641304 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.733073 | 0.599574 | 0.659637 | 0.599574 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 16:39:28,439 - trainer - INFO] - [Epoch Validation] Epoch:[49/100] Total Loss: 47.504050 GL_Loss: 0.005278 CRF_Loss: 46.976217 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.90184  | 0.936306 | 0.91875  | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.688525 | 0.446809 | 0.541935 | 0.446809 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.702602 | 0.601911 | 0.64837  | 0.601911 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.641304 | 0.641304 | 0.641304 | 0.641304 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.733073 | 0.599574 | 0.659637 | 0.599574 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 16:39:43,418 - trainer - INFO] - Train Epoch:[50/100] Step:[10/250] Total Loss: 39.801559 GL_Loss: 0.316696 CRF_Loss: 39.484863\n",
      "[2022-02-17 16:39:57,568 - trainer - INFO] - Train Epoch:[50/100] Step:[20/250] Total Loss: 25.884748 GL_Loss: 0.519269 CRF_Loss: 25.365479\n",
      "[2022-02-17 16:40:11,370 - trainer - INFO] - Train Epoch:[50/100] Step:[30/250] Total Loss: 25.139004 GL_Loss: 0.504482 CRF_Loss: 24.634521\n",
      "[2022-02-17 16:40:25,713 - trainer - INFO] - Train Epoch:[50/100] Step:[40/250] Total Loss: 30.868834 GL_Loss: 0.550231 CRF_Loss: 30.318604\n",
      "[2022-02-17 16:40:40,370 - trainer - INFO] - Train Epoch:[50/100] Step:[50/250] Total Loss: 26.236177 GL_Loss: 0.407808 CRF_Loss: 25.828369\n",
      "[2022-02-17 16:40:59,101 - trainer - INFO] - [Step Validation] Epoch:[50/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.907975 | 0.942675 | 0.925    | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.683128 | 0.441489 | 0.536349 | 0.441489 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.672355 | 0.627389 | 0.649094 | 0.627389 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.645161 | 0.652174 | 0.648649 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.72096  | 0.608094 | 0.659734 | 0.608094 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 16:41:14,727 - trainer - INFO] - Train Epoch:[50/100] Step:[60/250] Total Loss: 14.811156 GL_Loss: 0.649169 CRF_Loss: 14.161987\n",
      "[2022-02-17 16:41:28,664 - trainer - INFO] - Train Epoch:[50/100] Step:[70/250] Total Loss: 67.185242 GL_Loss: 0.387145 CRF_Loss: 66.798096\n",
      "[2022-02-17 16:41:42,703 - trainer - INFO] - Train Epoch:[50/100] Step:[80/250] Total Loss: 59.336636 GL_Loss: 0.323817 CRF_Loss: 59.012817\n",
      "[2022-02-17 16:41:57,673 - trainer - INFO] - Train Epoch:[50/100] Step:[90/250] Total Loss: 15.090828 GL_Loss: 0.585212 CRF_Loss: 14.505615\n",
      "[2022-02-17 16:42:11,325 - trainer - INFO] - Train Epoch:[50/100] Step:[100/250] Total Loss: 20.327009 GL_Loss: 0.718245 CRF_Loss: 19.608765\n",
      "[2022-02-17 16:42:30,323 - trainer - INFO] - [Step Validation] Epoch:[50/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.884146 | 0.923567 | 0.903427 | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.655602 | 0.420213 | 0.512156 | 0.420213 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.69145  | 0.592357 | 0.638079 | 0.592357 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.663043 | 0.663043 | 0.663043 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.718016 | 0.585729 | 0.645161 | 0.585729 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 16:42:45,158 - trainer - INFO] - Train Epoch:[50/100] Step:[110/250] Total Loss: 38.037193 GL_Loss: 0.533960 CRF_Loss: 37.503235\n",
      "[2022-02-17 16:42:58,822 - trainer - INFO] - Train Epoch:[50/100] Step:[120/250] Total Loss: 33.697166 GL_Loss: 0.460962 CRF_Loss: 33.236206\n",
      "[2022-02-17 16:43:11,985 - trainer - INFO] - Train Epoch:[50/100] Step:[130/250] Total Loss: 27.494478 GL_Loss: 0.386934 CRF_Loss: 27.107544\n",
      "[2022-02-17 16:43:26,451 - trainer - INFO] - Train Epoch:[50/100] Step:[140/250] Total Loss: 23.168087 GL_Loss: 0.513790 CRF_Loss: 22.654297\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 16:43:40,313 - trainer - INFO] - Train Epoch:[50/100] Step:[150/250] Total Loss: 17.611067 GL_Loss: 0.460309 CRF_Loss: 17.150757\n",
      "[2022-02-17 16:43:59,424 - trainer - INFO] - [Step Validation] Epoch:[50/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.890909 | 0.936306 | 0.913043 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.680328 | 0.441489 | 0.535484 | 0.441489 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.677305 | 0.60828  | 0.64094  | 0.60828  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.641304 | 0.641304 | 0.641304 | 0.641304 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.719029 | 0.599574 | 0.653891 | 0.599574 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 16:44:13,487 - trainer - INFO] - Train Epoch:[50/100] Step:[160/250] Total Loss: 17.160429 GL_Loss: 0.841947 CRF_Loss: 16.318481\n",
      "[2022-02-17 16:44:28,640 - trainer - INFO] - Train Epoch:[50/100] Step:[170/250] Total Loss: 11.022069 GL_Loss: 0.456517 CRF_Loss: 10.565552\n",
      "[2022-02-17 16:44:43,230 - trainer - INFO] - Train Epoch:[50/100] Step:[180/250] Total Loss: 53.720325 GL_Loss: 0.409292 CRF_Loss: 53.311035\n",
      "[2022-02-17 16:44:56,898 - trainer - INFO] - Train Epoch:[50/100] Step:[190/250] Total Loss: 19.908089 GL_Loss: 0.517097 CRF_Loss: 19.390991\n",
      "[2022-02-17 16:45:10,579 - trainer - INFO] - Train Epoch:[50/100] Step:[200/250] Total Loss: 44.832432 GL_Loss: 0.389193 CRF_Loss: 44.443237\n",
      "[2022-02-17 16:45:29,526 - trainer - INFO] - [Step Validation] Epoch:[50/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.90184  | 0.936306 | 0.91875  | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.689516 | 0.454787 | 0.548077 | 0.454787 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.641026 | 0.636943 | 0.638978 | 0.636943 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.648352 | 0.641304 | 0.644809 | 0.641304 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.708845 | 0.614483 | 0.6583   | 0.614483 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 16:45:43,732 - trainer - INFO] - Train Epoch:[50/100] Step:[210/250] Total Loss: 89.440567 GL_Loss: 0.411760 CRF_Loss: 89.028809\n",
      "[2022-02-17 16:45:58,111 - trainer - INFO] - Train Epoch:[50/100] Step:[220/250] Total Loss: 26.105999 GL_Loss: 0.725750 CRF_Loss: 25.380249\n",
      "[2022-02-17 16:46:12,208 - trainer - INFO] - Train Epoch:[50/100] Step:[230/250] Total Loss: 27.972734 GL_Loss: 0.410234 CRF_Loss: 27.562500\n",
      "[2022-02-17 16:46:26,703 - trainer - INFO] - Train Epoch:[50/100] Step:[240/250] Total Loss: 15.658694 GL_Loss: 0.312136 CRF_Loss: 15.346558\n",
      "[2022-02-17 16:46:40,763 - trainer - INFO] - Train Epoch:[50/100] Step:[250/250] Total Loss: 15.527006 GL_Loss: 0.454130 CRF_Loss: 15.072876\n",
      "[2022-02-17 16:46:59,942 - trainer - INFO] - [Step Validation] Epoch:[50/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.896341 | 0.936306 | 0.915888 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.688259 | 0.452128 | 0.545746 | 0.452128 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.691756 | 0.61465  | 0.650927 | 0.61465  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.641304 | 0.641304 | 0.641304 | 0.641304 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.727621 | 0.605964 | 0.661243 | 0.605964 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 16:47:02,140 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 16:47:22,007 - trainer - INFO] - [Epoch Validation] Epoch:[50/100] Total Loss: 47.813795 GL_Loss: 0.005190 CRF_Loss: 47.294815 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.896341 | 0.936306 | 0.915888 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.688259 | 0.452128 | 0.545746 | 0.452128 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.691756 | 0.61465  | 0.650927 | 0.61465  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.641304 | 0.641304 | 0.641304 | 0.641304 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.727621 | 0.605964 | 0.661243 | 0.605964 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 16:47:36,666 - trainer - INFO] - Train Epoch:[51/100] Step:[10/250] Total Loss: 43.890450 GL_Loss: 0.881629 CRF_Loss: 43.008820\n",
      "[2022-02-17 16:47:50,980 - trainer - INFO] - Train Epoch:[51/100] Step:[20/250] Total Loss: 17.370047 GL_Loss: 0.610524 CRF_Loss: 16.759521\n",
      "[2022-02-17 16:48:05,641 - trainer - INFO] - Train Epoch:[51/100] Step:[30/250] Total Loss: 45.002838 GL_Loss: 0.311920 CRF_Loss: 44.690918\n",
      "[2022-02-17 16:48:18,905 - trainer - INFO] - Train Epoch:[51/100] Step:[40/250] Total Loss: 345.501831 GL_Loss: 0.417487 CRF_Loss: 345.084351\n",
      "[2022-02-17 16:48:32,824 - trainer - INFO] - Train Epoch:[51/100] Step:[50/250] Total Loss: 31.803318 GL_Loss: 0.435764 CRF_Loss: 31.367554\n",
      "[2022-02-17 16:48:51,608 - trainer - INFO] - [Step Validation] Epoch:[51/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.690763 | 0.457447 | 0.5504   | 0.457447 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.641935 | 0.633758 | 0.637821 | 0.633758 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.663043 | 0.663043 | 0.663043 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.710074 | 0.615548 | 0.659441 | 0.615548 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 16:49:06,476 - trainer - INFO] - Train Epoch:[51/100] Step:[60/250] Total Loss: 14.920906 GL_Loss: 0.503914 CRF_Loss: 14.416992\n",
      "[2022-02-17 16:49:21,413 - trainer - INFO] - Train Epoch:[51/100] Step:[70/250] Total Loss: 12.475342 GL_Loss: 0.497315 CRF_Loss: 11.978027\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 16:49:35,163 - trainer - INFO] - Train Epoch:[51/100] Step:[80/250] Total Loss: 60.103806 GL_Loss: 0.457323 CRF_Loss: 59.646484\n",
      "[2022-02-17 16:49:48,726 - trainer - INFO] - Train Epoch:[51/100] Step:[90/250] Total Loss: 12.911903 GL_Loss: 0.614784 CRF_Loss: 12.297119\n",
      "[2022-02-17 16:50:02,939 - trainer - INFO] - Train Epoch:[51/100] Step:[100/250] Total Loss: 39.501301 GL_Loss: 0.508015 CRF_Loss: 38.993286\n",
      "[2022-02-17 16:50:21,948 - trainer - INFO] - [Step Validation] Epoch:[51/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.896341 | 0.936306 | 0.915888 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.685484 | 0.452128 | 0.544872 | 0.452128 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.663333 | 0.633758 | 0.648208 | 0.633758 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.648352 | 0.641304 | 0.644809 | 0.641304 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.716065 | 0.612354 | 0.660161 | 0.612354 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 16:50:35,450 - trainer - INFO] - Train Epoch:[51/100] Step:[110/250] Total Loss: 107.912933 GL_Loss: 0.500094 CRF_Loss: 107.412842\n",
      "[2022-02-17 16:50:50,631 - trainer - INFO] - Train Epoch:[51/100] Step:[120/250] Total Loss: 15.414865 GL_Loss: 0.443674 CRF_Loss: 14.971191\n",
      "[2022-02-17 16:51:04,378 - trainer - INFO] - Train Epoch:[51/100] Step:[130/250] Total Loss: 30.551167 GL_Loss: 1.055561 CRF_Loss: 29.495605\n",
      "[2022-02-17 16:51:18,298 - trainer - INFO] - Train Epoch:[51/100] Step:[140/250] Total Loss: 10.813751 GL_Loss: 0.528595 CRF_Loss: 10.285156\n",
      "[2022-02-17 16:51:32,554 - trainer - INFO] - Train Epoch:[51/100] Step:[150/250] Total Loss: 63.202477 GL_Loss: 0.852011 CRF_Loss: 62.350464\n",
      "[2022-02-17 16:51:51,703 - trainer - INFO] - [Step Validation] Epoch:[51/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.885542 | 0.936306 | 0.910217 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.699187 | 0.457447 | 0.553055 | 0.457447 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.704545 | 0.592357 | 0.643599 | 0.592357 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.623656 | 0.630435 | 0.627027 | 0.630435 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.73212  | 0.599574 | 0.659251 | 0.599574 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 16:52:06,670 - trainer - INFO] - Train Epoch:[51/100] Step:[160/250] Total Loss: 18.530497 GL_Loss: 0.465312 CRF_Loss: 18.065186\n",
      "[2022-02-17 16:52:21,348 - trainer - INFO] - Train Epoch:[51/100] Step:[170/250] Total Loss: 17.316298 GL_Loss: 0.499890 CRF_Loss: 16.816406\n",
      "[2022-02-17 16:52:34,898 - trainer - INFO] - Train Epoch:[51/100] Step:[180/250] Total Loss: 22.932278 GL_Loss: 0.489406 CRF_Loss: 22.442871\n",
      "[2022-02-17 16:52:49,237 - trainer - INFO] - Train Epoch:[51/100] Step:[190/250] Total Loss: 171.234207 GL_Loss: 0.573934 CRF_Loss: 170.660278\n",
      "[2022-02-17 16:53:04,461 - trainer - INFO] - Train Epoch:[51/100] Step:[200/250] Total Loss: 39.198669 GL_Loss: 0.667420 CRF_Loss: 38.531250\n",
      "[2022-02-17 16:53:23,374 - trainer - INFO] - [Step Validation] Epoch:[51/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.883436 | 0.917197 | 0.9      | 0.917197 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.690763 | 0.457447 | 0.5504   | 0.457447 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.66899  | 0.611465 | 0.638935 | 0.611465 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.655914 | 0.663043 | 0.659459 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.718434 | 0.605964 | 0.657423 | 0.605964 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 16:53:38,222 - trainer - INFO] - Train Epoch:[51/100] Step:[210/250] Total Loss: 24.942150 GL_Loss: 0.479748 CRF_Loss: 24.462402\n",
      "[2022-02-17 16:53:52,874 - trainer - INFO] - Train Epoch:[51/100] Step:[220/250] Total Loss: 64.910805 GL_Loss: 0.495036 CRF_Loss: 64.415771\n",
      "[2022-02-17 16:54:08,181 - trainer - INFO] - Train Epoch:[51/100] Step:[230/250] Total Loss: 15.943909 GL_Loss: 0.835022 CRF_Loss: 15.108887\n",
      "[2022-02-17 16:54:22,830 - trainer - INFO] - Train Epoch:[51/100] Step:[240/250] Total Loss: 16.367413 GL_Loss: 0.654278 CRF_Loss: 15.713135\n",
      "[2022-02-17 16:54:38,006 - trainer - INFO] - Train Epoch:[51/100] Step:[250/250] Total Loss: 33.602100 GL_Loss: 0.428883 CRF_Loss: 33.173218\n",
      "[2022-02-17 16:54:56,928 - trainer - INFO] - [Step Validation] Epoch:[51/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.907975 | 0.942675 | 0.925    | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.692623 | 0.449468 | 0.545161 | 0.449468 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.710937 | 0.579618 | 0.638596 | 0.579618 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.655914 | 0.663043 | 0.659459 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.740741 | 0.596379 | 0.660767 | 0.596379 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 16:55:17,604 - trainer - INFO] - [Epoch Validation] Epoch:[51/100] Total Loss: 47.729730 GL_Loss: 0.005305 CRF_Loss: 47.199270 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.907975 | 0.942675 | 0.925    | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.692623 | 0.449468 | 0.545161 | 0.449468 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.710937 | 0.579618 | 0.638596 | 0.579618 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.655914 | 0.663043 | 0.659459 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.740741 | 0.596379 | 0.660767 | 0.596379 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 16:55:33,935 - trainer - INFO] - Train Epoch:[52/100] Step:[10/250] Total Loss: 29.121040 GL_Loss: 0.434639 CRF_Loss: 28.686401\n",
      "[2022-02-17 16:55:48,591 - trainer - INFO] - Train Epoch:[52/100] Step:[20/250] Total Loss: 25.367023 GL_Loss: 0.478596 CRF_Loss: 24.888428\n",
      "[2022-02-17 16:56:04,041 - trainer - INFO] - Train Epoch:[52/100] Step:[30/250] Total Loss: 41.423092 GL_Loss: 0.660517 CRF_Loss: 40.762573\n",
      "[2022-02-17 16:56:18,930 - trainer - INFO] - Train Epoch:[52/100] Step:[40/250] Total Loss: 70.911850 GL_Loss: 0.359119 CRF_Loss: 70.552734\n",
      "[2022-02-17 16:56:34,072 - trainer - INFO] - Train Epoch:[52/100] Step:[50/250] Total Loss: 25.336081 GL_Loss: 0.526632 CRF_Loss: 24.809448\n",
      "[2022-02-17 16:56:53,128 - trainer - INFO] - [Step Validation] Epoch:[52/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.691057 | 0.452128 | 0.546624 | 0.452128 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.657627 | 0.617834 | 0.63711  | 0.617834 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.677419 | 0.684783 | 0.681081 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.718946 | 0.610224 | 0.660138 | 0.610224 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 16:57:07,561 - trainer - INFO] - Train Epoch:[52/100] Step:[60/250] Total Loss: 45.377579 GL_Loss: 0.620500 CRF_Loss: 44.757080\n",
      "[2022-02-17 16:57:21,120 - trainer - INFO] - Train Epoch:[52/100] Step:[70/250] Total Loss: 19.189369 GL_Loss: 0.486000 CRF_Loss: 18.703369\n",
      "[2022-02-17 16:57:34,776 - trainer - INFO] - Train Epoch:[52/100] Step:[80/250] Total Loss: 175.239838 GL_Loss: 0.452241 CRF_Loss: 174.787598\n",
      "[2022-02-17 16:57:49,978 - trainer - INFO] - Train Epoch:[52/100] Step:[90/250] Total Loss: 27.855276 GL_Loss: 0.457938 CRF_Loss: 27.397339\n",
      "[2022-02-17 16:58:05,072 - trainer - INFO] - Train Epoch:[52/100] Step:[100/250] Total Loss: 33.792900 GL_Loss: 0.420341 CRF_Loss: 33.372559\n",
      "[2022-02-17 16:58:23,988 - trainer - INFO] - [Step Validation] Epoch:[52/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.907407 | 0.936306 | 0.92163  | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.684211 | 0.449468 | 0.542536 | 0.449468 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.7      | 0.579618 | 0.634146 | 0.579618 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.67033  | 0.663043 | 0.666667 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.735526 | 0.595314 | 0.658034 | 0.595314 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 16:58:38,021 - trainer - INFO] - Train Epoch:[52/100] Step:[110/250] Total Loss: 34.894035 GL_Loss: 0.556391 CRF_Loss: 34.337646\n",
      "[2022-02-17 16:58:51,575 - trainer - INFO] - Train Epoch:[52/100] Step:[120/250] Total Loss: 35.467751 GL_Loss: 0.650124 CRF_Loss: 34.817627\n",
      "[2022-02-17 16:59:05,600 - trainer - INFO] - Train Epoch:[52/100] Step:[130/250] Total Loss: 29.827803 GL_Loss: 0.322310 CRF_Loss: 29.505493\n",
      "[2022-02-17 16:59:19,377 - trainer - INFO] - Train Epoch:[52/100] Step:[140/250] Total Loss: 26.993963 GL_Loss: 0.614325 CRF_Loss: 26.379639\n",
      "[2022-02-17 16:59:34,097 - trainer - INFO] - Train Epoch:[52/100] Step:[150/250] Total Loss: 11.346261 GL_Loss: 0.511056 CRF_Loss: 10.835205\n",
      "[2022-02-17 16:59:53,315 - trainer - INFO] - [Step Validation] Epoch:[52/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.879518 | 0.929936 | 0.904025 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.716535 | 0.484043 | 0.577778 | 0.484043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.650641 | 0.646497 | 0.648562 | 0.646497 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.666667 | 0.673913 | 0.67027  | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.718788 | 0.631523 | 0.672336 | 0.631523 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 16:59:55,580 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 17:00:10,158 - trainer - INFO] - Train Epoch:[52/100] Step:[160/250] Total Loss: 58.267582 GL_Loss: 0.957769 CRF_Loss: 57.309814\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 17:00:23,709 - trainer - INFO] - Train Epoch:[52/100] Step:[170/250] Total Loss: 24.385317 GL_Loss: 0.539248 CRF_Loss: 23.846069\n",
      "[2022-02-17 17:00:37,809 - trainer - INFO] - Train Epoch:[52/100] Step:[180/250] Total Loss: 13.923305 GL_Loss: 0.883510 CRF_Loss: 13.039795\n",
      "[2022-02-17 17:00:52,918 - trainer - INFO] - Train Epoch:[52/100] Step:[190/250] Total Loss: 20.044552 GL_Loss: 0.540157 CRF_Loss: 19.504395\n",
      "[2022-02-17 17:01:06,980 - trainer - INFO] - Train Epoch:[52/100] Step:[200/250] Total Loss: 16.957148 GL_Loss: 0.352900 CRF_Loss: 16.604248\n",
      "[2022-02-17 17:01:25,855 - trainer - INFO] - [Step Validation] Epoch:[52/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.896341 | 0.936306 | 0.915888 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.710317 | 0.476064 | 0.570064 | 0.476064 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.656863 | 0.640127 | 0.648387 | 0.640127 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.655914 | 0.663043 | 0.659459 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.721472 | 0.626198 | 0.670468 | 0.626198 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 17:02:08,621 - trainer - INFO] - Train Epoch:[52/100] Step:[230/250] Total Loss: 26.674355 GL_Loss: 0.522743 CRF_Loss: 26.151611\n",
      "[2022-02-17 17:02:21,635 - trainer - INFO] - Train Epoch:[52/100] Step:[240/250] Total Loss: 22.998075 GL_Loss: 0.519560 CRF_Loss: 22.478516\n",
      "[2022-02-17 17:02:35,487 - trainer - INFO] - Train Epoch:[52/100] Step:[250/250] Total Loss: 34.378132 GL_Loss: 0.563921 CRF_Loss: 33.814209\n",
      "[2022-02-17 17:02:54,263 - trainer - INFO] - [Step Validation] Epoch:[52/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.709804 | 0.481383 | 0.573693 | 0.481383 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.654605 | 0.633758 | 0.644013 | 0.633758 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.645161 | 0.652174 | 0.648649 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.719018 | 0.624068 | 0.668187 | 0.624068 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 17:03:13,147 - trainer - INFO] - [Epoch Validation] Epoch:[52/100] Total Loss: 46.450523 GL_Loss: 0.005432 CRF_Loss: 45.907356 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.709804 | 0.481383 | 0.573693 | 0.481383 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.654605 | 0.633758 | 0.644013 | 0.633758 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.645161 | 0.652174 | 0.648649 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.719018 | 0.624068 | 0.668187 | 0.624068 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 17:03:28,260 - trainer - INFO] - Train Epoch:[53/100] Step:[10/250] Total Loss: 43.984394 GL_Loss: 0.460043 CRF_Loss: 43.524353\n",
      "[2022-02-17 17:03:42,158 - trainer - INFO] - Train Epoch:[53/100] Step:[20/250] Total Loss: 58.838806 GL_Loss: 0.529968 CRF_Loss: 58.308838\n",
      "[2022-02-17 17:03:57,207 - trainer - INFO] - Train Epoch:[53/100] Step:[30/250] Total Loss: 19.849566 GL_Loss: 0.652788 CRF_Loss: 19.196777\n",
      "[2022-02-17 17:04:11,740 - trainer - INFO] - Train Epoch:[53/100] Step:[40/250] Total Loss: 16.654800 GL_Loss: 0.514054 CRF_Loss: 16.140747\n",
      "[2022-02-17 17:04:26,374 - trainer - INFO] - Train Epoch:[53/100] Step:[50/250] Total Loss: 19.752541 GL_Loss: 0.656960 CRF_Loss: 19.095581\n",
      "[2022-02-17 17:04:45,443 - trainer - INFO] - [Step Validation] Epoch:[53/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.901235 | 0.929936 | 0.915361 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.717647 | 0.486702 | 0.580032 | 0.486702 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.645902 | 0.627389 | 0.636511 | 0.627389 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.638298 | 0.652174 | 0.645161 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.718137 | 0.624068 | 0.667806 | 0.624068 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 17:04:59,122 - trainer - INFO] - Train Epoch:[53/100] Step:[60/250] Total Loss: 26.663078 GL_Loss: 0.429437 CRF_Loss: 26.233643\n",
      "[2022-02-17 17:05:13,386 - trainer - INFO] - Train Epoch:[53/100] Step:[70/250] Total Loss: 14.970780 GL_Loss: 0.402421 CRF_Loss: 14.568359\n",
      "[2022-02-17 17:05:27,027 - trainer - INFO] - Train Epoch:[53/100] Step:[80/250] Total Loss: 30.105024 GL_Loss: 0.515180 CRF_Loss: 29.589844\n",
      "[2022-02-17 17:05:41,223 - trainer - INFO] - Train Epoch:[53/100] Step:[90/250] Total Loss: 55.650429 GL_Loss: 0.380409 CRF_Loss: 55.270020\n",
      "[2022-02-17 17:05:55,346 - trainer - INFO] - Train Epoch:[53/100] Step:[100/250] Total Loss: 27.796997 GL_Loss: 0.427368 CRF_Loss: 27.369629\n",
      "[2022-02-17 17:06:14,348 - trainer - INFO] - [Step Validation] Epoch:[53/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.896341 | 0.936306 | 0.915888 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.709804 | 0.481383 | 0.573693 | 0.481383 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.651466 | 0.636943 | 0.644122 | 0.636943 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.638298 | 0.652174 | 0.645161 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.717073 | 0.626198 | 0.668562 | 0.626198 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 17:06:28,361 - trainer - INFO] - Train Epoch:[53/100] Step:[110/250] Total Loss: 52.408203 GL_Loss: 0.454954 CRF_Loss: 51.953247\n",
      "[2022-02-17 17:06:41,731 - trainer - INFO] - Train Epoch:[53/100] Step:[120/250] Total Loss: 62.037270 GL_Loss: 0.476601 CRF_Loss: 61.560669\n",
      "[2022-02-17 17:06:55,253 - trainer - INFO] - Train Epoch:[53/100] Step:[130/250] Total Loss: 58.229660 GL_Loss: 0.452683 CRF_Loss: 57.776978\n",
      "[2022-02-17 17:07:10,038 - trainer - INFO] - Train Epoch:[53/100] Step:[140/250] Total Loss: 36.789974 GL_Loss: 0.743831 CRF_Loss: 36.046143\n",
      "[2022-02-17 17:07:24,055 - trainer - INFO] - Train Epoch:[53/100] Step:[150/250] Total Loss: 24.913538 GL_Loss: 0.454310 CRF_Loss: 24.459229\n",
      "[2022-02-17 17:07:43,130 - trainer - INFO] - [Step Validation] Epoch:[53/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.890909 | 0.936306 | 0.913043 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.693548 | 0.457447 | 0.551282 | 0.457447 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.70428  | 0.576433 | 0.633975 | 0.576433 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.652174 | 0.652174 | 0.652174 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.734908 | 0.596379 | 0.658436 | 0.596379 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 17:07:58,555 - trainer - INFO] - Train Epoch:[53/100] Step:[160/250] Total Loss: 8.335624 GL_Loss: 0.584403 CRF_Loss: 7.751221\n",
      "[2022-02-17 17:08:12,972 - trainer - INFO] - Train Epoch:[53/100] Step:[170/250] Total Loss: 14.777432 GL_Loss: 0.348477 CRF_Loss: 14.428955\n",
      "[2022-02-17 17:08:26,896 - trainer - INFO] - Train Epoch:[53/100] Step:[180/250] Total Loss: 101.104614 GL_Loss: 0.396972 CRF_Loss: 100.707642\n",
      "[2022-02-17 17:08:40,935 - trainer - INFO] - Train Epoch:[53/100] Step:[190/250] Total Loss: 34.390915 GL_Loss: 0.570359 CRF_Loss: 33.820557\n",
      "[2022-02-17 17:08:55,400 - trainer - INFO] - Train Epoch:[53/100] Step:[200/250] Total Loss: 55.933575 GL_Loss: 0.494733 CRF_Loss: 55.438843\n",
      "[2022-02-17 17:09:14,560 - trainer - INFO] - [Step Validation] Epoch:[53/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.889571 | 0.923567 | 0.90625  | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.711462 | 0.478723 | 0.572337 | 0.478723 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.710937 | 0.579618 | 0.638596 | 0.579618 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.652174 | 0.652174 | 0.652174 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.742147 | 0.603834 | 0.665884 | 0.603834 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 17:09:28,970 - trainer - INFO] - Train Epoch:[53/100] Step:[210/250] Total Loss: 52.053391 GL_Loss: 0.455979 CRF_Loss: 51.597412\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 17:09:41,853 - trainer - INFO] - Train Epoch:[53/100] Step:[220/250] Total Loss: 21.725599 GL_Loss: 0.471693 CRF_Loss: 21.253906\n",
      "[2022-02-17 17:09:55,730 - trainer - INFO] - Train Epoch:[53/100] Step:[230/250] Total Loss: 59.511936 GL_Loss: 0.565647 CRF_Loss: 58.946289\n",
      "[2022-02-17 17:10:10,445 - trainer - INFO] - Train Epoch:[53/100] Step:[240/250] Total Loss: 24.795963 GL_Loss: 0.390446 CRF_Loss: 24.405518\n",
      "[2022-02-17 17:10:24,742 - trainer - INFO] - Train Epoch:[53/100] Step:[250/250] Total Loss: 48.142773 GL_Loss: 0.590405 CRF_Loss: 47.552368\n",
      "[2022-02-17 17:10:44,233 - trainer - INFO] - [Step Validation] Epoch:[53/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.896341 | 0.936306 | 0.915888 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.690476 | 0.462766 | 0.55414  | 0.462766 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.648208 | 0.633758 | 0.640902 | 0.633758 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.655556 | 0.641304 | 0.648352 | 0.641304 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.712177 | 0.616613 | 0.660959 | 0.616613 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 17:11:03,431 - trainer - INFO] - [Epoch Validation] Epoch:[53/100] Total Loss: 46.070715 GL_Loss: 0.005198 CRF_Loss: 45.550942 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.896341 | 0.936306 | 0.915888 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.690476 | 0.462766 | 0.55414  | 0.462766 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.648208 | 0.633758 | 0.640902 | 0.633758 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.655556 | 0.641304 | 0.648352 | 0.641304 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.712177 | 0.616613 | 0.660959 | 0.616613 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 17:11:18,439 - trainer - INFO] - Train Epoch:[54/100] Step:[10/250] Total Loss: 19.905579 GL_Loss: 0.690980 CRF_Loss: 19.214600\n",
      "[2022-02-17 17:11:32,573 - trainer - INFO] - Train Epoch:[54/100] Step:[20/250] Total Loss: 16.187838 GL_Loss: 0.622530 CRF_Loss: 15.565308\n",
      "[2022-02-17 17:11:47,129 - trainer - INFO] - Train Epoch:[54/100] Step:[30/250] Total Loss: 11.037844 GL_Loss: 0.508059 CRF_Loss: 10.529785\n",
      "[2022-02-17 17:12:01,929 - trainer - INFO] - Train Epoch:[54/100] Step:[40/250] Total Loss: 71.573738 GL_Loss: 0.479986 CRF_Loss: 71.093750\n",
      "[2022-02-17 17:12:16,733 - trainer - INFO] - Train Epoch:[54/100] Step:[50/250] Total Loss: 32.091003 GL_Loss: 0.414246 CRF_Loss: 31.676758\n",
      "[2022-02-17 17:12:35,975 - trainer - INFO] - [Step Validation] Epoch:[54/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.901235 | 0.929936 | 0.915361 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.705882 | 0.478723 | 0.570523 | 0.478723 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.636646 | 0.652866 | 0.644654 | 0.652866 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.652174 | 0.652174 | 0.652174 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.711191 | 0.629393 | 0.667797 | 0.629393 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 17:12:49,904 - trainer - INFO] - Train Epoch:[54/100] Step:[60/250] Total Loss: 41.618969 GL_Loss: 0.351390 CRF_Loss: 41.267578\n",
      "[2022-02-17 17:13:04,593 - trainer - INFO] - Train Epoch:[54/100] Step:[70/250] Total Loss: 75.393303 GL_Loss: 0.326654 CRF_Loss: 75.066650\n",
      "[2022-02-17 17:13:18,307 - trainer - INFO] - Train Epoch:[54/100] Step:[80/250] Total Loss: 190.441788 GL_Loss: 0.507093 CRF_Loss: 189.934692\n",
      "[2022-02-17 17:13:32,358 - trainer - INFO] - Train Epoch:[54/100] Step:[90/250] Total Loss: 13.860715 GL_Loss: 0.510007 CRF_Loss: 13.350708\n",
      "[2022-02-17 17:13:46,360 - trainer - INFO] - Train Epoch:[54/100] Step:[100/250] Total Loss: 23.181679 GL_Loss: 0.663369 CRF_Loss: 22.518311\n",
      "[2022-02-17 17:14:05,575 - trainer - INFO] - [Step Validation] Epoch:[54/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.90184  | 0.936306 | 0.91875  | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.71875  | 0.489362 | 0.582278 | 0.489362 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.702602 | 0.601911 | 0.64837  | 0.601911 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.630435 | 0.630435 | 0.630435 | 0.630435 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.741026 | 0.615548 | 0.672484 | 0.615548 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 17:14:07,710 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 17:14:22,254 - trainer - INFO] - Train Epoch:[54/100] Step:[110/250] Total Loss: 26.797291 GL_Loss: 0.384694 CRF_Loss: 26.412598\n",
      "[2022-02-17 17:14:35,983 - trainer - INFO] - Train Epoch:[54/100] Step:[120/250] Total Loss: 55.698399 GL_Loss: 0.964269 CRF_Loss: 54.734131\n",
      "[2022-02-17 17:14:50,063 - trainer - INFO] - Train Epoch:[54/100] Step:[130/250] Total Loss: 37.325024 GL_Loss: 0.333691 CRF_Loss: 36.991333\n",
      "[2022-02-17 17:15:04,144 - trainer - INFO] - Train Epoch:[54/100] Step:[140/250] Total Loss: 26.542778 GL_Loss: 0.594170 CRF_Loss: 25.948608\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 17:15:18,546 - trainer - INFO] - Train Epoch:[54/100] Step:[150/250] Total Loss: 23.236086 GL_Loss: 0.529543 CRF_Loss: 22.706543\n",
      "[2022-02-17 17:15:37,790 - trainer - INFO] - [Step Validation] Epoch:[54/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.896341 | 0.936306 | 0.915888 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.6917   | 0.465426 | 0.556439 | 0.465426 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.663265 | 0.621019 | 0.641447 | 0.621019 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.666667 | 0.673913 | 0.67027  | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.720149 | 0.616613 | 0.664372 | 0.616613 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 17:15:53,610 - trainer - INFO] - Train Epoch:[54/100] Step:[160/250] Total Loss: 18.515507 GL_Loss: 0.436588 CRF_Loss: 18.078918\n",
      "[2022-02-17 17:16:06,373 - trainer - INFO] - Train Epoch:[54/100] Step:[170/250] Total Loss: 36.922939 GL_Loss: 1.004972 CRF_Loss: 35.917969\n",
      "[2022-02-17 17:16:21,110 - trainer - INFO] - Train Epoch:[54/100] Step:[180/250] Total Loss: 18.579687 GL_Loss: 0.632666 CRF_Loss: 17.947021\n",
      "[2022-02-17 17:16:35,378 - trainer - INFO] - Train Epoch:[54/100] Step:[190/250] Total Loss: 289.767365 GL_Loss: 0.409586 CRF_Loss: 289.357788\n",
      "[2022-02-17 17:16:49,984 - trainer - INFO] - Train Epoch:[54/100] Step:[200/250] Total Loss: 76.422455 GL_Loss: 0.485196 CRF_Loss: 75.937256\n",
      "[2022-02-17 17:17:08,844 - trainer - INFO] - [Step Validation] Epoch:[54/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.896341 | 0.936306 | 0.915888 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.681102 | 0.460106 | 0.549206 | 0.460106 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.638095 | 0.640127 | 0.63911  | 0.640127 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.648936 | 0.663043 | 0.655914 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.703748 | 0.619808 | 0.659117 | 0.619808 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 17:17:23,132 - trainer - INFO] - Train Epoch:[54/100] Step:[210/250] Total Loss: 10.170263 GL_Loss: 0.627905 CRF_Loss: 9.542358\n",
      "[2022-02-17 17:17:37,120 - trainer - INFO] - Train Epoch:[54/100] Step:[220/250] Total Loss: 27.513563 GL_Loss: 0.551650 CRF_Loss: 26.961914\n",
      "[2022-02-17 17:17:51,748 - trainer - INFO] - Train Epoch:[54/100] Step:[230/250] Total Loss: 26.449745 GL_Loss: 0.558021 CRF_Loss: 25.891724\n",
      "[2022-02-17 17:18:05,181 - trainer - INFO] - Train Epoch:[54/100] Step:[240/250] Total Loss: 14.647771 GL_Loss: 0.542547 CRF_Loss: 14.105225\n",
      "[2022-02-17 17:18:18,304 - trainer - INFO] - Train Epoch:[54/100] Step:[250/250] Total Loss: 49.925907 GL_Loss: 0.523807 CRF_Loss: 49.402100\n",
      "[2022-02-17 17:18:37,368 - trainer - INFO] - [Step Validation] Epoch:[54/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.719368 | 0.484043 | 0.578696 | 0.484043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.684028 | 0.627389 | 0.654485 | 0.627389 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.648936 | 0.663043 | 0.655914 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.734336 | 0.624068 | 0.674727 | 0.624068 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 17:18:39,452 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 17:18:58,857 - trainer - INFO] - [Epoch Validation] Epoch:[54/100] Total Loss: 45.158243 GL_Loss: 0.005161 CRF_Loss: 44.642188 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.719368 | 0.484043 | 0.578696 | 0.484043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.684028 | 0.627389 | 0.654485 | 0.627389 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.648936 | 0.663043 | 0.655914 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.734336 | 0.624068 | 0.674727 | 0.624068 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 17:19:15,180 - trainer - INFO] - Train Epoch:[55/100] Step:[10/250] Total Loss: 16.692358 GL_Loss: 0.582372 CRF_Loss: 16.109985\n",
      "[2022-02-17 17:19:28,659 - trainer - INFO] - Train Epoch:[55/100] Step:[20/250] Total Loss: 91.805733 GL_Loss: 0.503733 CRF_Loss: 91.302002\n",
      "[2022-02-17 17:19:42,850 - trainer - INFO] - Train Epoch:[55/100] Step:[30/250] Total Loss: 37.807190 GL_Loss: 0.648497 CRF_Loss: 37.158691\n",
      "[2022-02-17 17:19:56,569 - trainer - INFO] - Train Epoch:[55/100] Step:[40/250] Total Loss: 83.284683 GL_Loss: 0.471209 CRF_Loss: 82.813477\n",
      "[2022-02-17 17:20:10,500 - trainer - INFO] - Train Epoch:[55/100] Step:[50/250] Total Loss: 21.177280 GL_Loss: 0.619054 CRF_Loss: 20.558228\n",
      "[2022-02-17 17:20:29,456 - trainer - INFO] - [Step Validation] Epoch:[55/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.890909 | 0.936306 | 0.913043 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.709804 | 0.481383 | 0.573693 | 0.481383 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.66323  | 0.61465  | 0.638017 | 0.61465  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.652174 | 0.652174 | 0.652174 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.723537 | 0.618743 | 0.667049 | 0.618743 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 17:20:43,779 - trainer - INFO] - Train Epoch:[55/100] Step:[60/250] Total Loss: 43.535381 GL_Loss: 0.536845 CRF_Loss: 42.998535\n",
      "[2022-02-17 17:20:58,695 - trainer - INFO] - Train Epoch:[55/100] Step:[70/250] Total Loss: 59.529694 GL_Loss: 0.662141 CRF_Loss: 58.867554\n",
      "[2022-02-17 17:21:13,270 - trainer - INFO] - Train Epoch:[55/100] Step:[80/250] Total Loss: 44.217148 GL_Loss: 0.535508 CRF_Loss: 43.681641\n",
      "[2022-02-17 17:21:28,143 - trainer - INFO] - Train Epoch:[55/100] Step:[90/250] Total Loss: 24.327988 GL_Loss: 0.372788 CRF_Loss: 23.955200\n",
      "[2022-02-17 17:21:41,950 - trainer - INFO] - Train Epoch:[55/100] Step:[100/250] Total Loss: 34.145870 GL_Loss: 0.399167 CRF_Loss: 33.746704\n",
      "[2022-02-17 17:22:01,250 - trainer - INFO] - [Step Validation] Epoch:[55/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.890909 | 0.936306 | 0.913043 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.722008 | 0.49734  | 0.588976 | 0.49734  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.615836 | 0.66879  | 0.641221 | 0.66879  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.641304 | 0.641304 | 0.641304 | 0.641304 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.703617 | 0.642173 | 0.671492 | 0.642173 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 17:22:16,141 - trainer - INFO] - Train Epoch:[55/100] Step:[110/250] Total Loss: 42.524757 GL_Loss: 0.365454 CRF_Loss: 42.159302\n",
      "[2022-02-17 17:22:30,381 - trainer - INFO] - Train Epoch:[55/100] Step:[120/250] Total Loss: 69.947266 GL_Loss: 0.411865 CRF_Loss: 69.535400\n",
      "[2022-02-17 17:22:44,768 - trainer - INFO] - Train Epoch:[55/100] Step:[130/250] Total Loss: 35.465618 GL_Loss: 0.616620 CRF_Loss: 34.848999\n",
      "[2022-02-17 17:22:58,781 - trainer - INFO] - Train Epoch:[55/100] Step:[140/250] Total Loss: 64.848030 GL_Loss: 0.299321 CRF_Loss: 64.548706\n",
      "[2022-02-17 17:23:13,879 - trainer - INFO] - Train Epoch:[55/100] Step:[150/250] Total Loss: 16.528282 GL_Loss: 0.311608 CRF_Loss: 16.216675\n",
      "[2022-02-17 17:23:32,842 - trainer - INFO] - [Step Validation] Epoch:[55/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.896341 | 0.936306 | 0.915888 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.676923 | 0.468085 | 0.553459 | 0.468085 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.672474 | 0.61465  | 0.642263 | 0.61465  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.670213 | 0.684783 | 0.677419 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.719255 | 0.616613 | 0.663991 | 0.616613 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 17:23:47,726 - trainer - INFO] - Train Epoch:[55/100] Step:[160/250] Total Loss: 30.775173 GL_Loss: 0.540187 CRF_Loss: 30.234985\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 17:24:01,044 - trainer - INFO] - Train Epoch:[55/100] Step:[170/250] Total Loss: 35.540478 GL_Loss: 0.581495 CRF_Loss: 34.958984\n",
      "[2022-02-17 17:24:14,291 - trainer - INFO] - Train Epoch:[55/100] Step:[180/250] Total Loss: 45.553627 GL_Loss: 0.479774 CRF_Loss: 45.073853\n",
      "[2022-02-17 17:24:29,241 - trainer - INFO] - Train Epoch:[55/100] Step:[190/250] Total Loss: 21.886744 GL_Loss: 0.550562 CRF_Loss: 21.336182\n",
      "[2022-02-17 17:24:43,466 - trainer - INFO] - Train Epoch:[55/100] Step:[200/250] Total Loss: 28.846901 GL_Loss: 0.512673 CRF_Loss: 28.334229\n",
      "[2022-02-17 17:25:02,638 - trainer - INFO] - [Step Validation] Epoch:[55/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.868263 | 0.923567 | 0.895062 | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.705426 | 0.484043 | 0.574132 | 0.484043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.676976 | 0.627389 | 0.65124  | 0.627389 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.630435 | 0.630435 | 0.630435 | 0.630435 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.720297 | 0.619808 | 0.666285 | 0.619808 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 17:25:16,670 - trainer - INFO] - Train Epoch:[55/100] Step:[210/250] Total Loss: 8.554389 GL_Loss: 0.566474 CRF_Loss: 7.987915\n",
      "[2022-02-17 17:25:31,949 - trainer - INFO] - Train Epoch:[55/100] Step:[220/250] Total Loss: 29.952631 GL_Loss: 0.607905 CRF_Loss: 29.344727\n",
      "[2022-02-17 17:25:46,063 - trainer - INFO] - Train Epoch:[55/100] Step:[230/250] Total Loss: 9.976508 GL_Loss: 0.299872 CRF_Loss: 9.676636\n",
      "[2022-02-17 17:25:59,109 - trainer - INFO] - Train Epoch:[55/100] Step:[240/250] Total Loss: 167.698410 GL_Loss: 0.556075 CRF_Loss: 167.142334\n",
      "[2022-02-17 17:26:12,538 - trainer - INFO] - Train Epoch:[55/100] Step:[250/250] Total Loss: 31.908167 GL_Loss: 0.467127 CRF_Loss: 31.441040\n",
      "[2022-02-17 17:26:31,515 - trainer - INFO] - [Step Validation] Epoch:[55/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.902439 | 0.942675 | 0.922118 | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.714286 | 0.478723 | 0.573248 | 0.478723 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.659016 | 0.640127 | 0.649435 | 0.640127 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.652174 | 0.652174 | 0.652174 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.724477 | 0.627263 | 0.672374 | 0.627263 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 17:26:50,624 - trainer - INFO] - [Epoch Validation] Epoch:[55/100] Total Loss: 45.057509 GL_Loss: 0.004933 CRF_Loss: 44.564178 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.902439 | 0.942675 | 0.922118 | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.714286 | 0.478723 | 0.573248 | 0.478723 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.659016 | 0.640127 | 0.649435 | 0.640127 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.652174 | 0.652174 | 0.652174 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.724477 | 0.627263 | 0.672374 | 0.627263 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 17:27:04,372 - trainer - INFO] - Train Epoch:[56/100] Step:[10/250] Total Loss: 44.336708 GL_Loss: 0.525796 CRF_Loss: 43.810913\n",
      "[2022-02-17 17:27:18,348 - trainer - INFO] - Train Epoch:[56/100] Step:[20/250] Total Loss: 46.721199 GL_Loss: 0.502571 CRF_Loss: 46.218628\n",
      "[2022-02-17 17:27:32,162 - trainer - INFO] - Train Epoch:[56/100] Step:[30/250] Total Loss: 80.936218 GL_Loss: 0.352478 CRF_Loss: 80.583740\n",
      "[2022-02-17 17:27:47,105 - trainer - INFO] - Train Epoch:[56/100] Step:[40/250] Total Loss: 21.160929 GL_Loss: 0.443034 CRF_Loss: 20.717896\n",
      "[2022-02-17 17:28:00,118 - trainer - INFO] - Train Epoch:[56/100] Step:[50/250] Total Loss: 22.391544 GL_Loss: 0.409734 CRF_Loss: 21.981812\n",
      "[2022-02-17 17:28:19,564 - trainer - INFO] - [Step Validation] Epoch:[56/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.879518 | 0.929936 | 0.904025 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.721569 | 0.489362 | 0.583201 | 0.489362 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.673267 | 0.649682 | 0.661264 | 0.649682 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.67033  | 0.663043 | 0.666667 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.730061 | 0.633653 | 0.678449 | 0.633653 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 17:28:21,727 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 17:28:36,743 - trainer - INFO] - Train Epoch:[56/100] Step:[60/250] Total Loss: 922.926575 GL_Loss: 0.408509 CRF_Loss: 922.518066\n",
      "[2022-02-17 17:28:50,414 - trainer - INFO] - Train Epoch:[56/100] Step:[70/250] Total Loss: 28.274883 GL_Loss: 0.456280 CRF_Loss: 27.818604\n",
      "[2022-02-17 17:29:05,715 - trainer - INFO] - Train Epoch:[56/100] Step:[80/250] Total Loss: 18.336290 GL_Loss: 0.507310 CRF_Loss: 17.828979\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 17:29:19,839 - trainer - INFO] - Train Epoch:[56/100] Step:[90/250] Total Loss: 23.495661 GL_Loss: 0.457330 CRF_Loss: 23.038330\n",
      "[2022-02-17 17:29:35,213 - trainer - INFO] - Train Epoch:[56/100] Step:[100/250] Total Loss: 51.696022 GL_Loss: 0.492775 CRF_Loss: 51.203247\n",
      "[2022-02-17 17:29:54,325 - trainer - INFO] - [Step Validation] Epoch:[56/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.896341 | 0.936306 | 0.915888 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.709302 | 0.486702 | 0.577287 | 0.486702 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.679443 | 0.621019 | 0.648918 | 0.621019 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.630435 | 0.630435 | 0.630435 | 0.630435 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.72784  | 0.620873 | 0.670115 | 0.620873 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 17:30:07,761 - trainer - INFO] - Train Epoch:[56/100] Step:[110/250] Total Loss: 102.097641 GL_Loss: 0.802844 CRF_Loss: 101.294800\n",
      "[2022-02-17 17:30:21,751 - trainer - INFO] - Train Epoch:[56/100] Step:[120/250] Total Loss: 16.595856 GL_Loss: 0.304962 CRF_Loss: 16.290894\n",
      "[2022-02-17 17:30:35,312 - trainer - INFO] - Train Epoch:[56/100] Step:[130/250] Total Loss: 61.618168 GL_Loss: 0.477787 CRF_Loss: 61.140381\n",
      "[2022-02-17 17:30:50,348 - trainer - INFO] - Train Epoch:[56/100] Step:[140/250] Total Loss: 34.822445 GL_Loss: 0.361873 CRF_Loss: 34.460571\n",
      "[2022-02-17 17:31:04,871 - trainer - INFO] - Train Epoch:[56/100] Step:[150/250] Total Loss: 33.429352 GL_Loss: 0.474030 CRF_Loss: 32.955322\n",
      "[2022-02-17 17:31:25,780 - trainer - INFO] - [Step Validation] Epoch:[56/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.90184  | 0.936306 | 0.91875  | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.720472 | 0.486702 | 0.580952 | 0.486702 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.708633 | 0.627389 | 0.665541 | 0.627389 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.681319 | 0.673913 | 0.677596 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.749364 | 0.627263 | 0.682899 | 0.627263 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 17:31:28,008 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 17:31:42,582 - trainer - INFO] - Train Epoch:[56/100] Step:[160/250] Total Loss: 59.673363 GL_Loss: 0.549339 CRF_Loss: 59.124023\n",
      "[2022-02-17 17:31:56,029 - trainer - INFO] - Train Epoch:[56/100] Step:[170/250] Total Loss: 18.552605 GL_Loss: 0.380973 CRF_Loss: 18.171631\n",
      "[2022-02-17 17:32:10,835 - trainer - INFO] - Train Epoch:[56/100] Step:[180/250] Total Loss: 82.925072 GL_Loss: 0.393337 CRF_Loss: 82.531738\n",
      "[2022-02-17 17:32:24,640 - trainer - INFO] - Train Epoch:[56/100] Step:[190/250] Total Loss: 47.579060 GL_Loss: 0.401570 CRF_Loss: 47.177490\n",
      "[2022-02-17 17:32:38,580 - trainer - INFO] - Train Epoch:[56/100] Step:[200/250] Total Loss: 63.209774 GL_Loss: 0.533383 CRF_Loss: 62.676392\n",
      "[2022-02-17 17:32:57,604 - trainer - INFO] - [Step Validation] Epoch:[56/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.890244 | 0.929936 | 0.909657 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.713147 | 0.476064 | 0.570973 | 0.476064 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.684211 | 0.621019 | 0.651085 | 0.621019 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.673913 | 0.673913 | 0.673913 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.734848 | 0.619808 | 0.672444 | 0.619808 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 17:33:11,518 - trainer - INFO] - Train Epoch:[56/100] Step:[210/250] Total Loss: 40.104641 GL_Loss: 0.316798 CRF_Loss: 39.787842\n",
      "[2022-02-17 17:33:25,639 - trainer - INFO] - Train Epoch:[56/100] Step:[220/250] Total Loss: 31.172026 GL_Loss: 0.603666 CRF_Loss: 30.568359\n",
      "[2022-02-17 17:33:40,364 - trainer - INFO] - Train Epoch:[56/100] Step:[230/250] Total Loss: 172.835754 GL_Loss: 0.740354 CRF_Loss: 172.095398\n",
      "[2022-02-17 17:33:55,177 - trainer - INFO] - Train Epoch:[56/100] Step:[240/250] Total Loss: 20.084660 GL_Loss: 0.438541 CRF_Loss: 19.646118\n",
      "[2022-02-17 17:34:09,548 - trainer - INFO] - Train Epoch:[56/100] Step:[250/250] Total Loss: 120.426247 GL_Loss: 0.658545 CRF_Loss: 119.767700\n",
      "[2022-02-17 17:34:28,611 - trainer - INFO] - [Step Validation] Epoch:[56/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.896341 | 0.936306 | 0.915888 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.712598 | 0.481383 | 0.574603 | 0.481383 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.657807 | 0.630573 | 0.643902 | 0.630573 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.673913 | 0.673913 | 0.673913 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.725031 | 0.626198 | 0.672    | 0.626198 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 17:34:47,653 - trainer - INFO] - [Epoch Validation] Epoch:[56/100] Total Loss: 44.871906 GL_Loss: 0.004967 CRF_Loss: 44.375223 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.896341 | 0.936306 | 0.915888 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.712598 | 0.481383 | 0.574603 | 0.481383 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.657807 | 0.630573 | 0.643902 | 0.630573 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.673913 | 0.673913 | 0.673913 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.725031 | 0.626198 | 0.672    | 0.626198 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 17:35:02,960 - trainer - INFO] - Train Epoch:[57/100] Step:[10/250] Total Loss: 17.409588 GL_Loss: 0.587811 CRF_Loss: 16.821777\n",
      "[2022-02-17 17:35:17,647 - trainer - INFO] - Train Epoch:[57/100] Step:[20/250] Total Loss: 29.355001 GL_Loss: 0.756613 CRF_Loss: 28.598389\n",
      "[2022-02-17 17:35:31,789 - trainer - INFO] - Train Epoch:[57/100] Step:[30/250] Total Loss: 10.866069 GL_Loss: 0.379252 CRF_Loss: 10.486816\n",
      "[2022-02-17 17:35:45,753 - trainer - INFO] - Train Epoch:[57/100] Step:[40/250] Total Loss: 42.553173 GL_Loss: 0.432813 CRF_Loss: 42.120361\n",
      "[2022-02-17 17:36:00,566 - trainer - INFO] - Train Epoch:[57/100] Step:[50/250] Total Loss: 55.507946 GL_Loss: 0.531995 CRF_Loss: 54.975952\n",
      "[2022-02-17 17:36:19,478 - trainer - INFO] - [Step Validation] Epoch:[57/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.884848 | 0.929936 | 0.906832 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.754789 | 0.523936 | 0.618524 | 0.523936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.705882 | 0.611465 | 0.65529  | 0.611465 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.692308 | 0.684783 | 0.688525 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.757921 | 0.636848 | 0.69213  | 0.636848 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 17:36:21,686 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 17:36:36,019 - trainer - INFO] - Train Epoch:[57/100] Step:[60/250] Total Loss: 35.008209 GL_Loss: 0.474884 CRF_Loss: 34.533325\n",
      "[2022-02-17 17:36:50,476 - trainer - INFO] - Train Epoch:[57/100] Step:[70/250] Total Loss: 42.089287 GL_Loss: 0.412040 CRF_Loss: 41.677246\n",
      "[2022-02-17 17:37:03,302 - trainer - INFO] - Train Epoch:[57/100] Step:[80/250] Total Loss: 18.277006 GL_Loss: 0.579740 CRF_Loss: 17.697266\n",
      "[2022-02-17 17:37:16,621 - trainer - INFO] - Train Epoch:[57/100] Step:[90/250] Total Loss: 36.133209 GL_Loss: 0.290068 CRF_Loss: 35.843140\n",
      "[2022-02-17 17:37:30,251 - trainer - INFO] - Train Epoch:[57/100] Step:[100/250] Total Loss: 12.976468 GL_Loss: 0.480131 CRF_Loss: 12.496338\n",
      "[2022-02-17 17:37:49,233 - trainer - INFO] - [Step Validation] Epoch:[57/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.890909 | 0.936306 | 0.913043 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.709804 | 0.481383 | 0.573693 | 0.481383 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.659164 | 0.652866 | 0.656    | 0.652866 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.648936 | 0.663043 | 0.655914 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.72     | 0.632588 | 0.673469 | 0.632588 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 17:38:02,977 - trainer - INFO] - Train Epoch:[57/100] Step:[110/250] Total Loss: 64.455849 GL_Loss: 0.476476 CRF_Loss: 63.979370\n",
      "[2022-02-17 17:38:17,764 - trainer - INFO] - Train Epoch:[57/100] Step:[120/250] Total Loss: 35.658947 GL_Loss: 0.607677 CRF_Loss: 35.051270\n",
      "[2022-02-17 17:38:32,023 - trainer - INFO] - Train Epoch:[57/100] Step:[130/250] Total Loss: 16.173824 GL_Loss: 0.411130 CRF_Loss: 15.762695\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 17:38:46,769 - trainer - INFO] - Train Epoch:[57/100] Step:[140/250] Total Loss: 15.606287 GL_Loss: 0.393030 CRF_Loss: 15.213257\n",
      "[2022-02-17 17:38:59,858 - trainer - INFO] - Train Epoch:[57/100] Step:[150/250] Total Loss: 20.761742 GL_Loss: 0.522483 CRF_Loss: 20.239258\n",
      "[2022-02-17 17:39:18,860 - trainer - INFO] - [Step Validation] Epoch:[57/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.89697  | 0.942675 | 0.919255 | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.698842 | 0.481383 | 0.570079 | 0.481383 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.685512 | 0.617834 | 0.649916 | 0.617834 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.659574 | 0.673913 | 0.666667 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.730337 | 0.623003 | 0.672414 | 0.623003 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 17:39:33,980 - trainer - INFO] - Train Epoch:[57/100] Step:[160/250] Total Loss: 47.856735 GL_Loss: 0.470262 CRF_Loss: 47.386475\n",
      "[2022-02-17 17:39:48,906 - trainer - INFO] - Train Epoch:[57/100] Step:[170/250] Total Loss: 77.526077 GL_Loss: 0.381545 CRF_Loss: 77.144531\n",
      "[2022-02-17 17:40:02,632 - trainer - INFO] - Train Epoch:[57/100] Step:[180/250] Total Loss: 109.008301 GL_Loss: 0.340945 CRF_Loss: 108.667358\n",
      "[2022-02-17 17:40:17,031 - trainer - INFO] - Train Epoch:[57/100] Step:[190/250] Total Loss: 11.527448 GL_Loss: 0.518781 CRF_Loss: 11.008667\n",
      "[2022-02-17 17:40:30,912 - trainer - INFO] - Train Epoch:[57/100] Step:[200/250] Total Loss: 25.245115 GL_Loss: 0.483397 CRF_Loss: 24.761719\n",
      "[2022-02-17 17:40:50,043 - trainer - INFO] - [Step Validation] Epoch:[57/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.879518 | 0.929936 | 0.904025 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.724138 | 0.50266  | 0.593407 | 0.50266  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.628319 | 0.678344 | 0.652374 | 0.678344 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.648936 | 0.663043 | 0.655914 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.70814  | 0.648562 | 0.677043 | 0.648562 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 17:41:05,165 - trainer - INFO] - Train Epoch:[57/100] Step:[210/250] Total Loss: 25.888462 GL_Loss: 0.405674 CRF_Loss: 25.482788\n",
      "[2022-02-17 17:41:19,890 - trainer - INFO] - Train Epoch:[57/100] Step:[220/250] Total Loss: 45.836597 GL_Loss: 0.500416 CRF_Loss: 45.336182\n",
      "[2022-02-17 17:41:34,356 - trainer - INFO] - Train Epoch:[57/100] Step:[230/250] Total Loss: 64.333931 GL_Loss: 0.381176 CRF_Loss: 63.952759\n",
      "[2022-02-17 17:41:47,889 - trainer - INFO] - Train Epoch:[57/100] Step:[240/250] Total Loss: 99.507294 GL_Loss: 0.370941 CRF_Loss: 99.136353\n",
      "[2022-02-17 17:42:01,606 - trainer - INFO] - Train Epoch:[57/100] Step:[250/250] Total Loss: 54.510544 GL_Loss: 0.373703 CRF_Loss: 54.136841\n",
      "[2022-02-17 17:42:21,609 - trainer - INFO] - [Step Validation] Epoch:[57/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.901235 | 0.929936 | 0.915361 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.673077 | 0.465426 | 0.550314 | 0.465426 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.679715 | 0.60828  | 0.642017 | 0.60828  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.641304 | 0.641304 | 0.641304 | 0.641304 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.718239 | 0.608094 | 0.658593 | 0.608094 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 17:42:40,850 - trainer - INFO] - [Epoch Validation] Epoch:[57/100] Total Loss: 44.430904 GL_Loss: 0.004793 CRF_Loss: 43.951593 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.901235 | 0.929936 | 0.915361 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.673077 | 0.465426 | 0.550314 | 0.465426 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.679715 | 0.60828  | 0.642017 | 0.60828  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.641304 | 0.641304 | 0.641304 | 0.641304 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.718239 | 0.608094 | 0.658593 | 0.608094 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 17:42:56,710 - trainer - INFO] - Train Epoch:[58/100] Step:[10/250] Total Loss: 28.275318 GL_Loss: 0.722401 CRF_Loss: 27.552917\n",
      "[2022-02-17 17:43:11,090 - trainer - INFO] - Train Epoch:[58/100] Step:[20/250] Total Loss: 32.443226 GL_Loss: 0.487905 CRF_Loss: 31.955322\n",
      "[2022-02-17 17:43:25,003 - trainer - INFO] - Train Epoch:[58/100] Step:[30/250] Total Loss: 28.889992 GL_Loss: 0.524879 CRF_Loss: 28.365112\n",
      "[2022-02-17 17:43:39,894 - trainer - INFO] - Train Epoch:[58/100] Step:[40/250] Total Loss: 55.641975 GL_Loss: 0.372076 CRF_Loss: 55.269897\n",
      "[2022-02-17 17:43:54,225 - trainer - INFO] - Train Epoch:[58/100] Step:[50/250] Total Loss: 42.850601 GL_Loss: 0.754043 CRF_Loss: 42.096558\n",
      "[2022-02-17 17:44:13,347 - trainer - INFO] - [Step Validation] Epoch:[58/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.896341 | 0.936306 | 0.915888 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.708171 | 0.484043 | 0.575039 | 0.484043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.647249 | 0.636943 | 0.642055 | 0.636943 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.645161 | 0.652174 | 0.648649 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.715674 | 0.627263 | 0.668558 | 0.627263 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 17:44:26,558 - trainer - INFO] - Train Epoch:[58/100] Step:[60/250] Total Loss: 19.553289 GL_Loss: 0.636298 CRF_Loss: 18.916992\n",
      "[2022-02-17 17:44:40,387 - trainer - INFO] - Train Epoch:[58/100] Step:[70/250] Total Loss: 98.091881 GL_Loss: 0.445277 CRF_Loss: 97.646606\n",
      "[2022-02-17 17:44:54,282 - trainer - INFO] - Train Epoch:[58/100] Step:[80/250] Total Loss: 17.451122 GL_Loss: 0.504590 CRF_Loss: 16.946533\n",
      "[2022-02-17 17:45:08,644 - trainer - INFO] - Train Epoch:[58/100] Step:[90/250] Total Loss: 21.906286 GL_Loss: 0.586583 CRF_Loss: 21.319702\n",
      "[2022-02-17 17:45:22,689 - trainer - INFO] - Train Epoch:[58/100] Step:[100/250] Total Loss: 160.624634 GL_Loss: 0.501835 CRF_Loss: 160.122803\n",
      "[2022-02-17 17:45:41,901 - trainer - INFO] - [Step Validation] Epoch:[58/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.896341 | 0.936306 | 0.915888 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.733333 | 0.49734  | 0.59271  | 0.49734  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.665563 | 0.640127 | 0.652597 | 0.640127 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.663043 | 0.663043 | 0.663043 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.733087 | 0.634718 | 0.680365 | 0.634718 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 17:45:56,190 - trainer - INFO] - Train Epoch:[58/100] Step:[110/250] Total Loss: 204.246521 GL_Loss: 0.483819 CRF_Loss: 203.762695\n",
      "[2022-02-17 17:46:10,486 - trainer - INFO] - Train Epoch:[58/100] Step:[120/250] Total Loss: 99.456917 GL_Loss: 0.518810 CRF_Loss: 98.938110\n",
      "[2022-02-17 17:46:24,160 - trainer - INFO] - Train Epoch:[58/100] Step:[130/250] Total Loss: 81.591026 GL_Loss: 0.336020 CRF_Loss: 81.255005\n",
      "[2022-02-17 17:46:38,984 - trainer - INFO] - Train Epoch:[58/100] Step:[140/250] Total Loss: 20.429636 GL_Loss: 0.360910 CRF_Loss: 20.068726\n",
      "[2022-02-17 17:46:52,179 - trainer - INFO] - Train Epoch:[58/100] Step:[150/250] Total Loss: 27.882267 GL_Loss: 0.657779 CRF_Loss: 27.224487\n",
      "[2022-02-17 17:47:11,270 - trainer - INFO] - [Step Validation] Epoch:[58/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.896341 | 0.936306 | 0.915888 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.695312 | 0.473404 | 0.563291 | 0.473404 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.67128  | 0.617834 | 0.643449 | 0.617834 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.659341 | 0.652174 | 0.655738 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.72375  | 0.616613 | 0.6659   | 0.616613 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 17:47:26,270 - trainer - INFO] - Train Epoch:[58/100] Step:[160/250] Total Loss: 347.528595 GL_Loss: 0.578393 CRF_Loss: 346.950195\n",
      "[2022-02-17 17:47:41,499 - trainer - INFO] - Train Epoch:[58/100] Step:[170/250] Total Loss: 64.075172 GL_Loss: 0.386083 CRF_Loss: 63.689087\n",
      "[2022-02-17 17:47:55,535 - trainer - INFO] - Train Epoch:[58/100] Step:[180/250] Total Loss: 49.498505 GL_Loss: 0.334078 CRF_Loss: 49.164429\n",
      "[2022-02-17 17:48:09,067 - trainer - INFO] - Train Epoch:[58/100] Step:[190/250] Total Loss: 17.085697 GL_Loss: 0.500981 CRF_Loss: 16.584717\n",
      "[2022-02-17 17:48:23,618 - trainer - INFO] - Train Epoch:[58/100] Step:[200/250] Total Loss: 66.463837 GL_Loss: 0.508518 CRF_Loss: 65.955322\n",
      "[2022-02-17 17:48:42,771 - trainer - INFO] - [Step Validation] Epoch:[58/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.689922 | 0.473404 | 0.561514 | 0.473404 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.707819 | 0.547771 | 0.617594 | 0.547771 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.674157 | 0.652174 | 0.662983 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.73838  | 0.592119 | 0.65721  | 0.592119 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 17:48:57,181 - trainer - INFO] - Train Epoch:[58/100] Step:[210/250] Total Loss: 43.173092 GL_Loss: 0.585200 CRF_Loss: 42.587891\n",
      "[2022-02-17 17:49:12,022 - trainer - INFO] - Train Epoch:[58/100] Step:[220/250] Total Loss: 37.213642 GL_Loss: 0.373555 CRF_Loss: 36.840088\n",
      "[2022-02-17 17:49:28,295 - trainer - INFO] - Train Epoch:[58/100] Step:[230/250] Total Loss: 22.445499 GL_Loss: 0.569768 CRF_Loss: 21.875732\n",
      "[2022-02-17 17:49:42,227 - trainer - INFO] - Train Epoch:[58/100] Step:[240/250] Total Loss: 21.721443 GL_Loss: 0.368903 CRF_Loss: 21.352539\n",
      "[2022-02-17 17:49:57,396 - trainer - INFO] - Train Epoch:[58/100] Step:[250/250] Total Loss: 37.882473 GL_Loss: 0.355497 CRF_Loss: 37.526978\n",
      "[2022-02-17 17:50:16,469 - trainer - INFO] - [Step Validation] Epoch:[58/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.878788 | 0.923567 | 0.900621 | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.707692 | 0.489362 | 0.578616 | 0.489362 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.66129  | 0.652866 | 0.657051 | 0.652866 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.659341 | 0.652174 | 0.655738 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.719128 | 0.632588 | 0.673088 | 0.632588 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 17:50:35,642 - trainer - INFO] - [Epoch Validation] Epoch:[58/100] Total Loss: 43.784295 GL_Loss: 0.005060 CRF_Loss: 43.278262 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.878788 | 0.923567 | 0.900621 | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.707692 | 0.489362 | 0.578616 | 0.489362 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.66129  | 0.652866 | 0.657051 | 0.652866 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.659341 | 0.652174 | 0.655738 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.719128 | 0.632588 | 0.673088 | 0.632588 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 17:50:49,716 - trainer - INFO] - Train Epoch:[59/100] Step:[10/250] Total Loss: 42.568184 GL_Loss: 0.299263 CRF_Loss: 42.268921\n",
      "[2022-02-17 17:51:03,693 - trainer - INFO] - Train Epoch:[59/100] Step:[20/250] Total Loss: 27.135527 GL_Loss: 0.714994 CRF_Loss: 26.420532\n",
      "[2022-02-17 17:51:18,113 - trainer - INFO] - Train Epoch:[59/100] Step:[30/250] Total Loss: 24.411884 GL_Loss: 0.651020 CRF_Loss: 23.760864\n",
      "[2022-02-17 17:51:31,970 - trainer - INFO] - Train Epoch:[59/100] Step:[40/250] Total Loss: 97.443184 GL_Loss: 0.434274 CRF_Loss: 97.008911\n",
      "[2022-02-17 17:51:45,841 - trainer - INFO] - Train Epoch:[59/100] Step:[50/250] Total Loss: 42.355534 GL_Loss: 0.476262 CRF_Loss: 41.879272\n",
      "[2022-02-17 17:52:04,952 - trainer - INFO] - [Step Validation] Epoch:[59/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.890909 | 0.936306 | 0.913043 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.725869 | 0.5      | 0.592126 | 0.5      |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.674658 | 0.627389 | 0.650165 | 0.627389 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.673913 | 0.673913 | 0.673913 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.735149 | 0.632588 | 0.680023 | 0.632588 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 17:52:20,088 - trainer - INFO] - Train Epoch:[59/100] Step:[60/250] Total Loss: 20.248728 GL_Loss: 0.378611 CRF_Loss: 19.870117\n",
      "[2022-02-17 17:52:34,278 - trainer - INFO] - Train Epoch:[59/100] Step:[70/250] Total Loss: 32.813812 GL_Loss: 0.387543 CRF_Loss: 32.426270\n",
      "[2022-02-17 17:52:48,094 - trainer - INFO] - Train Epoch:[59/100] Step:[80/250] Total Loss: 71.006516 GL_Loss: 0.288740 CRF_Loss: 70.717773\n",
      "[2022-02-17 17:53:02,375 - trainer - INFO] - Train Epoch:[59/100] Step:[90/250] Total Loss: 33.757355 GL_Loss: 0.605866 CRF_Loss: 33.151489\n",
      "[2022-02-17 17:53:16,477 - trainer - INFO] - Train Epoch:[59/100] Step:[100/250] Total Loss: 42.685974 GL_Loss: 0.465394 CRF_Loss: 42.220581\n",
      "[2022-02-17 17:53:35,576 - trainer - INFO] - [Step Validation] Epoch:[59/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.896341 | 0.936306 | 0.915888 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.695652 | 0.468085 | 0.559618 | 0.468085 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.681319 | 0.592357 | 0.633731 | 0.592357 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.67033  | 0.663043 | 0.666667 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.729834 | 0.607029 | 0.662791 | 0.607029 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 17:53:49,546 - trainer - INFO] - Train Epoch:[59/100] Step:[110/250] Total Loss: 13.766053 GL_Loss: 0.482484 CRF_Loss: 13.283569\n",
      "[2022-02-17 17:54:04,835 - trainer - INFO] - Train Epoch:[59/100] Step:[120/250] Total Loss: 19.553982 GL_Loss: 0.432888 CRF_Loss: 19.121094\n",
      "[2022-02-17 17:54:20,067 - trainer - INFO] - Train Epoch:[59/100] Step:[130/250] Total Loss: 21.104910 GL_Loss: 0.578664 CRF_Loss: 20.526245\n",
      "[2022-02-17 17:54:34,961 - trainer - INFO] - Train Epoch:[59/100] Step:[140/250] Total Loss: 22.724970 GL_Loss: 0.456048 CRF_Loss: 22.268921\n",
      "[2022-02-17 17:54:48,738 - trainer - INFO] - Train Epoch:[59/100] Step:[150/250] Total Loss: 26.790596 GL_Loss: 0.738472 CRF_Loss: 26.052124\n",
      "[2022-02-17 17:55:07,836 - trainer - INFO] - [Step Validation] Epoch:[59/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.884146 | 0.923567 | 0.903427 | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.727273 | 0.489362 | 0.585056 | 0.489362 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.663399 | 0.646497 | 0.654839 | 0.646497 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.663043 | 0.663043 | 0.663043 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.727607 | 0.631523 | 0.676169 | 0.631523 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 17:55:21,878 - trainer - INFO] - Train Epoch:[59/100] Step:[160/250] Total Loss: 46.458481 GL_Loss: 0.490584 CRF_Loss: 45.967896\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 17:55:35,851 - trainer - INFO] - Train Epoch:[59/100] Step:[170/250] Total Loss: 388.953705 GL_Loss: 0.507234 CRF_Loss: 388.446472\n",
      "[2022-02-17 17:55:49,069 - trainer - INFO] - Train Epoch:[59/100] Step:[180/250] Total Loss: 30.071182 GL_Loss: 0.303421 CRF_Loss: 29.767761\n",
      "[2022-02-17 17:56:03,680 - trainer - INFO] - Train Epoch:[59/100] Step:[190/250] Total Loss: 24.864552 GL_Loss: 0.558643 CRF_Loss: 24.305908\n",
      "[2022-02-17 17:56:17,564 - trainer - INFO] - Train Epoch:[59/100] Step:[200/250] Total Loss: 12.656218 GL_Loss: 0.334441 CRF_Loss: 12.321777\n",
      "[2022-02-17 17:56:36,518 - trainer - INFO] - [Step Validation] Epoch:[59/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.883436 | 0.917197 | 0.9      | 0.917197 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.68231  | 0.50266  | 0.578867 | 0.50266  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.683453 | 0.605096 | 0.641892 | 0.605096 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.652174 | 0.652174 | 0.652174 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.719753 | 0.620873 | 0.666667 | 0.620873 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 17:56:51,281 - trainer - INFO] - Train Epoch:[59/100] Step:[210/250] Total Loss: 12.106883 GL_Loss: 0.428660 CRF_Loss: 11.678223\n",
      "[2022-02-17 17:57:05,887 - trainer - INFO] - Train Epoch:[59/100] Step:[220/250] Total Loss: 21.442495 GL_Loss: 0.412955 CRF_Loss: 21.029541\n",
      "[2022-02-17 17:57:21,503 - trainer - INFO] - Train Epoch:[59/100] Step:[230/250] Total Loss: 14.815589 GL_Loss: 0.375404 CRF_Loss: 14.440186\n",
      "[2022-02-17 17:57:35,696 - trainer - INFO] - Train Epoch:[59/100] Step:[240/250] Total Loss: 34.072628 GL_Loss: 0.313108 CRF_Loss: 33.759521\n",
      "[2022-02-17 17:57:50,289 - trainer - INFO] - Train Epoch:[59/100] Step:[250/250] Total Loss: 19.736086 GL_Loss: 0.440675 CRF_Loss: 19.295410\n",
      "[2022-02-17 17:58:09,396 - trainer - INFO] - [Step Validation] Epoch:[59/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.90184  | 0.936306 | 0.91875  | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.707865 | 0.50266  | 0.587869 | 0.50266  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.677083 | 0.621019 | 0.647841 | 0.621019 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.663043 | 0.663043 | 0.663043 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.730864 | 0.630458 | 0.676958 | 0.630458 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 17:58:28,542 - trainer - INFO] - [Epoch Validation] Epoch:[59/100] Total Loss: 44.102065 GL_Loss: 0.004872 CRF_Loss: 43.614837 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.90184  | 0.936306 | 0.91875  | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.707865 | 0.50266  | 0.587869 | 0.50266  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.677083 | 0.621019 | 0.647841 | 0.621019 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.663043 | 0.663043 | 0.663043 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.730864 | 0.630458 | 0.676958 | 0.630458 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 17:58:44,697 - trainer - INFO] - Train Epoch:[60/100] Step:[10/250] Total Loss: 38.853546 GL_Loss: 0.527863 CRF_Loss: 38.325684\n",
      "[2022-02-17 17:58:59,680 - trainer - INFO] - Train Epoch:[60/100] Step:[20/250] Total Loss: 24.518723 GL_Loss: 0.311935 CRF_Loss: 24.206787\n",
      "[2022-02-17 17:59:13,983 - trainer - INFO] - Train Epoch:[60/100] Step:[30/250] Total Loss: 18.446617 GL_Loss: 0.463707 CRF_Loss: 17.982910\n",
      "[2022-02-17 17:59:28,603 - trainer - INFO] - Train Epoch:[60/100] Step:[40/250] Total Loss: 34.808510 GL_Loss: 0.431923 CRF_Loss: 34.376587\n",
      "[2022-02-17 17:59:43,692 - trainer - INFO] - Train Epoch:[60/100] Step:[50/250] Total Loss: 6.659846 GL_Loss: 0.480647 CRF_Loss: 6.179199\n",
      "[2022-02-17 18:00:02,776 - trainer - INFO] - [Step Validation] Epoch:[60/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.681648 | 0.484043 | 0.566096 | 0.484043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.685921 | 0.605096 | 0.642978 | 0.605096 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.677778 | 0.663043 | 0.67033  | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.726474 | 0.616613 | 0.667051 | 0.616613 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 18:00:16,748 - trainer - INFO] - Train Epoch:[60/100] Step:[60/250] Total Loss: 31.999794 GL_Loss: 0.434731 CRF_Loss: 31.565063\n",
      "[2022-02-17 18:00:31,361 - trainer - INFO] - Train Epoch:[60/100] Step:[70/250] Total Loss: 53.390015 GL_Loss: 0.297484 CRF_Loss: 53.092529\n",
      "[2022-02-17 18:00:45,418 - trainer - INFO] - Train Epoch:[60/100] Step:[80/250] Total Loss: 33.572903 GL_Loss: 0.559719 CRF_Loss: 33.013184\n",
      "[2022-02-17 18:00:59,675 - trainer - INFO] - Train Epoch:[60/100] Step:[90/250] Total Loss: 21.237080 GL_Loss: 1.096088 CRF_Loss: 20.140991\n",
      "[2022-02-17 18:01:14,429 - trainer - INFO] - Train Epoch:[60/100] Step:[100/250] Total Loss: 83.264084 GL_Loss: 0.427535 CRF_Loss: 82.836548\n",
      "[2022-02-17 18:01:33,416 - trainer - INFO] - [Step Validation] Epoch:[60/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.884146 | 0.923567 | 0.903427 | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.742308 | 0.513298 | 0.606918 | 0.513298 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.675325 | 0.66242  | 0.66881  | 0.66242  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.666667 | 0.673913 | 0.67027  | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.73697  | 0.647497 | 0.689342 | 0.647497 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 18:01:47,830 - trainer - INFO] - Train Epoch:[60/100] Step:[110/250] Total Loss: 32.020706 GL_Loss: 0.521439 CRF_Loss: 31.499268\n",
      "[2022-02-17 18:02:01,805 - trainer - INFO] - Train Epoch:[60/100] Step:[120/250] Total Loss: 44.779049 GL_Loss: 0.307490 CRF_Loss: 44.471558\n",
      "[2022-02-17 18:02:16,273 - trainer - INFO] - Train Epoch:[60/100] Step:[130/250] Total Loss: 33.058014 GL_Loss: 0.372468 CRF_Loss: 32.685547\n",
      "[2022-02-17 18:02:31,024 - trainer - INFO] - Train Epoch:[60/100] Step:[140/250] Total Loss: 167.308594 GL_Loss: 0.569030 CRF_Loss: 166.739563\n",
      "[2022-02-17 18:02:45,809 - trainer - INFO] - Train Epoch:[60/100] Step:[150/250] Total Loss: 11.153257 GL_Loss: 0.659239 CRF_Loss: 10.494019\n",
      "[2022-02-17 18:03:04,971 - trainer - INFO] - [Step Validation] Epoch:[60/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.906832 | 0.929936 | 0.918239 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.75     | 0.518617 | 0.613208 | 0.518617 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.681507 | 0.633758 | 0.656766 | 0.633758 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.673913 | 0.673913 | 0.673913 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.747826 | 0.641108 | 0.690367 | 0.641108 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 18:03:19,660 - trainer - INFO] - Train Epoch:[60/100] Step:[160/250] Total Loss: 15.533949 GL_Loss: 0.581556 CRF_Loss: 14.952393\n",
      "[2022-02-17 18:03:34,119 - trainer - INFO] - Train Epoch:[60/100] Step:[170/250] Total Loss: 173.327652 GL_Loss: 0.459248 CRF_Loss: 172.868408\n",
      "[2022-02-17 18:03:47,963 - trainer - INFO] - Train Epoch:[60/100] Step:[180/250] Total Loss: 22.840595 GL_Loss: 0.736836 CRF_Loss: 22.103760\n",
      "[2022-02-17 18:04:02,175 - trainer - INFO] - Train Epoch:[60/100] Step:[190/250] Total Loss: 12.605491 GL_Loss: 0.871604 CRF_Loss: 11.733887\n",
      "[2022-02-17 18:04:15,550 - trainer - INFO] - Train Epoch:[60/100] Step:[200/250] Total Loss: 13.047079 GL_Loss: 0.533285 CRF_Loss: 12.513794\n",
      "[2022-02-17 18:04:34,569 - trainer - INFO] - [Step Validation] Epoch:[60/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.884146 | 0.923567 | 0.903427 | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.730769 | 0.505319 | 0.597484 | 0.505319 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.654206 | 0.66879  | 0.661417 | 0.66879  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.684783 | 0.684783 | 0.684783 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.726404 | 0.647497 | 0.684685 | 0.647497 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 18:04:48,726 - trainer - INFO] - Train Epoch:[60/100] Step:[210/250] Total Loss: 17.032087 GL_Loss: 0.403304 CRF_Loss: 16.628784\n",
      "[2022-02-17 18:05:02,517 - trainer - INFO] - Train Epoch:[60/100] Step:[220/250] Total Loss: 35.141590 GL_Loss: 0.586903 CRF_Loss: 34.554688\n",
      "[2022-02-17 18:05:15,769 - trainer - INFO] - Train Epoch:[60/100] Step:[230/250] Total Loss: 16.238529 GL_Loss: 0.391362 CRF_Loss: 15.847168\n",
      "[2022-02-17 18:05:30,503 - trainer - INFO] - Train Epoch:[60/100] Step:[240/250] Total Loss: 19.676975 GL_Loss: 0.448460 CRF_Loss: 19.228516\n",
      "[2022-02-17 18:05:45,796 - trainer - INFO] - Train Epoch:[60/100] Step:[250/250] Total Loss: 90.039398 GL_Loss: 0.318330 CRF_Loss: 89.721069\n",
      "[2022-02-17 18:06:04,898 - trainer - INFO] - [Step Validation] Epoch:[60/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.891566 | 0.942675 | 0.916409 | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.740458 | 0.515957 | 0.60815  | 0.515957 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.694245 | 0.61465  | 0.652027 | 0.61465  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.706522 | 0.706522 | 0.706522 | 0.706522 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.75188  | 0.638978 | 0.690846 | 0.638978 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 18:06:24,086 - trainer - INFO] - [Epoch Validation] Epoch:[60/100] Total Loss: 42.893220 GL_Loss: 0.004806 CRF_Loss: 42.412573 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.891566 | 0.942675 | 0.916409 | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.740458 | 0.515957 | 0.60815  | 0.515957 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.694245 | 0.61465  | 0.652027 | 0.61465  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.706522 | 0.706522 | 0.706522 | 0.706522 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.75188  | 0.638978 | 0.690846 | 0.638978 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 18:06:25,870 - trainer - INFO] - Saving checkpoint: saved/models/PICK_Default/test_0217_100852/checkpoint-epoch60.pth ...\n",
      "[2022-02-17 18:06:41,750 - trainer - INFO] - Train Epoch:[61/100] Step:[10/250] Total Loss: 10.726852 GL_Loss: 0.861130 CRF_Loss: 9.865723\n",
      "[2022-02-17 18:06:55,879 - trainer - INFO] - Train Epoch:[61/100] Step:[20/250] Total Loss: 32.178310 GL_Loss: 0.670620 CRF_Loss: 31.507690\n",
      "[2022-02-17 18:07:10,301 - trainer - INFO] - Train Epoch:[61/100] Step:[30/250] Total Loss: 29.255442 GL_Loss: 0.591501 CRF_Loss: 28.663940\n",
      "[2022-02-17 18:07:24,857 - trainer - INFO] - Train Epoch:[61/100] Step:[40/250] Total Loss: 48.461407 GL_Loss: 0.410992 CRF_Loss: 48.050415\n",
      "[2022-02-17 18:07:38,934 - trainer - INFO] - Train Epoch:[61/100] Step:[50/250] Total Loss: 63.953178 GL_Loss: 0.409722 CRF_Loss: 63.543457\n",
      "[2022-02-17 18:07:57,785 - trainer - INFO] - [Step Validation] Epoch:[61/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.890244 | 0.929936 | 0.909657 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.726923 | 0.50266  | 0.59434  | 0.50266  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.692308 | 0.630573 | 0.66     | 0.630573 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.673913 | 0.673913 | 0.673913 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.741895 | 0.633653 | 0.683515 | 0.633653 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 18:08:12,122 - trainer - INFO] - Train Epoch:[61/100] Step:[60/250] Total Loss: 24.725332 GL_Loss: 0.434561 CRF_Loss: 24.290771\n",
      "[2022-02-17 18:08:25,362 - trainer - INFO] - Train Epoch:[61/100] Step:[70/250] Total Loss: 32.021797 GL_Loss: 0.413032 CRF_Loss: 31.608765\n",
      "[2022-02-17 18:08:40,138 - trainer - INFO] - Train Epoch:[61/100] Step:[80/250] Total Loss: 40.139477 GL_Loss: 0.547559 CRF_Loss: 39.591919\n",
      "[2022-02-17 18:08:55,060 - trainer - INFO] - Train Epoch:[61/100] Step:[90/250] Total Loss: 29.392580 GL_Loss: 0.429689 CRF_Loss: 28.962891\n",
      "[2022-02-17 18:09:08,897 - trainer - INFO] - Train Epoch:[61/100] Step:[100/250] Total Loss: 29.130091 GL_Loss: 0.505213 CRF_Loss: 28.624878\n",
      "[2022-02-17 18:09:27,978 - trainer - INFO] - [Step Validation] Epoch:[61/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.889571 | 0.923567 | 0.90625  | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.721374 | 0.50266  | 0.592476 | 0.50266  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.681208 | 0.646497 | 0.663399 | 0.646497 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.684783 | 0.684783 | 0.684783 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.736196 | 0.638978 | 0.684151 | 0.638978 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 18:09:41,696 - trainer - INFO] - Train Epoch:[61/100] Step:[110/250] Total Loss: 18.332306 GL_Loss: 0.983063 CRF_Loss: 17.349243\n",
      "[2022-02-17 18:09:55,886 - trainer - INFO] - Train Epoch:[61/100] Step:[120/250] Total Loss: 23.126947 GL_Loss: 0.353144 CRF_Loss: 22.773804\n",
      "[2022-02-17 18:10:10,574 - trainer - INFO] - Train Epoch:[61/100] Step:[130/250] Total Loss: 11.077952 GL_Loss: 0.615794 CRF_Loss: 10.462158\n",
      "[2022-02-17 18:10:23,929 - trainer - INFO] - Train Epoch:[61/100] Step:[140/250] Total Loss: 14.577319 GL_Loss: 0.475391 CRF_Loss: 14.101929\n",
      "[2022-02-17 18:10:38,209 - trainer - INFO] - Train Epoch:[61/100] Step:[150/250] Total Loss: 22.041788 GL_Loss: 0.490763 CRF_Loss: 21.551025\n",
      "[2022-02-17 18:10:57,186 - trainer - INFO] - [Step Validation] Epoch:[61/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.891566 | 0.942675 | 0.916409 | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.696154 | 0.481383 | 0.569182 | 0.481383 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.684932 | 0.636943 | 0.660066 | 0.636943 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.673913 | 0.673913 | 0.673913 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.72963  | 0.629393 | 0.675815 | 0.629393 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 18:11:11,436 - trainer - INFO] - Train Epoch:[61/100] Step:[160/250] Total Loss: 18.975851 GL_Loss: 0.612082 CRF_Loss: 18.363770\n",
      "[2022-02-17 18:11:27,034 - trainer - INFO] - Train Epoch:[61/100] Step:[170/250] Total Loss: 14.169219 GL_Loss: 0.388213 CRF_Loss: 13.781006\n",
      "[2022-02-17 18:11:41,782 - trainer - INFO] - Train Epoch:[61/100] Step:[180/250] Total Loss: 19.654480 GL_Loss: 0.363098 CRF_Loss: 19.291382\n",
      "[2022-02-17 18:11:55,948 - trainer - INFO] - Train Epoch:[61/100] Step:[190/250] Total Loss: 27.653873 GL_Loss: 0.564884 CRF_Loss: 27.088989\n",
      "[2022-02-17 18:12:10,152 - trainer - INFO] - Train Epoch:[61/100] Step:[200/250] Total Loss: 22.341011 GL_Loss: 0.451729 CRF_Loss: 21.889282\n",
      "[2022-02-17 18:12:29,315 - trainer - INFO] - [Step Validation] Epoch:[61/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.890909 | 0.936306 | 0.913043 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.701149 | 0.486702 | 0.574568 | 0.486702 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.681507 | 0.633758 | 0.656766 | 0.633758 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.692308 | 0.684783 | 0.688525 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.731768 | 0.630458 | 0.677346 | 0.630458 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 18:12:43,605 - trainer - INFO] - Train Epoch:[61/100] Step:[210/250] Total Loss: 14.542686 GL_Loss: 0.475182 CRF_Loss: 14.067505\n",
      "[2022-02-17 18:12:56,983 - trainer - INFO] - Train Epoch:[61/100] Step:[220/250] Total Loss: 56.484550 GL_Loss: 0.401788 CRF_Loss: 56.082764\n",
      "[2022-02-17 18:13:10,617 - trainer - INFO] - Train Epoch:[61/100] Step:[230/250] Total Loss: 15.336181 GL_Loss: 0.611694 CRF_Loss: 14.724487\n",
      "[2022-02-17 18:13:24,421 - trainer - INFO] - Train Epoch:[61/100] Step:[240/250] Total Loss: 14.661000 GL_Loss: 0.335438 CRF_Loss: 14.325562\n",
      "[2022-02-17 18:13:39,338 - trainer - INFO] - Train Epoch:[61/100] Step:[250/250] Total Loss: 33.287991 GL_Loss: 0.445338 CRF_Loss: 32.842651\n",
      "[2022-02-17 18:13:58,218 - trainer - INFO] - [Step Validation] Epoch:[61/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.884146 | 0.923567 | 0.903427 | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.731801 | 0.507979 | 0.599686 | 0.507979 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.683168 | 0.659236 | 0.670989 | 0.659236 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.663043 | 0.663043 | 0.663043 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.736585 | 0.643237 | 0.686754 | 0.643237 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 18:14:17,332 - trainer - INFO] - [Epoch Validation] Epoch:[61/100] Total Loss: 41.965404 GL_Loss: 0.004981 CRF_Loss: 41.467282 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.884146 | 0.923567 | 0.903427 | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.731801 | 0.507979 | 0.599686 | 0.507979 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.683168 | 0.659236 | 0.670989 | 0.659236 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.663043 | 0.663043 | 0.663043 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.736585 | 0.643237 | 0.686754 | 0.643237 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 18:14:32,390 - trainer - INFO] - Train Epoch:[62/100] Step:[10/250] Total Loss: 28.878094 GL_Loss: 0.388348 CRF_Loss: 28.489746\n",
      "[2022-02-17 18:14:46,125 - trainer - INFO] - Train Epoch:[62/100] Step:[20/250] Total Loss: 19.968218 GL_Loss: 0.435137 CRF_Loss: 19.533081\n",
      "[2022-02-17 18:15:00,012 - trainer - INFO] - Train Epoch:[62/100] Step:[30/250] Total Loss: 107.532043 GL_Loss: 0.588076 CRF_Loss: 106.943970\n",
      "[2022-02-17 18:15:14,112 - trainer - INFO] - Train Epoch:[62/100] Step:[40/250] Total Loss: 166.089096 GL_Loss: 0.500109 CRF_Loss: 165.588989\n",
      "[2022-02-17 18:15:28,547 - trainer - INFO] - Train Epoch:[62/100] Step:[50/250] Total Loss: 23.747683 GL_Loss: 0.472657 CRF_Loss: 23.275024\n",
      "[2022-02-17 18:15:47,724 - trainer - INFO] - [Step Validation] Epoch:[62/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.709302 | 0.486702 | 0.577287 | 0.486702 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.676768 | 0.640127 | 0.657938 | 0.640127 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.67033  | 0.663043 | 0.666667 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.730532 | 0.629393 | 0.676201 | 0.629393 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 18:16:01,805 - trainer - INFO] - Train Epoch:[62/100] Step:[60/250] Total Loss: 54.840229 GL_Loss: 0.566549 CRF_Loss: 54.273682\n",
      "[2022-02-17 18:16:15,587 - trainer - INFO] - Train Epoch:[62/100] Step:[70/250] Total Loss: 8.790695 GL_Loss: 0.695968 CRF_Loss: 8.094727\n",
      "[2022-02-17 18:16:29,869 - trainer - INFO] - Train Epoch:[62/100] Step:[80/250] Total Loss: 39.539371 GL_Loss: 0.469061 CRF_Loss: 39.070312\n",
      "[2022-02-17 18:16:44,476 - trainer - INFO] - Train Epoch:[62/100] Step:[90/250] Total Loss: 93.012695 GL_Loss: 0.406858 CRF_Loss: 92.605835\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 18:16:58,827 - trainer - INFO] - Train Epoch:[62/100] Step:[100/250] Total Loss: 26.239630 GL_Loss: 0.526496 CRF_Loss: 25.713135\n",
      "[2022-02-17 18:17:17,823 - trainer - INFO] - [Step Validation] Epoch:[62/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.91358  | 0.942675 | 0.9279   | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.685824 | 0.476064 | 0.562009 | 0.476064 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.677083 | 0.621019 | 0.647841 | 0.621019 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.681319 | 0.673913 | 0.677596 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.72818  | 0.621938 | 0.670879 | 0.621938 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 18:17:33,020 - trainer - INFO] - Train Epoch:[62/100] Step:[110/250] Total Loss: 19.614658 GL_Loss: 0.473423 CRF_Loss: 19.141235\n",
      "[2022-02-17 18:17:47,800 - trainer - INFO] - Train Epoch:[62/100] Step:[120/250] Total Loss: 26.180447 GL_Loss: 0.510281 CRF_Loss: 25.670166\n",
      "[2022-02-17 18:18:02,306 - trainer - INFO] - Train Epoch:[62/100] Step:[130/250] Total Loss: 21.894550 GL_Loss: 0.491231 CRF_Loss: 21.403320\n",
      "[2022-02-17 18:18:16,366 - trainer - INFO] - Train Epoch:[62/100] Step:[140/250] Total Loss: 28.281033 GL_Loss: 0.364041 CRF_Loss: 27.916992\n",
      "[2022-02-17 18:18:30,497 - trainer - INFO] - Train Epoch:[62/100] Step:[150/250] Total Loss: 25.180820 GL_Loss: 0.684971 CRF_Loss: 24.495850\n",
      "[2022-02-17 18:18:49,348 - trainer - INFO] - [Step Validation] Epoch:[62/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.89697  | 0.942675 | 0.919255 | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.702703 | 0.484043 | 0.573228 | 0.484043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.677083 | 0.621019 | 0.647841 | 0.621019 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.692308 | 0.684783 | 0.688525 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.732254 | 0.626198 | 0.675086 | 0.626198 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 18:19:02,778 - trainer - INFO] - Train Epoch:[62/100] Step:[160/250] Total Loss: 54.929192 GL_Loss: 0.683952 CRF_Loss: 54.245239\n",
      "[2022-02-17 18:19:15,768 - trainer - INFO] - Train Epoch:[62/100] Step:[170/250] Total Loss: 8.767607 GL_Loss: 0.424467 CRF_Loss: 8.343140\n",
      "[2022-02-17 18:19:29,242 - trainer - INFO] - Train Epoch:[62/100] Step:[180/250] Total Loss: 89.953094 GL_Loss: 0.377170 CRF_Loss: 89.575928\n",
      "[2022-02-17 18:19:43,499 - trainer - INFO] - Train Epoch:[62/100] Step:[190/250] Total Loss: 20.716915 GL_Loss: 0.414304 CRF_Loss: 20.302612\n",
      "[2022-02-17 18:19:56,614 - trainer - INFO] - Train Epoch:[62/100] Step:[200/250] Total Loss: 32.519680 GL_Loss: 0.459132 CRF_Loss: 32.060547\n",
      "[2022-02-17 18:20:15,453 - trainer - INFO] - [Step Validation] Epoch:[62/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.878788 | 0.923567 | 0.900621 | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.735632 | 0.510638 | 0.602826 | 0.510638 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.684385 | 0.656051 | 0.669919 | 0.656051 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.659341 | 0.652174 | 0.655738 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.737164 | 0.642173 | 0.686397 | 0.642173 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 18:20:29,956 - trainer - INFO] - Train Epoch:[62/100] Step:[210/250] Total Loss: 47.537819 GL_Loss: 0.377906 CRF_Loss: 47.159912\n",
      "[2022-02-17 18:20:43,593 - trainer - INFO] - Train Epoch:[62/100] Step:[220/250] Total Loss: 12.968194 GL_Loss: 0.422174 CRF_Loss: 12.546021\n",
      "[2022-02-17 18:20:59,298 - trainer - INFO] - Train Epoch:[62/100] Step:[230/250] Total Loss: 35.674316 GL_Loss: 0.471557 CRF_Loss: 35.202759\n",
      "[2022-02-17 18:21:12,593 - trainer - INFO] - Train Epoch:[62/100] Step:[240/250] Total Loss: 22.349674 GL_Loss: 0.595889 CRF_Loss: 21.753784\n",
      "[2022-02-17 18:21:26,915 - trainer - INFO] - Train Epoch:[62/100] Step:[250/250] Total Loss: 55.281769 GL_Loss: 0.317781 CRF_Loss: 54.963989\n",
      "[2022-02-17 18:21:45,894 - trainer - INFO] - [Step Validation] Epoch:[62/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.879518 | 0.929936 | 0.904025 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.738636 | 0.518617 | 0.609375 | 0.518617 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.67893  | 0.646497 | 0.662316 | 0.646497 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.684783 | 0.684783 | 0.684783 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.739342 | 0.646432 | 0.689773 | 0.646432 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 18:22:04,813 - trainer - INFO] - [Epoch Validation] Epoch:[62/100] Total Loss: 41.723751 GL_Loss: 0.004928 CRF_Loss: 41.231000 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.879518 | 0.929936 | 0.904025 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.738636 | 0.518617 | 0.609375 | 0.518617 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.67893  | 0.646497 | 0.662316 | 0.646497 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.684783 | 0.684783 | 0.684783 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.739342 | 0.646432 | 0.689773 | 0.646432 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 18:22:20,861 - trainer - INFO] - Train Epoch:[63/100] Step:[10/250] Total Loss: 57.834167 GL_Loss: 0.601989 CRF_Loss: 57.232178\n",
      "[2022-02-17 18:22:34,955 - trainer - INFO] - Train Epoch:[63/100] Step:[20/250] Total Loss: 15.847471 GL_Loss: 0.386656 CRF_Loss: 15.460815\n",
      "[2022-02-17 18:22:49,464 - trainer - INFO] - Train Epoch:[63/100] Step:[30/250] Total Loss: 60.772495 GL_Loss: 0.406895 CRF_Loss: 60.365601\n",
      "[2022-02-17 18:23:03,510 - trainer - INFO] - Train Epoch:[63/100] Step:[40/250] Total Loss: 62.497921 GL_Loss: 0.257808 CRF_Loss: 62.240112\n",
      "[2022-02-17 18:23:17,152 - trainer - INFO] - Train Epoch:[63/100] Step:[50/250] Total Loss: 21.775320 GL_Loss: 0.394949 CRF_Loss: 21.380371\n",
      "[2022-02-17 18:23:36,196 - trainer - INFO] - [Step Validation] Epoch:[63/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.885542 | 0.936306 | 0.910217 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.703422 | 0.492021 | 0.57903  | 0.492021 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.689046 | 0.621019 | 0.653266 | 0.621019 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.681319 | 0.673913 | 0.677596 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.733499 | 0.627263 | 0.676234 | 0.627263 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 18:23:51,206 - trainer - INFO] - Train Epoch:[63/100] Step:[60/250] Total Loss: 19.630104 GL_Loss: 0.401467 CRF_Loss: 19.228638\n",
      "[2022-02-17 18:24:05,790 - trainer - INFO] - Train Epoch:[63/100] Step:[70/250] Total Loss: 17.316740 GL_Loss: 0.353605 CRF_Loss: 16.963135\n",
      "[2022-02-17 18:24:19,612 - trainer - INFO] - Train Epoch:[63/100] Step:[80/250] Total Loss: 82.301308 GL_Loss: 0.326575 CRF_Loss: 81.974731\n",
      "[2022-02-17 18:24:32,739 - trainer - INFO] - Train Epoch:[63/100] Step:[90/250] Total Loss: 16.790134 GL_Loss: 0.703220 CRF_Loss: 16.086914\n",
      "[2022-02-17 18:24:46,524 - trainer - INFO] - Train Epoch:[63/100] Step:[100/250] Total Loss: 22.506212 GL_Loss: 0.708849 CRF_Loss: 21.797363\n",
      "[2022-02-17 18:25:05,235 - trainer - INFO] - [Step Validation] Epoch:[63/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.879518 | 0.929936 | 0.904025 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.753788 | 0.529255 | 0.621875 | 0.529255 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.686869 | 0.649682 | 0.667758 | 0.649682 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.673913 | 0.673913 | 0.673913 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.746032 | 0.650692 | 0.695108 | 0.650692 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 18:25:07,520 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 18:25:21,155 - trainer - INFO] - Train Epoch:[63/100] Step:[110/250] Total Loss: 16.759804 GL_Loss: 0.475259 CRF_Loss: 16.284546\n",
      "[2022-02-17 18:25:35,754 - trainer - INFO] - Train Epoch:[63/100] Step:[120/250] Total Loss: 30.475903 GL_Loss: 0.477733 CRF_Loss: 29.998169\n",
      "[2022-02-17 18:25:49,603 - trainer - INFO] - Train Epoch:[63/100] Step:[130/250] Total Loss: 11.308829 GL_Loss: 0.509269 CRF_Loss: 10.799561\n",
      "[2022-02-17 18:26:03,247 - trainer - INFO] - Train Epoch:[63/100] Step:[140/250] Total Loss: 14.994884 GL_Loss: 0.486827 CRF_Loss: 14.508057\n",
      "[2022-02-17 18:26:17,236 - trainer - INFO] - Train Epoch:[63/100] Step:[150/250] Total Loss: 19.425814 GL_Loss: 0.459871 CRF_Loss: 18.965942\n",
      "[2022-02-17 18:26:36,363 - trainer - INFO] - [Step Validation] Epoch:[63/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.884848 | 0.929936 | 0.906832 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.708812 | 0.492021 | 0.580848 | 0.492021 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.677966 | 0.636943 | 0.656814 | 0.636943 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.663043 | 0.663043 | 0.663043 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.728167 | 0.630458 | 0.675799 | 0.630458 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 18:26:50,261 - trainer - INFO] - Train Epoch:[63/100] Step:[160/250] Total Loss: 10.417518 GL_Loss: 0.511878 CRF_Loss: 9.905640\n",
      "[2022-02-17 18:27:04,924 - trainer - INFO] - Train Epoch:[63/100] Step:[170/250] Total Loss: 9.650577 GL_Loss: 0.509219 CRF_Loss: 9.141357\n",
      "[2022-02-17 18:27:19,997 - trainer - INFO] - Train Epoch:[63/100] Step:[180/250] Total Loss: 63.284107 GL_Loss: 0.432179 CRF_Loss: 62.851929\n",
      "[2022-02-17 18:27:34,484 - trainer - INFO] - Train Epoch:[63/100] Step:[190/250] Total Loss: 33.214119 GL_Loss: 0.627451 CRF_Loss: 32.586670\n",
      "[2022-02-17 18:27:48,721 - trainer - INFO] - Train Epoch:[63/100] Step:[200/250] Total Loss: 14.549664 GL_Loss: 0.502300 CRF_Loss: 14.047363\n",
      "[2022-02-17 18:28:07,831 - trainer - INFO] - [Step Validation] Epoch:[63/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.884848 | 0.929936 | 0.906832 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.736641 | 0.513298 | 0.605016 | 0.513298 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.685619 | 0.652866 | 0.668842 | 0.652866 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.67033  | 0.663043 | 0.666667 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.740514 | 0.644302 | 0.689066 | 0.644302 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 18:28:21,270 - trainer - INFO] - Train Epoch:[63/100] Step:[210/250] Total Loss: 56.296959 GL_Loss: 0.373983 CRF_Loss: 55.922974\n",
      "[2022-02-17 18:28:36,299 - trainer - INFO] - Train Epoch:[63/100] Step:[220/250] Total Loss: 97.967163 GL_Loss: 0.476320 CRF_Loss: 97.490845\n",
      "[2022-02-17 18:28:49,923 - trainer - INFO] - Train Epoch:[63/100] Step:[230/250] Total Loss: 43.113525 GL_Loss: 0.373656 CRF_Loss: 42.739868\n",
      "[2022-02-17 18:29:04,715 - trainer - INFO] - Train Epoch:[63/100] Step:[240/250] Total Loss: 47.165031 GL_Loss: 0.343863 CRF_Loss: 46.821167\n",
      "[2022-02-17 18:29:19,730 - trainer - INFO] - Train Epoch:[63/100] Step:[250/250] Total Loss: 10.412349 GL_Loss: 0.629390 CRF_Loss: 9.782959\n",
      "[2022-02-17 18:29:38,593 - trainer - INFO] - [Step Validation] Epoch:[63/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.889571 | 0.923567 | 0.90625  | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.704981 | 0.489362 | 0.577708 | 0.489362 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.666667 | 0.643312 | 0.654781 | 0.643312 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.67033  | 0.663043 | 0.666667 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.723716 | 0.630458 | 0.673876 | 0.630458 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 18:29:59,115 - trainer - INFO] - [Epoch Validation] Epoch:[63/100] Total Loss: 42.109966 GL_Loss: 0.004955 CRF_Loss: 41.614432 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.889571 | 0.923567 | 0.90625  | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.704981 | 0.489362 | 0.577708 | 0.489362 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.666667 | 0.643312 | 0.654781 | 0.643312 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.67033  | 0.663043 | 0.666667 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.723716 | 0.630458 | 0.673876 | 0.630458 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 18:30:13,876 - trainer - INFO] - Train Epoch:[64/100] Step:[10/250] Total Loss: 351.918701 GL_Loss: 0.630447 CRF_Loss: 351.288269\n",
      "[2022-02-17 18:30:27,788 - trainer - INFO] - Train Epoch:[64/100] Step:[20/250] Total Loss: 7.367452 GL_Loss: 0.478780 CRF_Loss: 6.888672\n",
      "[2022-02-17 18:30:41,864 - trainer - INFO] - Train Epoch:[64/100] Step:[30/250] Total Loss: 20.566872 GL_Loss: 0.749366 CRF_Loss: 19.817505\n",
      "[2022-02-17 18:30:55,951 - trainer - INFO] - Train Epoch:[64/100] Step:[40/250] Total Loss: 26.503403 GL_Loss: 0.436814 CRF_Loss: 26.066589\n",
      "[2022-02-17 18:31:09,409 - trainer - INFO] - Train Epoch:[64/100] Step:[50/250] Total Loss: 13.335035 GL_Loss: 0.589064 CRF_Loss: 12.745972\n",
      "[2022-02-17 18:31:30,325 - trainer - INFO] - [Step Validation] Epoch:[64/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.879518 | 0.929936 | 0.904025 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.731061 | 0.513298 | 0.603125 | 0.513298 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.673333 | 0.643312 | 0.65798  | 0.643312 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.67033  | 0.663043 | 0.666667 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.733252 | 0.641108 | 0.684091 | 0.641108 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 18:31:43,692 - trainer - INFO] - Train Epoch:[64/100] Step:[60/250] Total Loss: 6.286877 GL_Loss: 0.531750 CRF_Loss: 5.755127\n",
      "[2022-02-17 18:31:58,424 - trainer - INFO] - Train Epoch:[64/100] Step:[70/250] Total Loss: 16.277294 GL_Loss: 0.549633 CRF_Loss: 15.727661\n",
      "[2022-02-17 18:32:12,674 - trainer - INFO] - Train Epoch:[64/100] Step:[80/250] Total Loss: 33.417404 GL_Loss: 0.383714 CRF_Loss: 33.033691\n",
      "[2022-02-17 18:32:26,840 - trainer - INFO] - Train Epoch:[64/100] Step:[90/250] Total Loss: 47.210064 GL_Loss: 0.459820 CRF_Loss: 46.750244\n",
      "[2022-02-17 18:32:40,519 - trainer - INFO] - Train Epoch:[64/100] Step:[100/250] Total Loss: 37.670860 GL_Loss: 0.436118 CRF_Loss: 37.234741\n",
      "[2022-02-17 18:32:59,497 - trainer - INFO] - [Step Validation] Epoch:[64/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.884848 | 0.929936 | 0.906832 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.73384  | 0.513298 | 0.604069 | 0.513298 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.683333 | 0.652866 | 0.667752 | 0.652866 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.681319 | 0.673913 | 0.677596 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.739927 | 0.645367 | 0.68942  | 0.645367 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 18:33:13,565 - trainer - INFO] - Train Epoch:[64/100] Step:[110/250] Total Loss: 90.679497 GL_Loss: 0.495413 CRF_Loss: 90.184082\n",
      "[2022-02-17 18:33:27,420 - trainer - INFO] - Train Epoch:[64/100] Step:[120/250] Total Loss: 14.921712 GL_Loss: 0.596395 CRF_Loss: 14.325317\n",
      "[2022-02-17 18:33:41,906 - trainer - INFO] - Train Epoch:[64/100] Step:[130/250] Total Loss: 18.489614 GL_Loss: 0.408927 CRF_Loss: 18.080688\n",
      "[2022-02-17 18:33:56,185 - trainer - INFO] - Train Epoch:[64/100] Step:[140/250] Total Loss: 46.463810 GL_Loss: 0.425113 CRF_Loss: 46.038696\n",
      "[2022-02-17 18:34:11,070 - trainer - INFO] - Train Epoch:[64/100] Step:[150/250] Total Loss: 15.207898 GL_Loss: 0.566785 CRF_Loss: 14.641113\n",
      "[2022-02-17 18:34:30,221 - trainer - INFO] - [Step Validation] Epoch:[64/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.727273 | 0.510638 | 0.6      | 0.510638 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.677966 | 0.636943 | 0.656814 | 0.636943 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.67033  | 0.663043 | 0.666667 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.736777 | 0.637913 | 0.68379  | 0.637913 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 18:34:44,333 - trainer - INFO] - Train Epoch:[64/100] Step:[160/250] Total Loss: 14.385235 GL_Loss: 0.453595 CRF_Loss: 13.931641\n",
      "[2022-02-17 18:34:58,467 - trainer - INFO] - Train Epoch:[64/100] Step:[170/250] Total Loss: 20.029152 GL_Loss: 0.606545 CRF_Loss: 19.422607\n",
      "[2022-02-17 18:35:13,485 - trainer - INFO] - Train Epoch:[64/100] Step:[180/250] Total Loss: 77.170624 GL_Loss: 0.531465 CRF_Loss: 76.639160\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 18:35:27,407 - trainer - INFO] - Train Epoch:[64/100] Step:[190/250] Total Loss: 29.828192 GL_Loss: 0.816961 CRF_Loss: 29.011230\n",
      "[2022-02-17 18:35:42,085 - trainer - INFO] - Train Epoch:[64/100] Step:[200/250] Total Loss: 12.936857 GL_Loss: 0.493620 CRF_Loss: 12.443237\n",
      "[2022-02-17 18:36:01,127 - trainer - INFO] - [Step Validation] Epoch:[64/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.884848 | 0.929936 | 0.906832 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.720755 | 0.507979 | 0.595944 | 0.507979 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.674497 | 0.640127 | 0.656863 | 0.640127 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.67033  | 0.663043 | 0.666667 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.73138  | 0.637913 | 0.681456 | 0.637913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 18:36:15,690 - trainer - INFO] - Train Epoch:[64/100] Step:[210/250] Total Loss: 21.264484 GL_Loss: 0.469990 CRF_Loss: 20.794495\n",
      "[2022-02-17 18:36:30,304 - trainer - INFO] - Train Epoch:[64/100] Step:[220/250] Total Loss: 17.007986 GL_Loss: 0.429129 CRF_Loss: 16.578857\n",
      "[2022-02-17 18:36:45,408 - trainer - INFO] - Train Epoch:[64/100] Step:[230/250] Total Loss: 25.005423 GL_Loss: 0.300955 CRF_Loss: 24.704468\n",
      "[2022-02-17 18:36:59,790 - trainer - INFO] - Train Epoch:[64/100] Step:[240/250] Total Loss: 27.328196 GL_Loss: 0.429637 CRF_Loss: 26.898560\n",
      "[2022-02-17 18:37:13,661 - trainer - INFO] - Train Epoch:[64/100] Step:[250/250] Total Loss: 16.356838 GL_Loss: 0.409816 CRF_Loss: 15.947021\n",
      "[2022-02-17 18:37:32,704 - trainer - INFO] - [Step Validation] Epoch:[64/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.879518 | 0.929936 | 0.904025 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.746212 | 0.523936 | 0.615625 | 0.523936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.677632 | 0.656051 | 0.666667 | 0.656051 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.692308 | 0.684783 | 0.688525 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.741818 | 0.651757 | 0.693878 | 0.651757 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 18:37:51,637 - trainer - INFO] - [Epoch Validation] Epoch:[64/100] Total Loss: 41.410664 GL_Loss: 0.005023 CRF_Loss: 40.908389 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.879518 | 0.929936 | 0.904025 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.746212 | 0.523936 | 0.615625 | 0.523936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.677632 | 0.656051 | 0.666667 | 0.656051 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.692308 | 0.684783 | 0.688525 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.741818 | 0.651757 | 0.693878 | 0.651757 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 18:38:05,998 - trainer - INFO] - Train Epoch:[65/100] Step:[10/250] Total Loss: 17.016069 GL_Loss: 0.508012 CRF_Loss: 16.508057\n",
      "[2022-02-17 18:38:20,635 - trainer - INFO] - Train Epoch:[65/100] Step:[20/250] Total Loss: 29.723696 GL_Loss: 0.381532 CRF_Loss: 29.342163\n",
      "[2022-02-17 18:38:34,837 - trainer - INFO] - Train Epoch:[65/100] Step:[30/250] Total Loss: 17.285320 GL_Loss: 0.584637 CRF_Loss: 16.700684\n",
      "[2022-02-17 18:38:48,538 - trainer - INFO] - Train Epoch:[65/100] Step:[40/250] Total Loss: 28.284969 GL_Loss: 0.709531 CRF_Loss: 27.575439\n",
      "[2022-02-17 18:39:03,283 - trainer - INFO] - Train Epoch:[65/100] Step:[50/250] Total Loss: 17.615534 GL_Loss: 0.469049 CRF_Loss: 17.146484\n",
      "[2022-02-17 18:39:22,481 - trainer - INFO] - [Step Validation] Epoch:[65/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.902439 | 0.942675 | 0.922118 | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.693182 | 0.486702 | 0.571875 | 0.486702 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.679443 | 0.621019 | 0.648918 | 0.621019 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.730435 | 0.626198 | 0.674312 | 0.626198 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 18:39:36,429 - trainer - INFO] - Train Epoch:[65/100] Step:[60/250] Total Loss: 49.477631 GL_Loss: 0.449556 CRF_Loss: 49.028076\n",
      "[2022-02-17 18:39:51,582 - trainer - INFO] - Train Epoch:[65/100] Step:[70/250] Total Loss: 25.608772 GL_Loss: 0.423470 CRF_Loss: 25.185303\n",
      "[2022-02-17 18:40:06,208 - trainer - INFO] - Train Epoch:[65/100] Step:[80/250] Total Loss: 13.591124 GL_Loss: 0.585996 CRF_Loss: 13.005127\n",
      "[2022-02-17 18:40:20,126 - trainer - INFO] - Train Epoch:[65/100] Step:[90/250] Total Loss: 29.038107 GL_Loss: 0.657370 CRF_Loss: 28.380737\n",
      "[2022-02-17 18:40:34,283 - trainer - INFO] - Train Epoch:[65/100] Step:[100/250] Total Loss: 14.646934 GL_Loss: 0.410971 CRF_Loss: 14.235962\n",
      "[2022-02-17 18:40:53,419 - trainer - INFO] - [Step Validation] Epoch:[65/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.884848 | 0.929936 | 0.906832 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.741445 | 0.518617 | 0.610329 | 0.518617 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.685619 | 0.652866 | 0.668842 | 0.652866 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.681319 | 0.673913 | 0.677596 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.743276 | 0.647497 | 0.692089 | 0.647497 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 18:41:07,299 - trainer - INFO] - Train Epoch:[65/100] Step:[110/250] Total Loss: 36.271015 GL_Loss: 0.676290 CRF_Loss: 35.594727\n",
      "[2022-02-17 18:41:21,451 - trainer - INFO] - Train Epoch:[65/100] Step:[120/250] Total Loss: 42.639030 GL_Loss: 0.329340 CRF_Loss: 42.309692\n",
      "[2022-02-17 18:41:35,940 - trainer - INFO] - Train Epoch:[65/100] Step:[130/250] Total Loss: 29.337729 GL_Loss: 0.411092 CRF_Loss: 28.926636\n",
      "[2022-02-17 18:41:49,404 - trainer - INFO] - Train Epoch:[65/100] Step:[140/250] Total Loss: 14.499296 GL_Loss: 0.586454 CRF_Loss: 13.912842\n",
      "[2022-02-17 18:42:04,140 - trainer - INFO] - Train Epoch:[65/100] Step:[150/250] Total Loss: 48.326210 GL_Loss: 0.394934 CRF_Loss: 47.931274\n",
      "[2022-02-17 18:42:24,994 - trainer - INFO] - [Step Validation] Epoch:[65/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.896341 | 0.936306 | 0.915888 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.692015 | 0.484043 | 0.56964  | 0.484043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.671096 | 0.643312 | 0.656911 | 0.643312 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.67033  | 0.663043 | 0.666667 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.722833 | 0.630458 | 0.673493 | 0.630458 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 18:42:40,322 - trainer - INFO] - Train Epoch:[65/100] Step:[160/250] Total Loss: 37.664223 GL_Loss: 0.619302 CRF_Loss: 37.044922\n",
      "[2022-02-17 18:42:54,049 - trainer - INFO] - Train Epoch:[65/100] Step:[170/250] Total Loss: 17.365063 GL_Loss: 0.298656 CRF_Loss: 17.066406\n",
      "[2022-02-17 18:43:08,441 - trainer - INFO] - Train Epoch:[65/100] Step:[180/250] Total Loss: 26.070967 GL_Loss: 0.511273 CRF_Loss: 25.559692\n",
      "[2022-02-17 18:43:23,396 - trainer - INFO] - Train Epoch:[65/100] Step:[190/250] Total Loss: 25.337032 GL_Loss: 0.476803 CRF_Loss: 24.860229\n",
      "[2022-02-17 18:43:37,652 - trainer - INFO] - Train Epoch:[65/100] Step:[200/250] Total Loss: 26.201704 GL_Loss: 0.373579 CRF_Loss: 25.828125\n",
      "[2022-02-17 18:43:56,753 - trainer - INFO] - [Step Validation] Epoch:[65/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.907975 | 0.942675 | 0.925    | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.705426 | 0.484043 | 0.574132 | 0.484043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.676976 | 0.627389 | 0.65124  | 0.627389 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.677778 | 0.663043 | 0.67033  | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.733167 | 0.626198 | 0.675474 | 0.626198 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 18:44:11,249 - trainer - INFO] - Train Epoch:[65/100] Step:[210/250] Total Loss: 32.710094 GL_Loss: 0.407361 CRF_Loss: 32.302734\n",
      "[2022-02-17 18:44:25,233 - trainer - INFO] - Train Epoch:[65/100] Step:[220/250] Total Loss: 51.997326 GL_Loss: 0.541760 CRF_Loss: 51.455566\n",
      "[2022-02-17 18:44:38,937 - trainer - INFO] - Train Epoch:[65/100] Step:[230/250] Total Loss: 15.813051 GL_Loss: 0.457216 CRF_Loss: 15.355835\n",
      "[2022-02-17 18:44:51,918 - trainer - INFO] - Train Epoch:[65/100] Step:[240/250] Total Loss: 23.914812 GL_Loss: 0.406388 CRF_Loss: 23.508423\n",
      "[2022-02-17 18:45:05,482 - trainer - INFO] - Train Epoch:[65/100] Step:[250/250] Total Loss: 16.344627 GL_Loss: 0.485009 CRF_Loss: 15.859619\n",
      "[2022-02-17 18:45:24,519 - trainer - INFO] - [Step Validation] Epoch:[65/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.884848 | 0.929936 | 0.906832 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.729008 | 0.507979 | 0.598746 | 0.507979 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.682432 | 0.643312 | 0.662295 | 0.643312 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.666667 | 0.652174 | 0.659341 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.736777 | 0.637913 | 0.68379  | 0.637913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 18:45:43,556 - trainer - INFO] - [Epoch Validation] Epoch:[65/100] Total Loss: 41.880336 GL_Loss: 0.004902 CRF_Loss: 41.390180 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.884848 | 0.929936 | 0.906832 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.729008 | 0.507979 | 0.598746 | 0.507979 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.682432 | 0.643312 | 0.662295 | 0.643312 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.666667 | 0.652174 | 0.659341 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.736777 | 0.637913 | 0.68379  | 0.637913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 18:45:58,412 - trainer - INFO] - Train Epoch:[66/100] Step:[10/250] Total Loss: 20.273544 GL_Loss: 0.565902 CRF_Loss: 19.707642\n",
      "[2022-02-17 18:46:12,843 - trainer - INFO] - Train Epoch:[66/100] Step:[20/250] Total Loss: 147.474182 GL_Loss: 0.442803 CRF_Loss: 147.031372\n",
      "[2022-02-17 18:46:26,694 - trainer - INFO] - Train Epoch:[66/100] Step:[30/250] Total Loss: 14.511303 GL_Loss: 0.505566 CRF_Loss: 14.005737\n",
      "[2022-02-17 18:46:41,726 - trainer - INFO] - Train Epoch:[66/100] Step:[40/250] Total Loss: 18.935728 GL_Loss: 0.480894 CRF_Loss: 18.454834\n",
      "[2022-02-17 18:46:55,997 - trainer - INFO] - Train Epoch:[66/100] Step:[50/250] Total Loss: 24.643557 GL_Loss: 0.632692 CRF_Loss: 24.010864\n",
      "[2022-02-17 18:47:14,998 - trainer - INFO] - [Step Validation] Epoch:[66/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.902439 | 0.942675 | 0.922118 | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.718147 | 0.494681 | 0.585827 | 0.494681 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.677193 | 0.61465  | 0.644407 | 0.61465  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.7      | 0.684783 | 0.692308 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.739348 | 0.628328 | 0.679332 | 0.628328 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 18:47:29,209 - trainer - INFO] - Train Epoch:[66/100] Step:[60/250] Total Loss: 45.649822 GL_Loss: 0.415203 CRF_Loss: 45.234619\n",
      "[2022-02-17 18:47:43,306 - trainer - INFO] - Train Epoch:[66/100] Step:[70/250] Total Loss: 19.702307 GL_Loss: 0.472083 CRF_Loss: 19.230225\n",
      "[2022-02-17 18:47:57,271 - trainer - INFO] - Train Epoch:[66/100] Step:[80/250] Total Loss: 18.261675 GL_Loss: 0.496416 CRF_Loss: 17.765259\n",
      "[2022-02-17 18:48:10,146 - trainer - INFO] - Train Epoch:[66/100] Step:[90/250] Total Loss: 49.680801 GL_Loss: 0.360243 CRF_Loss: 49.320557\n",
      "[2022-02-17 18:48:24,057 - trainer - INFO] - Train Epoch:[66/100] Step:[100/250] Total Loss: 13.962945 GL_Loss: 0.731988 CRF_Loss: 13.230957\n",
      "[2022-02-17 18:48:43,095 - trainer - INFO] - [Step Validation] Epoch:[66/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.91358  | 0.942675 | 0.9279   | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.70155  | 0.481383 | 0.570978 | 0.481383 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.675768 | 0.630573 | 0.652389 | 0.630573 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.67033  | 0.663043 | 0.666667 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.731343 | 0.626198 | 0.674699 | 0.626198 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 18:48:58,363 - trainer - INFO] - Train Epoch:[66/100] Step:[110/250] Total Loss: 6.913227 GL_Loss: 0.574116 CRF_Loss: 6.339111\n",
      "[2022-02-17 18:49:12,760 - trainer - INFO] - Train Epoch:[66/100] Step:[120/250] Total Loss: 34.202675 GL_Loss: 0.446207 CRF_Loss: 33.756470\n",
      "[2022-02-17 18:49:26,822 - trainer - INFO] - Train Epoch:[66/100] Step:[130/250] Total Loss: 45.258064 GL_Loss: 0.464361 CRF_Loss: 44.793701\n",
      "[2022-02-17 18:49:41,140 - trainer - INFO] - Train Epoch:[66/100] Step:[140/250] Total Loss: 23.710938 GL_Loss: 0.672485 CRF_Loss: 23.038452\n",
      "[2022-02-17 18:49:54,766 - trainer - INFO] - Train Epoch:[66/100] Step:[150/250] Total Loss: 16.598665 GL_Loss: 0.342562 CRF_Loss: 16.256104\n",
      "[2022-02-17 18:50:13,664 - trainer - INFO] - [Step Validation] Epoch:[66/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.890909 | 0.936306 | 0.913043 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.712644 | 0.494681 | 0.583987 | 0.494681 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.686207 | 0.633758 | 0.65894  | 0.633758 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.67033  | 0.663043 | 0.666667 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.73482  | 0.631523 | 0.679267 | 0.631523 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 18:50:27,779 - trainer - INFO] - Train Epoch:[66/100] Step:[160/250] Total Loss: 14.804947 GL_Loss: 0.349869 CRF_Loss: 14.455078\n",
      "[2022-02-17 18:50:42,766 - trainer - INFO] - Train Epoch:[66/100] Step:[170/250] Total Loss: 7.017315 GL_Loss: 0.465801 CRF_Loss: 6.551514\n",
      "[2022-02-17 18:50:56,900 - trainer - INFO] - Train Epoch:[66/100] Step:[180/250] Total Loss: 20.807816 GL_Loss: 0.420365 CRF_Loss: 20.387451\n",
      "[2022-02-17 18:51:10,668 - trainer - INFO] - Train Epoch:[66/100] Step:[190/250] Total Loss: 15.369572 GL_Loss: 0.425114 CRF_Loss: 14.944458\n",
      "[2022-02-17 18:51:24,961 - trainer - INFO] - Train Epoch:[66/100] Step:[200/250] Total Loss: 39.799805 GL_Loss: 0.455568 CRF_Loss: 39.344238\n",
      "[2022-02-17 18:51:43,842 - trainer - INFO] - [Step Validation] Epoch:[66/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.890909 | 0.936306 | 0.913043 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.732075 | 0.515957 | 0.605304 | 0.515957 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.687285 | 0.636943 | 0.661157 | 0.636943 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.743527 | 0.642173 | 0.689143 | 0.642173 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 18:51:57,695 - trainer - INFO] - Train Epoch:[66/100] Step:[210/250] Total Loss: 23.109100 GL_Loss: 0.390960 CRF_Loss: 22.718140\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 18:52:11,790 - trainer - INFO] - Train Epoch:[66/100] Step:[220/250] Total Loss: 31.660749 GL_Loss: 0.560286 CRF_Loss: 31.100464\n",
      "[2022-02-17 18:52:25,106 - trainer - INFO] - Train Epoch:[66/100] Step:[230/250] Total Loss: 39.137630 GL_Loss: 0.361017 CRF_Loss: 38.776611\n",
      "[2022-02-17 18:52:40,197 - trainer - INFO] - Train Epoch:[66/100] Step:[240/250] Total Loss: 60.585484 GL_Loss: 0.464632 CRF_Loss: 60.120850\n",
      "[2022-02-17 18:52:54,160 - trainer - INFO] - Train Epoch:[66/100] Step:[250/250] Total Loss: 35.771530 GL_Loss: 0.523974 CRF_Loss: 35.247559\n",
      "[2022-02-17 18:53:13,157 - trainer - INFO] - [Step Validation] Epoch:[66/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.884848 | 0.929936 | 0.906832 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.734615 | 0.507979 | 0.600629 | 0.507979 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.692308 | 0.659236 | 0.675367 | 0.659236 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.684783 | 0.684783 | 0.684783 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.743873 | 0.646432 | 0.691738 | 0.646432 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 18:53:32,312 - trainer - INFO] - [Epoch Validation] Epoch:[66/100] Total Loss: 41.122733 GL_Loss: 0.004979 CRF_Loss: 40.624835 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.884848 | 0.929936 | 0.906832 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.734615 | 0.507979 | 0.600629 | 0.507979 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.692308 | 0.659236 | 0.675367 | 0.659236 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.684783 | 0.684783 | 0.684783 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.743873 | 0.646432 | 0.691738 | 0.646432 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 18:53:47,720 - trainer - INFO] - Train Epoch:[67/100] Step:[10/250] Total Loss: 17.100031 GL_Loss: 0.540583 CRF_Loss: 16.559448\n",
      "[2022-02-17 18:54:01,943 - trainer - INFO] - Train Epoch:[67/100] Step:[20/250] Total Loss: 21.509180 GL_Loss: 0.697291 CRF_Loss: 20.811890\n",
      "[2022-02-17 18:54:16,016 - trainer - INFO] - Train Epoch:[67/100] Step:[30/250] Total Loss: 11.875476 GL_Loss: 0.547473 CRF_Loss: 11.328003\n",
      "[2022-02-17 18:54:30,550 - trainer - INFO] - Train Epoch:[67/100] Step:[40/250] Total Loss: 13.417617 GL_Loss: 0.695693 CRF_Loss: 12.721924\n",
      "[2022-02-17 18:54:44,279 - trainer - INFO] - Train Epoch:[67/100] Step:[50/250] Total Loss: 15.399626 GL_Loss: 0.520353 CRF_Loss: 14.879272\n",
      "[2022-02-17 18:55:03,198 - trainer - INFO] - [Step Validation] Epoch:[67/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.896341 | 0.936306 | 0.915888 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.698473 | 0.486702 | 0.573668 | 0.486702 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.672241 | 0.640127 | 0.655791 | 0.640127 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.67033  | 0.663043 | 0.666667 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.72549  | 0.630458 | 0.674644 | 0.630458 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 18:55:16,838 - trainer - INFO] - Train Epoch:[67/100] Step:[60/250] Total Loss: 75.766617 GL_Loss: 0.454359 CRF_Loss: 75.312256\n",
      "[2022-02-17 18:55:31,014 - trainer - INFO] - Train Epoch:[67/100] Step:[70/250] Total Loss: 15.984702 GL_Loss: 0.443931 CRF_Loss: 15.540771\n",
      "[2022-02-17 18:55:44,693 - trainer - INFO] - Train Epoch:[67/100] Step:[80/250] Total Loss: 22.429476 GL_Loss: 0.490389 CRF_Loss: 21.939087\n",
      "[2022-02-17 18:55:58,471 - trainer - INFO] - Train Epoch:[67/100] Step:[90/250] Total Loss: 32.338135 GL_Loss: 0.500245 CRF_Loss: 31.837891\n",
      "[2022-02-17 18:56:13,717 - trainer - INFO] - Train Epoch:[67/100] Step:[100/250] Total Loss: 112.238693 GL_Loss: 0.491131 CRF_Loss: 111.747559\n",
      "[2022-02-17 18:56:32,595 - trainer - INFO] - [Step Validation] Epoch:[67/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.890244 | 0.929936 | 0.909657 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.731061 | 0.513298 | 0.603125 | 0.513298 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.683673 | 0.640127 | 0.661184 | 0.640127 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.681319 | 0.673913 | 0.677596 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.740467 | 0.641108 | 0.687215 | 0.641108 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 18:56:47,458 - trainer - INFO] - Train Epoch:[67/100] Step:[110/250] Total Loss: 15.598919 GL_Loss: 0.544964 CRF_Loss: 15.053955\n",
      "[2022-02-17 18:57:02,040 - trainer - INFO] - Train Epoch:[67/100] Step:[120/250] Total Loss: 15.103833 GL_Loss: 0.386059 CRF_Loss: 14.717773\n",
      "[2022-02-17 18:57:16,828 - trainer - INFO] - Train Epoch:[67/100] Step:[130/250] Total Loss: 17.312799 GL_Loss: 0.497796 CRF_Loss: 16.815002\n",
      "[2022-02-17 18:57:30,438 - trainer - INFO] - Train Epoch:[67/100] Step:[140/250] Total Loss: 22.114340 GL_Loss: 0.518271 CRF_Loss: 21.596069\n",
      "[2022-02-17 18:57:44,154 - trainer - INFO] - Train Epoch:[67/100] Step:[150/250] Total Loss: 25.384609 GL_Loss: 0.473720 CRF_Loss: 24.910889\n",
      "[2022-02-17 18:58:05,165 - trainer - INFO] - [Step Validation] Epoch:[67/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.879518 | 0.929936 | 0.904025 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.745247 | 0.521277 | 0.613459 | 0.521277 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.693333 | 0.66242  | 0.677524 | 0.66242  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.747253 | 0.651757 | 0.696246 | 0.651757 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 18:58:07,370 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 18:58:22,039 - trainer - INFO] - Train Epoch:[67/100] Step:[160/250] Total Loss: 47.356796 GL_Loss: 0.953352 CRF_Loss: 46.403442\n",
      "[2022-02-17 18:58:35,681 - trainer - INFO] - Train Epoch:[67/100] Step:[170/250] Total Loss: 77.522163 GL_Loss: 0.611883 CRF_Loss: 76.910278\n",
      "[2022-02-17 18:58:49,686 - trainer - INFO] - Train Epoch:[67/100] Step:[180/250] Total Loss: 33.997368 GL_Loss: 0.435844 CRF_Loss: 33.561523\n",
      "[2022-02-17 18:59:03,784 - trainer - INFO] - Train Epoch:[67/100] Step:[190/250] Total Loss: 27.335049 GL_Loss: 0.438565 CRF_Loss: 26.896484\n",
      "[2022-02-17 18:59:19,665 - trainer - INFO] - Train Epoch:[67/100] Step:[200/250] Total Loss: 13.343603 GL_Loss: 0.558935 CRF_Loss: 12.784668\n",
      "[2022-02-17 18:59:38,972 - trainer - INFO] - [Step Validation] Epoch:[67/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.901235 | 0.929936 | 0.915361 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.716475 | 0.49734  | 0.587127 | 0.49734  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.680412 | 0.630573 | 0.654545 | 0.630573 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.681319 | 0.673913 | 0.677596 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.736646 | 0.631523 | 0.680046 | 0.631523 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 18:59:53,857 - trainer - INFO] - Train Epoch:[67/100] Step:[210/250] Total Loss: 16.025879 GL_Loss: 0.487671 CRF_Loss: 15.538208\n",
      "[2022-02-17 19:00:07,972 - trainer - INFO] - Train Epoch:[67/100] Step:[220/250] Total Loss: 9.716392 GL_Loss: 0.475913 CRF_Loss: 9.240479\n",
      "[2022-02-17 19:00:21,804 - trainer - INFO] - Train Epoch:[67/100] Step:[230/250] Total Loss: 315.697693 GL_Loss: 0.447314 CRF_Loss: 315.250366\n",
      "[2022-02-17 19:00:36,288 - trainer - INFO] - Train Epoch:[67/100] Step:[240/250] Total Loss: 21.526209 GL_Loss: 0.331752 CRF_Loss: 21.194458\n",
      "[2022-02-17 19:00:49,586 - trainer - INFO] - Train Epoch:[67/100] Step:[250/250] Total Loss: 28.467091 GL_Loss: 0.486011 CRF_Loss: 27.981079\n",
      "[2022-02-17 19:01:09,093 - trainer - INFO] - [Step Validation] Epoch:[67/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.730038 | 0.510638 | 0.600939 | 0.510638 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.671096 | 0.643312 | 0.656911 | 0.643312 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.677778 | 0.663043 | 0.67033  | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.735618 | 0.640043 | 0.68451  | 0.640043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 19:01:28,345 - trainer - INFO] - [Epoch Validation] Epoch:[67/100] Total Loss: 41.006268 GL_Loss: 0.005051 CRF_Loss: 40.501200 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.730038 | 0.510638 | 0.600939 | 0.510638 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.671096 | 0.643312 | 0.656911 | 0.643312 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.677778 | 0.663043 | 0.67033  | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.735618 | 0.640043 | 0.68451  | 0.640043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 19:01:42,645 - trainer - INFO] - Train Epoch:[68/100] Step:[10/250] Total Loss: 43.802547 GL_Loss: 0.711850 CRF_Loss: 43.090698\n",
      "[2022-02-17 19:01:57,706 - trainer - INFO] - Train Epoch:[68/100] Step:[20/250] Total Loss: 13.425089 GL_Loss: 0.321939 CRF_Loss: 13.103149\n",
      "[2022-02-17 19:02:12,726 - trainer - INFO] - Train Epoch:[68/100] Step:[30/250] Total Loss: 26.811995 GL_Loss: 0.598372 CRF_Loss: 26.213623\n",
      "[2022-02-17 19:02:26,973 - trainer - INFO] - Train Epoch:[68/100] Step:[40/250] Total Loss: 19.519636 GL_Loss: 0.496199 CRF_Loss: 19.023438\n",
      "[2022-02-17 19:02:41,198 - trainer - INFO] - Train Epoch:[68/100] Step:[50/250] Total Loss: 14.871981 GL_Loss: 0.444125 CRF_Loss: 14.427856\n",
      "[2022-02-17 19:03:00,314 - trainer - INFO] - [Step Validation] Epoch:[68/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.878788 | 0.923567 | 0.900621 | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.739623 | 0.521277 | 0.611544 | 0.521277 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.676568 | 0.652866 | 0.664506 | 0.652866 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.738761 | 0.647497 | 0.690125 | 0.647497 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 19:03:13,882 - trainer - INFO] - Train Epoch:[68/100] Step:[60/250] Total Loss: 50.821056 GL_Loss: 0.351816 CRF_Loss: 50.469238\n",
      "[2022-02-17 19:03:27,038 - trainer - INFO] - Train Epoch:[68/100] Step:[70/250] Total Loss: 32.218426 GL_Loss: 0.333416 CRF_Loss: 31.885010\n",
      "[2022-02-17 19:03:41,001 - trainer - INFO] - Train Epoch:[68/100] Step:[80/250] Total Loss: 17.050091 GL_Loss: 0.429241 CRF_Loss: 16.620850\n",
      "[2022-02-17 19:03:55,154 - trainer - INFO] - Train Epoch:[68/100] Step:[90/250] Total Loss: 22.400097 GL_Loss: 0.558055 CRF_Loss: 21.842041\n",
      "[2022-02-17 19:04:09,933 - trainer - INFO] - Train Epoch:[68/100] Step:[100/250] Total Loss: 7.857531 GL_Loss: 0.535144 CRF_Loss: 7.322388\n",
      "[2022-02-17 19:04:28,857 - trainer - INFO] - [Step Validation] Epoch:[68/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.901235 | 0.929936 | 0.915361 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.703125 | 0.478723 | 0.56962  | 0.478723 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.690647 | 0.611465 | 0.648649 | 0.611465 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.677778 | 0.663043 | 0.67033  | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.736641 | 0.616613 | 0.671304 | 0.616613 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 19:04:43,751 - trainer - INFO] - Train Epoch:[68/100] Step:[110/250] Total Loss: 21.847506 GL_Loss: 0.323091 CRF_Loss: 21.524414\n",
      "[2022-02-17 19:04:58,928 - trainer - INFO] - Train Epoch:[68/100] Step:[120/250] Total Loss: 15.975520 GL_Loss: 0.763728 CRF_Loss: 15.211792\n",
      "[2022-02-17 19:05:13,156 - trainer - INFO] - Train Epoch:[68/100] Step:[130/250] Total Loss: 15.746778 GL_Loss: 0.533826 CRF_Loss: 15.212952\n",
      "[2022-02-17 19:05:26,818 - trainer - INFO] - Train Epoch:[68/100] Step:[140/250] Total Loss: 17.592230 GL_Loss: 0.492010 CRF_Loss: 17.100220\n",
      "[2022-02-17 19:05:40,558 - trainer - INFO] - Train Epoch:[68/100] Step:[150/250] Total Loss: 50.574524 GL_Loss: 0.468691 CRF_Loss: 50.105835\n",
      "[2022-02-17 19:06:00,127 - trainer - INFO] - [Step Validation] Epoch:[68/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.907975 | 0.942675 | 0.925    | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.694981 | 0.478723 | 0.566929 | 0.478723 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.666667 | 0.617834 | 0.641322 | 0.617834 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.67033  | 0.663043 | 0.666667 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.725124 | 0.620873 | 0.668962 | 0.620873 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 19:06:15,084 - trainer - INFO] - Train Epoch:[68/100] Step:[160/250] Total Loss: 26.882769 GL_Loss: 0.730913 CRF_Loss: 26.151855\n",
      "[2022-02-17 19:06:28,812 - trainer - INFO] - Train Epoch:[68/100] Step:[170/250] Total Loss: 17.612734 GL_Loss: 0.422792 CRF_Loss: 17.189941\n",
      "[2022-02-17 19:06:42,683 - trainer - INFO] - Train Epoch:[68/100] Step:[180/250] Total Loss: 22.196745 GL_Loss: 0.634000 CRF_Loss: 21.562744\n",
      "[2022-02-17 19:06:56,901 - trainer - INFO] - Train Epoch:[68/100] Step:[190/250] Total Loss: 25.797939 GL_Loss: 0.508754 CRF_Loss: 25.289185\n",
      "[2022-02-17 19:07:10,182 - trainer - INFO] - Train Epoch:[68/100] Step:[200/250] Total Loss: 37.970131 GL_Loss: 0.381994 CRF_Loss: 37.588135\n",
      "[2022-02-17 19:07:29,362 - trainer - INFO] - [Step Validation] Epoch:[68/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.901235 | 0.929936 | 0.915361 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.727273 | 0.510638 | 0.6      | 0.510638 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.68     | 0.649682 | 0.664495 | 0.649682 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.67033  | 0.663043 | 0.666667 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.738066 | 0.642173 | 0.686788 | 0.642173 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 19:07:44,592 - trainer - INFO] - Train Epoch:[68/100] Step:[210/250] Total Loss: 164.384201 GL_Loss: 0.416057 CRF_Loss: 163.968140\n",
      "[2022-02-17 19:07:58,695 - trainer - INFO] - Train Epoch:[68/100] Step:[220/250] Total Loss: 54.730675 GL_Loss: 0.674158 CRF_Loss: 54.056519\n",
      "[2022-02-17 19:08:12,348 - trainer - INFO] - Train Epoch:[68/100] Step:[230/250] Total Loss: 16.064541 GL_Loss: 0.551235 CRF_Loss: 15.513306\n",
      "[2022-02-17 19:08:27,068 - trainer - INFO] - Train Epoch:[68/100] Step:[240/250] Total Loss: 35.998718 GL_Loss: 0.440857 CRF_Loss: 35.557861\n",
      "[2022-02-17 19:08:41,706 - trainer - INFO] - Train Epoch:[68/100] Step:[250/250] Total Loss: 24.966129 GL_Loss: 0.388004 CRF_Loss: 24.578125\n",
      "[2022-02-17 19:09:00,829 - trainer - INFO] - [Step Validation] Epoch:[68/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895062 | 0.923567 | 0.909091 | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.73384  | 0.513298 | 0.604069 | 0.513298 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.681208 | 0.646497 | 0.663399 | 0.646497 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.67033  | 0.663043 | 0.666667 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.739558 | 0.641108 | 0.686823 | 0.641108 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 19:09:19,844 - trainer - INFO] - [Epoch Validation] Epoch:[68/100] Total Loss: 41.296880 GL_Loss: 0.005036 CRF_Loss: 40.793283 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895062 | 0.923567 | 0.909091 | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.73384  | 0.513298 | 0.604069 | 0.513298 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.681208 | 0.646497 | 0.663399 | 0.646497 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.67033  | 0.663043 | 0.666667 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.739558 | 0.641108 | 0.686823 | 0.641108 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 19:09:34,334 - trainer - INFO] - Train Epoch:[69/100] Step:[10/250] Total Loss: 24.834072 GL_Loss: 0.573086 CRF_Loss: 24.260986\n",
      "[2022-02-17 19:09:48,694 - trainer - INFO] - Train Epoch:[69/100] Step:[20/250] Total Loss: 18.301302 GL_Loss: 0.458284 CRF_Loss: 17.843018\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 19:10:04,917 - trainer - INFO] - Train Epoch:[69/100] Step:[30/250] Total Loss: 79.342598 GL_Loss: 0.360420 CRF_Loss: 78.982178\n",
      "[2022-02-17 19:10:19,673 - trainer - INFO] - Train Epoch:[69/100] Step:[40/250] Total Loss: 165.048691 GL_Loss: 0.441882 CRF_Loss: 164.606812\n",
      "[2022-02-17 19:10:33,163 - trainer - INFO] - Train Epoch:[69/100] Step:[50/250] Total Loss: 10.560328 GL_Loss: 0.274317 CRF_Loss: 10.286011\n",
      "[2022-02-17 19:10:52,101 - trainer - INFO] - [Step Validation] Epoch:[69/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.713208 | 0.50266  | 0.589704 | 0.50266  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.681507 | 0.633758 | 0.656766 | 0.633758 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.67033  | 0.663043 | 0.666667 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.733662 | 0.633653 | 0.68     | 0.633653 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 19:11:06,310 - trainer - INFO] - Train Epoch:[69/100] Step:[60/250] Total Loss: 818.130249 GL_Loss: 0.389290 CRF_Loss: 817.740967\n",
      "[2022-02-17 19:11:21,410 - trainer - INFO] - Train Epoch:[69/100] Step:[70/250] Total Loss: 11.044530 GL_Loss: 0.555273 CRF_Loss: 10.489258\n",
      "[2022-02-17 19:11:34,431 - trainer - INFO] - Train Epoch:[69/100] Step:[80/250] Total Loss: 11.945917 GL_Loss: 0.958186 CRF_Loss: 10.987732\n",
      "[2022-02-17 19:11:48,182 - trainer - INFO] - Train Epoch:[69/100] Step:[90/250] Total Loss: 36.959095 GL_Loss: 0.694445 CRF_Loss: 36.264648\n",
      "[2022-02-17 19:12:02,801 - trainer - INFO] - Train Epoch:[69/100] Step:[100/250] Total Loss: 15.905290 GL_Loss: 0.375383 CRF_Loss: 15.529907\n",
      "[2022-02-17 19:12:21,963 - trainer - INFO] - [Step Validation] Epoch:[69/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.728302 | 0.513298 | 0.602184 | 0.513298 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.68     | 0.649682 | 0.664495 | 0.649682 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.677778 | 0.663043 | 0.67033  | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.738386 | 0.643237 | 0.687536 | 0.643237 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 19:12:36,584 - trainer - INFO] - Train Epoch:[69/100] Step:[110/250] Total Loss: 26.478289 GL_Loss: 0.435930 CRF_Loss: 26.042358\n",
      "[2022-02-17 19:12:49,803 - trainer - INFO] - Train Epoch:[69/100] Step:[120/250] Total Loss: 15.273915 GL_Loss: 0.535634 CRF_Loss: 14.738281\n",
      "[2022-02-17 19:13:03,089 - trainer - INFO] - Train Epoch:[69/100] Step:[130/250] Total Loss: 9.544487 GL_Loss: 0.500053 CRF_Loss: 9.044434\n",
      "[2022-02-17 19:13:18,360 - trainer - INFO] - Train Epoch:[69/100] Step:[140/250] Total Loss: 23.245705 GL_Loss: 0.529641 CRF_Loss: 22.716064\n",
      "[2022-02-17 19:13:33,177 - trainer - INFO] - Train Epoch:[69/100] Step:[150/250] Total Loss: 13.177622 GL_Loss: 0.579355 CRF_Loss: 12.598267\n",
      "[2022-02-17 19:13:52,193 - trainer - INFO] - [Step Validation] Epoch:[69/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.907975 | 0.942675 | 0.925    | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.720307 | 0.5      | 0.590267 | 0.5      |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.667797 | 0.627389 | 0.646962 | 0.627389 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.735476 | 0.633653 | 0.680778 | 0.633653 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 19:14:06,704 - trainer - INFO] - Train Epoch:[69/100] Step:[160/250] Total Loss: 8.937276 GL_Loss: 0.313253 CRF_Loss: 8.624023\n",
      "[2022-02-17 19:14:21,294 - trainer - INFO] - Train Epoch:[69/100] Step:[170/250] Total Loss: 62.667698 GL_Loss: 0.312353 CRF_Loss: 62.355347\n",
      "[2022-02-17 19:14:35,400 - trainer - INFO] - Train Epoch:[69/100] Step:[180/250] Total Loss: 19.404327 GL_Loss: 0.406403 CRF_Loss: 18.997925\n",
      "[2022-02-17 19:14:49,155 - trainer - INFO] - Train Epoch:[69/100] Step:[190/250] Total Loss: 23.539055 GL_Loss: 0.663811 CRF_Loss: 22.875244\n",
      "[2022-02-17 19:15:02,903 - trainer - INFO] - Train Epoch:[69/100] Step:[200/250] Total Loss: 27.448526 GL_Loss: 0.469279 CRF_Loss: 26.979248\n",
      "[2022-02-17 19:15:22,150 - trainer - INFO] - [Step Validation] Epoch:[69/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.907975 | 0.942675 | 0.925    | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.707224 | 0.494681 | 0.58216  | 0.494681 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.682657 | 0.589172 | 0.632479 | 0.589172 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.738247 | 0.618743 | 0.673233 | 0.618743 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 19:15:38,058 - trainer - INFO] - Train Epoch:[69/100] Step:[210/250] Total Loss: 43.943127 GL_Loss: 0.364636 CRF_Loss: 43.578491\n",
      "[2022-02-17 19:15:52,025 - trainer - INFO] - Train Epoch:[69/100] Step:[220/250] Total Loss: 50.104397 GL_Loss: 0.419461 CRF_Loss: 49.684937\n",
      "[2022-02-17 19:16:06,325 - trainer - INFO] - Train Epoch:[69/100] Step:[230/250] Total Loss: 37.400032 GL_Loss: 0.638801 CRF_Loss: 36.761230\n",
      "[2022-02-17 19:16:20,881 - trainer - INFO] - Train Epoch:[69/100] Step:[240/250] Total Loss: 43.862141 GL_Loss: 0.534259 CRF_Loss: 43.327881\n",
      "[2022-02-17 19:16:36,083 - trainer - INFO] - Train Epoch:[69/100] Step:[250/250] Total Loss: 50.912018 GL_Loss: 0.479765 CRF_Loss: 50.432251\n",
      "[2022-02-17 19:16:56,210 - trainer - INFO] - [Step Validation] Epoch:[69/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.884146 | 0.923567 | 0.903427 | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.742424 | 0.521277 | 0.6125   | 0.521277 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.680921 | 0.659236 | 0.669903 | 0.659236 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.67033  | 0.663043 | 0.666667 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.739976 | 0.648562 | 0.69126  | 0.648562 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 19:17:15,493 - trainer - INFO] - [Epoch Validation] Epoch:[69/100] Total Loss: 40.817393 GL_Loss: 0.005062 CRF_Loss: 40.311164 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.884146 | 0.923567 | 0.903427 | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.742424 | 0.521277 | 0.6125   | 0.521277 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.680921 | 0.659236 | 0.669903 | 0.659236 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.67033  | 0.663043 | 0.666667 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.739976 | 0.648562 | 0.69126  | 0.648562 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 19:17:33,243 - trainer - INFO] - Train Epoch:[70/100] Step:[10/250] Total Loss: 8.938251 GL_Loss: 0.433245 CRF_Loss: 8.505005\n",
      "[2022-02-17 19:17:49,413 - trainer - INFO] - Train Epoch:[70/100] Step:[20/250] Total Loss: 27.894831 GL_Loss: 0.549371 CRF_Loss: 27.345459\n",
      "[2022-02-17 19:18:03,854 - trainer - INFO] - Train Epoch:[70/100] Step:[30/250] Total Loss: 31.209570 GL_Loss: 0.498632 CRF_Loss: 30.710938\n",
      "[2022-02-17 19:18:19,074 - trainer - INFO] - Train Epoch:[70/100] Step:[40/250] Total Loss: 24.537674 GL_Loss: 0.483476 CRF_Loss: 24.054199\n",
      "[2022-02-17 19:18:33,777 - trainer - INFO] - Train Epoch:[70/100] Step:[50/250] Total Loss: 13.455115 GL_Loss: 0.520423 CRF_Loss: 12.934692\n",
      "[2022-02-17 19:18:52,778 - trainer - INFO] - [Step Validation] Epoch:[70/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.890244 | 0.929936 | 0.909657 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.730038 | 0.510638 | 0.600939 | 0.510638 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.680135 | 0.643312 | 0.661211 | 0.643312 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.739558 | 0.641108 | 0.686823 | 0.641108 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 19:19:07,556 - trainer - INFO] - Train Epoch:[70/100] Step:[60/250] Total Loss: 44.451954 GL_Loss: 0.348562 CRF_Loss: 44.103394\n",
      "[2022-02-17 19:19:21,932 - trainer - INFO] - Train Epoch:[70/100] Step:[70/250] Total Loss: 9.536818 GL_Loss: 0.728834 CRF_Loss: 8.807983\n",
      "[2022-02-17 19:19:38,061 - trainer - INFO] - Train Epoch:[70/100] Step:[80/250] Total Loss: 8.541048 GL_Loss: 0.410677 CRF_Loss: 8.130371\n",
      "[2022-02-17 19:19:53,815 - trainer - INFO] - Train Epoch:[70/100] Step:[90/250] Total Loss: 18.959988 GL_Loss: 0.746852 CRF_Loss: 18.213135\n",
      "[2022-02-17 19:20:09,412 - trainer - INFO] - Train Epoch:[70/100] Step:[100/250] Total Loss: 11.033408 GL_Loss: 0.577842 CRF_Loss: 10.455566\n",
      "[2022-02-17 19:20:28,476 - trainer - INFO] - [Step Validation] Epoch:[70/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.896341 | 0.936306 | 0.915888 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.735849 | 0.518617 | 0.608424 | 0.518617 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.671141 | 0.636943 | 0.653595 | 0.636943 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.67033  | 0.663043 | 0.666667 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.737164 | 0.642173 | 0.686397 | 0.642173 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 19:20:42,213 - trainer - INFO] - Train Epoch:[70/100] Step:[110/250] Total Loss: 29.625526 GL_Loss: 1.004555 CRF_Loss: 28.620972\n",
      "[2022-02-17 19:20:57,163 - trainer - INFO] - Train Epoch:[70/100] Step:[120/250] Total Loss: 37.752300 GL_Loss: 0.380839 CRF_Loss: 37.371460\n",
      "[2022-02-17 19:21:10,883 - trainer - INFO] - Train Epoch:[70/100] Step:[130/250] Total Loss: 16.222002 GL_Loss: 0.602496 CRF_Loss: 15.619507\n",
      "[2022-02-17 19:21:25,225 - trainer - INFO] - Train Epoch:[70/100] Step:[140/250] Total Loss: 59.899876 GL_Loss: 0.536352 CRF_Loss: 59.363525\n",
      "[2022-02-17 19:21:41,317 - trainer - INFO] - Train Epoch:[70/100] Step:[150/250] Total Loss: 36.181507 GL_Loss: 0.300524 CRF_Loss: 35.880981\n",
      "[2022-02-17 19:22:00,389 - trainer - INFO] - [Step Validation] Epoch:[70/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.686792 | 0.484043 | 0.567863 | 0.484043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.675862 | 0.624204 | 0.649007 | 0.624204 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.681319 | 0.673913 | 0.677596 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.724351 | 0.624068 | 0.670481 | 0.624068 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 19:22:15,090 - trainer - INFO] - Train Epoch:[70/100] Step:[160/250] Total Loss: 11.745450 GL_Loss: 0.410123 CRF_Loss: 11.335327\n",
      "[2022-02-17 19:22:29,895 - trainer - INFO] - Train Epoch:[70/100] Step:[170/250] Total Loss: 23.495520 GL_Loss: 0.430944 CRF_Loss: 23.064575\n",
      "[2022-02-17 19:22:44,107 - trainer - INFO] - Train Epoch:[70/100] Step:[180/250] Total Loss: 21.607853 GL_Loss: 0.444646 CRF_Loss: 21.163208\n",
      "[2022-02-17 19:22:57,555 - trainer - INFO] - Train Epoch:[70/100] Step:[190/250] Total Loss: 70.653336 GL_Loss: 0.554583 CRF_Loss: 70.098755\n",
      "[2022-02-17 19:23:11,814 - trainer - INFO] - Train Epoch:[70/100] Step:[200/250] Total Loss: 78.392540 GL_Loss: 0.495445 CRF_Loss: 77.897095\n",
      "[2022-02-17 19:23:31,115 - trainer - INFO] - [Step Validation] Epoch:[70/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.890909 | 0.936306 | 0.913043 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.717557 | 0.5      | 0.589342 | 0.5      |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.672355 | 0.627389 | 0.649094 | 0.627389 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.711111 | 0.695652 | 0.703297 | 0.695652 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.735802 | 0.634718 | 0.681532 | 0.634718 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 19:23:44,727 - trainer - INFO] - Train Epoch:[70/100] Step:[210/250] Total Loss: 31.530664 GL_Loss: 0.462304 CRF_Loss: 31.068359\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 19:23:59,836 - trainer - INFO] - Train Epoch:[70/100] Step:[220/250] Total Loss: 20.937418 GL_Loss: 0.412271 CRF_Loss: 20.525146\n",
      "[2022-02-17 19:24:13,542 - trainer - INFO] - Train Epoch:[70/100] Step:[230/250] Total Loss: 25.284369 GL_Loss: 0.361274 CRF_Loss: 24.923096\n",
      "[2022-02-17 19:24:28,377 - trainer - INFO] - Train Epoch:[70/100] Step:[240/250] Total Loss: 11.426697 GL_Loss: 0.368347 CRF_Loss: 11.058350\n",
      "[2022-02-17 19:24:42,440 - trainer - INFO] - Train Epoch:[70/100] Step:[250/250] Total Loss: 823.396545 GL_Loss: 0.568198 CRF_Loss: 822.828369\n",
      "[2022-02-17 19:25:01,629 - trainer - INFO] - [Step Validation] Epoch:[70/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.901235 | 0.929936 | 0.915361 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.730038 | 0.510638 | 0.600939 | 0.510638 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.681356 | 0.640127 | 0.660099 | 0.640127 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.741975 | 0.640043 | 0.68725  | 0.640043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 19:25:20,784 - trainer - INFO] - [Epoch Validation] Epoch:[70/100] Total Loss: 40.740323 GL_Loss: 0.005038 CRF_Loss: 40.236480 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.901235 | 0.929936 | 0.915361 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.730038 | 0.510638 | 0.600939 | 0.510638 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.681356 | 0.640127 | 0.660099 | 0.640127 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.741975 | 0.640043 | 0.68725  | 0.640043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 19:25:35,514 - trainer - INFO] - Train Epoch:[71/100] Step:[10/250] Total Loss: 35.207916 GL_Loss: 0.743074 CRF_Loss: 34.464844\n",
      "[2022-02-17 19:25:49,878 - trainer - INFO] - Train Epoch:[71/100] Step:[20/250] Total Loss: 21.493622 GL_Loss: 0.421844 CRF_Loss: 21.071777\n",
      "[2022-02-17 19:26:04,468 - trainer - INFO] - Train Epoch:[71/100] Step:[30/250] Total Loss: 15.278016 GL_Loss: 0.490906 CRF_Loss: 14.787109\n",
      "[2022-02-17 19:26:18,029 - trainer - INFO] - Train Epoch:[71/100] Step:[40/250] Total Loss: 125.829475 GL_Loss: 0.720222 CRF_Loss: 125.109253\n",
      "[2022-02-17 19:26:32,207 - trainer - INFO] - Train Epoch:[71/100] Step:[50/250] Total Loss: 26.520489 GL_Loss: 0.521831 CRF_Loss: 25.998657\n",
      "[2022-02-17 19:26:51,288 - trainer - INFO] - [Step Validation] Epoch:[71/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.890244 | 0.929936 | 0.909657 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.704545 | 0.494681 | 0.58125  | 0.494681 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.671141 | 0.636943 | 0.653595 | 0.636943 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.67033  | 0.663043 | 0.666667 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.725826 | 0.631523 | 0.675399 | 0.631523 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 19:27:06,161 - trainer - INFO] - Train Epoch:[71/100] Step:[60/250] Total Loss: 11.055030 GL_Loss: 0.570288 CRF_Loss: 10.484741\n",
      "[2022-02-17 19:27:20,476 - trainer - INFO] - Train Epoch:[71/100] Step:[70/250] Total Loss: 70.019272 GL_Loss: 0.530627 CRF_Loss: 69.488647\n",
      "[2022-02-17 19:27:34,763 - trainer - INFO] - Train Epoch:[71/100] Step:[80/250] Total Loss: 97.891869 GL_Loss: 0.361596 CRF_Loss: 97.530273\n",
      "[2022-02-17 19:27:50,006 - trainer - INFO] - Train Epoch:[71/100] Step:[90/250] Total Loss: 31.310022 GL_Loss: 0.325281 CRF_Loss: 30.984741\n",
      "[2022-02-17 19:28:04,462 - trainer - INFO] - Train Epoch:[71/100] Step:[100/250] Total Loss: 15.347879 GL_Loss: 0.529275 CRF_Loss: 14.818604\n",
      "[2022-02-17 19:28:23,538 - trainer - INFO] - [Step Validation] Epoch:[71/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.878788 | 0.923567 | 0.900621 | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.726236 | 0.507979 | 0.597809 | 0.507979 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.683168 | 0.659236 | 0.670989 | 0.659236 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.67033  | 0.663043 | 0.666667 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.734793 | 0.643237 | 0.685974 | 0.643237 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 19:28:37,358 - trainer - INFO] - Train Epoch:[71/100] Step:[110/250] Total Loss: 24.786413 GL_Loss: 0.430578 CRF_Loss: 24.355835\n",
      "[2022-02-17 19:28:51,362 - trainer - INFO] - Train Epoch:[71/100] Step:[120/250] Total Loss: 73.242477 GL_Loss: 0.473677 CRF_Loss: 72.768799\n",
      "[2022-02-17 19:29:05,769 - trainer - INFO] - Train Epoch:[71/100] Step:[130/250] Total Loss: 24.894064 GL_Loss: 0.459738 CRF_Loss: 24.434326\n",
      "[2022-02-17 19:29:20,221 - trainer - INFO] - Train Epoch:[71/100] Step:[140/250] Total Loss: 18.324572 GL_Loss: 0.713488 CRF_Loss: 17.611084\n",
      "[2022-02-17 19:29:34,330 - trainer - INFO] - Train Epoch:[71/100] Step:[150/250] Total Loss: 18.247780 GL_Loss: 0.503273 CRF_Loss: 17.744507\n",
      "[2022-02-17 19:29:53,286 - trainer - INFO] - [Step Validation] Epoch:[71/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.890244 | 0.929936 | 0.909657 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.744275 | 0.518617 | 0.611285 | 0.518617 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.692308 | 0.659236 | 0.675367 | 0.659236 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.67033  | 0.663043 | 0.666667 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.746324 | 0.648562 | 0.694017 | 0.648562 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 19:30:07,386 - trainer - INFO] - Train Epoch:[71/100] Step:[160/250] Total Loss: 19.413687 GL_Loss: 0.494132 CRF_Loss: 18.919556\n",
      "[2022-02-17 19:30:20,655 - trainer - INFO] - Train Epoch:[71/100] Step:[170/250] Total Loss: 54.153187 GL_Loss: 0.408068 CRF_Loss: 53.745117\n",
      "[2022-02-17 19:30:34,933 - trainer - INFO] - Train Epoch:[71/100] Step:[180/250] Total Loss: 50.017868 GL_Loss: 0.471483 CRF_Loss: 49.546387\n",
      "[2022-02-17 19:30:49,020 - trainer - INFO] - Train Epoch:[71/100] Step:[190/250] Total Loss: 28.943794 GL_Loss: 0.625434 CRF_Loss: 28.318359\n",
      "[2022-02-17 19:31:03,065 - trainer - INFO] - Train Epoch:[71/100] Step:[200/250] Total Loss: 24.375908 GL_Loss: 0.466240 CRF_Loss: 23.909668\n",
      "[2022-02-17 19:31:22,073 - trainer - INFO] - [Step Validation] Epoch:[71/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.890244 | 0.929936 | 0.909657 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.737643 | 0.515957 | 0.607199 | 0.515957 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.686469 | 0.66242  | 0.67423  | 0.66242  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.67033  | 0.663043 | 0.666667 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.741778 | 0.648562 | 0.692045 | 0.648562 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 19:31:36,258 - trainer - INFO] - Train Epoch:[71/100] Step:[210/250] Total Loss: 251.601135 GL_Loss: 0.594546 CRF_Loss: 251.006592\n",
      "[2022-02-17 19:31:50,858 - trainer - INFO] - Train Epoch:[71/100] Step:[220/250] Total Loss: 57.399986 GL_Loss: 0.331261 CRF_Loss: 57.068726\n",
      "[2022-02-17 19:32:05,368 - trainer - INFO] - Train Epoch:[71/100] Step:[230/250] Total Loss: 30.956507 GL_Loss: 0.332971 CRF_Loss: 30.623535\n",
      "[2022-02-17 19:32:19,974 - trainer - INFO] - Train Epoch:[71/100] Step:[240/250] Total Loss: 45.427380 GL_Loss: 0.394786 CRF_Loss: 45.032593\n",
      "[2022-02-17 19:32:34,667 - trainer - INFO] - Train Epoch:[71/100] Step:[250/250] Total Loss: 7.204787 GL_Loss: 0.594191 CRF_Loss: 6.610596\n",
      "[2022-02-17 19:32:53,638 - trainer - INFO] - [Step Validation] Epoch:[71/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.884146 | 0.923567 | 0.903427 | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.697674 | 0.478723 | 0.567823 | 0.478723 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.673267 | 0.649682 | 0.661264 | 0.649682 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.666667 | 0.652174 | 0.659341 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.722699 | 0.627263 | 0.671608 | 0.627263 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 19:33:12,795 - trainer - INFO] - [Epoch Validation] Epoch:[71/100] Total Loss: 40.915728 GL_Loss: 0.005027 CRF_Loss: 40.413041 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.884146 | 0.923567 | 0.903427 | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.697674 | 0.478723 | 0.567823 | 0.478723 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.673267 | 0.649682 | 0.661264 | 0.649682 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.666667 | 0.652174 | 0.659341 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.722699 | 0.627263 | 0.671608 | 0.627263 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 19:33:28,548 - trainer - INFO] - Train Epoch:[72/100] Step:[10/250] Total Loss: 60.997883 GL_Loss: 0.387042 CRF_Loss: 60.610840\n",
      "[2022-02-17 19:33:41,905 - trainer - INFO] - Train Epoch:[72/100] Step:[20/250] Total Loss: 25.298525 GL_Loss: 0.470156 CRF_Loss: 24.828369\n",
      "[2022-02-17 19:33:55,586 - trainer - INFO] - Train Epoch:[72/100] Step:[30/250] Total Loss: 52.510265 GL_Loss: 0.941908 CRF_Loss: 51.568359\n",
      "[2022-02-17 19:34:10,781 - trainer - INFO] - Train Epoch:[72/100] Step:[40/250] Total Loss: 19.581963 GL_Loss: 0.499199 CRF_Loss: 19.082764\n",
      "[2022-02-17 19:34:24,923 - trainer - INFO] - Train Epoch:[72/100] Step:[50/250] Total Loss: 9.483471 GL_Loss: 0.635937 CRF_Loss: 8.847534\n",
      "[2022-02-17 19:34:43,898 - trainer - INFO] - [Step Validation] Epoch:[72/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.884848 | 0.929936 | 0.906832 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.734848 | 0.515957 | 0.60625  | 0.515957 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.686469 | 0.66242  | 0.67423  | 0.66242  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.677778 | 0.663043 | 0.67033  | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.740876 | 0.648562 | 0.691652 | 0.648562 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 19:34:58,399 - trainer - INFO] - Train Epoch:[72/100] Step:[60/250] Total Loss: 21.903965 GL_Loss: 0.640660 CRF_Loss: 21.263306\n",
      "[2022-02-17 19:35:11,335 - trainer - INFO] - Train Epoch:[72/100] Step:[70/250] Total Loss: 44.676003 GL_Loss: 0.598245 CRF_Loss: 44.077759\n",
      "[2022-02-17 19:35:25,596 - trainer - INFO] - Train Epoch:[72/100] Step:[80/250] Total Loss: 17.915928 GL_Loss: 0.569005 CRF_Loss: 17.346924\n",
      "[2022-02-17 19:35:39,559 - trainer - INFO] - Train Epoch:[72/100] Step:[90/250] Total Loss: 54.816826 GL_Loss: 0.384819 CRF_Loss: 54.432007\n",
      "[2022-02-17 19:35:53,800 - trainer - INFO] - Train Epoch:[72/100] Step:[100/250] Total Loss: 46.030899 GL_Loss: 0.404434 CRF_Loss: 45.626465\n",
      "[2022-02-17 19:36:13,043 - trainer - INFO] - [Step Validation] Epoch:[72/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.884848 | 0.929936 | 0.906832 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.751908 | 0.523936 | 0.617555 | 0.523936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.668831 | 0.656051 | 0.662379 | 0.656051 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.7      | 0.684783 | 0.692308 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.741818 | 0.651757 | 0.693878 | 0.651757 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 19:36:26,356 - trainer - INFO] - Train Epoch:[72/100] Step:[110/250] Total Loss: 59.315434 GL_Loss: 0.432867 CRF_Loss: 58.882568\n",
      "[2022-02-17 19:36:40,488 - trainer - INFO] - Train Epoch:[72/100] Step:[120/250] Total Loss: 32.320370 GL_Loss: 0.547666 CRF_Loss: 31.772705\n",
      "[2022-02-17 19:36:56,488 - trainer - INFO] - Train Epoch:[72/100] Step:[130/250] Total Loss: 78.348396 GL_Loss: 0.558599 CRF_Loss: 77.789795\n",
      "[2022-02-17 19:37:10,323 - trainer - INFO] - Train Epoch:[72/100] Step:[140/250] Total Loss: 28.707926 GL_Loss: 1.020670 CRF_Loss: 27.687256\n",
      "[2022-02-17 19:37:24,790 - trainer - INFO] - Train Epoch:[72/100] Step:[150/250] Total Loss: 34.636280 GL_Loss: 0.486256 CRF_Loss: 34.150024\n",
      "[2022-02-17 19:37:44,329 - trainer - INFO] - [Step Validation] Epoch:[72/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.896341 | 0.936306 | 0.915888 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.718147 | 0.494681 | 0.585827 | 0.494681 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.666667 | 0.643312 | 0.654781 | 0.643312 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.681319 | 0.673913 | 0.677596 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.730722 | 0.635783 | 0.679954 | 0.635783 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 19:37:58,258 - trainer - INFO] - Train Epoch:[72/100] Step:[160/250] Total Loss: 40.537300 GL_Loss: 0.659861 CRF_Loss: 39.877441\n",
      "[2022-02-17 19:38:12,616 - trainer - INFO] - Train Epoch:[72/100] Step:[170/250] Total Loss: 12.881120 GL_Loss: 0.445329 CRF_Loss: 12.435791\n",
      "[2022-02-17 19:38:26,871 - trainer - INFO] - Train Epoch:[72/100] Step:[180/250] Total Loss: 12.432165 GL_Loss: 0.420080 CRF_Loss: 12.012085\n",
      "[2022-02-17 19:38:41,183 - trainer - INFO] - Train Epoch:[72/100] Step:[190/250] Total Loss: 17.478056 GL_Loss: 0.420195 CRF_Loss: 17.057861\n",
      "[2022-02-17 19:38:55,075 - trainer - INFO] - Train Epoch:[72/100] Step:[200/250] Total Loss: 89.215271 GL_Loss: 0.621769 CRF_Loss: 88.593506\n",
      "[2022-02-17 19:39:14,038 - trainer - INFO] - [Step Validation] Epoch:[72/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.890244 | 0.929936 | 0.909657 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.742424 | 0.521277 | 0.6125   | 0.521277 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.67541  | 0.656051 | 0.66559  | 0.656051 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.659341 | 0.652174 | 0.655738 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.737864 | 0.647497 | 0.689733 | 0.647497 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 19:39:28,673 - trainer - INFO] - Train Epoch:[72/100] Step:[210/250] Total Loss: 47.894096 GL_Loss: 0.385063 CRF_Loss: 47.509033\n",
      "[2022-02-17 19:39:42,744 - trainer - INFO] - Train Epoch:[72/100] Step:[220/250] Total Loss: 25.227421 GL_Loss: 0.402287 CRF_Loss: 24.825134\n",
      "[2022-02-17 19:39:57,478 - trainer - INFO] - Train Epoch:[72/100] Step:[230/250] Total Loss: 43.229031 GL_Loss: 0.466212 CRF_Loss: 42.762817\n",
      "[2022-02-17 19:40:11,976 - trainer - INFO] - Train Epoch:[72/100] Step:[240/250] Total Loss: 32.869869 GL_Loss: 0.590573 CRF_Loss: 32.279297\n",
      "[2022-02-17 19:40:26,692 - trainer - INFO] - Train Epoch:[72/100] Step:[250/250] Total Loss: 80.744698 GL_Loss: 0.458199 CRF_Loss: 80.286499\n",
      "[2022-02-17 19:40:45,859 - trainer - INFO] - [Step Validation] Epoch:[72/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.907407 | 0.936306 | 0.92163  | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.711538 | 0.492021 | 0.581761 | 0.492021 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.687719 | 0.624204 | 0.654424 | 0.624204 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.7      | 0.684783 | 0.692308 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.741531 | 0.629393 | 0.680876 | 0.629393 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 19:41:06,145 - trainer - INFO] - [Epoch Validation] Epoch:[72/100] Total Loss: 40.677790 GL_Loss: 0.005098 CRF_Loss: 40.168006 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.907407 | 0.936306 | 0.92163  | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.711538 | 0.492021 | 0.581761 | 0.492021 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.687719 | 0.624204 | 0.654424 | 0.624204 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.7      | 0.684783 | 0.692308 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.741531 | 0.629393 | 0.680876 | 0.629393 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 19:41:20,500 - trainer - INFO] - Train Epoch:[73/100] Step:[10/250] Total Loss: 13.102407 GL_Loss: 0.378408 CRF_Loss: 12.723999\n",
      "[2022-02-17 19:41:34,365 - trainer - INFO] - Train Epoch:[73/100] Step:[20/250] Total Loss: 29.392588 GL_Loss: 0.417246 CRF_Loss: 28.975342\n",
      "[2022-02-17 19:41:48,150 - trainer - INFO] - Train Epoch:[73/100] Step:[30/250] Total Loss: 22.261580 GL_Loss: 0.335676 CRF_Loss: 21.925903\n",
      "[2022-02-17 19:42:02,843 - trainer - INFO] - Train Epoch:[73/100] Step:[40/250] Total Loss: 27.514271 GL_Loss: 0.482288 CRF_Loss: 27.031982\n",
      "[2022-02-17 19:42:17,021 - trainer - INFO] - Train Epoch:[73/100] Step:[50/250] Total Loss: 6.662321 GL_Loss: 0.644255 CRF_Loss: 6.018066\n",
      "[2022-02-17 19:42:35,979 - trainer - INFO] - [Step Validation] Epoch:[73/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.896341 | 0.936306 | 0.915888 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.708333 | 0.49734  | 0.584375 | 0.49734  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.681507 | 0.633758 | 0.656766 | 0.633758 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.681319 | 0.673913 | 0.677596 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.733662 | 0.633653 | 0.68     | 0.633653 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 19:42:50,070 - trainer - INFO] - Train Epoch:[73/100] Step:[60/250] Total Loss: 26.714169 GL_Loss: 0.465510 CRF_Loss: 26.248657\n",
      "[2022-02-17 19:43:04,929 - trainer - INFO] - Train Epoch:[73/100] Step:[70/250] Total Loss: 15.878598 GL_Loss: 0.700253 CRF_Loss: 15.178345\n",
      "[2022-02-17 19:43:18,901 - trainer - INFO] - Train Epoch:[73/100] Step:[80/250] Total Loss: 19.336027 GL_Loss: 0.397062 CRF_Loss: 18.938965\n",
      "[2022-02-17 19:43:33,247 - trainer - INFO] - Train Epoch:[73/100] Step:[90/250] Total Loss: 25.778442 GL_Loss: 0.448121 CRF_Loss: 25.330322\n",
      "[2022-02-17 19:43:47,076 - trainer - INFO] - Train Epoch:[73/100] Step:[100/250] Total Loss: 47.154331 GL_Loss: 0.394138 CRF_Loss: 46.760193\n",
      "[2022-02-17 19:44:05,986 - trainer - INFO] - [Step Validation] Epoch:[73/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.890244 | 0.929936 | 0.909657 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.744275 | 0.518617 | 0.611285 | 0.518617 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.686469 | 0.66242  | 0.67423  | 0.66242  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.673913 | 0.673913 | 0.673913 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.744214 | 0.650692 | 0.694318 | 0.650692 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 19:44:21,642 - trainer - INFO] - Train Epoch:[73/100] Step:[110/250] Total Loss: 14.500900 GL_Loss: 0.448410 CRF_Loss: 14.052490\n",
      "[2022-02-17 19:44:35,267 - trainer - INFO] - Train Epoch:[73/100] Step:[120/250] Total Loss: 24.209713 GL_Loss: 0.451291 CRF_Loss: 23.758423\n",
      "[2022-02-17 19:44:49,163 - trainer - INFO] - Train Epoch:[73/100] Step:[130/250] Total Loss: 23.401505 GL_Loss: 0.551529 CRF_Loss: 22.849976\n",
      "[2022-02-17 19:45:03,940 - trainer - INFO] - Train Epoch:[73/100] Step:[140/250] Total Loss: 18.466610 GL_Loss: 0.345516 CRF_Loss: 18.121094\n",
      "[2022-02-17 19:45:18,106 - trainer - INFO] - Train Epoch:[73/100] Step:[150/250] Total Loss: 9.502420 GL_Loss: 0.351786 CRF_Loss: 9.150635\n",
      "[2022-02-17 19:45:37,287 - trainer - INFO] - [Step Validation] Epoch:[73/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.889571 | 0.923567 | 0.90625  | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.735849 | 0.518617 | 0.608424 | 0.518617 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.685619 | 0.652866 | 0.668842 | 0.652866 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.695652 | 0.695652 | 0.695652 | 0.695652 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.74359  | 0.648562 | 0.692833 | 0.648562 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 19:45:51,866 - trainer - INFO] - Train Epoch:[73/100] Step:[160/250] Total Loss: 26.981932 GL_Loss: 0.615171 CRF_Loss: 26.366760\n",
      "[2022-02-17 19:46:06,499 - trainer - INFO] - Train Epoch:[73/100] Step:[170/250] Total Loss: 12.090644 GL_Loss: 0.599677 CRF_Loss: 11.490967\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 19:46:20,537 - trainer - INFO] - Train Epoch:[73/100] Step:[180/250] Total Loss: 40.420986 GL_Loss: 0.503507 CRF_Loss: 39.917480\n",
      "[2022-02-17 19:46:34,890 - trainer - INFO] - Train Epoch:[73/100] Step:[190/250] Total Loss: 13.897874 GL_Loss: 0.586778 CRF_Loss: 13.311096\n",
      "[2022-02-17 19:46:50,280 - trainer - INFO] - Train Epoch:[73/100] Step:[200/250] Total Loss: 28.434959 GL_Loss: 0.495872 CRF_Loss: 27.939087\n",
      "[2022-02-17 19:47:09,603 - trainer - INFO] - [Step Validation] Epoch:[73/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.890244 | 0.929936 | 0.909657 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.734848 | 0.515957 | 0.60625  | 0.515957 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.688963 | 0.656051 | 0.672104 | 0.656051 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.659341 | 0.652174 | 0.655738 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.740831 | 0.645367 | 0.689812 | 0.645367 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 19:47:23,811 - trainer - INFO] - Train Epoch:[73/100] Step:[210/250] Total Loss: 56.054916 GL_Loss: 0.578111 CRF_Loss: 55.476807\n",
      "[2022-02-17 19:47:37,663 - trainer - INFO] - Train Epoch:[73/100] Step:[220/250] Total Loss: 31.685822 GL_Loss: 0.326812 CRF_Loss: 31.359009\n",
      "[2022-02-17 19:47:52,062 - trainer - INFO] - Train Epoch:[73/100] Step:[230/250] Total Loss: 50.506325 GL_Loss: 0.622415 CRF_Loss: 49.883911\n",
      "[2022-02-17 19:48:06,537 - trainer - INFO] - Train Epoch:[73/100] Step:[240/250] Total Loss: 12.309299 GL_Loss: 0.356417 CRF_Loss: 11.952881\n",
      "[2022-02-17 19:48:20,515 - trainer - INFO] - Train Epoch:[73/100] Step:[250/250] Total Loss: 13.563647 GL_Loss: 0.391528 CRF_Loss: 13.172119\n",
      "[2022-02-17 19:48:39,725 - trainer - INFO] - [Step Validation] Epoch:[73/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.90184  | 0.936306 | 0.91875  | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.725191 | 0.505319 | 0.595611 | 0.505319 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.675585 | 0.643312 | 0.659054 | 0.643312 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.67033  | 0.663043 | 0.666667 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.736196 | 0.638978 | 0.684151 | 0.638978 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 19:48:58,869 - trainer - INFO] - [Epoch Validation] Epoch:[73/100] Total Loss: 40.987947 GL_Loss: 0.005032 CRF_Loss: 40.484726 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.90184  | 0.936306 | 0.91875  | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.725191 | 0.505319 | 0.595611 | 0.505319 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.675585 | 0.643312 | 0.659054 | 0.643312 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.67033  | 0.663043 | 0.666667 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.736196 | 0.638978 | 0.684151 | 0.638978 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 19:49:13,832 - trainer - INFO] - Train Epoch:[74/100] Step:[10/250] Total Loss: 8.297821 GL_Loss: 1.105866 CRF_Loss: 7.191956\n",
      "[2022-02-17 19:49:28,023 - trainer - INFO] - Train Epoch:[74/100] Step:[20/250] Total Loss: 16.568886 GL_Loss: 0.407997 CRF_Loss: 16.160889\n",
      "[2022-02-17 19:49:41,292 - trainer - INFO] - Train Epoch:[74/100] Step:[30/250] Total Loss: 16.940990 GL_Loss: 0.411206 CRF_Loss: 16.529785\n",
      "[2022-02-17 19:49:55,630 - trainer - INFO] - Train Epoch:[74/100] Step:[40/250] Total Loss: 17.796751 GL_Loss: 0.443725 CRF_Loss: 17.353027\n",
      "[2022-02-17 19:50:09,698 - trainer - INFO] - Train Epoch:[74/100] Step:[50/250] Total Loss: 15.416975 GL_Loss: 0.375471 CRF_Loss: 15.041504\n",
      "[2022-02-17 19:50:28,822 - trainer - INFO] - [Step Validation] Epoch:[74/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.907975 | 0.942675 | 0.925    | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.703422 | 0.492021 | 0.57903  | 0.492021 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.691176 | 0.598726 | 0.641638 | 0.598726 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.739848 | 0.620873 | 0.675159 | 0.620873 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 19:50:42,763 - trainer - INFO] - Train Epoch:[74/100] Step:[60/250] Total Loss: 72.523628 GL_Loss: 0.308171 CRF_Loss: 72.215454\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 19:50:56,542 - trainer - INFO] - Train Epoch:[74/100] Step:[70/250] Total Loss: 53.128368 GL_Loss: 0.421580 CRF_Loss: 52.706787\n",
      "[2022-02-17 19:51:10,768 - trainer - INFO] - Train Epoch:[74/100] Step:[80/250] Total Loss: 25.263697 GL_Loss: 0.579859 CRF_Loss: 24.683838\n",
      "[2022-02-17 19:51:26,066 - trainer - INFO] - Train Epoch:[74/100] Step:[90/250] Total Loss: 42.998909 GL_Loss: 0.527351 CRF_Loss: 42.471558\n",
      "[2022-02-17 19:51:41,025 - trainer - INFO] - Train Epoch:[74/100] Step:[100/250] Total Loss: 22.918465 GL_Loss: 0.482551 CRF_Loss: 22.435913\n",
      "[2022-02-17 19:52:01,414 - trainer - INFO] - [Step Validation] Epoch:[74/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.901235 | 0.929936 | 0.915361 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.704981 | 0.489362 | 0.577708 | 0.489362 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.685714 | 0.611465 | 0.646465 | 0.611465 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.7      | 0.684783 | 0.692308 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.737705 | 0.623003 | 0.67552  | 0.623003 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 19:52:16,025 - trainer - INFO] - Train Epoch:[74/100] Step:[110/250] Total Loss: 18.220070 GL_Loss: 0.486549 CRF_Loss: 17.733521\n",
      "[2022-02-17 19:52:30,986 - trainer - INFO] - Train Epoch:[74/100] Step:[120/250] Total Loss: 54.202393 GL_Loss: 0.652468 CRF_Loss: 53.549927\n",
      "[2022-02-17 19:52:46,520 - trainer - INFO] - Train Epoch:[74/100] Step:[130/250] Total Loss: 7.623238 GL_Loss: 0.415963 CRF_Loss: 7.207275\n",
      "[2022-02-17 19:53:02,041 - trainer - INFO] - Train Epoch:[74/100] Step:[140/250] Total Loss: 17.938215 GL_Loss: 0.737653 CRF_Loss: 17.200562\n",
      "[2022-02-17 19:53:17,125 - trainer - INFO] - Train Epoch:[74/100] Step:[150/250] Total Loss: 18.690746 GL_Loss: 0.435497 CRF_Loss: 18.255249\n",
      "[2022-02-17 19:53:36,021 - trainer - INFO] - [Step Validation] Epoch:[74/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.73384  | 0.513298 | 0.604069 | 0.513298 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.683502 | 0.646497 | 0.664484 | 0.646497 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.681319 | 0.673913 | 0.677596 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.742015 | 0.643237 | 0.689104 | 0.643237 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 19:53:49,612 - trainer - INFO] - Train Epoch:[74/100] Step:[160/250] Total Loss: 41.525017 GL_Loss: 0.757315 CRF_Loss: 40.767700\n",
      "[2022-02-17 19:54:04,593 - trainer - INFO] - Train Epoch:[74/100] Step:[170/250] Total Loss: 24.919632 GL_Loss: 0.505814 CRF_Loss: 24.413818\n",
      "[2022-02-17 19:54:19,253 - trainer - INFO] - Train Epoch:[74/100] Step:[180/250] Total Loss: 12.202393 GL_Loss: 0.448242 CRF_Loss: 11.754150\n",
      "[2022-02-17 19:54:35,632 - trainer - INFO] - Train Epoch:[74/100] Step:[190/250] Total Loss: 37.902065 GL_Loss: 0.617520 CRF_Loss: 37.284546\n",
      "[2022-02-17 19:54:51,316 - trainer - INFO] - Train Epoch:[74/100] Step:[200/250] Total Loss: 37.262783 GL_Loss: 0.482875 CRF_Loss: 36.779907\n",
      "[2022-02-17 19:55:10,376 - trainer - INFO] - [Step Validation] Epoch:[74/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.901235 | 0.929936 | 0.915361 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.723485 | 0.507979 | 0.596875 | 0.507979 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.671141 | 0.636943 | 0.653595 | 0.636943 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.666667 | 0.652174 | 0.659341 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.733415 | 0.635783 | 0.681118 | 0.635783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 19:55:24,654 - trainer - INFO] - Train Epoch:[74/100] Step:[210/250] Total Loss: 42.203659 GL_Loss: 0.524827 CRF_Loss: 41.678833\n",
      "[2022-02-17 19:55:38,311 - trainer - INFO] - Train Epoch:[74/100] Step:[220/250] Total Loss: 21.595652 GL_Loss: 0.449290 CRF_Loss: 21.146362\n",
      "[2022-02-17 19:55:52,711 - trainer - INFO] - Train Epoch:[74/100] Step:[230/250] Total Loss: 161.346542 GL_Loss: 0.647445 CRF_Loss: 160.699097\n",
      "[2022-02-17 19:56:06,712 - trainer - INFO] - Train Epoch:[74/100] Step:[240/250] Total Loss: 13.622178 GL_Loss: 0.480332 CRF_Loss: 13.141846\n",
      "[2022-02-17 19:56:19,602 - trainer - INFO] - Train Epoch:[74/100] Step:[250/250] Total Loss: 53.993401 GL_Loss: 0.511346 CRF_Loss: 53.482056\n",
      "[2022-02-17 19:56:38,818 - trainer - INFO] - [Step Validation] Epoch:[74/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.730038 | 0.510638 | 0.600939 | 0.510638 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.677632 | 0.656051 | 0.666667 | 0.656051 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.7      | 0.684783 | 0.692308 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.740244 | 0.646432 | 0.690165 | 0.646432 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 19:56:57,917 - trainer - INFO] - [Epoch Validation] Epoch:[74/100] Total Loss: 41.303210 GL_Loss: 0.005053 CRF_Loss: 40.797954 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.730038 | 0.510638 | 0.600939 | 0.510638 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.677632 | 0.656051 | 0.666667 | 0.656051 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.7      | 0.684783 | 0.692308 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.740244 | 0.646432 | 0.690165 | 0.646432 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 19:57:13,608 - trainer - INFO] - Train Epoch:[75/100] Step:[10/250] Total Loss: 48.029053 GL_Loss: 0.432007 CRF_Loss: 47.597046\n",
      "[2022-02-17 19:57:27,694 - trainer - INFO] - Train Epoch:[75/100] Step:[20/250] Total Loss: 12.398033 GL_Loss: 0.573082 CRF_Loss: 11.824951\n",
      "[2022-02-17 19:57:42,448 - trainer - INFO] - Train Epoch:[75/100] Step:[30/250] Total Loss: 82.603554 GL_Loss: 0.382121 CRF_Loss: 82.221436\n",
      "[2022-02-17 19:57:56,111 - trainer - INFO] - Train Epoch:[75/100] Step:[40/250] Total Loss: 41.608398 GL_Loss: 0.507081 CRF_Loss: 41.101318\n",
      "[2022-02-17 19:58:10,266 - trainer - INFO] - Train Epoch:[75/100] Step:[50/250] Total Loss: 40.056385 GL_Loss: 0.423940 CRF_Loss: 39.632446\n",
      "[2022-02-17 19:58:29,336 - trainer - INFO] - [Step Validation] Epoch:[75/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.723485 | 0.507979 | 0.596875 | 0.507979 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.683502 | 0.646497 | 0.664484 | 0.646497 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.677778 | 0.663043 | 0.67033  | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.738329 | 0.640043 | 0.685682 | 0.640043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 19:58:42,932 - trainer - INFO] - Train Epoch:[75/100] Step:[60/250] Total Loss: 50.138424 GL_Loss: 0.441889 CRF_Loss: 49.696533\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 19:58:55,781 - trainer - INFO] - Train Epoch:[75/100] Step:[70/250] Total Loss: 87.546944 GL_Loss: 0.406200 CRF_Loss: 87.140747\n",
      "[2022-02-17 19:59:10,537 - trainer - INFO] - Train Epoch:[75/100] Step:[80/250] Total Loss: 34.616955 GL_Loss: 0.459485 CRF_Loss: 34.157471\n",
      "[2022-02-17 19:59:25,156 - trainer - INFO] - Train Epoch:[75/100] Step:[90/250] Total Loss: 23.011940 GL_Loss: 0.848732 CRF_Loss: 22.163208\n",
      "[2022-02-17 19:59:39,514 - trainer - INFO] - Train Epoch:[75/100] Step:[100/250] Total Loss: 59.093704 GL_Loss: 0.399980 CRF_Loss: 58.693726\n",
      "[2022-02-17 19:59:58,646 - trainer - INFO] - [Step Validation] Epoch:[75/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.890244 | 0.929936 | 0.909657 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.727273 | 0.510638 | 0.6      | 0.510638 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.694915 | 0.652866 | 0.673235 | 0.652866 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.684783 | 0.684783 | 0.684783 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.743558 | 0.645367 | 0.690992 | 0.645367 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 20:00:12,741 - trainer - INFO] - Train Epoch:[75/100] Step:[110/250] Total Loss: 10.643888 GL_Loss: 0.343962 CRF_Loss: 10.299927\n",
      "[2022-02-17 20:00:26,648 - trainer - INFO] - Train Epoch:[75/100] Step:[120/250] Total Loss: 24.225702 GL_Loss: 0.472163 CRF_Loss: 23.753540\n",
      "[2022-02-17 20:00:40,844 - trainer - INFO] - Train Epoch:[75/100] Step:[130/250] Total Loss: 18.220457 GL_Loss: 0.604735 CRF_Loss: 17.615723\n",
      "[2022-02-17 20:00:55,605 - trainer - INFO] - Train Epoch:[75/100] Step:[140/250] Total Loss: 17.771620 GL_Loss: 0.502333 CRF_Loss: 17.269287\n",
      "[2022-02-17 20:01:10,443 - trainer - INFO] - Train Epoch:[75/100] Step:[150/250] Total Loss: 65.999916 GL_Loss: 0.568886 CRF_Loss: 65.431030\n",
      "[2022-02-17 20:01:29,461 - trainer - INFO] - [Step Validation] Epoch:[75/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.91358  | 0.942675 | 0.9279   | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.704545 | 0.494681 | 0.58125  | 0.494681 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.676871 | 0.633758 | 0.654605 | 0.633758 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.677778 | 0.663043 | 0.67033  | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.733333 | 0.632588 | 0.679245 | 0.632588 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 20:01:43,581 - trainer - INFO] - Train Epoch:[75/100] Step:[160/250] Total Loss: 15.070739 GL_Loss: 0.592833 CRF_Loss: 14.477905\n",
      "[2022-02-17 20:01:57,944 - trainer - INFO] - Train Epoch:[75/100] Step:[170/250] Total Loss: 78.976990 GL_Loss: 0.576840 CRF_Loss: 78.400146\n",
      "[2022-02-17 20:02:11,644 - trainer - INFO] - Train Epoch:[75/100] Step:[180/250] Total Loss: 13.166802 GL_Loss: 0.628229 CRF_Loss: 12.538574\n",
      "[2022-02-17 20:02:25,400 - trainer - INFO] - Train Epoch:[75/100] Step:[190/250] Total Loss: 33.920784 GL_Loss: 0.352304 CRF_Loss: 33.568481\n",
      "[2022-02-17 20:02:39,375 - trainer - INFO] - Train Epoch:[75/100] Step:[200/250] Total Loss: 25.379658 GL_Loss: 0.754780 CRF_Loss: 24.624878\n",
      "[2022-02-17 20:02:58,273 - trainer - INFO] - [Step Validation] Epoch:[75/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.901235 | 0.929936 | 0.915361 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.736842 | 0.521277 | 0.610592 | 0.521277 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.666667 | 0.656051 | 0.661316 | 0.656051 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.681319 | 0.673913 | 0.677596 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.736715 | 0.649627 | 0.690436 | 0.649627 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 20:03:13,162 - trainer - INFO] - Train Epoch:[75/100] Step:[210/250] Total Loss: 26.595152 GL_Loss: 0.482969 CRF_Loss: 26.112183\n",
      "[2022-02-17 20:03:27,317 - trainer - INFO] - Train Epoch:[75/100] Step:[220/250] Total Loss: 19.230495 GL_Loss: 0.503078 CRF_Loss: 18.727417\n",
      "[2022-02-17 20:03:41,994 - trainer - INFO] - Train Epoch:[75/100] Step:[230/250] Total Loss: 25.872652 GL_Loss: 0.521333 CRF_Loss: 25.351318\n",
      "[2022-02-17 20:03:56,555 - trainer - INFO] - Train Epoch:[75/100] Step:[240/250] Total Loss: 17.655125 GL_Loss: 0.409397 CRF_Loss: 17.245728\n",
      "[2022-02-17 20:04:11,147 - trainer - INFO] - Train Epoch:[75/100] Step:[250/250] Total Loss: 12.640619 GL_Loss: 0.529536 CRF_Loss: 12.111084\n",
      "[2022-02-17 20:04:30,351 - trainer - INFO] - [Step Validation] Epoch:[75/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.729008 | 0.507979 | 0.598746 | 0.507979 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.68543  | 0.659236 | 0.672078 | 0.659236 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.659341 | 0.652174 | 0.655738 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.738386 | 0.643237 | 0.687536 | 0.643237 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 20:04:49,632 - trainer - INFO] - [Epoch Validation] Epoch:[75/100] Total Loss: 41.000206 GL_Loss: 0.005136 CRF_Loss: 40.486615 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.729008 | 0.507979 | 0.598746 | 0.507979 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.68543  | 0.659236 | 0.672078 | 0.659236 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.659341 | 0.652174 | 0.655738 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.738386 | 0.643237 | 0.687536 | 0.643237 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 20:05:04,749 - trainer - INFO] - Train Epoch:[76/100] Step:[10/250] Total Loss: 19.137529 GL_Loss: 0.628619 CRF_Loss: 18.508911\n",
      "[2022-02-17 20:05:19,246 - trainer - INFO] - Train Epoch:[76/100] Step:[20/250] Total Loss: 10.385988 GL_Loss: 0.460451 CRF_Loss: 9.925537\n",
      "[2022-02-17 20:05:33,171 - trainer - INFO] - Train Epoch:[76/100] Step:[30/250] Total Loss: 19.116764 GL_Loss: 0.639836 CRF_Loss: 18.476929\n",
      "[2022-02-17 20:05:46,564 - trainer - INFO] - Train Epoch:[76/100] Step:[40/250] Total Loss: 28.421530 GL_Loss: 0.375998 CRF_Loss: 28.045532\n",
      "[2022-02-17 20:06:00,521 - trainer - INFO] - Train Epoch:[76/100] Step:[50/250] Total Loss: 17.288631 GL_Loss: 0.623227 CRF_Loss: 16.665405\n",
      "[2022-02-17 20:06:19,449 - trainer - INFO] - [Step Validation] Epoch:[76/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.896341 | 0.936306 | 0.915888 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.717557 | 0.5      | 0.589342 | 0.5      |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.686411 | 0.627389 | 0.655574 | 0.627389 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.7      | 0.684783 | 0.692308 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.740971 | 0.633653 | 0.683123 | 0.633653 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 20:06:35,481 - trainer - INFO] - Train Epoch:[76/100] Step:[60/250] Total Loss: 21.460163 GL_Loss: 0.433797 CRF_Loss: 21.026367\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 20:06:50,226 - trainer - INFO] - Train Epoch:[76/100] Step:[70/250] Total Loss: 25.454756 GL_Loss: 0.366072 CRF_Loss: 25.088684\n",
      "[2022-02-17 20:07:04,783 - trainer - INFO] - Train Epoch:[76/100] Step:[80/250] Total Loss: 41.021152 GL_Loss: 0.439121 CRF_Loss: 40.582031\n",
      "[2022-02-17 20:07:19,815 - trainer - INFO] - Train Epoch:[76/100] Step:[90/250] Total Loss: 49.974365 GL_Loss: 0.583375 CRF_Loss: 49.390991\n",
      "[2022-02-17 20:07:34,449 - trainer - INFO] - Train Epoch:[76/100] Step:[100/250] Total Loss: 57.725521 GL_Loss: 0.597225 CRF_Loss: 57.128296\n",
      "[2022-02-17 20:07:53,606 - trainer - INFO] - [Step Validation] Epoch:[76/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.90184  | 0.936306 | 0.91875  | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.719697 | 0.505319 | 0.59375  | 0.505319 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.674576 | 0.633758 | 0.65353  | 0.633758 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.7      | 0.684783 | 0.692308 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.737685 | 0.637913 | 0.68418  | 0.637913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 20:08:07,015 - trainer - INFO] - Train Epoch:[76/100] Step:[110/250] Total Loss: 49.800060 GL_Loss: 0.497571 CRF_Loss: 49.302490\n",
      "[2022-02-17 20:08:20,741 - trainer - INFO] - Train Epoch:[76/100] Step:[120/250] Total Loss: 19.684706 GL_Loss: 0.382765 CRF_Loss: 19.301941\n",
      "[2022-02-17 20:08:35,330 - trainer - INFO] - Train Epoch:[76/100] Step:[130/250] Total Loss: 18.431776 GL_Loss: 0.431776 CRF_Loss: 18.000000\n",
      "[2022-02-17 20:08:50,178 - trainer - INFO] - Train Epoch:[76/100] Step:[140/250] Total Loss: 18.972754 GL_Loss: 0.507911 CRF_Loss: 18.464844\n",
      "[2022-02-17 20:09:04,122 - trainer - INFO] - Train Epoch:[76/100] Step:[150/250] Total Loss: 21.946766 GL_Loss: 0.435535 CRF_Loss: 21.511230\n",
      "[2022-02-17 20:09:23,335 - trainer - INFO] - [Step Validation] Epoch:[76/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.90184  | 0.936306 | 0.91875  | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.743396 | 0.523936 | 0.614665 | 0.523936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.679054 | 0.640127 | 0.659016 | 0.640127 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.684783 | 0.684783 | 0.684783 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.745098 | 0.647497 | 0.692877 | 0.647497 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 20:09:36,971 - trainer - INFO] - Train Epoch:[76/100] Step:[160/250] Total Loss: 30.090034 GL_Loss: 0.393746 CRF_Loss: 29.696289\n",
      "[2022-02-17 20:09:50,893 - trainer - INFO] - Train Epoch:[76/100] Step:[170/250] Total Loss: 48.269089 GL_Loss: 0.431321 CRF_Loss: 47.837769\n",
      "[2022-02-17 20:10:06,050 - trainer - INFO] - Train Epoch:[76/100] Step:[180/250] Total Loss: 25.614752 GL_Loss: 0.349126 CRF_Loss: 25.265625\n",
      "[2022-02-17 20:10:20,539 - trainer - INFO] - Train Epoch:[76/100] Step:[190/250] Total Loss: 36.167679 GL_Loss: 0.443434 CRF_Loss: 35.724243\n",
      "[2022-02-17 20:10:34,905 - trainer - INFO] - Train Epoch:[76/100] Step:[200/250] Total Loss: 26.879248 GL_Loss: 0.372045 CRF_Loss: 26.507202\n",
      "[2022-02-17 20:10:53,951 - trainer - INFO] - [Step Validation] Epoch:[76/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.907975 | 0.942675 | 0.925    | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.730038 | 0.510638 | 0.600939 | 0.510638 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.67931  | 0.627389 | 0.652318 | 0.627389 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.677778 | 0.663043 | 0.67033  | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.741935 | 0.636848 | 0.685387 | 0.636848 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 20:11:07,323 - trainer - INFO] - Train Epoch:[76/100] Step:[210/250] Total Loss: 13.596998 GL_Loss: 0.296095 CRF_Loss: 13.300903\n",
      "[2022-02-17 20:11:21,674 - trainer - INFO] - Train Epoch:[76/100] Step:[220/250] Total Loss: 8.700679 GL_Loss: 0.496822 CRF_Loss: 8.203857\n",
      "[2022-02-17 20:11:34,952 - trainer - INFO] - Train Epoch:[76/100] Step:[230/250] Total Loss: 73.157845 GL_Loss: 0.483409 CRF_Loss: 72.674438\n",
      "[2022-02-17 20:11:49,470 - trainer - INFO] - Train Epoch:[76/100] Step:[240/250] Total Loss: 42.310444 GL_Loss: 0.326681 CRF_Loss: 41.983765\n",
      "[2022-02-17 20:12:04,713 - trainer - INFO] - Train Epoch:[76/100] Step:[250/250] Total Loss: 23.487074 GL_Loss: 0.414076 CRF_Loss: 23.072998\n",
      "[2022-02-17 20:12:23,784 - trainer - INFO] - [Step Validation] Epoch:[76/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895062 | 0.923567 | 0.909091 | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.734082 | 0.521277 | 0.609642 | 0.521277 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.676568 | 0.652866 | 0.664506 | 0.652866 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.67033  | 0.663043 | 0.666667 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.737546 | 0.646432 | 0.68899  | 0.646432 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 20:12:42,870 - trainer - INFO] - [Epoch Validation] Epoch:[76/100] Total Loss: 40.331032 GL_Loss: 0.005153 CRF_Loss: 39.815738 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895062 | 0.923567 | 0.909091 | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.734082 | 0.521277 | 0.609642 | 0.521277 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.676568 | 0.652866 | 0.664506 | 0.652866 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.67033  | 0.663043 | 0.666667 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.737546 | 0.646432 | 0.68899  | 0.646432 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 20:12:58,570 - trainer - INFO] - Train Epoch:[77/100] Step:[10/250] Total Loss: 38.011448 GL_Loss: 0.469821 CRF_Loss: 37.541626\n",
      "[2022-02-17 20:13:12,819 - trainer - INFO] - Train Epoch:[77/100] Step:[20/250] Total Loss: 9.732959 GL_Loss: 0.413256 CRF_Loss: 9.319702\n",
      "[2022-02-17 20:13:26,439 - trainer - INFO] - Train Epoch:[77/100] Step:[30/250] Total Loss: 47.295841 GL_Loss: 0.260319 CRF_Loss: 47.035522\n",
      "[2022-02-17 20:13:40,522 - trainer - INFO] - Train Epoch:[77/100] Step:[40/250] Total Loss: 31.295101 GL_Loss: 0.620907 CRF_Loss: 30.674194\n",
      "[2022-02-17 20:13:56,071 - trainer - INFO] - Train Epoch:[77/100] Step:[50/250] Total Loss: 46.549454 GL_Loss: 0.456435 CRF_Loss: 46.093018\n",
      "[2022-02-17 20:14:15,325 - trainer - INFO] - [Step Validation] Epoch:[77/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.728302 | 0.513298 | 0.602184 | 0.513298 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.678571 | 0.665605 | 0.672026 | 0.665605 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.659341 | 0.652174 | 0.655738 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.735187 | 0.647497 | 0.688562 | 0.647497 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 20:14:29,151 - trainer - INFO] - Train Epoch:[77/100] Step:[60/250] Total Loss: 24.351950 GL_Loss: 0.366354 CRF_Loss: 23.985596\n",
      "[2022-02-17 20:14:41,754 - trainer - INFO] - Train Epoch:[77/100] Step:[70/250] Total Loss: 26.449034 GL_Loss: 0.420835 CRF_Loss: 26.028198\n",
      "[2022-02-17 20:14:55,933 - trainer - INFO] - Train Epoch:[77/100] Step:[80/250] Total Loss: 9.898101 GL_Loss: 0.668608 CRF_Loss: 9.229492\n",
      "[2022-02-17 20:15:09,695 - trainer - INFO] - Train Epoch:[77/100] Step:[90/250] Total Loss: 76.546875 GL_Loss: 0.417847 CRF_Loss: 76.129028\n",
      "[2022-02-17 20:15:23,204 - trainer - INFO] - Train Epoch:[77/100] Step:[100/250] Total Loss: 29.849669 GL_Loss: 0.385924 CRF_Loss: 29.463745\n",
      "[2022-02-17 20:15:43,681 - trainer - INFO] - [Step Validation] Epoch:[77/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.902439 | 0.942675 | 0.922118 | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.734848 | 0.515957 | 0.60625  | 0.515957 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.675676 | 0.636943 | 0.655738 | 0.636943 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.742015 | 0.643237 | 0.689104 | 0.643237 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 20:15:57,905 - trainer - INFO] - Train Epoch:[77/100] Step:[110/250] Total Loss: 33.605377 GL_Loss: 0.817170 CRF_Loss: 32.788208\n",
      "[2022-02-17 20:16:13,197 - trainer - INFO] - Train Epoch:[77/100] Step:[120/250] Total Loss: 15.249660 GL_Loss: 0.599269 CRF_Loss: 14.650391\n",
      "[2022-02-17 20:16:28,148 - trainer - INFO] - Train Epoch:[77/100] Step:[130/250] Total Loss: 33.148094 GL_Loss: 0.450096 CRF_Loss: 32.697998\n",
      "[2022-02-17 20:16:44,062 - trainer - INFO] - Train Epoch:[77/100] Step:[140/250] Total Loss: 10.521777 GL_Loss: 0.259815 CRF_Loss: 10.261963\n",
      "[2022-02-17 20:16:58,346 - trainer - INFO] - Train Epoch:[77/100] Step:[150/250] Total Loss: 10.485852 GL_Loss: 0.339123 CRF_Loss: 10.146729\n",
      "[2022-02-17 20:17:17,585 - trainer - INFO] - [Step Validation] Epoch:[77/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.907975 | 0.942675 | 0.925    | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.714829 | 0.5      | 0.588419 | 0.5      |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.676667 | 0.646497 | 0.661238 | 0.646497 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.677778 | 0.663043 | 0.67033  | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.735294 | 0.638978 | 0.683761 | 0.638978 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 20:17:32,519 - trainer - INFO] - Train Epoch:[77/100] Step:[160/250] Total Loss: 16.507807 GL_Loss: 0.350825 CRF_Loss: 16.156982\n",
      "[2022-02-17 20:17:47,092 - trainer - INFO] - Train Epoch:[77/100] Step:[170/250] Total Loss: 34.526222 GL_Loss: 0.390723 CRF_Loss: 34.135498\n",
      "[2022-02-17 20:18:01,967 - trainer - INFO] - Train Epoch:[77/100] Step:[180/250] Total Loss: 20.656656 GL_Loss: 0.412882 CRF_Loss: 20.243774\n",
      "[2022-02-17 20:18:16,601 - trainer - INFO] - Train Epoch:[77/100] Step:[190/250] Total Loss: 27.321722 GL_Loss: 0.522894 CRF_Loss: 26.798828\n",
      "[2022-02-17 20:18:31,054 - trainer - INFO] - Train Epoch:[77/100] Step:[200/250] Total Loss: 40.148323 GL_Loss: 0.376594 CRF_Loss: 39.771729\n",
      "[2022-02-17 20:18:49,927 - trainer - INFO] - [Step Validation] Epoch:[77/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.890244 | 0.929936 | 0.909657 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.742424 | 0.521277 | 0.6125   | 0.521277 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.687919 | 0.652866 | 0.669935 | 0.652866 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.746324 | 0.648562 | 0.694017 | 0.648562 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 20:19:04,411 - trainer - INFO] - Train Epoch:[77/100] Step:[210/250] Total Loss: 18.885897 GL_Loss: 0.453523 CRF_Loss: 18.432373\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 20:19:17,910 - trainer - INFO] - Train Epoch:[77/100] Step:[220/250] Total Loss: 109.329659 GL_Loss: 0.471993 CRF_Loss: 108.857666\n",
      "[2022-02-17 20:19:32,631 - trainer - INFO] - Train Epoch:[77/100] Step:[230/250] Total Loss: 11.151278 GL_Loss: 0.412143 CRF_Loss: 10.739136\n",
      "[2022-02-17 20:19:46,761 - trainer - INFO] - Train Epoch:[77/100] Step:[240/250] Total Loss: 12.461944 GL_Loss: 0.617583 CRF_Loss: 11.844360\n",
      "[2022-02-17 20:20:01,126 - trainer - INFO] - Train Epoch:[77/100] Step:[250/250] Total Loss: 25.674862 GL_Loss: 0.738826 CRF_Loss: 24.936035\n",
      "[2022-02-17 20:20:20,093 - trainer - INFO] - [Step Validation] Epoch:[77/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.734848 | 0.515957 | 0.60625  | 0.515957 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.683168 | 0.659236 | 0.670989 | 0.659236 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.659341 | 0.652174 | 0.655738 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.739342 | 0.646432 | 0.689773 | 0.646432 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 20:20:39,065 - trainer - INFO] - [Epoch Validation] Epoch:[77/100] Total Loss: 40.927816 GL_Loss: 0.005023 CRF_Loss: 40.425502 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.734848 | 0.515957 | 0.60625  | 0.515957 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.683168 | 0.659236 | 0.670989 | 0.659236 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.659341 | 0.652174 | 0.655738 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.739342 | 0.646432 | 0.689773 | 0.646432 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 20:20:52,894 - trainer - INFO] - Train Epoch:[78/100] Step:[10/250] Total Loss: 32.515865 GL_Loss: 0.906734 CRF_Loss: 31.609131\n",
      "[2022-02-17 20:21:07,392 - trainer - INFO] - Train Epoch:[78/100] Step:[20/250] Total Loss: 25.481192 GL_Loss: 0.839346 CRF_Loss: 24.641846\n",
      "[2022-02-17 20:21:21,693 - trainer - INFO] - Train Epoch:[78/100] Step:[30/250] Total Loss: 19.605587 GL_Loss: 0.531734 CRF_Loss: 19.073853\n",
      "[2022-02-17 20:21:35,213 - trainer - INFO] - Train Epoch:[78/100] Step:[40/250] Total Loss: 13.806169 GL_Loss: 0.546159 CRF_Loss: 13.260010\n",
      "[2022-02-17 20:21:48,899 - trainer - INFO] - Train Epoch:[78/100] Step:[50/250] Total Loss: 27.453575 GL_Loss: 0.471031 CRF_Loss: 26.982544\n",
      "[2022-02-17 20:22:08,507 - trainer - INFO] - [Step Validation] Epoch:[78/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.736641 | 0.513298 | 0.605016 | 0.513298 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.677741 | 0.649682 | 0.663415 | 0.649682 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.666667 | 0.652174 | 0.659341 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.738971 | 0.642173 | 0.687179 | 0.642173 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 20:22:22,879 - trainer - INFO] - Train Epoch:[78/100] Step:[60/250] Total Loss: 5.239645 GL_Loss: 0.537008 CRF_Loss: 4.702637\n",
      "[2022-02-17 20:22:37,405 - trainer - INFO] - Train Epoch:[78/100] Step:[70/250] Total Loss: 19.358618 GL_Loss: 0.517309 CRF_Loss: 18.841309\n",
      "[2022-02-17 20:22:50,946 - trainer - INFO] - Train Epoch:[78/100] Step:[80/250] Total Loss: 27.877325 GL_Loss: 0.433965 CRF_Loss: 27.443359\n",
      "[2022-02-17 20:23:05,531 - trainer - INFO] - Train Epoch:[78/100] Step:[90/250] Total Loss: 101.943672 GL_Loss: 0.322826 CRF_Loss: 101.620850\n",
      "[2022-02-17 20:23:20,475 - trainer - INFO] - Train Epoch:[78/100] Step:[100/250] Total Loss: 53.479237 GL_Loss: 0.488391 CRF_Loss: 52.990845\n",
      "[2022-02-17 20:23:39,723 - trainer - INFO] - [Step Validation] Epoch:[78/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.884848 | 0.929936 | 0.906832 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.741445 | 0.518617 | 0.610329 | 0.518617 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.672078 | 0.659236 | 0.665595 | 0.659236 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.677778 | 0.663043 | 0.67033  | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.737288 | 0.648562 | 0.690085 | 0.648562 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 20:23:53,789 - trainer - INFO] - Train Epoch:[78/100] Step:[110/250] Total Loss: 41.381905 GL_Loss: 0.416330 CRF_Loss: 40.965576\n",
      "[2022-02-17 20:24:07,813 - trainer - INFO] - Train Epoch:[78/100] Step:[120/250] Total Loss: 15.087239 GL_Loss: 0.664753 CRF_Loss: 14.422485\n",
      "[2022-02-17 20:24:23,317 - trainer - INFO] - Train Epoch:[78/100] Step:[130/250] Total Loss: 28.261789 GL_Loss: 0.511179 CRF_Loss: 27.750610\n",
      "[2022-02-17 20:24:38,059 - trainer - INFO] - Train Epoch:[78/100] Step:[140/250] Total Loss: 73.419853 GL_Loss: 0.360162 CRF_Loss: 73.059692\n",
      "[2022-02-17 20:24:52,720 - trainer - INFO] - Train Epoch:[78/100] Step:[150/250] Total Loss: 57.492634 GL_Loss: 0.333821 CRF_Loss: 57.158813\n",
      "[2022-02-17 20:25:11,787 - trainer - INFO] - [Step Validation] Epoch:[78/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.884146 | 0.923567 | 0.903427 | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.69697  | 0.489362 | 0.575    | 0.489362 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.681507 | 0.633758 | 0.656766 | 0.633758 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.681319 | 0.673913 | 0.677596 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.727497 | 0.628328 | 0.674286 | 0.628328 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 20:25:25,095 - trainer - INFO] - Train Epoch:[78/100] Step:[160/250] Total Loss: 26.167940 GL_Loss: 0.414156 CRF_Loss: 25.753784\n",
      "[2022-02-17 20:25:39,367 - trainer - INFO] - Train Epoch:[78/100] Step:[170/250] Total Loss: 22.114317 GL_Loss: 0.909482 CRF_Loss: 21.204834\n",
      "[2022-02-17 20:25:53,231 - trainer - INFO] - Train Epoch:[78/100] Step:[180/250] Total Loss: 20.953550 GL_Loss: 0.531186 CRF_Loss: 20.422363\n",
      "[2022-02-17 20:26:07,533 - trainer - INFO] - Train Epoch:[78/100] Step:[190/250] Total Loss: 21.168869 GL_Loss: 0.540572 CRF_Loss: 20.628296\n",
      "[2022-02-17 20:26:20,594 - trainer - INFO] - Train Epoch:[78/100] Step:[200/250] Total Loss: 36.176723 GL_Loss: 0.653165 CRF_Loss: 35.523560\n",
      "[2022-02-17 20:26:39,641 - trainer - INFO] - [Step Validation] Epoch:[78/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.896341 | 0.936306 | 0.915888 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.718631 | 0.50266  | 0.591549 | 0.50266  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.688356 | 0.640127 | 0.663366 | 0.640127 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.74042  | 0.637913 | 0.685355 | 0.637913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 20:26:54,358 - trainer - INFO] - Train Epoch:[78/100] Step:[210/250] Total Loss: 16.367184 GL_Loss: 0.513790 CRF_Loss: 15.853394\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 20:27:08,317 - trainer - INFO] - Train Epoch:[78/100] Step:[220/250] Total Loss: 25.017473 GL_Loss: 0.390521 CRF_Loss: 24.626953\n",
      "[2022-02-17 20:27:23,580 - trainer - INFO] - Train Epoch:[78/100] Step:[230/250] Total Loss: 324.017090 GL_Loss: 0.390383 CRF_Loss: 323.626709\n",
      "[2022-02-17 20:27:38,161 - trainer - INFO] - Train Epoch:[78/100] Step:[240/250] Total Loss: 26.569738 GL_Loss: 0.461340 CRF_Loss: 26.108398\n",
      "[2022-02-17 20:27:52,113 - trainer - INFO] - Train Epoch:[78/100] Step:[250/250] Total Loss: 20.881737 GL_Loss: 0.360985 CRF_Loss: 20.520752\n",
      "[2022-02-17 20:28:11,086 - trainer - INFO] - [Step Validation] Epoch:[78/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.90184  | 0.936306 | 0.91875  | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.732075 | 0.515957 | 0.605304 | 0.515957 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.673267 | 0.649682 | 0.661264 | 0.649682 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.659341 | 0.652174 | 0.655738 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.73601  | 0.644302 | 0.68711  | 0.644302 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 20:28:30,184 - trainer - INFO] - [Epoch Validation] Epoch:[78/100] Total Loss: 40.755248 GL_Loss: 0.005064 CRF_Loss: 40.248888 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.90184  | 0.936306 | 0.91875  | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.732075 | 0.515957 | 0.605304 | 0.515957 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.673267 | 0.649682 | 0.661264 | 0.649682 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.659341 | 0.652174 | 0.655738 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.73601  | 0.644302 | 0.68711  | 0.644302 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 20:28:45,868 - trainer - INFO] - Train Epoch:[79/100] Step:[10/250] Total Loss: 16.740318 GL_Loss: 0.531577 CRF_Loss: 16.208740\n",
      "[2022-02-17 20:29:01,402 - trainer - INFO] - Train Epoch:[79/100] Step:[20/250] Total Loss: 35.385727 GL_Loss: 0.453719 CRF_Loss: 34.932007\n",
      "[2022-02-17 20:29:16,242 - trainer - INFO] - Train Epoch:[79/100] Step:[30/250] Total Loss: 36.613510 GL_Loss: 0.492784 CRF_Loss: 36.120728\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 20:29:32,222 - trainer - INFO] - Train Epoch:[79/100] Step:[40/250] Total Loss: 35.317745 GL_Loss: 0.548947 CRF_Loss: 34.768799\n",
      "[2022-02-17 20:29:46,703 - trainer - INFO] - Train Epoch:[79/100] Step:[50/250] Total Loss: 15.546786 GL_Loss: 0.264804 CRF_Loss: 15.281982\n",
      "[2022-02-17 20:30:05,697 - trainer - INFO] - [Step Validation] Epoch:[79/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.730627 | 0.526596 | 0.612056 | 0.526596 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.666667 | 0.649682 | 0.658065 | 0.649682 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.659341 | 0.652174 | 0.655738 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.731649 | 0.647497 | 0.687006 | 0.647497 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 20:30:20,800 - trainer - INFO] - Train Epoch:[79/100] Step:[60/250] Total Loss: 20.560926 GL_Loss: 0.520521 CRF_Loss: 20.040405\n",
      "[2022-02-17 20:30:34,887 - trainer - INFO] - Train Epoch:[79/100] Step:[70/250] Total Loss: 46.227615 GL_Loss: 0.468581 CRF_Loss: 45.759033\n",
      "[2022-02-17 20:30:50,296 - trainer - INFO] - Train Epoch:[79/100] Step:[80/250] Total Loss: 18.472874 GL_Loss: 0.421970 CRF_Loss: 18.050903\n",
      "[2022-02-17 20:31:04,736 - trainer - INFO] - Train Epoch:[79/100] Step:[90/250] Total Loss: 29.708851 GL_Loss: 0.728381 CRF_Loss: 28.980469\n",
      "[2022-02-17 20:31:18,376 - trainer - INFO] - Train Epoch:[79/100] Step:[100/250] Total Loss: 54.809395 GL_Loss: 0.428656 CRF_Loss: 54.380737\n",
      "[2022-02-17 20:31:37,468 - trainer - INFO] - [Step Validation] Epoch:[79/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.91358  | 0.942675 | 0.9279   | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.711538 | 0.492021 | 0.581761 | 0.492021 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.677966 | 0.636943 | 0.656814 | 0.636943 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.67033  | 0.663043 | 0.666667 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.735149 | 0.632588 | 0.680023 | 0.632588 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 20:31:52,897 - trainer - INFO] - Train Epoch:[79/100] Step:[110/250] Total Loss: 7.201032 GL_Loss: 0.473737 CRF_Loss: 6.727295\n",
      "[2022-02-17 20:32:06,724 - trainer - INFO] - Train Epoch:[79/100] Step:[120/250] Total Loss: 34.522507 GL_Loss: 0.367354 CRF_Loss: 34.155151\n",
      "[2022-02-17 20:32:21,043 - trainer - INFO] - Train Epoch:[79/100] Step:[130/250] Total Loss: 9.683569 GL_Loss: 0.442724 CRF_Loss: 9.240845\n",
      "[2022-02-17 20:32:34,986 - trainer - INFO] - Train Epoch:[79/100] Step:[140/250] Total Loss: 22.751268 GL_Loss: 0.472461 CRF_Loss: 22.278809\n",
      "[2022-02-17 20:32:48,903 - trainer - INFO] - Train Epoch:[79/100] Step:[150/250] Total Loss: 12.080956 GL_Loss: 0.416527 CRF_Loss: 11.664429\n",
      "[2022-02-17 20:33:08,103 - trainer - INFO] - [Step Validation] Epoch:[79/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.90184  | 0.936306 | 0.91875  | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.734848 | 0.515957 | 0.60625  | 0.515957 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.675497 | 0.649682 | 0.662338 | 0.649682 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.659341 | 0.652174 | 0.655738 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.737805 | 0.644302 | 0.687891 | 0.644302 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 20:33:22,216 - trainer - INFO] - Train Epoch:[79/100] Step:[160/250] Total Loss: 68.378052 GL_Loss: 0.433596 CRF_Loss: 67.944458\n",
      "[2022-02-17 20:33:35,652 - trainer - INFO] - Train Epoch:[79/100] Step:[170/250] Total Loss: 78.975639 GL_Loss: 0.377370 CRF_Loss: 78.598267\n",
      "[2022-02-17 20:33:50,806 - trainer - INFO] - Train Epoch:[79/100] Step:[180/250] Total Loss: 32.931923 GL_Loss: 0.498451 CRF_Loss: 32.433472\n",
      "[2022-02-17 20:34:03,884 - trainer - INFO] - Train Epoch:[79/100] Step:[190/250] Total Loss: 13.272275 GL_Loss: 0.432187 CRF_Loss: 12.840088\n",
      "[2022-02-17 20:34:18,275 - trainer - INFO] - Train Epoch:[79/100] Step:[200/250] Total Loss: 19.129810 GL_Loss: 0.499073 CRF_Loss: 18.630737\n",
      "[2022-02-17 20:34:37,521 - trainer - INFO] - [Step Validation] Epoch:[79/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.890244 | 0.929936 | 0.909657 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.731343 | 0.521277 | 0.608696 | 0.521277 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.695652 | 0.66242  | 0.67863  | 0.66242  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688172 | 0.695652 | 0.691892 | 0.695652 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.745146 | 0.653887 | 0.69654  | 0.653887 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 20:34:39,712 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 20:34:54,773 - trainer - INFO] - Train Epoch:[79/100] Step:[210/250] Total Loss: 23.117710 GL_Loss: 0.419591 CRF_Loss: 22.698120\n",
      "[2022-02-17 20:35:09,549 - trainer - INFO] - Train Epoch:[79/100] Step:[220/250] Total Loss: 9.377482 GL_Loss: 0.607951 CRF_Loss: 8.769531\n",
      "[2022-02-17 20:35:23,739 - trainer - INFO] - Train Epoch:[79/100] Step:[230/250] Total Loss: 27.791119 GL_Loss: 0.394390 CRF_Loss: 27.396729\n",
      "[2022-02-17 20:35:39,245 - trainer - INFO] - Train Epoch:[79/100] Step:[240/250] Total Loss: 51.245388 GL_Loss: 0.371852 CRF_Loss: 50.873535\n",
      "[2022-02-17 20:35:53,389 - trainer - INFO] - Train Epoch:[79/100] Step:[250/250] Total Loss: 31.445982 GL_Loss: 0.337583 CRF_Loss: 31.108398\n",
      "[2022-02-17 20:36:12,361 - trainer - INFO] - [Step Validation] Epoch:[79/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.890244 | 0.929936 | 0.909657 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.734848 | 0.515957 | 0.60625  | 0.515957 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.691275 | 0.656051 | 0.673203 | 0.656051 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.681319 | 0.673913 | 0.677596 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.744186 | 0.647497 | 0.692483 | 0.647497 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 20:36:31,513 - trainer - INFO] - [Epoch Validation] Epoch:[79/100] Total Loss: 40.519694 GL_Loss: 0.005009 CRF_Loss: 40.018810 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.890244 | 0.929936 | 0.909657 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.734848 | 0.515957 | 0.60625  | 0.515957 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.691275 | 0.656051 | 0.673203 | 0.656051 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.681319 | 0.673913 | 0.677596 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.744186 | 0.647497 | 0.692483 | 0.647497 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 20:36:47,019 - trainer - INFO] - Train Epoch:[80/100] Step:[10/250] Total Loss: 9.056805 GL_Loss: 0.506389 CRF_Loss: 8.550415\n",
      "[2022-02-17 20:37:01,636 - trainer - INFO] - Train Epoch:[80/100] Step:[20/250] Total Loss: 63.849190 GL_Loss: 0.392282 CRF_Loss: 63.456909\n",
      "[2022-02-17 20:37:16,908 - trainer - INFO] - Train Epoch:[80/100] Step:[30/250] Total Loss: 16.674404 GL_Loss: 0.499233 CRF_Loss: 16.175171\n",
      "[2022-02-17 20:37:31,440 - trainer - INFO] - Train Epoch:[80/100] Step:[40/250] Total Loss: 26.114618 GL_Loss: 0.557612 CRF_Loss: 25.557007\n",
      "[2022-02-17 20:37:46,344 - trainer - INFO] - Train Epoch:[80/100] Step:[50/250] Total Loss: 21.722591 GL_Loss: 0.710384 CRF_Loss: 21.012207\n",
      "[2022-02-17 20:38:05,914 - trainer - INFO] - [Step Validation] Epoch:[80/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.913043 | 0.936306 | 0.924528 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.715385 | 0.494681 | 0.584906 | 0.494681 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.685714 | 0.611465 | 0.646465 | 0.611465 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.696629 | 0.673913 | 0.685083 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.743038 | 0.625133 | 0.679005 | 0.625133 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 20:38:20,735 - trainer - INFO] - Train Epoch:[80/100] Step:[60/250] Total Loss: 45.360268 GL_Loss: 0.418009 CRF_Loss: 44.942261\n",
      "[2022-02-17 20:38:34,953 - trainer - INFO] - Train Epoch:[80/100] Step:[70/250] Total Loss: 11.164271 GL_Loss: 0.709438 CRF_Loss: 10.454834\n",
      "[2022-02-17 20:38:49,299 - trainer - INFO] - Train Epoch:[80/100] Step:[80/250] Total Loss: 22.434963 GL_Loss: 0.395046 CRF_Loss: 22.039917\n",
      "[2022-02-17 20:39:02,282 - trainer - INFO] - Train Epoch:[80/100] Step:[90/250] Total Loss: 30.181906 GL_Loss: 0.839254 CRF_Loss: 29.342651\n",
      "[2022-02-17 20:39:16,050 - trainer - INFO] - Train Epoch:[80/100] Step:[100/250] Total Loss: 7.094833 GL_Loss: 0.460800 CRF_Loss: 6.634033\n",
      "[2022-02-17 20:39:35,092 - trainer - INFO] - [Step Validation] Epoch:[80/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.907975 | 0.942675 | 0.925    | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.703846 | 0.486702 | 0.575472 | 0.486702 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.686411 | 0.627389 | 0.655574 | 0.627389 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.677778 | 0.663043 | 0.67033  | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.73625  | 0.627263 | 0.677401 | 0.627263 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 20:39:49,794 - trainer - INFO] - Train Epoch:[80/100] Step:[110/250] Total Loss: 88.650291 GL_Loss: 0.748684 CRF_Loss: 87.901611\n",
      "[2022-02-17 20:40:04,099 - trainer - INFO] - Train Epoch:[80/100] Step:[120/250] Total Loss: 9.353880 GL_Loss: 0.352903 CRF_Loss: 9.000977\n",
      "[2022-02-17 20:40:18,086 - trainer - INFO] - Train Epoch:[80/100] Step:[130/250] Total Loss: 19.023939 GL_Loss: 0.282362 CRF_Loss: 18.741577\n",
      "[2022-02-17 20:40:32,600 - trainer - INFO] - Train Epoch:[80/100] Step:[140/250] Total Loss: 19.741507 GL_Loss: 0.544242 CRF_Loss: 19.197266\n",
      "[2022-02-17 20:40:47,796 - trainer - INFO] - Train Epoch:[80/100] Step:[150/250] Total Loss: 45.454510 GL_Loss: 0.567791 CRF_Loss: 44.886719\n",
      "[2022-02-17 20:41:06,716 - trainer - INFO] - [Step Validation] Epoch:[80/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.896341 | 0.936306 | 0.915888 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.734082 | 0.521277 | 0.609642 | 0.521277 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.681356 | 0.640127 | 0.660099 | 0.640127 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.67033  | 0.663043 | 0.666667 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.740514 | 0.644302 | 0.689066 | 0.644302 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 20:41:20,881 - trainer - INFO] - Train Epoch:[80/100] Step:[160/250] Total Loss: 24.619860 GL_Loss: 0.555773 CRF_Loss: 24.064087\n",
      "[2022-02-17 20:41:34,718 - trainer - INFO] - Train Epoch:[80/100] Step:[170/250] Total Loss: 16.509809 GL_Loss: 0.415082 CRF_Loss: 16.094727\n",
      "[2022-02-17 20:41:50,261 - trainer - INFO] - Train Epoch:[80/100] Step:[180/250] Total Loss: 22.048714 GL_Loss: 0.425544 CRF_Loss: 21.623169\n",
      "[2022-02-17 20:42:03,911 - trainer - INFO] - Train Epoch:[80/100] Step:[190/250] Total Loss: 185.506668 GL_Loss: 0.399972 CRF_Loss: 185.106689\n",
      "[2022-02-17 20:42:18,105 - trainer - INFO] - Train Epoch:[80/100] Step:[200/250] Total Loss: 26.826942 GL_Loss: 0.379188 CRF_Loss: 26.447754\n",
      "[2022-02-17 20:42:37,300 - trainer - INFO] - [Step Validation] Epoch:[80/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.902439 | 0.942675 | 0.922118 | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.734082 | 0.521277 | 0.609642 | 0.521277 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.675585 | 0.643312 | 0.659054 | 0.643312 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.677778 | 0.663043 | 0.67033  | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.740244 | 0.646432 | 0.690165 | 0.646432 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 20:42:52,264 - trainer - INFO] - Train Epoch:[80/100] Step:[210/250] Total Loss: 16.469837 GL_Loss: 0.548572 CRF_Loss: 15.921265\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 20:43:05,431 - trainer - INFO] - Train Epoch:[80/100] Step:[220/250] Total Loss: 40.771267 GL_Loss: 0.454005 CRF_Loss: 40.317261\n",
      "[2022-02-17 20:43:19,405 - trainer - INFO] - Train Epoch:[80/100] Step:[230/250] Total Loss: 22.487049 GL_Loss: 0.391102 CRF_Loss: 22.095947\n",
      "[2022-02-17 20:43:34,240 - trainer - INFO] - Train Epoch:[80/100] Step:[240/250] Total Loss: 9.935138 GL_Loss: 0.640216 CRF_Loss: 9.294922\n",
      "[2022-02-17 20:43:48,426 - trainer - INFO] - Train Epoch:[80/100] Step:[250/250] Total Loss: 30.632065 GL_Loss: 0.334213 CRF_Loss: 30.297852\n",
      "[2022-02-17 20:44:07,536 - trainer - INFO] - [Step Validation] Epoch:[80/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.884848 | 0.929936 | 0.906832 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.730337 | 0.518617 | 0.606532 | 0.518617 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.679739 | 0.66242  | 0.670968 | 0.66242  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.673913 | 0.673913 | 0.673913 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.736145 | 0.650692 | 0.690786 | 0.650692 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 20:44:26,808 - trainer - INFO] - [Epoch Validation] Epoch:[80/100] Total Loss: 40.704142 GL_Loss: 0.005014 CRF_Loss: 40.202762 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.884848 | 0.929936 | 0.906832 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.730337 | 0.518617 | 0.606532 | 0.518617 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.679739 | 0.66242  | 0.670968 | 0.66242  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.673913 | 0.673913 | 0.673913 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.736145 | 0.650692 | 0.690786 | 0.650692 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 20:44:28,758 - trainer - INFO] - Saving checkpoint: saved/models/PICK_Default/test_0217_100852/checkpoint-epoch80.pth ...\n",
      "[2022-02-17 20:44:43,872 - trainer - INFO] - Train Epoch:[81/100] Step:[10/250] Total Loss: 27.498215 GL_Loss: 0.436325 CRF_Loss: 27.061890\n",
      "[2022-02-17 20:44:57,543 - trainer - INFO] - Train Epoch:[81/100] Step:[20/250] Total Loss: 8.814270 GL_Loss: 0.594055 CRF_Loss: 8.220215\n",
      "[2022-02-17 20:45:11,339 - trainer - INFO] - Train Epoch:[81/100] Step:[30/250] Total Loss: 18.249214 GL_Loss: 0.321236 CRF_Loss: 17.927979\n",
      "[2022-02-17 20:45:25,304 - trainer - INFO] - Train Epoch:[81/100] Step:[40/250] Total Loss: 32.888508 GL_Loss: 0.575030 CRF_Loss: 32.313477\n",
      "[2022-02-17 20:45:39,900 - trainer - INFO] - Train Epoch:[81/100] Step:[50/250] Total Loss: 15.076290 GL_Loss: 1.075313 CRF_Loss: 14.000977\n",
      "[2022-02-17 20:46:01,041 - trainer - INFO] - [Step Validation] Epoch:[81/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.91358  | 0.942675 | 0.9279   | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.716981 | 0.505319 | 0.592824 | 0.505319 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.670034 | 0.633758 | 0.651391 | 0.633758 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.735872 | 0.637913 | 0.6834   | 0.637913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 20:46:15,332 - trainer - INFO] - Train Epoch:[81/100] Step:[60/250] Total Loss: 79.030609 GL_Loss: 0.279631 CRF_Loss: 78.750977\n",
      "[2022-02-17 20:46:29,053 - trainer - INFO] - Train Epoch:[81/100] Step:[70/250] Total Loss: 52.400276 GL_Loss: 0.556158 CRF_Loss: 51.844116\n",
      "[2022-02-17 20:46:43,807 - trainer - INFO] - Train Epoch:[81/100] Step:[80/250] Total Loss: 11.421947 GL_Loss: 0.407421 CRF_Loss: 11.014526\n",
      "[2022-02-17 20:46:57,792 - trainer - INFO] - Train Epoch:[81/100] Step:[90/250] Total Loss: 65.580902 GL_Loss: 0.384615 CRF_Loss: 65.196289\n",
      "[2022-02-17 20:47:12,174 - trainer - INFO] - Train Epoch:[81/100] Step:[100/250] Total Loss: 31.633877 GL_Loss: 0.534634 CRF_Loss: 31.099243\n",
      "[2022-02-17 20:47:31,179 - trainer - INFO] - [Step Validation] Epoch:[81/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.719697 | 0.505319 | 0.59375  | 0.505319 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.684039 | 0.66879  | 0.676329 | 0.66879  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.67033  | 0.663043 | 0.666667 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.735758 | 0.646432 | 0.688209 | 0.646432 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 20:47:45,011 - trainer - INFO] - Train Epoch:[81/100] Step:[110/250] Total Loss: 16.415133 GL_Loss: 0.484102 CRF_Loss: 15.931030\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 20:47:59,744 - trainer - INFO] - Train Epoch:[81/100] Step:[120/250] Total Loss: 264.556549 GL_Loss: 0.694237 CRF_Loss: 263.862305\n",
      "[2022-02-17 20:48:13,914 - trainer - INFO] - Train Epoch:[81/100] Step:[130/250] Total Loss: 13.614875 GL_Loss: 0.387824 CRF_Loss: 13.227051\n",
      "[2022-02-17 20:48:28,762 - trainer - INFO] - Train Epoch:[81/100] Step:[140/250] Total Loss: 32.493114 GL_Loss: 0.535839 CRF_Loss: 31.957275\n",
      "[2022-02-17 20:48:43,346 - trainer - INFO] - Train Epoch:[81/100] Step:[150/250] Total Loss: 64.545845 GL_Loss: 0.457465 CRF_Loss: 64.088379\n",
      "[2022-02-17 20:49:02,321 - trainer - INFO] - [Step Validation] Epoch:[81/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.736842 | 0.521277 | 0.610592 | 0.521277 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.678344 | 0.678344 | 0.678344 | 0.678344 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.655914 | 0.663043 | 0.659459 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.736842 | 0.656017 | 0.694085 | 0.656017 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 20:49:15,906 - trainer - INFO] - Train Epoch:[81/100] Step:[160/250] Total Loss: 18.688229 GL_Loss: 0.341061 CRF_Loss: 18.347168\n",
      "[2022-02-17 20:49:30,070 - trainer - INFO] - Train Epoch:[81/100] Step:[170/250] Total Loss: 11.585424 GL_Loss: 0.380102 CRF_Loss: 11.205322\n",
      "[2022-02-17 20:49:45,033 - trainer - INFO] - Train Epoch:[81/100] Step:[180/250] Total Loss: 19.259901 GL_Loss: 0.628431 CRF_Loss: 18.631470\n",
      "[2022-02-17 20:49:59,529 - trainer - INFO] - Train Epoch:[81/100] Step:[190/250] Total Loss: 17.484594 GL_Loss: 0.478125 CRF_Loss: 17.006470\n",
      "[2022-02-17 20:50:13,301 - trainer - INFO] - Train Epoch:[81/100] Step:[200/250] Total Loss: 28.931097 GL_Loss: 0.300115 CRF_Loss: 28.630981\n",
      "[2022-02-17 20:50:32,288 - trainer - INFO] - [Step Validation] Epoch:[81/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.731061 | 0.513298 | 0.603125 | 0.513298 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.684385 | 0.656051 | 0.669919 | 0.656051 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.677778 | 0.663043 | 0.67033  | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.740831 | 0.645367 | 0.689812 | 0.645367 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 20:50:46,093 - trainer - INFO] - Train Epoch:[81/100] Step:[210/250] Total Loss: 33.192699 GL_Loss: 0.568677 CRF_Loss: 32.624023\n",
      "[2022-02-17 20:50:59,923 - trainer - INFO] - Train Epoch:[81/100] Step:[220/250] Total Loss: 11.447879 GL_Loss: 0.391238 CRF_Loss: 11.056641\n",
      "[2022-02-17 20:51:14,932 - trainer - INFO] - Train Epoch:[81/100] Step:[230/250] Total Loss: 12.497305 GL_Loss: 0.366568 CRF_Loss: 12.130737\n",
      "[2022-02-17 20:51:29,888 - trainer - INFO] - Train Epoch:[81/100] Step:[240/250] Total Loss: 11.181221 GL_Loss: 0.495674 CRF_Loss: 10.685547\n",
      "[2022-02-17 20:51:44,349 - trainer - INFO] - Train Epoch:[81/100] Step:[250/250] Total Loss: 27.230101 GL_Loss: 0.649779 CRF_Loss: 26.580322\n",
      "[2022-02-17 20:52:03,447 - trainer - INFO] - [Step Validation] Epoch:[81/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.901235 | 0.929936 | 0.915361 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.731343 | 0.521277 | 0.608696 | 0.521277 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.67893  | 0.646497 | 0.662316 | 0.646497 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.659341 | 0.652174 | 0.655738 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.737805 | 0.644302 | 0.687891 | 0.644302 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 20:52:22,562 - trainer - INFO] - [Epoch Validation] Epoch:[81/100] Total Loss: 41.013980 GL_Loss: 0.005079 CRF_Loss: 40.506064 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.901235 | 0.929936 | 0.915361 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.731343 | 0.521277 | 0.608696 | 0.521277 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.67893  | 0.646497 | 0.662316 | 0.646497 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.659341 | 0.652174 | 0.655738 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.737805 | 0.644302 | 0.687891 | 0.644302 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 20:52:38,204 - trainer - INFO] - Train Epoch:[82/100] Step:[10/250] Total Loss: 13.335725 GL_Loss: 0.511750 CRF_Loss: 12.823975\n",
      "[2022-02-17 20:52:52,919 - trainer - INFO] - Train Epoch:[82/100] Step:[20/250] Total Loss: 41.087494 GL_Loss: 0.681124 CRF_Loss: 40.406372\n",
      "[2022-02-17 20:53:07,109 - trainer - INFO] - Train Epoch:[82/100] Step:[30/250] Total Loss: 31.791664 GL_Loss: 0.579993 CRF_Loss: 31.211670\n",
      "[2022-02-17 20:53:22,047 - trainer - INFO] - Train Epoch:[82/100] Step:[40/250] Total Loss: 65.036392 GL_Loss: 0.525647 CRF_Loss: 64.510742\n",
      "[2022-02-17 20:53:36,035 - trainer - INFO] - Train Epoch:[82/100] Step:[50/250] Total Loss: 22.193708 GL_Loss: 0.518661 CRF_Loss: 21.675049\n",
      "[2022-02-17 20:53:55,047 - trainer - INFO] - [Step Validation] Epoch:[82/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.896341 | 0.936306 | 0.915888 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.732075 | 0.515957 | 0.605304 | 0.515957 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.689655 | 0.636943 | 0.662252 | 0.636943 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.7      | 0.684783 | 0.692308 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.746601 | 0.643237 | 0.691076 | 0.643237 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 20:54:09,147 - trainer - INFO] - Train Epoch:[82/100] Step:[60/250] Total Loss: 12.248857 GL_Loss: 0.589555 CRF_Loss: 11.659302\n",
      "[2022-02-17 20:54:21,817 - trainer - INFO] - Train Epoch:[82/100] Step:[70/250] Total Loss: 24.416216 GL_Loss: 0.287920 CRF_Loss: 24.128296\n",
      "[2022-02-17 20:54:36,899 - trainer - INFO] - Train Epoch:[82/100] Step:[80/250] Total Loss: 21.249262 GL_Loss: 0.372310 CRF_Loss: 20.876953\n",
      "[2022-02-17 20:54:51,548 - trainer - INFO] - Train Epoch:[82/100] Step:[90/250] Total Loss: 38.396980 GL_Loss: 0.800299 CRF_Loss: 37.596680\n",
      "[2022-02-17 20:55:05,582 - trainer - INFO] - Train Epoch:[82/100] Step:[100/250] Total Loss: 21.162436 GL_Loss: 0.682944 CRF_Loss: 20.479492\n",
      "[2022-02-17 20:55:24,709 - trainer - INFO] - [Step Validation] Epoch:[82/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.90184  | 0.936306 | 0.91875  | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.733083 | 0.518617 | 0.607477 | 0.518617 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.677852 | 0.643312 | 0.660131 | 0.643312 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.67033  | 0.663043 | 0.666667 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.739609 | 0.644302 | 0.688674 | 0.644302 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 20:55:39,095 - trainer - INFO] - Train Epoch:[82/100] Step:[110/250] Total Loss: 27.933973 GL_Loss: 0.484633 CRF_Loss: 27.449341\n",
      "[2022-02-17 20:55:52,602 - trainer - INFO] - Train Epoch:[82/100] Step:[120/250] Total Loss: 37.670185 GL_Loss: 0.254537 CRF_Loss: 37.415649\n",
      "[2022-02-17 20:56:07,264 - trainer - INFO] - Train Epoch:[82/100] Step:[130/250] Total Loss: 36.936710 GL_Loss: 0.446477 CRF_Loss: 36.490234\n",
      "[2022-02-17 20:56:21,170 - trainer - INFO] - Train Epoch:[82/100] Step:[140/250] Total Loss: 83.337227 GL_Loss: 0.485174 CRF_Loss: 82.852051\n",
      "[2022-02-17 20:56:35,450 - trainer - INFO] - Train Epoch:[82/100] Step:[150/250] Total Loss: 10.938106 GL_Loss: 0.480464 CRF_Loss: 10.457642\n",
      "[2022-02-17 20:56:54,715 - trainer - INFO] - [Step Validation] Epoch:[82/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.896341 | 0.936306 | 0.915888 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.716981 | 0.505319 | 0.592824 | 0.505319 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.680135 | 0.643312 | 0.661211 | 0.643312 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.677778 | 0.663043 | 0.67033  | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.735294 | 0.638978 | 0.683761 | 0.638978 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 20:57:08,706 - trainer - INFO] - Train Epoch:[82/100] Step:[160/250] Total Loss: 39.204880 GL_Loss: 0.821700 CRF_Loss: 38.383179\n",
      "[2022-02-17 20:57:23,743 - trainer - INFO] - Train Epoch:[82/100] Step:[170/250] Total Loss: 16.487885 GL_Loss: 0.410248 CRF_Loss: 16.077637\n",
      "[2022-02-17 20:57:37,579 - trainer - INFO] - Train Epoch:[82/100] Step:[180/250] Total Loss: 58.971222 GL_Loss: 0.469512 CRF_Loss: 58.501709\n",
      "[2022-02-17 20:57:51,927 - trainer - INFO] - Train Epoch:[82/100] Step:[190/250] Total Loss: 46.531750 GL_Loss: 0.571055 CRF_Loss: 45.960693\n",
      "[2022-02-17 20:58:06,177 - trainer - INFO] - Train Epoch:[82/100] Step:[200/250] Total Loss: 38.190762 GL_Loss: 0.515591 CRF_Loss: 37.675171\n",
      "[2022-02-17 20:58:25,117 - trainer - INFO] - [Step Validation] Epoch:[82/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.734848 | 0.515957 | 0.60625  | 0.515957 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.696246 | 0.649682 | 0.672158 | 0.649682 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.692308 | 0.684783 | 0.688525 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.748459 | 0.646432 | 0.693714 | 0.646432 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 20:58:38,960 - trainer - INFO] - Train Epoch:[82/100] Step:[210/250] Total Loss: 21.793484 GL_Loss: 0.539700 CRF_Loss: 21.253784\n",
      "[2022-02-17 20:58:53,232 - trainer - INFO] - Train Epoch:[82/100] Step:[220/250] Total Loss: 20.062403 GL_Loss: 0.484888 CRF_Loss: 19.577515\n",
      "[2022-02-17 20:59:06,821 - trainer - INFO] - Train Epoch:[82/100] Step:[230/250] Total Loss: 23.657351 GL_Loss: 0.827028 CRF_Loss: 22.830322\n",
      "[2022-02-17 20:59:21,344 - trainer - INFO] - Train Epoch:[82/100] Step:[240/250] Total Loss: 15.668815 GL_Loss: 0.535758 CRF_Loss: 15.133057\n",
      "[2022-02-17 20:59:36,173 - trainer - INFO] - Train Epoch:[82/100] Step:[250/250] Total Loss: 23.224701 GL_Loss: 0.420746 CRF_Loss: 22.803955\n",
      "[2022-02-17 20:59:55,062 - trainer - INFO] - [Step Validation] Epoch:[82/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.736842 | 0.521277 | 0.610592 | 0.521277 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.677632 | 0.656051 | 0.666667 | 0.656051 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.677778 | 0.663043 | 0.67033  | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.739976 | 0.648562 | 0.69126  | 0.648562 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 21:00:14,308 - trainer - INFO] - [Epoch Validation] Epoch:[82/100] Total Loss: 40.898020 GL_Loss: 0.005156 CRF_Loss: 40.382464 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.736842 | 0.521277 | 0.610592 | 0.521277 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.677632 | 0.656051 | 0.666667 | 0.656051 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.677778 | 0.663043 | 0.67033  | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.739976 | 0.648562 | 0.69126  | 0.648562 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 21:00:29,536 - trainer - INFO] - Train Epoch:[83/100] Step:[10/250] Total Loss: 21.030415 GL_Loss: 0.719624 CRF_Loss: 20.310791\n",
      "[2022-02-17 21:00:43,433 - trainer - INFO] - Train Epoch:[83/100] Step:[20/250] Total Loss: 12.162155 GL_Loss: 0.596482 CRF_Loss: 11.565674\n",
      "[2022-02-17 21:00:57,497 - trainer - INFO] - Train Epoch:[83/100] Step:[30/250] Total Loss: 26.672552 GL_Loss: 0.347478 CRF_Loss: 26.325073\n",
      "[2022-02-17 21:01:10,969 - trainer - INFO] - Train Epoch:[83/100] Step:[40/250] Total Loss: 26.935419 GL_Loss: 0.476922 CRF_Loss: 26.458496\n",
      "[2022-02-17 21:01:25,261 - trainer - INFO] - Train Epoch:[83/100] Step:[50/250] Total Loss: 47.975674 GL_Loss: 0.383023 CRF_Loss: 47.592651\n",
      "[2022-02-17 21:01:44,177 - trainer - INFO] - [Step Validation] Epoch:[83/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.901235 | 0.929936 | 0.915361 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.731061 | 0.513298 | 0.603125 | 0.513298 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.683333 | 0.652866 | 0.667752 | 0.652866 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.677778 | 0.663043 | 0.67033  | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.741422 | 0.644302 | 0.689459 | 0.644302 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 21:01:58,393 - trainer - INFO] - Train Epoch:[83/100] Step:[60/250] Total Loss: 12.504729 GL_Loss: 0.481292 CRF_Loss: 12.023438\n",
      "[2022-02-17 21:02:12,456 - trainer - INFO] - Train Epoch:[83/100] Step:[70/250] Total Loss: 15.474378 GL_Loss: 0.350110 CRF_Loss: 15.124268\n",
      "[2022-02-17 21:02:27,295 - trainer - INFO] - Train Epoch:[83/100] Step:[80/250] Total Loss: 11.918255 GL_Loss: 0.544354 CRF_Loss: 11.373901\n",
      "[2022-02-17 21:02:41,150 - trainer - INFO] - Train Epoch:[83/100] Step:[90/250] Total Loss: 21.464859 GL_Loss: 0.418716 CRF_Loss: 21.046143\n",
      "[2022-02-17 21:02:55,595 - trainer - INFO] - Train Epoch:[83/100] Step:[100/250] Total Loss: 56.820229 GL_Loss: 0.463662 CRF_Loss: 56.356567\n",
      "[2022-02-17 21:03:14,473 - trainer - INFO] - [Step Validation] Epoch:[83/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.907975 | 0.942675 | 0.925    | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.703422 | 0.492021 | 0.57903  | 0.492021 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.674497 | 0.640127 | 0.656863 | 0.640127 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.677778 | 0.663043 | 0.67033  | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.730958 | 0.633653 | 0.678836 | 0.633653 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 21:03:29,678 - trainer - INFO] - Train Epoch:[83/100] Step:[110/250] Total Loss: 50.168999 GL_Loss: 0.560965 CRF_Loss: 49.608032\n",
      "[2022-02-17 21:03:43,071 - trainer - INFO] - Train Epoch:[83/100] Step:[120/250] Total Loss: 11.257489 GL_Loss: 0.359662 CRF_Loss: 10.897827\n",
      "[2022-02-17 21:03:56,917 - trainer - INFO] - Train Epoch:[83/100] Step:[130/250] Total Loss: 26.954542 GL_Loss: 0.356885 CRF_Loss: 26.597656\n",
      "[2022-02-17 21:04:11,988 - trainer - INFO] - Train Epoch:[83/100] Step:[140/250] Total Loss: 18.782440 GL_Loss: 0.255340 CRF_Loss: 18.527100\n",
      "[2022-02-17 21:04:26,012 - trainer - INFO] - Train Epoch:[83/100] Step:[150/250] Total Loss: 12.515800 GL_Loss: 0.375052 CRF_Loss: 12.140747\n",
      "[2022-02-17 21:04:45,086 - trainer - INFO] - [Step Validation] Epoch:[83/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.907975 | 0.942675 | 0.925    | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.73384  | 0.513298 | 0.604069 | 0.513298 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.683673 | 0.640127 | 0.661184 | 0.640127 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.745679 | 0.643237 | 0.69068  | 0.643237 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 21:04:59,437 - trainer - INFO] - Train Epoch:[83/100] Step:[160/250] Total Loss: 21.533026 GL_Loss: 0.464788 CRF_Loss: 21.068237\n",
      "[2022-02-17 21:05:13,695 - trainer - INFO] - Train Epoch:[83/100] Step:[170/250] Total Loss: 19.966940 GL_Loss: 0.445945 CRF_Loss: 19.520996\n",
      "[2022-02-17 21:05:27,274 - trainer - INFO] - Train Epoch:[83/100] Step:[180/250] Total Loss: 45.344894 GL_Loss: 0.560226 CRF_Loss: 44.784668\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 21:05:42,377 - trainer - INFO] - Train Epoch:[83/100] Step:[190/250] Total Loss: 44.299522 GL_Loss: 0.614828 CRF_Loss: 43.684692\n",
      "[2022-02-17 21:05:57,114 - trainer - INFO] - Train Epoch:[83/100] Step:[200/250] Total Loss: 283.119141 GL_Loss: 0.532218 CRF_Loss: 282.586914\n",
      "[2022-02-17 21:06:16,296 - trainer - INFO] - [Step Validation] Epoch:[83/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.901235 | 0.929936 | 0.915361 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.737828 | 0.523936 | 0.612753 | 0.523936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.674342 | 0.652866 | 0.66343  | 0.652866 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.741191 | 0.649627 | 0.692395 | 0.649627 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 21:06:31,864 - trainer - INFO] - Train Epoch:[83/100] Step:[210/250] Total Loss: 11.197244 GL_Loss: 0.762307 CRF_Loss: 10.434937\n",
      "[2022-02-17 21:06:45,231 - trainer - INFO] - Train Epoch:[83/100] Step:[220/250] Total Loss: 38.652695 GL_Loss: 0.293687 CRF_Loss: 38.359009\n",
      "[2022-02-17 21:06:59,623 - trainer - INFO] - Train Epoch:[83/100] Step:[230/250] Total Loss: 59.520222 GL_Loss: 0.770589 CRF_Loss: 58.749634\n",
      "[2022-02-17 21:07:13,073 - trainer - INFO] - Train Epoch:[83/100] Step:[240/250] Total Loss: 33.040623 GL_Loss: 0.324315 CRF_Loss: 32.716309\n",
      "[2022-02-17 21:07:26,688 - trainer - INFO] - Train Epoch:[83/100] Step:[250/250] Total Loss: 65.512451 GL_Loss: 0.381223 CRF_Loss: 65.131226\n",
      "[2022-02-17 21:07:45,882 - trainer - INFO] - [Step Validation] Epoch:[83/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.91358  | 0.942675 | 0.9279   | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.724138 | 0.50266  | 0.593407 | 0.50266  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.674576 | 0.633758 | 0.65353  | 0.633758 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.677778 | 0.663043 | 0.67033  | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.738861 | 0.635783 | 0.683457 | 0.635783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 21:08:05,140 - trainer - INFO] - [Epoch Validation] Epoch:[83/100] Total Loss: 40.519845 GL_Loss: 0.005006 CRF_Loss: 40.019290 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.91358  | 0.942675 | 0.9279   | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.724138 | 0.50266  | 0.593407 | 0.50266  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.674576 | 0.633758 | 0.65353  | 0.633758 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.677778 | 0.663043 | 0.67033  | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.738861 | 0.635783 | 0.683457 | 0.635783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 21:08:19,552 - trainer - INFO] - Train Epoch:[84/100] Step:[10/250] Total Loss: 20.982185 GL_Loss: 0.604012 CRF_Loss: 20.378174\n",
      "[2022-02-17 21:08:32,869 - trainer - INFO] - Train Epoch:[84/100] Step:[20/250] Total Loss: 17.046177 GL_Loss: 0.510411 CRF_Loss: 16.535767\n",
      "[2022-02-17 21:08:47,979 - trainer - INFO] - Train Epoch:[84/100] Step:[30/250] Total Loss: 19.371925 GL_Loss: 0.744606 CRF_Loss: 18.627319\n",
      "[2022-02-17 21:09:01,040 - trainer - INFO] - Train Epoch:[84/100] Step:[40/250] Total Loss: 30.747322 GL_Loss: 0.563972 CRF_Loss: 30.183350\n",
      "[2022-02-17 21:09:15,094 - trainer - INFO] - Train Epoch:[84/100] Step:[50/250] Total Loss: 6.026532 GL_Loss: 0.502606 CRF_Loss: 5.523926\n",
      "[2022-02-17 21:09:34,364 - trainer - INFO] - [Step Validation] Epoch:[84/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.907407 | 0.936306 | 0.92163  | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.704545 | 0.494681 | 0.58125  | 0.494681 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.685121 | 0.630573 | 0.656716 | 0.630573 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.7      | 0.684783 | 0.692308 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.737888 | 0.632588 | 0.681193 | 0.632588 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 21:09:48,757 - trainer - INFO] - Train Epoch:[84/100] Step:[60/250] Total Loss: 14.049109 GL_Loss: 0.453528 CRF_Loss: 13.595581\n",
      "[2022-02-17 21:10:03,127 - trainer - INFO] - Train Epoch:[84/100] Step:[70/250] Total Loss: 22.650318 GL_Loss: 0.461231 CRF_Loss: 22.189087\n",
      "[2022-02-17 21:10:16,159 - trainer - INFO] - Train Epoch:[84/100] Step:[80/250] Total Loss: 33.903191 GL_Loss: 0.522821 CRF_Loss: 33.380371\n",
      "[2022-02-17 21:10:31,463 - trainer - INFO] - Train Epoch:[84/100] Step:[90/250] Total Loss: 29.797779 GL_Loss: 0.532520 CRF_Loss: 29.265259\n",
      "[2022-02-17 21:10:45,503 - trainer - INFO] - Train Epoch:[84/100] Step:[100/250] Total Loss: 14.885058 GL_Loss: 0.716357 CRF_Loss: 14.168701\n",
      "[2022-02-17 21:11:04,530 - trainer - INFO] - [Step Validation] Epoch:[84/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.90184  | 0.936306 | 0.91875  | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.727273 | 0.510638 | 0.6      | 0.510638 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.672185 | 0.646497 | 0.659091 | 0.646497 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.67033  | 0.663043 | 0.666667 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.735366 | 0.642173 | 0.685617 | 0.642173 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 21:11:19,410 - trainer - INFO] - Train Epoch:[84/100] Step:[110/250] Total Loss: 37.512939 GL_Loss: 0.429811 CRF_Loss: 37.083130\n",
      "[2022-02-17 21:11:33,870 - trainer - INFO] - Train Epoch:[84/100] Step:[120/250] Total Loss: 57.792549 GL_Loss: 0.438666 CRF_Loss: 57.353882\n",
      "[2022-02-17 21:11:47,606 - trainer - INFO] - Train Epoch:[84/100] Step:[130/250] Total Loss: 25.767647 GL_Loss: 0.539131 CRF_Loss: 25.228516\n",
      "[2022-02-17 21:12:02,638 - trainer - INFO] - Train Epoch:[84/100] Step:[140/250] Total Loss: 52.873165 GL_Loss: 0.432248 CRF_Loss: 52.440918\n",
      "[2022-02-17 21:12:17,141 - trainer - INFO] - Train Epoch:[84/100] Step:[150/250] Total Loss: 50.013885 GL_Loss: 0.500090 CRF_Loss: 49.513794\n",
      "[2022-02-17 21:12:38,208 - trainer - INFO] - [Step Validation] Epoch:[84/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.73384  | 0.513298 | 0.604069 | 0.513298 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.681967 | 0.66242  | 0.672052 | 0.66242  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.67033  | 0.663043 | 0.666667 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.739659 | 0.647497 | 0.690517 | 0.647497 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 21:12:52,721 - trainer - INFO] - Train Epoch:[84/100] Step:[160/250] Total Loss: 41.858532 GL_Loss: 0.695080 CRF_Loss: 41.163452\n",
      "[2022-02-17 21:13:06,957 - trainer - INFO] - Train Epoch:[84/100] Step:[170/250] Total Loss: 48.783298 GL_Loss: 0.552404 CRF_Loss: 48.230896\n",
      "[2022-02-17 21:13:22,417 - trainer - INFO] - Train Epoch:[84/100] Step:[180/250] Total Loss: 30.231709 GL_Loss: 0.364277 CRF_Loss: 29.867432\n",
      "[2022-02-17 21:13:37,447 - trainer - INFO] - Train Epoch:[84/100] Step:[190/250] Total Loss: 10.401609 GL_Loss: 0.581419 CRF_Loss: 9.820190\n",
      "[2022-02-17 21:13:51,584 - trainer - INFO] - Train Epoch:[84/100] Step:[200/250] Total Loss: 37.094219 GL_Loss: 0.416973 CRF_Loss: 36.677246\n",
      "[2022-02-17 21:14:12,616 - trainer - INFO] - [Step Validation] Epoch:[84/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.902439 | 0.942675 | 0.922118 | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.708333 | 0.49734  | 0.584375 | 0.49734  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.671096 | 0.643312 | 0.656911 | 0.643312 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.677778 | 0.663043 | 0.67033  | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.730159 | 0.636848 | 0.680319 | 0.636848 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 21:14:27,480 - trainer - INFO] - Train Epoch:[84/100] Step:[210/250] Total Loss: 19.920137 GL_Loss: 0.797702 CRF_Loss: 19.122437\n",
      "[2022-02-17 21:14:41,696 - trainer - INFO] - Train Epoch:[84/100] Step:[220/250] Total Loss: 15.137375 GL_Loss: 0.436691 CRF_Loss: 14.700684\n",
      "[2022-02-17 21:14:57,057 - trainer - INFO] - Train Epoch:[84/100] Step:[230/250] Total Loss: 174.647095 GL_Loss: 0.516720 CRF_Loss: 174.130371\n",
      "[2022-02-17 21:15:11,289 - trainer - INFO] - Train Epoch:[84/100] Step:[240/250] Total Loss: 22.015203 GL_Loss: 0.612494 CRF_Loss: 21.402710\n",
      "[2022-02-17 21:15:26,182 - trainer - INFO] - Train Epoch:[84/100] Step:[250/250] Total Loss: 44.565399 GL_Loss: 0.744966 CRF_Loss: 43.820435\n",
      "[2022-02-17 21:15:45,275 - trainer - INFO] - [Step Validation] Epoch:[84/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.901235 | 0.929936 | 0.915361 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.75     | 0.526596 | 0.61875  | 0.526596 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.674342 | 0.652866 | 0.66343  | 0.652866 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.745122 | 0.650692 | 0.694713 | 0.650692 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 21:16:04,312 - trainer - INFO] - [Epoch Validation] Epoch:[84/100] Total Loss: 39.960481 GL_Loss: 0.004964 CRF_Loss: 39.464032 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.901235 | 0.929936 | 0.915361 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.75     | 0.526596 | 0.61875  | 0.526596 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.674342 | 0.652866 | 0.66343  | 0.652866 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.745122 | 0.650692 | 0.694713 | 0.650692 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 21:16:18,334 - trainer - INFO] - Train Epoch:[85/100] Step:[10/250] Total Loss: 21.649204 GL_Loss: 0.804111 CRF_Loss: 20.845093\n",
      "[2022-02-17 21:16:33,613 - trainer - INFO] - Train Epoch:[85/100] Step:[20/250] Total Loss: 42.110355 GL_Loss: 0.364504 CRF_Loss: 41.745850\n",
      "[2022-02-17 21:16:48,161 - trainer - INFO] - Train Epoch:[85/100] Step:[30/250] Total Loss: 29.218782 GL_Loss: 0.508454 CRF_Loss: 28.710327\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 21:17:02,718 - trainer - INFO] - Train Epoch:[85/100] Step:[40/250] Total Loss: 46.119606 GL_Loss: 0.451272 CRF_Loss: 45.668335\n",
      "[2022-02-17 21:17:18,621 - trainer - INFO] - Train Epoch:[85/100] Step:[50/250] Total Loss: 50.763447 GL_Loss: 0.495379 CRF_Loss: 50.268066\n",
      "[2022-02-17 21:17:37,588 - trainer - INFO] - [Step Validation] Epoch:[85/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.90184  | 0.936306 | 0.91875  | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.749049 | 0.523936 | 0.616588 | 0.523936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.677632 | 0.656051 | 0.666667 | 0.656051 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.746341 | 0.651757 | 0.69585  | 0.651757 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 21:17:53,926 - trainer - INFO] - Train Epoch:[85/100] Step:[60/250] Total Loss: 16.282471 GL_Loss: 0.486329 CRF_Loss: 15.796143\n",
      "[2022-02-17 21:18:10,596 - trainer - INFO] - Train Epoch:[85/100] Step:[70/250] Total Loss: 21.428888 GL_Loss: 0.609186 CRF_Loss: 20.819702\n",
      "[2022-02-17 21:18:25,362 - trainer - INFO] - Train Epoch:[85/100] Step:[80/250] Total Loss: 814.581360 GL_Loss: 0.346429 CRF_Loss: 814.234924\n",
      "[2022-02-17 21:18:40,418 - trainer - INFO] - Train Epoch:[85/100] Step:[90/250] Total Loss: 15.570299 GL_Loss: 0.530870 CRF_Loss: 15.039429\n",
      "[2022-02-17 21:18:53,657 - trainer - INFO] - Train Epoch:[85/100] Step:[100/250] Total Loss: 40.543056 GL_Loss: 0.462369 CRF_Loss: 40.080688\n",
      "[2022-02-17 21:19:12,888 - trainer - INFO] - [Step Validation] Epoch:[85/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.741445 | 0.518617 | 0.610329 | 0.518617 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.679868 | 0.656051 | 0.667747 | 0.656051 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.7      | 0.684783 | 0.692308 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.744811 | 0.649627 | 0.69397  | 0.649627 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 21:19:26,836 - trainer - INFO] - Train Epoch:[85/100] Step:[110/250] Total Loss: 21.546555 GL_Loss: 0.440110 CRF_Loss: 21.106445\n",
      "[2022-02-17 21:19:42,243 - trainer - INFO] - Train Epoch:[85/100] Step:[120/250] Total Loss: 15.383249 GL_Loss: 0.467234 CRF_Loss: 14.916016\n",
      "[2022-02-17 21:19:56,810 - trainer - INFO] - Train Epoch:[85/100] Step:[130/250] Total Loss: 27.974720 GL_Loss: 0.437123 CRF_Loss: 27.537598\n",
      "[2022-02-17 21:20:10,280 - trainer - INFO] - Train Epoch:[85/100] Step:[140/250] Total Loss: 11.213511 GL_Loss: 0.367075 CRF_Loss: 10.846436\n",
      "[2022-02-17 21:20:24,984 - trainer - INFO] - Train Epoch:[85/100] Step:[150/250] Total Loss: 49.389061 GL_Loss: 0.451195 CRF_Loss: 48.937866\n",
      "[2022-02-17 21:20:45,217 - trainer - INFO] - [Step Validation] Epoch:[85/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.896341 | 0.936306 | 0.915888 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.742424 | 0.521277 | 0.6125   | 0.521277 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.669935 | 0.652866 | 0.66129  | 0.652866 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.677778 | 0.663043 | 0.67033  | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.739078 | 0.648562 | 0.690868 | 0.648562 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 21:21:00,138 - trainer - INFO] - Train Epoch:[85/100] Step:[160/250] Total Loss: 25.438610 GL_Loss: 0.433240 CRF_Loss: 25.005371\n",
      "[2022-02-17 21:21:14,435 - trainer - INFO] - Train Epoch:[85/100] Step:[170/250] Total Loss: 22.184124 GL_Loss: 0.467083 CRF_Loss: 21.717041\n",
      "[2022-02-17 21:21:28,653 - trainer - INFO] - Train Epoch:[85/100] Step:[180/250] Total Loss: 17.449577 GL_Loss: 0.764396 CRF_Loss: 16.685181\n",
      "[2022-02-17 21:21:42,684 - trainer - INFO] - Train Epoch:[85/100] Step:[190/250] Total Loss: 17.479855 GL_Loss: 0.514890 CRF_Loss: 16.964966\n",
      "[2022-02-17 21:21:56,523 - trainer - INFO] - Train Epoch:[85/100] Step:[200/250] Total Loss: 15.517515 GL_Loss: 0.473448 CRF_Loss: 15.044067\n",
      "[2022-02-17 21:22:15,390 - trainer - INFO] - [Step Validation] Epoch:[85/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.896341 | 0.936306 | 0.915888 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.743396 | 0.523936 | 0.614665 | 0.523936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.690236 | 0.652866 | 0.671031 | 0.652866 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.748775 | 0.650692 | 0.696296 | 0.650692 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 21:22:30,104 - trainer - INFO] - Train Epoch:[85/100] Step:[210/250] Total Loss: 244.222351 GL_Loss: 0.625187 CRF_Loss: 243.597168\n",
      "[2022-02-17 21:22:43,792 - trainer - INFO] - Train Epoch:[85/100] Step:[220/250] Total Loss: 21.738251 GL_Loss: 0.437592 CRF_Loss: 21.300659\n",
      "[2022-02-17 21:22:57,780 - trainer - INFO] - Train Epoch:[85/100] Step:[230/250] Total Loss: 51.706474 GL_Loss: 0.449882 CRF_Loss: 51.256592\n",
      "[2022-02-17 21:23:13,182 - trainer - INFO] - Train Epoch:[85/100] Step:[240/250] Total Loss: 52.646729 GL_Loss: 0.390990 CRF_Loss: 52.255737\n",
      "[2022-02-17 21:23:27,799 - trainer - INFO] - Train Epoch:[85/100] Step:[250/250] Total Loss: 19.278593 GL_Loss: 0.305814 CRF_Loss: 18.972778\n",
      "[2022-02-17 21:23:46,736 - trainer - INFO] - [Step Validation] Epoch:[85/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.890244 | 0.929936 | 0.909657 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.714286 | 0.492021 | 0.582677 | 0.492021 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.672297 | 0.633758 | 0.652459 | 0.633758 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.677778 | 0.663043 | 0.67033  | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.730532 | 0.629393 | 0.676201 | 0.629393 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 21:24:05,930 - trainer - INFO] - [Epoch Validation] Epoch:[85/100] Total Loss: 40.130275 GL_Loss: 0.004967 CRF_Loss: 39.633606 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.890244 | 0.929936 | 0.909657 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.714286 | 0.492021 | 0.582677 | 0.492021 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.672297 | 0.633758 | 0.652459 | 0.633758 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.677778 | 0.663043 | 0.67033  | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.730532 | 0.629393 | 0.676201 | 0.629393 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 21:24:20,236 - trainer - INFO] - Train Epoch:[86/100] Step:[10/250] Total Loss: 19.547039 GL_Loss: 0.405193 CRF_Loss: 19.141846\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 21:24:36,067 - trainer - INFO] - Train Epoch:[86/100] Step:[20/250] Total Loss: 25.189127 GL_Loss: 0.726846 CRF_Loss: 24.462280\n",
      "[2022-02-17 21:24:50,668 - trainer - INFO] - Train Epoch:[86/100] Step:[30/250] Total Loss: 33.425621 GL_Loss: 0.572837 CRF_Loss: 32.852783\n",
      "[2022-02-17 21:25:04,067 - trainer - INFO] - Train Epoch:[86/100] Step:[40/250] Total Loss: 23.721222 GL_Loss: 0.329864 CRF_Loss: 23.391357\n",
      "[2022-02-17 21:25:18,587 - trainer - INFO] - Train Epoch:[86/100] Step:[50/250] Total Loss: 40.821953 GL_Loss: 0.462091 CRF_Loss: 40.359863\n",
      "[2022-02-17 21:25:37,576 - trainer - INFO] - [Step Validation] Epoch:[86/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.90184  | 0.936306 | 0.91875  | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.715356 | 0.507979 | 0.59409  | 0.507979 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.677966 | 0.636943 | 0.656814 | 0.636943 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.67033  | 0.663043 | 0.666667 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.734069 | 0.637913 | 0.682621 | 0.637913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 21:25:51,848 - trainer - INFO] - Train Epoch:[86/100] Step:[60/250] Total Loss: 79.117989 GL_Loss: 0.341743 CRF_Loss: 78.776245\n",
      "[2022-02-17 21:26:05,834 - trainer - INFO] - Train Epoch:[86/100] Step:[70/250] Total Loss: 13.001251 GL_Loss: 0.793487 CRF_Loss: 12.207764\n",
      "[2022-02-17 21:26:19,743 - trainer - INFO] - Train Epoch:[86/100] Step:[80/250] Total Loss: 36.535885 GL_Loss: 0.319456 CRF_Loss: 36.216431\n",
      "[2022-02-17 21:26:33,840 - trainer - INFO] - Train Epoch:[86/100] Step:[90/250] Total Loss: 11.738767 GL_Loss: 0.374753 CRF_Loss: 11.364014\n",
      "[2022-02-17 21:26:47,978 - trainer - INFO] - Train Epoch:[86/100] Step:[100/250] Total Loss: 26.021051 GL_Loss: 0.642756 CRF_Loss: 25.378296\n",
      "[2022-02-17 21:27:06,890 - trainer - INFO] - [Step Validation] Epoch:[86/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.884848 | 0.929936 | 0.906832 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.734082 | 0.521277 | 0.609642 | 0.521277 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.688963 | 0.656051 | 0.672104 | 0.656051 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.681319 | 0.673913 | 0.677596 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.742092 | 0.649627 | 0.692788 | 0.649627 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 21:27:20,188 - trainer - INFO] - Train Epoch:[86/100] Step:[110/250] Total Loss: 22.862284 GL_Loss: 0.441020 CRF_Loss: 22.421265\n",
      "[2022-02-17 21:27:34,752 - trainer - INFO] - Train Epoch:[86/100] Step:[120/250] Total Loss: 11.594736 GL_Loss: 0.572763 CRF_Loss: 11.021973\n",
      "[2022-02-17 21:27:48,818 - trainer - INFO] - Train Epoch:[86/100] Step:[130/250] Total Loss: 15.626629 GL_Loss: 0.436199 CRF_Loss: 15.190430\n",
      "[2022-02-17 21:28:02,517 - trainer - INFO] - Train Epoch:[86/100] Step:[140/250] Total Loss: 44.585018 GL_Loss: 0.940607 CRF_Loss: 43.644409\n",
      "[2022-02-17 21:28:16,867 - trainer - INFO] - Train Epoch:[86/100] Step:[150/250] Total Loss: 28.845928 GL_Loss: 0.433087 CRF_Loss: 28.412842\n",
      "[2022-02-17 21:28:36,551 - trainer - INFO] - [Step Validation] Epoch:[86/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.896341 | 0.936306 | 0.915888 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.732075 | 0.515957 | 0.605304 | 0.515957 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.67893  | 0.646497 | 0.662316 | 0.646497 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.740831 | 0.645367 | 0.689812 | 0.645367 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 21:28:50,896 - trainer - INFO] - Train Epoch:[86/100] Step:[160/250] Total Loss: 17.002945 GL_Loss: 0.468520 CRF_Loss: 16.534424\n",
      "[2022-02-17 21:29:03,950 - trainer - INFO] - Train Epoch:[86/100] Step:[170/250] Total Loss: 18.008215 GL_Loss: 0.476232 CRF_Loss: 17.531982\n",
      "[2022-02-17 21:29:18,558 - trainer - INFO] - Train Epoch:[86/100] Step:[180/250] Total Loss: 16.181437 GL_Loss: 0.439982 CRF_Loss: 15.741455\n",
      "[2022-02-17 21:29:32,382 - trainer - INFO] - Train Epoch:[86/100] Step:[190/250] Total Loss: 20.452394 GL_Loss: 1.204347 CRF_Loss: 19.248047\n",
      "[2022-02-17 21:29:45,364 - trainer - INFO] - Train Epoch:[86/100] Step:[200/250] Total Loss: 18.939201 GL_Loss: 0.439689 CRF_Loss: 18.499512\n",
      "[2022-02-17 21:30:04,361 - trainer - INFO] - [Step Validation] Epoch:[86/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.889571 | 0.923567 | 0.90625  | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.730038 | 0.510638 | 0.600939 | 0.510638 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.68     | 0.649682 | 0.664495 | 0.649682 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.681319 | 0.673913 | 0.677596 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.738066 | 0.642173 | 0.686788 | 0.642173 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 21:30:18,330 - trainer - INFO] - Train Epoch:[86/100] Step:[210/250] Total Loss: 58.691299 GL_Loss: 0.355363 CRF_Loss: 58.335938\n",
      "[2022-02-17 21:30:33,135 - trainer - INFO] - Train Epoch:[86/100] Step:[220/250] Total Loss: 40.721558 GL_Loss: 0.338014 CRF_Loss: 40.383545\n",
      "[2022-02-17 21:30:48,196 - trainer - INFO] - Train Epoch:[86/100] Step:[230/250] Total Loss: 8.299962 GL_Loss: 0.478917 CRF_Loss: 7.821045\n",
      "[2022-02-17 21:31:02,057 - trainer - INFO] - Train Epoch:[86/100] Step:[240/250] Total Loss: 19.224216 GL_Loss: 0.827365 CRF_Loss: 18.396851\n",
      "[2022-02-17 21:31:16,798 - trainer - INFO] - Train Epoch:[86/100] Step:[250/250] Total Loss: 21.700304 GL_Loss: 0.499010 CRF_Loss: 21.201294\n",
      "[2022-02-17 21:31:35,794 - trainer - INFO] - [Step Validation] Epoch:[86/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.90184  | 0.936306 | 0.91875  | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.729323 | 0.515957 | 0.604361 | 0.515957 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.674497 | 0.640127 | 0.656863 | 0.640127 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.677778 | 0.663043 | 0.67033  | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.738066 | 0.642173 | 0.686788 | 0.642173 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 21:31:54,903 - trainer - INFO] - [Epoch Validation] Epoch:[86/100] Total Loss: 40.547499 GL_Loss: 0.004983 CRF_Loss: 40.049196 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.90184  | 0.936306 | 0.91875  | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.729323 | 0.515957 | 0.604361 | 0.515957 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.674497 | 0.640127 | 0.656863 | 0.640127 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.677778 | 0.663043 | 0.67033  | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.738066 | 0.642173 | 0.686788 | 0.642173 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 21:32:10,738 - trainer - INFO] - Train Epoch:[87/100] Step:[10/250] Total Loss: 51.969582 GL_Loss: 0.367041 CRF_Loss: 51.602539\n",
      "[2022-02-17 21:32:25,354 - trainer - INFO] - Train Epoch:[87/100] Step:[20/250] Total Loss: 9.921906 GL_Loss: 0.810212 CRF_Loss: 9.111694\n",
      "[2022-02-17 21:32:39,984 - trainer - INFO] - Train Epoch:[87/100] Step:[30/250] Total Loss: 23.948076 GL_Loss: 0.623430 CRF_Loss: 23.324646\n",
      "[2022-02-17 21:32:55,193 - trainer - INFO] - Train Epoch:[87/100] Step:[40/250] Total Loss: 16.259222 GL_Loss: 0.555121 CRF_Loss: 15.704102\n",
      "[2022-02-17 21:33:09,859 - trainer - INFO] - Train Epoch:[87/100] Step:[50/250] Total Loss: 22.084442 GL_Loss: 0.436859 CRF_Loss: 21.647583\n",
      "[2022-02-17 21:33:28,943 - trainer - INFO] - [Step Validation] Epoch:[87/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.90184  | 0.936306 | 0.91875  | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.749064 | 0.531915 | 0.622084 | 0.531915 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.677852 | 0.643312 | 0.660131 | 0.643312 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.692308 | 0.684783 | 0.688525 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.747253 | 0.651757 | 0.696246 | 0.651757 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 21:33:42,726 - trainer - INFO] - Train Epoch:[87/100] Step:[60/250] Total Loss: 15.917242 GL_Loss: 0.870245 CRF_Loss: 15.046997\n",
      "[2022-02-17 21:33:56,174 - trainer - INFO] - Train Epoch:[87/100] Step:[70/250] Total Loss: 21.785009 GL_Loss: 0.374487 CRF_Loss: 21.410522\n",
      "[2022-02-17 21:34:10,664 - trainer - INFO] - Train Epoch:[87/100] Step:[80/250] Total Loss: 49.411388 GL_Loss: 0.588025 CRF_Loss: 48.823364\n",
      "[2022-02-17 21:34:24,923 - trainer - INFO] - Train Epoch:[87/100] Step:[90/250] Total Loss: 12.867433 GL_Loss: 0.730469 CRF_Loss: 12.136963\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 21:34:40,354 - trainer - INFO] - Train Epoch:[87/100] Step:[100/250] Total Loss: 24.008734 GL_Loss: 0.633979 CRF_Loss: 23.374756\n",
      "[2022-02-17 21:34:59,425 - trainer - INFO] - [Step Validation] Epoch:[87/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.913043 | 0.936306 | 0.924528 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.727969 | 0.505319 | 0.596546 | 0.505319 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.676364 | 0.592357 | 0.631579 | 0.592357 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.7      | 0.684783 | 0.692308 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.7446   | 0.624068 | 0.679027 | 0.624068 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 21:35:12,775 - trainer - INFO] - Train Epoch:[87/100] Step:[110/250] Total Loss: 24.528605 GL_Loss: 0.690592 CRF_Loss: 23.838013\n",
      "[2022-02-17 21:35:27,584 - trainer - INFO] - Train Epoch:[87/100] Step:[120/250] Total Loss: 22.416157 GL_Loss: 1.259419 CRF_Loss: 21.156738\n",
      "[2022-02-17 21:35:41,623 - trainer - INFO] - Train Epoch:[87/100] Step:[130/250] Total Loss: 10.281581 GL_Loss: 0.475062 CRF_Loss: 9.806519\n",
      "[2022-02-17 21:35:55,390 - trainer - INFO] - Train Epoch:[87/100] Step:[140/250] Total Loss: 21.604748 GL_Loss: 0.661387 CRF_Loss: 20.943359\n",
      "[2022-02-17 21:36:09,841 - trainer - INFO] - Train Epoch:[87/100] Step:[150/250] Total Loss: 19.748180 GL_Loss: 0.481456 CRF_Loss: 19.266724\n",
      "[2022-02-17 21:36:28,949 - trainer - INFO] - [Step Validation] Epoch:[87/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.727273 | 0.510638 | 0.6      | 0.510638 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.663492 | 0.665605 | 0.664547 | 0.665605 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.677778 | 0.663043 | 0.67033  | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.730769 | 0.647497 | 0.686618 | 0.647497 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 21:36:42,479 - trainer - INFO] - Train Epoch:[87/100] Step:[160/250] Total Loss: 87.148621 GL_Loss: 0.375184 CRF_Loss: 86.773438\n",
      "[2022-02-17 21:36:57,262 - trainer - INFO] - Train Epoch:[87/100] Step:[170/250] Total Loss: 5.852141 GL_Loss: 0.619475 CRF_Loss: 5.232666\n",
      "[2022-02-17 21:37:11,775 - trainer - INFO] - Train Epoch:[87/100] Step:[180/250] Total Loss: 89.004776 GL_Loss: 0.511001 CRF_Loss: 88.493774\n",
      "[2022-02-17 21:37:25,187 - trainer - INFO] - Train Epoch:[87/100] Step:[190/250] Total Loss: 9.315113 GL_Loss: 0.353809 CRF_Loss: 8.961304\n",
      "[2022-02-17 21:37:39,105 - trainer - INFO] - Train Epoch:[87/100] Step:[200/250] Total Loss: 14.581776 GL_Loss: 0.348743 CRF_Loss: 14.233032\n",
      "[2022-02-17 21:37:58,098 - trainer - INFO] - [Step Validation] Epoch:[87/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.90184  | 0.936306 | 0.91875  | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.753788 | 0.529255 | 0.621875 | 0.529255 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.685811 | 0.646497 | 0.665574 | 0.646497 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.711111 | 0.695652 | 0.703297 | 0.695652 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.753998 | 0.652822 | 0.699772 | 0.652822 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 21:38:00,176 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 21:38:13,820 - trainer - INFO] - Train Epoch:[87/100] Step:[210/250] Total Loss: 27.475813 GL_Loss: 0.396834 CRF_Loss: 27.078979\n",
      "[2022-02-17 21:38:28,469 - trainer - INFO] - Train Epoch:[87/100] Step:[220/250] Total Loss: 28.301083 GL_Loss: 0.376279 CRF_Loss: 27.924805\n",
      "[2022-02-17 21:38:43,707 - trainer - INFO] - Train Epoch:[87/100] Step:[230/250] Total Loss: 8.267100 GL_Loss: 0.601695 CRF_Loss: 7.665405\n",
      "[2022-02-17 21:38:57,242 - trainer - INFO] - Train Epoch:[87/100] Step:[240/250] Total Loss: 21.989283 GL_Loss: 0.354883 CRF_Loss: 21.634399\n",
      "[2022-02-17 21:39:11,300 - trainer - INFO] - Train Epoch:[87/100] Step:[250/250] Total Loss: 16.720737 GL_Loss: 0.486484 CRF_Loss: 16.234253\n",
      "[2022-02-17 21:39:30,369 - trainer - INFO] - [Step Validation] Epoch:[87/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.896341 | 0.936306 | 0.915888 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.736842 | 0.521277 | 0.610592 | 0.521277 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.678808 | 0.652866 | 0.665584 | 0.652866 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.67033  | 0.663043 | 0.666667 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.739976 | 0.648562 | 0.69126  | 0.648562 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 21:39:49,588 - trainer - INFO] - [Epoch Validation] Epoch:[87/100] Total Loss: 40.969275 GL_Loss: 0.005051 CRF_Loss: 40.464188 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.896341 | 0.936306 | 0.915888 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.736842 | 0.521277 | 0.610592 | 0.521277 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.678808 | 0.652866 | 0.665584 | 0.652866 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.67033  | 0.663043 | 0.666667 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.739976 | 0.648562 | 0.69126  | 0.648562 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 21:40:05,113 - trainer - INFO] - Train Epoch:[88/100] Step:[10/250] Total Loss: 17.556610 GL_Loss: 0.542693 CRF_Loss: 17.013916\n",
      "[2022-02-17 21:40:20,167 - trainer - INFO] - Train Epoch:[88/100] Step:[20/250] Total Loss: 26.255560 GL_Loss: 0.303656 CRF_Loss: 25.951904\n",
      "[2022-02-17 21:40:34,360 - trainer - INFO] - Train Epoch:[88/100] Step:[30/250] Total Loss: 190.258698 GL_Loss: 0.387109 CRF_Loss: 189.871582\n",
      "[2022-02-17 21:40:48,540 - trainer - INFO] - Train Epoch:[88/100] Step:[40/250] Total Loss: 12.802999 GL_Loss: 0.694844 CRF_Loss: 12.108154\n",
      "[2022-02-17 21:41:02,950 - trainer - INFO] - Train Epoch:[88/100] Step:[50/250] Total Loss: 44.661407 GL_Loss: 0.555207 CRF_Loss: 44.106201\n",
      "[2022-02-17 21:41:21,982 - trainer - INFO] - [Step Validation] Epoch:[88/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.896341 | 0.936306 | 0.915888 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.735849 | 0.518617 | 0.608424 | 0.518617 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.681063 | 0.652866 | 0.666667 | 0.652866 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.7      | 0.684783 | 0.692308 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.743902 | 0.649627 | 0.693576 | 0.649627 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 21:41:35,317 - trainer - INFO] - Train Epoch:[88/100] Step:[60/250] Total Loss: 18.950422 GL_Loss: 0.519391 CRF_Loss: 18.431030\n",
      "[2022-02-17 21:41:48,686 - trainer - INFO] - Train Epoch:[88/100] Step:[70/250] Total Loss: 20.474125 GL_Loss: 0.681401 CRF_Loss: 19.792725\n",
      "[2022-02-17 21:42:03,340 - trainer - INFO] - Train Epoch:[88/100] Step:[80/250] Total Loss: 19.409935 GL_Loss: 0.637230 CRF_Loss: 18.772705\n",
      "[2022-02-17 21:42:18,368 - trainer - INFO] - Train Epoch:[88/100] Step:[90/250] Total Loss: 31.238571 GL_Loss: 0.366501 CRF_Loss: 30.872070\n",
      "[2022-02-17 21:42:32,084 - trainer - INFO] - Train Epoch:[88/100] Step:[100/250] Total Loss: 17.001789 GL_Loss: 0.288289 CRF_Loss: 16.713501\n",
      "[2022-02-17 21:42:51,199 - trainer - INFO] - [Step Validation] Epoch:[88/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.901235 | 0.929936 | 0.915361 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.739623 | 0.521277 | 0.611544 | 0.521277 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.680921 | 0.659236 | 0.669903 | 0.659236 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.659341 | 0.652174 | 0.655738 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.740876 | 0.648562 | 0.691652 | 0.648562 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 21:43:05,649 - trainer - INFO] - Train Epoch:[88/100] Step:[110/250] Total Loss: 12.668346 GL_Loss: 0.297375 CRF_Loss: 12.370972\n",
      "[2022-02-17 21:43:19,949 - trainer - INFO] - Train Epoch:[88/100] Step:[120/250] Total Loss: 16.539902 GL_Loss: 0.415633 CRF_Loss: 16.124268\n",
      "[2022-02-17 21:43:34,664 - trainer - INFO] - Train Epoch:[88/100] Step:[130/250] Total Loss: 89.825920 GL_Loss: 0.424063 CRF_Loss: 89.401855\n",
      "[2022-02-17 21:43:48,575 - trainer - INFO] - Train Epoch:[88/100] Step:[140/250] Total Loss: 39.713421 GL_Loss: 0.517744 CRF_Loss: 39.195679\n",
      "[2022-02-17 21:44:02,290 - trainer - INFO] - Train Epoch:[88/100] Step:[150/250] Total Loss: 22.543091 GL_Loss: 0.645019 CRF_Loss: 21.898071\n",
      "[2022-02-17 21:44:21,240 - trainer - INFO] - [Step Validation] Epoch:[88/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.896341 | 0.936306 | 0.915888 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.739623 | 0.521277 | 0.611544 | 0.521277 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.676667 | 0.646497 | 0.661238 | 0.646497 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.677778 | 0.663043 | 0.67033  | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.741148 | 0.646432 | 0.690557 | 0.646432 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 21:44:35,019 - trainer - INFO] - Train Epoch:[88/100] Step:[160/250] Total Loss: 9.517396 GL_Loss: 0.503480 CRF_Loss: 9.013916\n",
      "[2022-02-17 21:44:48,504 - trainer - INFO] - Train Epoch:[88/100] Step:[170/250] Total Loss: 40.516541 GL_Loss: 0.503235 CRF_Loss: 40.013306\n",
      "[2022-02-17 21:45:02,344 - trainer - INFO] - Train Epoch:[88/100] Step:[180/250] Total Loss: 54.828125 GL_Loss: 0.367188 CRF_Loss: 54.460938\n",
      "[2022-02-17 21:45:16,288 - trainer - INFO] - Train Epoch:[88/100] Step:[190/250] Total Loss: 36.094597 GL_Loss: 0.435538 CRF_Loss: 35.659058\n",
      "[2022-02-17 21:45:31,188 - trainer - INFO] - Train Epoch:[88/100] Step:[200/250] Total Loss: 17.112642 GL_Loss: 0.804780 CRF_Loss: 16.307861\n",
      "[2022-02-17 21:45:50,121 - trainer - INFO] - [Step Validation] Epoch:[88/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.884848 | 0.929936 | 0.906832 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.734082 | 0.521277 | 0.609642 | 0.521277 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.680782 | 0.665605 | 0.673108 | 0.665605 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.666667 | 0.652174 | 0.659341 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.737033 | 0.650692 | 0.691176 | 0.650692 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 21:46:04,637 - trainer - INFO] - Train Epoch:[88/100] Step:[210/250] Total Loss: 33.520622 GL_Loss: 0.532830 CRF_Loss: 32.987793\n",
      "[2022-02-17 21:46:19,338 - trainer - INFO] - Train Epoch:[88/100] Step:[220/250] Total Loss: 29.316641 GL_Loss: 0.712636 CRF_Loss: 28.604004\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 21:46:33,515 - trainer - INFO] - Train Epoch:[88/100] Step:[230/250] Total Loss: 42.012817 GL_Loss: 0.786986 CRF_Loss: 41.225830\n",
      "[2022-02-17 21:46:46,563 - trainer - INFO] - Train Epoch:[88/100] Step:[240/250] Total Loss: 7.055861 GL_Loss: 0.523146 CRF_Loss: 6.532715\n",
      "[2022-02-17 21:46:59,897 - trainer - INFO] - Train Epoch:[88/100] Step:[250/250] Total Loss: 16.574446 GL_Loss: 0.640364 CRF_Loss: 15.934082\n",
      "[2022-02-17 21:47:18,892 - trainer - INFO] - [Step Validation] Epoch:[88/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.890244 | 0.929936 | 0.909657 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.733083 | 0.518617 | 0.607477 | 0.518617 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.672131 | 0.652866 | 0.662359 | 0.652866 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.7      | 0.684783 | 0.692308 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.738182 | 0.648562 | 0.690476 | 0.648562 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 21:47:37,992 - trainer - INFO] - [Epoch Validation] Epoch:[88/100] Total Loss: 39.845126 GL_Loss: 0.004943 CRF_Loss: 39.350847 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.890244 | 0.929936 | 0.909657 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.733083 | 0.518617 | 0.607477 | 0.518617 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.672131 | 0.652866 | 0.662359 | 0.652866 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.7      | 0.684783 | 0.692308 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.738182 | 0.648562 | 0.690476 | 0.648562 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 21:47:53,210 - trainer - INFO] - Train Epoch:[89/100] Step:[10/250] Total Loss: 21.611832 GL_Loss: 0.446305 CRF_Loss: 21.165527\n",
      "[2022-02-17 21:48:06,487 - trainer - INFO] - Train Epoch:[89/100] Step:[20/250] Total Loss: 17.643509 GL_Loss: 0.592727 CRF_Loss: 17.050781\n",
      "[2022-02-17 21:48:21,263 - trainer - INFO] - Train Epoch:[89/100] Step:[30/250] Total Loss: 21.589117 GL_Loss: 0.557134 CRF_Loss: 21.031982\n",
      "[2022-02-17 21:48:34,687 - trainer - INFO] - Train Epoch:[89/100] Step:[40/250] Total Loss: 26.641834 GL_Loss: 0.446644 CRF_Loss: 26.195190\n",
      "[2022-02-17 21:48:48,398 - trainer - INFO] - Train Epoch:[89/100] Step:[50/250] Total Loss: 187.175858 GL_Loss: 0.815510 CRF_Loss: 186.360352\n",
      "[2022-02-17 21:49:07,127 - trainer - INFO] - [Step Validation] Epoch:[89/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.902439 | 0.942675 | 0.922118 | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.727273 | 0.510638 | 0.6      | 0.510638 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.668874 | 0.643312 | 0.655844 | 0.643312 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.736585 | 0.643237 | 0.686754 | 0.643237 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 21:49:21,285 - trainer - INFO] - Train Epoch:[89/100] Step:[60/250] Total Loss: 24.973961 GL_Loss: 0.431358 CRF_Loss: 24.542603\n",
      "[2022-02-17 21:49:35,358 - trainer - INFO] - Train Epoch:[89/100] Step:[70/250] Total Loss: 24.954462 GL_Loss: 0.375482 CRF_Loss: 24.578979\n",
      "[2022-02-17 21:49:50,034 - trainer - INFO] - Train Epoch:[89/100] Step:[80/250] Total Loss: 24.439472 GL_Loss: 0.625752 CRF_Loss: 23.813721\n",
      "[2022-02-17 21:50:04,291 - trainer - INFO] - Train Epoch:[89/100] Step:[90/250] Total Loss: 35.278736 GL_Loss: 0.689016 CRF_Loss: 34.589722\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 21:50:19,362 - trainer - INFO] - Train Epoch:[89/100] Step:[100/250] Total Loss: 9.474724 GL_Loss: 0.631218 CRF_Loss: 8.843506\n",
      "[2022-02-17 21:50:38,229 - trainer - INFO] - [Step Validation] Epoch:[89/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.890244 | 0.929936 | 0.909657 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.74717  | 0.526596 | 0.617785 | 0.526596 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.6875   | 0.665605 | 0.676375 | 0.665605 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688172 | 0.695652 | 0.691892 | 0.695652 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.746973 | 0.657082 | 0.69915  | 0.657082 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 21:50:52,880 - trainer - INFO] - Train Epoch:[89/100] Step:[110/250] Total Loss: 100.645615 GL_Loss: 0.426373 CRF_Loss: 100.219238\n",
      "[2022-02-17 21:51:06,842 - trainer - INFO] - Train Epoch:[89/100] Step:[120/250] Total Loss: 29.090851 GL_Loss: 0.451935 CRF_Loss: 28.638916\n",
      "[2022-02-17 21:51:21,150 - trainer - INFO] - Train Epoch:[89/100] Step:[130/250] Total Loss: 18.590704 GL_Loss: 0.392949 CRF_Loss: 18.197754\n",
      "[2022-02-17 21:51:35,220 - trainer - INFO] - Train Epoch:[89/100] Step:[140/250] Total Loss: 32.145760 GL_Loss: 0.552375 CRF_Loss: 31.593384\n",
      "[2022-02-17 21:51:48,093 - trainer - INFO] - Train Epoch:[89/100] Step:[150/250] Total Loss: 64.695351 GL_Loss: 0.730020 CRF_Loss: 63.965332\n",
      "[2022-02-17 21:52:07,487 - trainer - INFO] - [Step Validation] Epoch:[89/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.901235 | 0.929936 | 0.915361 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.719231 | 0.49734  | 0.58805  | 0.49734  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.695971 | 0.605096 | 0.647359 | 0.605096 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.745223 | 0.623003 | 0.678654 | 0.623003 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 21:52:21,691 - trainer - INFO] - Train Epoch:[89/100] Step:[160/250] Total Loss: 12.056721 GL_Loss: 0.586261 CRF_Loss: 11.470459\n",
      "[2022-02-17 21:52:36,223 - trainer - INFO] - Train Epoch:[89/100] Step:[170/250] Total Loss: 34.137905 GL_Loss: 0.453580 CRF_Loss: 33.684326\n",
      "[2022-02-17 21:52:50,316 - trainer - INFO] - Train Epoch:[89/100] Step:[180/250] Total Loss: 16.857857 GL_Loss: 0.383979 CRF_Loss: 16.473877\n",
      "[2022-02-17 21:53:04,942 - trainer - INFO] - Train Epoch:[89/100] Step:[190/250] Total Loss: 37.748196 GL_Loss: 0.422268 CRF_Loss: 37.325928\n",
      "[2022-02-17 21:53:19,072 - trainer - INFO] - Train Epoch:[89/100] Step:[200/250] Total Loss: 17.073181 GL_Loss: 0.661072 CRF_Loss: 16.412109\n",
      "[2022-02-17 21:53:38,044 - trainer - INFO] - [Step Validation] Epoch:[89/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.890909 | 0.936306 | 0.913043 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.726592 | 0.515957 | 0.603421 | 0.515957 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.674342 | 0.652866 | 0.66343  | 0.652866 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.659341 | 0.652174 | 0.655738 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.732769 | 0.645367 | 0.686297 | 0.645367 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 21:53:52,380 - trainer - INFO] - Train Epoch:[89/100] Step:[210/250] Total Loss: 93.762573 GL_Loss: 0.349365 CRF_Loss: 93.413208\n",
      "[2022-02-17 21:54:05,294 - trainer - INFO] - Train Epoch:[89/100] Step:[220/250] Total Loss: 20.415554 GL_Loss: 0.443752 CRF_Loss: 19.971802\n",
      "[2022-02-17 21:54:19,823 - trainer - INFO] - Train Epoch:[89/100] Step:[230/250] Total Loss: 29.710487 GL_Loss: 0.391640 CRF_Loss: 29.318848\n",
      "[2022-02-17 21:54:34,020 - trainer - INFO] - Train Epoch:[89/100] Step:[240/250] Total Loss: 15.735377 GL_Loss: 0.459742 CRF_Loss: 15.275635\n",
      "[2022-02-17 21:54:48,271 - trainer - INFO] - Train Epoch:[89/100] Step:[250/250] Total Loss: 21.178970 GL_Loss: 0.564712 CRF_Loss: 20.614258\n",
      "[2022-02-17 21:55:07,187 - trainer - INFO] - [Step Validation] Epoch:[89/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.90184  | 0.936306 | 0.91875  | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.734082 | 0.521277 | 0.609642 | 0.521277 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.674576 | 0.633758 | 0.65353  | 0.633758 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.741104 | 0.643237 | 0.688712 | 0.643237 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 21:55:26,193 - trainer - INFO] - [Epoch Validation] Epoch:[89/100] Total Loss: 40.363523 GL_Loss: 0.004977 CRF_Loss: 39.865835 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.90184  | 0.936306 | 0.91875  | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.734082 | 0.521277 | 0.609642 | 0.521277 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.674576 | 0.633758 | 0.65353  | 0.633758 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.741104 | 0.643237 | 0.688712 | 0.643237 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 21:55:40,509 - trainer - INFO] - Train Epoch:[90/100] Step:[10/250] Total Loss: 20.842329 GL_Loss: 0.341108 CRF_Loss: 20.501221\n",
      "[2022-02-17 21:55:54,778 - trainer - INFO] - Train Epoch:[90/100] Step:[20/250] Total Loss: 24.385662 GL_Loss: 0.600749 CRF_Loss: 23.784912\n",
      "[2022-02-17 21:56:09,182 - trainer - INFO] - Train Epoch:[90/100] Step:[30/250] Total Loss: 31.538540 GL_Loss: 0.534084 CRF_Loss: 31.004456\n",
      "[2022-02-17 21:56:23,048 - trainer - INFO] - Train Epoch:[90/100] Step:[40/250] Total Loss: 11.640247 GL_Loss: 0.594959 CRF_Loss: 11.045288\n",
      "[2022-02-17 21:56:37,911 - trainer - INFO] - Train Epoch:[90/100] Step:[50/250] Total Loss: 47.099541 GL_Loss: 0.332208 CRF_Loss: 46.767334\n",
      "[2022-02-17 21:56:57,214 - trainer - INFO] - [Step Validation] Epoch:[90/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.90184  | 0.936306 | 0.91875  | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.740741 | 0.531915 | 0.619195 | 0.531915 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.675676 | 0.636943 | 0.655738 | 0.636943 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.74359  | 0.648562 | 0.692833 | 0.648562 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 21:57:11,546 - trainer - INFO] - Train Epoch:[90/100] Step:[60/250] Total Loss: 29.245716 GL_Loss: 0.555165 CRF_Loss: 28.690552\n",
      "[2022-02-17 21:57:25,750 - trainer - INFO] - Train Epoch:[90/100] Step:[70/250] Total Loss: 34.808319 GL_Loss: 0.273527 CRF_Loss: 34.534790\n",
      "[2022-02-17 21:57:40,251 - trainer - INFO] - Train Epoch:[90/100] Step:[80/250] Total Loss: 13.909801 GL_Loss: 0.483776 CRF_Loss: 13.426025\n",
      "[2022-02-17 21:57:55,110 - trainer - INFO] - Train Epoch:[90/100] Step:[90/250] Total Loss: 53.184292 GL_Loss: 0.441495 CRF_Loss: 52.742798\n",
      "[2022-02-17 21:58:08,729 - trainer - INFO] - Train Epoch:[90/100] Step:[100/250] Total Loss: 27.970732 GL_Loss: 0.674651 CRF_Loss: 27.296082\n",
      "[2022-02-17 21:58:29,841 - trainer - INFO] - [Step Validation] Epoch:[90/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.90184  | 0.936306 | 0.91875  | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.716981 | 0.505319 | 0.592824 | 0.505319 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.680851 | 0.611465 | 0.644295 | 0.611465 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.73875  | 0.629393 | 0.679701 | 0.629393 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 21:58:43,774 - trainer - INFO] - Train Epoch:[90/100] Step:[110/250] Total Loss: 12.259231 GL_Loss: 0.518874 CRF_Loss: 11.740356\n",
      "[2022-02-17 21:58:58,950 - trainer - INFO] - Train Epoch:[90/100] Step:[120/250] Total Loss: 10.929435 GL_Loss: 0.470451 CRF_Loss: 10.458984\n",
      "[2022-02-17 21:59:12,931 - trainer - INFO] - Train Epoch:[90/100] Step:[130/250] Total Loss: 18.348160 GL_Loss: 0.472550 CRF_Loss: 17.875610\n",
      "[2022-02-17 21:59:26,971 - trainer - INFO] - Train Epoch:[90/100] Step:[140/250] Total Loss: 27.263659 GL_Loss: 0.410875 CRF_Loss: 26.852783\n",
      "[2022-02-17 21:59:41,147 - trainer - INFO] - Train Epoch:[90/100] Step:[150/250] Total Loss: 25.473255 GL_Loss: 0.433338 CRF_Loss: 25.039917\n",
      "[2022-02-17 22:00:00,186 - trainer - INFO] - [Step Validation] Epoch:[90/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.896341 | 0.936306 | 0.915888 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.740602 | 0.523936 | 0.613707 | 0.523936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.685619 | 0.652866 | 0.668842 | 0.652866 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.659341 | 0.652174 | 0.655738 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.742683 | 0.648562 | 0.692439 | 0.648562 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 22:00:13,648 - trainer - INFO] - Train Epoch:[90/100] Step:[160/250] Total Loss: 18.405298 GL_Loss: 0.433131 CRF_Loss: 17.972168\n",
      "[2022-02-17 22:00:27,979 - trainer - INFO] - Train Epoch:[90/100] Step:[170/250] Total Loss: 12.225750 GL_Loss: 0.424603 CRF_Loss: 11.801147\n",
      "[2022-02-17 22:00:43,635 - trainer - INFO] - Train Epoch:[90/100] Step:[180/250] Total Loss: 50.877312 GL_Loss: 0.709711 CRF_Loss: 50.167603\n",
      "[2022-02-17 22:00:57,598 - trainer - INFO] - Train Epoch:[90/100] Step:[190/250] Total Loss: 21.153875 GL_Loss: 0.478339 CRF_Loss: 20.675537\n",
      "[2022-02-17 22:01:11,023 - trainer - INFO] - Train Epoch:[90/100] Step:[200/250] Total Loss: 17.363165 GL_Loss: 0.376714 CRF_Loss: 16.986450\n",
      "[2022-02-17 22:01:29,962 - trainer - INFO] - [Step Validation] Epoch:[90/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.896341 | 0.936306 | 0.915888 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.742537 | 0.529255 | 0.618012 | 0.529255 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.67893  | 0.646497 | 0.662316 | 0.646497 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.744214 | 0.650692 | 0.694318 | 0.650692 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 22:01:44,019 - trainer - INFO] - Train Epoch:[90/100] Step:[210/250] Total Loss: 9.211748 GL_Loss: 0.444903 CRF_Loss: 8.766846\n",
      "[2022-02-17 22:01:58,532 - trainer - INFO] - Train Epoch:[90/100] Step:[220/250] Total Loss: 13.222030 GL_Loss: 0.609725 CRF_Loss: 12.612305\n",
      "[2022-02-17 22:02:13,210 - trainer - INFO] - Train Epoch:[90/100] Step:[230/250] Total Loss: 18.751591 GL_Loss: 0.486454 CRF_Loss: 18.265137\n",
      "[2022-02-17 22:02:27,077 - trainer - INFO] - Train Epoch:[90/100] Step:[240/250] Total Loss: 19.724518 GL_Loss: 0.437530 CRF_Loss: 19.286987\n",
      "[2022-02-17 22:02:41,269 - trainer - INFO] - Train Epoch:[90/100] Step:[250/250] Total Loss: 21.772408 GL_Loss: 0.608467 CRF_Loss: 21.163940\n",
      "[2022-02-17 22:03:00,478 - trainer - INFO] - [Step Validation] Epoch:[90/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.90184  | 0.936306 | 0.91875  | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.714829 | 0.5      | 0.588419 | 0.5      |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.672185 | 0.646497 | 0.659091 | 0.646497 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.7      | 0.684783 | 0.692308 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.734719 | 0.640043 | 0.684121 | 0.640043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 22:03:19,741 - trainer - INFO] - [Epoch Validation] Epoch:[90/100] Total Loss: 40.068403 GL_Loss: 0.004974 CRF_Loss: 39.571030 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.90184  | 0.936306 | 0.91875  | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.714829 | 0.5      | 0.588419 | 0.5      |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.672185 | 0.646497 | 0.659091 | 0.646497 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.7      | 0.684783 | 0.692308 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.734719 | 0.640043 | 0.684121 | 0.640043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 22:03:34,851 - trainer - INFO] - Train Epoch:[91/100] Step:[10/250] Total Loss: 19.536749 GL_Loss: 0.488775 CRF_Loss: 19.047974\n",
      "[2022-02-17 22:03:49,579 - trainer - INFO] - Train Epoch:[91/100] Step:[20/250] Total Loss: 8.035112 GL_Loss: 0.409136 CRF_Loss: 7.625977\n",
      "[2022-02-17 22:04:03,764 - trainer - INFO] - Train Epoch:[91/100] Step:[30/250] Total Loss: 47.210018 GL_Loss: 0.317806 CRF_Loss: 46.892212\n",
      "[2022-02-17 22:04:17,744 - trainer - INFO] - Train Epoch:[91/100] Step:[40/250] Total Loss: 22.520527 GL_Loss: 0.354511 CRF_Loss: 22.166016\n",
      "[2022-02-17 22:04:31,816 - trainer - INFO] - Train Epoch:[91/100] Step:[50/250] Total Loss: 36.719238 GL_Loss: 0.490966 CRF_Loss: 36.228271\n",
      "[2022-02-17 22:04:50,822 - trainer - INFO] - [Step Validation] Epoch:[91/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.907975 | 0.942675 | 0.925    | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.710526 | 0.50266  | 0.588785 | 0.50266  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.687075 | 0.643312 | 0.664474 | 0.643312 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.677778 | 0.663043 | 0.67033  | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.738007 | 0.638978 | 0.684932 | 0.638978 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 22:05:05,243 - trainer - INFO] - Train Epoch:[91/100] Step:[60/250] Total Loss: 28.456572 GL_Loss: 0.334257 CRF_Loss: 28.122314\n",
      "[2022-02-17 22:05:19,603 - trainer - INFO] - Train Epoch:[91/100] Step:[70/250] Total Loss: 17.199806 GL_Loss: 0.466774 CRF_Loss: 16.733032\n",
      "[2022-02-17 22:05:34,450 - trainer - INFO] - Train Epoch:[91/100] Step:[80/250] Total Loss: 38.894119 GL_Loss: 0.629469 CRF_Loss: 38.264648\n",
      "[2022-02-17 22:05:50,028 - trainer - INFO] - Train Epoch:[91/100] Step:[90/250] Total Loss: 18.900658 GL_Loss: 0.462669 CRF_Loss: 18.437988\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 22:06:04,115 - trainer - INFO] - Train Epoch:[91/100] Step:[100/250] Total Loss: 144.968246 GL_Loss: 0.548931 CRF_Loss: 144.419312\n",
      "[2022-02-17 22:06:23,052 - trainer - INFO] - [Step Validation] Epoch:[91/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.735849 | 0.518617 | 0.608424 | 0.518617 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.678808 | 0.652866 | 0.665584 | 0.652866 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.741463 | 0.647497 | 0.691302 | 0.647497 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 22:06:37,282 - trainer - INFO] - Train Epoch:[91/100] Step:[110/250] Total Loss: 54.802261 GL_Loss: 0.375992 CRF_Loss: 54.426270\n",
      "[2022-02-17 22:06:51,039 - trainer - INFO] - Train Epoch:[91/100] Step:[120/250] Total Loss: 47.477749 GL_Loss: 0.409025 CRF_Loss: 47.068726\n",
      "[2022-02-17 22:07:04,544 - trainer - INFO] - Train Epoch:[91/100] Step:[130/250] Total Loss: 147.907791 GL_Loss: 0.459789 CRF_Loss: 147.447998\n",
      "[2022-02-17 22:07:18,726 - trainer - INFO] - Train Epoch:[91/100] Step:[140/250] Total Loss: 12.501715 GL_Loss: 0.411627 CRF_Loss: 12.090088\n",
      "[2022-02-17 22:07:32,887 - trainer - INFO] - Train Epoch:[91/100] Step:[150/250] Total Loss: 31.084780 GL_Loss: 0.457582 CRF_Loss: 30.627197\n",
      "[2022-02-17 22:07:52,162 - trainer - INFO] - [Step Validation] Epoch:[91/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.890244 | 0.929936 | 0.909657 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.736842 | 0.521277 | 0.610592 | 0.521277 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.683007 | 0.665605 | 0.674194 | 0.665605 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.677778 | 0.663043 | 0.67033  | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.74092  | 0.651757 | 0.693484 | 0.651757 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 22:08:06,204 - trainer - INFO] - Train Epoch:[91/100] Step:[160/250] Total Loss: 32.034702 GL_Loss: 0.491612 CRF_Loss: 31.543091\n",
      "[2022-02-17 22:08:20,212 - trainer - INFO] - Train Epoch:[91/100] Step:[170/250] Total Loss: 12.210919 GL_Loss: 0.727887 CRF_Loss: 11.483032\n",
      "[2022-02-17 22:08:33,980 - trainer - INFO] - Train Epoch:[91/100] Step:[180/250] Total Loss: 26.952095 GL_Loss: 0.813789 CRF_Loss: 26.138306\n",
      "[2022-02-17 22:08:48,142 - trainer - INFO] - Train Epoch:[91/100] Step:[190/250] Total Loss: 34.465324 GL_Loss: 0.473382 CRF_Loss: 33.991943\n",
      "[2022-02-17 22:09:03,249 - trainer - INFO] - Train Epoch:[91/100] Step:[200/250] Total Loss: 26.519800 GL_Loss: 0.791529 CRF_Loss: 25.728271\n",
      "[2022-02-17 22:09:22,437 - trainer - INFO] - [Step Validation] Epoch:[91/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.91358  | 0.942675 | 0.9279   | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.714286 | 0.505319 | 0.5919   | 0.505319 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.672241 | 0.640127 | 0.655791 | 0.640127 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.735618 | 0.640043 | 0.68451  | 0.640043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 22:09:36,054 - trainer - INFO] - Train Epoch:[91/100] Step:[210/250] Total Loss: 68.875481 GL_Loss: 0.410152 CRF_Loss: 68.465332\n",
      "[2022-02-17 22:09:49,496 - trainer - INFO] - Train Epoch:[91/100] Step:[220/250] Total Loss: 14.503038 GL_Loss: 0.551867 CRF_Loss: 13.951172\n",
      "[2022-02-17 22:10:03,948 - trainer - INFO] - Train Epoch:[91/100] Step:[230/250] Total Loss: 41.473690 GL_Loss: 0.336116 CRF_Loss: 41.137573\n",
      "[2022-02-17 22:10:17,112 - trainer - INFO] - Train Epoch:[91/100] Step:[240/250] Total Loss: 266.262512 GL_Loss: 0.605522 CRF_Loss: 265.656982\n",
      "[2022-02-17 22:10:31,462 - trainer - INFO] - Train Epoch:[91/100] Step:[250/250] Total Loss: 26.933653 GL_Loss: 0.423887 CRF_Loss: 26.509766\n",
      "[2022-02-17 22:10:50,598 - trainer - INFO] - [Step Validation] Epoch:[91/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.889571 | 0.923567 | 0.90625  | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.735849 | 0.518617 | 0.608424 | 0.518617 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.683007 | 0.665605 | 0.674194 | 0.665605 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.659341 | 0.652174 | 0.655738 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.738182 | 0.648562 | 0.690476 | 0.648562 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 22:11:09,799 - trainer - INFO] - [Epoch Validation] Epoch:[91/100] Total Loss: 39.755600 GL_Loss: 0.004922 CRF_Loss: 39.263374 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.889571 | 0.923567 | 0.90625  | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.735849 | 0.518617 | 0.608424 | 0.518617 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.683007 | 0.665605 | 0.674194 | 0.665605 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.659341 | 0.652174 | 0.655738 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.738182 | 0.648562 | 0.690476 | 0.648562 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 22:11:24,341 - trainer - INFO] - Train Epoch:[92/100] Step:[10/250] Total Loss: 16.009266 GL_Loss: 0.526966 CRF_Loss: 15.482300\n",
      "[2022-02-17 22:11:39,244 - trainer - INFO] - Train Epoch:[92/100] Step:[20/250] Total Loss: 25.248215 GL_Loss: 0.542282 CRF_Loss: 24.705933\n",
      "[2022-02-17 22:11:53,485 - trainer - INFO] - Train Epoch:[92/100] Step:[30/250] Total Loss: 19.598366 GL_Loss: 0.387429 CRF_Loss: 19.210938\n",
      "[2022-02-17 22:12:07,461 - trainer - INFO] - Train Epoch:[92/100] Step:[40/250] Total Loss: 33.062168 GL_Loss: 0.648474 CRF_Loss: 32.413696\n",
      "[2022-02-17 22:12:21,084 - trainer - INFO] - Train Epoch:[92/100] Step:[50/250] Total Loss: 33.415871 GL_Loss: 0.943091 CRF_Loss: 32.472778\n",
      "[2022-02-17 22:12:40,228 - trainer - INFO] - [Step Validation] Epoch:[92/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.90184  | 0.936306 | 0.91875  | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.745318 | 0.529255 | 0.618974 | 0.529255 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.686869 | 0.649682 | 0.667758 | 0.649682 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.692308 | 0.684783 | 0.688525 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.749389 | 0.652822 | 0.69778  | 0.652822 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 22:12:54,820 - trainer - INFO] - Train Epoch:[92/100] Step:[60/250] Total Loss: 42.591415 GL_Loss: 0.402573 CRF_Loss: 42.188843\n",
      "[2022-02-17 22:13:09,607 - trainer - INFO] - Train Epoch:[92/100] Step:[70/250] Total Loss: 24.872730 GL_Loss: 0.702931 CRF_Loss: 24.169800\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 22:13:23,942 - trainer - INFO] - Train Epoch:[92/100] Step:[80/250] Total Loss: 59.398632 GL_Loss: 0.538402 CRF_Loss: 58.860229\n",
      "[2022-02-17 22:13:37,927 - trainer - INFO] - Train Epoch:[92/100] Step:[90/250] Total Loss: 37.295044 GL_Loss: 0.577149 CRF_Loss: 36.717896\n",
      "[2022-02-17 22:13:51,178 - trainer - INFO] - Train Epoch:[92/100] Step:[100/250] Total Loss: 25.677456 GL_Loss: 0.870510 CRF_Loss: 24.806946\n",
      "[2022-02-17 22:14:10,056 - trainer - INFO] - [Step Validation] Epoch:[92/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.890244 | 0.929936 | 0.909657 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.738636 | 0.518617 | 0.609375 | 0.518617 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.677632 | 0.656051 | 0.666667 | 0.656051 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.677778 | 0.663043 | 0.67033  | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.739659 | 0.647497 | 0.690517 | 0.647497 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 22:14:24,000 - trainer - INFO] - Train Epoch:[92/100] Step:[110/250] Total Loss: 9.299249 GL_Loss: 0.742364 CRF_Loss: 8.556885\n",
      "[2022-02-17 22:14:37,965 - trainer - INFO] - Train Epoch:[92/100] Step:[120/250] Total Loss: 40.606171 GL_Loss: 0.367279 CRF_Loss: 40.238892\n",
      "[2022-02-17 22:14:53,413 - trainer - INFO] - Train Epoch:[92/100] Step:[130/250] Total Loss: 25.565632 GL_Loss: 0.530720 CRF_Loss: 25.034912\n",
      "[2022-02-17 22:15:07,533 - trainer - INFO] - Train Epoch:[92/100] Step:[140/250] Total Loss: 71.867905 GL_Loss: 0.468978 CRF_Loss: 71.398926\n",
      "[2022-02-17 22:15:22,025 - trainer - INFO] - Train Epoch:[92/100] Step:[150/250] Total Loss: 7.198906 GL_Loss: 0.557793 CRF_Loss: 6.641113\n",
      "[2022-02-17 22:15:41,144 - trainer - INFO] - [Step Validation] Epoch:[92/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.890244 | 0.929936 | 0.909657 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.733333 | 0.526596 | 0.613003 | 0.526596 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.681967 | 0.66242  | 0.672052 | 0.66242  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.677778 | 0.663043 | 0.67033  | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.739445 | 0.652822 | 0.693439 | 0.652822 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 22:15:55,279 - trainer - INFO] - Train Epoch:[92/100] Step:[160/250] Total Loss: 13.072090 GL_Loss: 0.729805 CRF_Loss: 12.342285\n",
      "[2022-02-17 22:16:09,564 - trainer - INFO] - Train Epoch:[92/100] Step:[170/250] Total Loss: 18.480825 GL_Loss: 0.552115 CRF_Loss: 17.928711\n",
      "[2022-02-17 22:16:24,292 - trainer - INFO] - Train Epoch:[92/100] Step:[180/250] Total Loss: 24.530083 GL_Loss: 0.462455 CRF_Loss: 24.067627\n",
      "[2022-02-17 22:16:38,957 - trainer - INFO] - Train Epoch:[92/100] Step:[190/250] Total Loss: 35.170441 GL_Loss: 0.334380 CRF_Loss: 34.836060\n",
      "[2022-02-17 22:16:53,542 - trainer - INFO] - Train Epoch:[92/100] Step:[200/250] Total Loss: 95.532433 GL_Loss: 0.474571 CRF_Loss: 95.057861\n",
      "[2022-02-17 22:17:12,702 - trainer - INFO] - [Step Validation] Epoch:[92/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.896341 | 0.936306 | 0.915888 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.726592 | 0.515957 | 0.603421 | 0.515957 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.677852 | 0.643312 | 0.660131 | 0.643312 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.681319 | 0.673913 | 0.677596 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.737805 | 0.644302 | 0.687891 | 0.644302 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 22:17:26,367 - trainer - INFO] - Train Epoch:[92/100] Step:[210/250] Total Loss: 36.537285 GL_Loss: 0.448539 CRF_Loss: 36.088745\n",
      "[2022-02-17 22:17:39,937 - trainer - INFO] - Train Epoch:[92/100] Step:[220/250] Total Loss: 51.824730 GL_Loss: 0.266747 CRF_Loss: 51.557983\n",
      "[2022-02-17 22:17:53,873 - trainer - INFO] - Train Epoch:[92/100] Step:[230/250] Total Loss: 59.713062 GL_Loss: 0.462330 CRF_Loss: 59.250732\n",
      "[2022-02-17 22:18:08,415 - trainer - INFO] - Train Epoch:[92/100] Step:[240/250] Total Loss: 49.964394 GL_Loss: 0.424353 CRF_Loss: 49.540039\n",
      "[2022-02-17 22:18:22,542 - trainer - INFO] - Train Epoch:[92/100] Step:[250/250] Total Loss: 53.692123 GL_Loss: 0.354234 CRF_Loss: 53.337891\n",
      "[2022-02-17 22:18:41,708 - trainer - INFO] - [Step Validation] Epoch:[92/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.890244 | 0.929936 | 0.909657 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.740602 | 0.523936 | 0.613707 | 0.523936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.680921 | 0.659236 | 0.669903 | 0.659236 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.666667 | 0.652174 | 0.659341 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.740291 | 0.649627 | 0.692002 | 0.649627 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 22:19:00,869 - trainer - INFO] - [Epoch Validation] Epoch:[92/100] Total Loss: 39.620843 GL_Loss: 0.004927 CRF_Loss: 39.128171 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.890244 | 0.929936 | 0.909657 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.740602 | 0.523936 | 0.613707 | 0.523936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.680921 | 0.659236 | 0.669903 | 0.659236 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.666667 | 0.652174 | 0.659341 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.740291 | 0.649627 | 0.692002 | 0.649627 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 22:19:15,831 - trainer - INFO] - Train Epoch:[93/100] Step:[10/250] Total Loss: 20.680597 GL_Loss: 0.392023 CRF_Loss: 20.288574\n",
      "[2022-02-17 22:19:31,400 - trainer - INFO] - Train Epoch:[93/100] Step:[20/250] Total Loss: 74.799583 GL_Loss: 0.475368 CRF_Loss: 74.324219\n",
      "[2022-02-17 22:19:45,353 - trainer - INFO] - Train Epoch:[93/100] Step:[30/250] Total Loss: 46.002239 GL_Loss: 0.399090 CRF_Loss: 45.603149\n",
      "[2022-02-17 22:19:59,500 - trainer - INFO] - Train Epoch:[93/100] Step:[40/250] Total Loss: 37.196190 GL_Loss: 0.278955 CRF_Loss: 36.917236\n",
      "[2022-02-17 22:20:13,457 - trainer - INFO] - Train Epoch:[93/100] Step:[50/250] Total Loss: 41.405846 GL_Loss: 0.603965 CRF_Loss: 40.801880\n",
      "[2022-02-17 22:20:32,426 - trainer - INFO] - [Step Validation] Epoch:[93/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.896341 | 0.936306 | 0.915888 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.736059 | 0.526596 | 0.613953 | 0.526596 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.68     | 0.649682 | 0.664495 | 0.649682 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.742406 | 0.650692 | 0.69353  | 0.650692 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 22:20:47,164 - trainer - INFO] - Train Epoch:[93/100] Step:[60/250] Total Loss: 56.947014 GL_Loss: 0.337151 CRF_Loss: 56.609863\n",
      "[2022-02-17 22:21:00,534 - trainer - INFO] - Train Epoch:[93/100] Step:[70/250] Total Loss: 35.788357 GL_Loss: 0.813504 CRF_Loss: 34.974854\n",
      "[2022-02-17 22:21:14,896 - trainer - INFO] - Train Epoch:[93/100] Step:[80/250] Total Loss: 12.042990 GL_Loss: 0.409201 CRF_Loss: 11.633789\n",
      "[2022-02-17 22:21:27,639 - trainer - INFO] - Train Epoch:[93/100] Step:[90/250] Total Loss: 28.676758 GL_Loss: 0.527101 CRF_Loss: 28.149658\n",
      "[2022-02-17 22:21:41,183 - trainer - INFO] - Train Epoch:[93/100] Step:[100/250] Total Loss: 28.894819 GL_Loss: 0.426923 CRF_Loss: 28.467896\n",
      "[2022-02-17 22:22:02,284 - trainer - INFO] - [Step Validation] Epoch:[93/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.907975 | 0.942675 | 0.925    | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.735849 | 0.518617 | 0.608424 | 0.518617 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.673401 | 0.636943 | 0.654664 | 0.636943 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.742331 | 0.644302 | 0.689852 | 0.644302 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 22:22:16,739 - trainer - INFO] - Train Epoch:[93/100] Step:[110/250] Total Loss: 13.968385 GL_Loss: 0.607667 CRF_Loss: 13.360718\n",
      "[2022-02-17 22:22:31,365 - trainer - INFO] - Train Epoch:[93/100] Step:[120/250] Total Loss: 77.324036 GL_Loss: 0.412412 CRF_Loss: 76.911621\n",
      "[2022-02-17 22:22:47,594 - trainer - INFO] - Train Epoch:[93/100] Step:[130/250] Total Loss: 41.878792 GL_Loss: 0.606451 CRF_Loss: 41.272339\n",
      "[2022-02-17 22:23:02,270 - trainer - INFO] - Train Epoch:[93/100] Step:[140/250] Total Loss: 81.948372 GL_Loss: 0.452036 CRF_Loss: 81.496338\n",
      "[2022-02-17 22:23:16,268 - trainer - INFO] - Train Epoch:[93/100] Step:[150/250] Total Loss: 14.662427 GL_Loss: 0.695142 CRF_Loss: 13.967285\n",
      "[2022-02-17 22:23:35,361 - trainer - INFO] - [Step Validation] Epoch:[93/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.90184  | 0.936306 | 0.91875  | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.737037 | 0.529255 | 0.616099 | 0.529255 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.672241 | 0.640127 | 0.655791 | 0.640127 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.7      | 0.684783 | 0.692308 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.742092 | 0.649627 | 0.692788 | 0.649627 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 22:23:49,893 - trainer - INFO] - Train Epoch:[93/100] Step:[160/250] Total Loss: 23.320293 GL_Loss: 0.625836 CRF_Loss: 22.694458\n",
      "[2022-02-17 22:24:03,768 - trainer - INFO] - Train Epoch:[93/100] Step:[170/250] Total Loss: 46.683804 GL_Loss: 0.779386 CRF_Loss: 45.904419\n",
      "[2022-02-17 22:24:18,386 - trainer - INFO] - Train Epoch:[93/100] Step:[180/250] Total Loss: 14.103187 GL_Loss: 0.466712 CRF_Loss: 13.636475\n",
      "[2022-02-17 22:24:32,493 - trainer - INFO] - Train Epoch:[93/100] Step:[190/250] Total Loss: 24.739866 GL_Loss: 0.555052 CRF_Loss: 24.184814\n",
      "[2022-02-17 22:24:47,109 - trainer - INFO] - Train Epoch:[93/100] Step:[200/250] Total Loss: 36.114048 GL_Loss: 0.408237 CRF_Loss: 35.705811\n",
      "[2022-02-17 22:25:06,158 - trainer - INFO] - [Step Validation] Epoch:[93/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.91358  | 0.942675 | 0.9279   | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.728302 | 0.513298 | 0.602184 | 0.513298 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.681356 | 0.640127 | 0.660099 | 0.640127 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.743842 | 0.643237 | 0.689891 | 0.643237 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 22:25:20,094 - trainer - INFO] - Train Epoch:[93/100] Step:[210/250] Total Loss: 26.452055 GL_Loss: 0.553617 CRF_Loss: 25.898438\n",
      "[2022-02-17 22:25:34,960 - trainer - INFO] - Train Epoch:[93/100] Step:[220/250] Total Loss: 19.901186 GL_Loss: 0.522524 CRF_Loss: 19.378662\n",
      "[2022-02-17 22:25:48,926 - trainer - INFO] - Train Epoch:[93/100] Step:[230/250] Total Loss: 13.258083 GL_Loss: 0.453030 CRF_Loss: 12.805054\n",
      "[2022-02-17 22:26:02,562 - trainer - INFO] - Train Epoch:[93/100] Step:[240/250] Total Loss: 98.524597 GL_Loss: 0.596127 CRF_Loss: 97.928467\n",
      "[2022-02-17 22:26:15,887 - trainer - INFO] - Train Epoch:[93/100] Step:[250/250] Total Loss: 30.982956 GL_Loss: 0.336471 CRF_Loss: 30.646484\n",
      "[2022-02-17 22:26:35,027 - trainer - INFO] - [Step Validation] Epoch:[93/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.901235 | 0.929936 | 0.915361 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.739623 | 0.521277 | 0.611544 | 0.521277 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.68543  | 0.659236 | 0.672078 | 0.659236 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.666667 | 0.673913 | 0.67027  | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.743309 | 0.650692 | 0.693924 | 0.650692 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 22:26:54,164 - trainer - INFO] - [Epoch Validation] Epoch:[93/100] Total Loss: 39.526431 GL_Loss: 0.004896 CRF_Loss: 39.036794 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.901235 | 0.929936 | 0.915361 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.739623 | 0.521277 | 0.611544 | 0.521277 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.68543  | 0.659236 | 0.672078 | 0.659236 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.666667 | 0.673913 | 0.67027  | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.743309 | 0.650692 | 0.693924 | 0.650692 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 22:27:09,778 - trainer - INFO] - Train Epoch:[94/100] Step:[10/250] Total Loss: 40.115059 GL_Loss: 0.391547 CRF_Loss: 39.723511\n",
      "[2022-02-17 22:27:23,869 - trainer - INFO] - Train Epoch:[94/100] Step:[20/250] Total Loss: 10.616677 GL_Loss: 0.335305 CRF_Loss: 10.281372\n",
      "[2022-02-17 22:27:37,132 - trainer - INFO] - Train Epoch:[94/100] Step:[30/250] Total Loss: 15.013401 GL_Loss: 0.481053 CRF_Loss: 14.532349\n",
      "[2022-02-17 22:27:51,079 - trainer - INFO] - Train Epoch:[94/100] Step:[40/250] Total Loss: 37.818195 GL_Loss: 0.390462 CRF_Loss: 37.427734\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 22:28:04,593 - trainer - INFO] - Train Epoch:[94/100] Step:[50/250] Total Loss: 21.567635 GL_Loss: 0.560432 CRF_Loss: 21.007202\n",
      "[2022-02-17 22:28:23,494 - trainer - INFO] - [Step Validation] Epoch:[94/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.889571 | 0.923567 | 0.90625  | 0.923567 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.731343 | 0.521277 | 0.608696 | 0.521277 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.680921 | 0.659236 | 0.669903 | 0.659236 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.659341 | 0.652174 | 0.655738 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.736077 | 0.647497 | 0.688952 | 0.647497 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 22:28:37,924 - trainer - INFO] - Train Epoch:[94/100] Step:[60/250] Total Loss: 33.488827 GL_Loss: 0.411679 CRF_Loss: 33.077148\n",
      "[2022-02-17 22:28:51,889 - trainer - INFO] - Train Epoch:[94/100] Step:[70/250] Total Loss: 24.225386 GL_Loss: 0.415449 CRF_Loss: 23.809937\n",
      "[2022-02-17 22:29:05,802 - trainer - INFO] - Train Epoch:[94/100] Step:[80/250] Total Loss: 32.620621 GL_Loss: 0.430559 CRF_Loss: 32.190063\n",
      "[2022-02-17 22:29:19,953 - trainer - INFO] - Train Epoch:[94/100] Step:[90/250] Total Loss: 13.321211 GL_Loss: 0.583662 CRF_Loss: 12.737549\n",
      "[2022-02-17 22:29:35,298 - trainer - INFO] - Train Epoch:[94/100] Step:[100/250] Total Loss: 22.463219 GL_Loss: 0.661766 CRF_Loss: 21.801453\n",
      "[2022-02-17 22:29:54,476 - trainer - INFO] - [Step Validation] Epoch:[94/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.90184  | 0.936306 | 0.91875  | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.75     | 0.534574 | 0.624224 | 0.534574 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.677741 | 0.649682 | 0.663415 | 0.649682 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.746959 | 0.653887 | 0.697331 | 0.653887 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 22:30:08,316 - trainer - INFO] - Train Epoch:[94/100] Step:[110/250] Total Loss: 16.837648 GL_Loss: 0.443849 CRF_Loss: 16.393799\n",
      "[2022-02-17 22:30:23,712 - trainer - INFO] - Train Epoch:[94/100] Step:[120/250] Total Loss: 20.957157 GL_Loss: 0.558965 CRF_Loss: 20.398193\n",
      "[2022-02-17 22:30:38,090 - trainer - INFO] - Train Epoch:[94/100] Step:[130/250] Total Loss: 48.789337 GL_Loss: 0.391020 CRF_Loss: 48.398315\n",
      "[2022-02-17 22:30:52,775 - trainer - INFO] - Train Epoch:[94/100] Step:[140/250] Total Loss: 19.302269 GL_Loss: 0.601280 CRF_Loss: 18.700989\n",
      "[2022-02-17 22:31:06,881 - trainer - INFO] - Train Epoch:[94/100] Step:[150/250] Total Loss: 12.868931 GL_Loss: 0.293614 CRF_Loss: 12.575317\n",
      "[2022-02-17 22:31:25,962 - trainer - INFO] - [Step Validation] Epoch:[94/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.896341 | 0.936306 | 0.915888 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.710526 | 0.50266  | 0.588785 | 0.50266  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.676768 | 0.640127 | 0.657938 | 0.640127 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.73317  | 0.637913 | 0.682232 | 0.637913 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 22:31:39,835 - trainer - INFO] - Train Epoch:[94/100] Step:[160/250] Total Loss: 26.667831 GL_Loss: 0.489730 CRF_Loss: 26.178101\n",
      "[2022-02-17 22:31:54,486 - trainer - INFO] - Train Epoch:[94/100] Step:[170/250] Total Loss: 74.575539 GL_Loss: 0.426245 CRF_Loss: 74.149292\n",
      "[2022-02-17 22:32:09,157 - trainer - INFO] - Train Epoch:[94/100] Step:[180/250] Total Loss: 20.653723 GL_Loss: 0.780798 CRF_Loss: 19.872925\n",
      "[2022-02-17 22:32:23,236 - trainer - INFO] - Train Epoch:[94/100] Step:[190/250] Total Loss: 15.258705 GL_Loss: 0.563881 CRF_Loss: 14.694824\n",
      "[2022-02-17 22:32:37,029 - trainer - INFO] - Train Epoch:[94/100] Step:[200/250] Total Loss: 50.122540 GL_Loss: 0.466289 CRF_Loss: 49.656250\n",
      "[2022-02-17 22:32:56,107 - trainer - INFO] - [Step Validation] Epoch:[94/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.901235 | 0.929936 | 0.915361 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.750943 | 0.529255 | 0.620905 | 0.529255 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.68543  | 0.659236 | 0.672078 | 0.659236 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.749695 | 0.653887 | 0.698521 | 0.653887 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 22:33:10,763 - trainer - INFO] - Train Epoch:[94/100] Step:[210/250] Total Loss: 63.933224 GL_Loss: 0.327512 CRF_Loss: 63.605713\n",
      "[2022-02-17 22:33:24,233 - trainer - INFO] - Train Epoch:[94/100] Step:[220/250] Total Loss: 339.178558 GL_Loss: 0.462740 CRF_Loss: 338.715820\n",
      "[2022-02-17 22:33:38,534 - trainer - INFO] - Train Epoch:[94/100] Step:[230/250] Total Loss: 10.825717 GL_Loss: 0.415805 CRF_Loss: 10.409912\n",
      "[2022-02-17 22:33:53,641 - trainer - INFO] - Train Epoch:[94/100] Step:[240/250] Total Loss: 17.109751 GL_Loss: 0.399423 CRF_Loss: 16.710327\n",
      "[2022-02-17 22:34:08,035 - trainer - INFO] - Train Epoch:[94/100] Step:[250/250] Total Loss: 43.337254 GL_Loss: 0.351169 CRF_Loss: 42.986084\n",
      "[2022-02-17 22:34:27,139 - trainer - INFO] - [Step Validation] Epoch:[94/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.70566  | 0.49734  | 0.583463 | 0.49734  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.676768 | 0.640127 | 0.657938 | 0.640127 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.681319 | 0.673913 | 0.677596 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.730392 | 0.634718 | 0.679202 | 0.634718 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 22:34:48,381 - trainer - INFO] - [Epoch Validation] Epoch:[94/100] Total Loss: 40.237909 GL_Loss: 0.004991 CRF_Loss: 39.738776 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.70566  | 0.49734  | 0.583463 | 0.49734  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.676768 | 0.640127 | 0.657938 | 0.640127 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.681319 | 0.673913 | 0.677596 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.730392 | 0.634718 | 0.679202 | 0.634718 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 22:35:03,329 - trainer - INFO] - Train Epoch:[95/100] Step:[10/250] Total Loss: 18.967260 GL_Loss: 0.462987 CRF_Loss: 18.504272\n",
      "[2022-02-17 22:35:17,704 - trainer - INFO] - Train Epoch:[95/100] Step:[20/250] Total Loss: 8.242240 GL_Loss: 0.408988 CRF_Loss: 7.833252\n",
      "[2022-02-17 22:35:33,061 - trainer - INFO] - Train Epoch:[95/100] Step:[30/250] Total Loss: 22.748562 GL_Loss: 0.642971 CRF_Loss: 22.105591\n",
      "[2022-02-17 22:35:47,215 - trainer - INFO] - Train Epoch:[95/100] Step:[40/250] Total Loss: 67.506584 GL_Loss: 0.408681 CRF_Loss: 67.097900\n",
      "[2022-02-17 22:36:01,311 - trainer - INFO] - Train Epoch:[95/100] Step:[50/250] Total Loss: 14.945045 GL_Loss: 0.538429 CRF_Loss: 14.406616\n",
      "[2022-02-17 22:36:20,410 - trainer - INFO] - [Step Validation] Epoch:[95/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.907407 | 0.936306 | 0.92163  | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.69962  | 0.489362 | 0.5759   | 0.489362 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.68662  | 0.621019 | 0.652174 | 0.621019 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.73592  | 0.626198 | 0.67664  | 0.626198 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 22:36:34,454 - trainer - INFO] - Train Epoch:[95/100] Step:[60/250] Total Loss: 31.080301 GL_Loss: 0.673441 CRF_Loss: 30.406860\n",
      "[2022-02-17 22:36:47,870 - trainer - INFO] - Train Epoch:[95/100] Step:[70/250] Total Loss: 41.189102 GL_Loss: 0.502457 CRF_Loss: 40.686646\n",
      "[2022-02-17 22:37:03,219 - trainer - INFO] - Train Epoch:[95/100] Step:[80/250] Total Loss: 17.758625 GL_Loss: 0.661702 CRF_Loss: 17.096924\n",
      "[2022-02-17 22:37:17,483 - trainer - INFO] - Train Epoch:[95/100] Step:[90/250] Total Loss: 30.743750 GL_Loss: 0.490699 CRF_Loss: 30.253052\n",
      "[2022-02-17 22:37:31,152 - trainer - INFO] - Train Epoch:[95/100] Step:[100/250] Total Loss: 26.465668 GL_Loss: 1.098114 CRF_Loss: 25.367554\n",
      "[2022-02-17 22:37:50,257 - trainer - INFO] - [Step Validation] Epoch:[95/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.90184  | 0.936306 | 0.91875  | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.701149 | 0.486702 | 0.574568 | 0.486702 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.681507 | 0.633758 | 0.656766 | 0.633758 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.733251 | 0.629393 | 0.677364 | 0.629393 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 22:38:05,197 - trainer - INFO] - Train Epoch:[95/100] Step:[110/250] Total Loss: 17.249271 GL_Loss: 0.500003 CRF_Loss: 16.749268\n",
      "[2022-02-17 22:38:19,745 - trainer - INFO] - Train Epoch:[95/100] Step:[120/250] Total Loss: 26.921141 GL_Loss: 0.419553 CRF_Loss: 26.501587\n",
      "[2022-02-17 22:38:33,877 - trainer - INFO] - Train Epoch:[95/100] Step:[130/250] Total Loss: 54.714169 GL_Loss: 0.285947 CRF_Loss: 54.428223\n",
      "[2022-02-17 22:38:47,533 - trainer - INFO] - Train Epoch:[95/100] Step:[140/250] Total Loss: 15.744512 GL_Loss: 0.441899 CRF_Loss: 15.302612\n",
      "[2022-02-17 22:39:01,538 - trainer - INFO] - Train Epoch:[95/100] Step:[150/250] Total Loss: 11.745970 GL_Loss: 0.667234 CRF_Loss: 11.078735\n",
      "[2022-02-17 22:39:20,603 - trainer - INFO] - [Step Validation] Epoch:[95/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.896341 | 0.936306 | 0.915888 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.737828 | 0.523936 | 0.612753 | 0.523936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.68543  | 0.659236 | 0.672078 | 0.659236 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.744836 | 0.652822 | 0.6958   | 0.652822 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 22:39:34,391 - trainer - INFO] - Train Epoch:[95/100] Step:[160/250] Total Loss: 318.467438 GL_Loss: 0.487947 CRF_Loss: 317.979492\n",
      "[2022-02-17 22:39:48,626 - trainer - INFO] - Train Epoch:[95/100] Step:[170/250] Total Loss: 43.786263 GL_Loss: 0.384652 CRF_Loss: 43.401611\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 22:40:03,274 - trainer - INFO] - Train Epoch:[95/100] Step:[180/250] Total Loss: 30.917765 GL_Loss: 0.534341 CRF_Loss: 30.383423\n",
      "[2022-02-17 22:40:18,146 - trainer - INFO] - Train Epoch:[95/100] Step:[190/250] Total Loss: 10.804144 GL_Loss: 0.477239 CRF_Loss: 10.326904\n",
      "[2022-02-17 22:40:33,273 - trainer - INFO] - Train Epoch:[95/100] Step:[200/250] Total Loss: 25.354950 GL_Loss: 0.460540 CRF_Loss: 24.894409\n",
      "[2022-02-17 22:40:52,394 - trainer - INFO] - [Step Validation] Epoch:[95/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.90184  | 0.936306 | 0.91875  | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.740602 | 0.523936 | 0.613707 | 0.523936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.680135 | 0.643312 | 0.661211 | 0.643312 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.7      | 0.684783 | 0.692308 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.746324 | 0.648562 | 0.694017 | 0.648562 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 22:41:07,065 - trainer - INFO] - Train Epoch:[95/100] Step:[210/250] Total Loss: 33.732941 GL_Loss: 0.435822 CRF_Loss: 33.297119\n",
      "[2022-02-17 22:41:21,050 - trainer - INFO] - Train Epoch:[95/100] Step:[220/250] Total Loss: 39.576721 GL_Loss: 0.326231 CRF_Loss: 39.250488\n",
      "[2022-02-17 22:41:34,597 - trainer - INFO] - Train Epoch:[95/100] Step:[230/250] Total Loss: 16.355928 GL_Loss: 0.522066 CRF_Loss: 15.833862\n",
      "[2022-02-17 22:41:49,212 - trainer - INFO] - Train Epoch:[95/100] Step:[240/250] Total Loss: 66.133980 GL_Loss: 0.532665 CRF_Loss: 65.601318\n",
      "[2022-02-17 22:42:02,900 - trainer - INFO] - Train Epoch:[95/100] Step:[250/250] Total Loss: 19.160711 GL_Loss: 0.407537 CRF_Loss: 18.753174\n",
      "[2022-02-17 22:42:22,075 - trainer - INFO] - [Step Validation] Epoch:[95/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.890244 | 0.929936 | 0.909657 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.74812  | 0.529255 | 0.619938 | 0.529255 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.693333 | 0.66242  | 0.677524 | 0.66242  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.692308 | 0.684783 | 0.688525 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.750305 | 0.656017 | 0.7      | 0.656017 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 22:42:24,089 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 22:42:43,674 - trainer - INFO] - [Epoch Validation] Epoch:[95/100] Total Loss: 40.165551 GL_Loss: 0.004968 CRF_Loss: 39.668724 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.890244 | 0.929936 | 0.909657 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.74812  | 0.529255 | 0.619938 | 0.529255 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.693333 | 0.66242  | 0.677524 | 0.66242  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.692308 | 0.684783 | 0.688525 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.750305 | 0.656017 | 0.7      | 0.656017 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 22:42:58,354 - trainer - INFO] - Train Epoch:[96/100] Step:[10/250] Total Loss: 44.051212 GL_Loss: 1.005923 CRF_Loss: 43.045288\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 22:43:13,782 - trainer - INFO] - Train Epoch:[96/100] Step:[20/250] Total Loss: 37.036018 GL_Loss: 0.651253 CRF_Loss: 36.384766\n",
      "[2022-02-17 22:43:28,397 - trainer - INFO] - Train Epoch:[96/100] Step:[30/250] Total Loss: 63.684296 GL_Loss: 0.492891 CRF_Loss: 63.191406\n",
      "[2022-02-17 22:43:43,317 - trainer - INFO] - Train Epoch:[96/100] Step:[40/250] Total Loss: 39.541496 GL_Loss: 1.054313 CRF_Loss: 38.487183\n",
      "[2022-02-17 22:43:57,615 - trainer - INFO] - Train Epoch:[96/100] Step:[50/250] Total Loss: 47.364178 GL_Loss: 0.303264 CRF_Loss: 47.060913\n",
      "[2022-02-17 22:44:16,835 - trainer - INFO] - [Step Validation] Epoch:[96/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.884848 | 0.929936 | 0.906832 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.75     | 0.526596 | 0.61875  | 0.526596 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.690554 | 0.675159 | 0.68277  | 0.675159 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.684783 | 0.684783 | 0.684783 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.747585 | 0.659212 | 0.700623 | 0.659212 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 22:44:19,058 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-02-17 22:44:33,080 - trainer - INFO] - Train Epoch:[96/100] Step:[60/250] Total Loss: 22.810211 GL_Loss: 0.656036 CRF_Loss: 22.154175\n",
      "[2022-02-17 22:44:47,922 - trainer - INFO] - Train Epoch:[96/100] Step:[70/250] Total Loss: 13.109055 GL_Loss: 0.495285 CRF_Loss: 12.613770\n",
      "[2022-02-17 22:45:01,931 - trainer - INFO] - Train Epoch:[96/100] Step:[80/250] Total Loss: 16.670288 GL_Loss: 0.466798 CRF_Loss: 16.203491\n",
      "[2022-02-17 22:45:17,337 - trainer - INFO] - Train Epoch:[96/100] Step:[90/250] Total Loss: 10.011307 GL_Loss: 0.876297 CRF_Loss: 9.135010\n",
      "[2022-02-17 22:45:31,176 - trainer - INFO] - Train Epoch:[96/100] Step:[100/250] Total Loss: 13.322355 GL_Loss: 0.523161 CRF_Loss: 12.799194\n",
      "[2022-02-17 22:45:50,571 - trainer - INFO] - [Step Validation] Epoch:[96/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.739623 | 0.521277 | 0.611544 | 0.521277 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.681967 | 0.66242  | 0.672052 | 0.66242  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.666667 | 0.652174 | 0.659341 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.741191 | 0.649627 | 0.692395 | 0.649627 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 22:46:06,273 - trainer - INFO] - Train Epoch:[96/100] Step:[110/250] Total Loss: 24.212400 GL_Loss: 0.446288 CRF_Loss: 23.766113\n",
      "[2022-02-17 22:46:20,062 - trainer - INFO] - Train Epoch:[96/100] Step:[120/250] Total Loss: 25.321112 GL_Loss: 0.669867 CRF_Loss: 24.651245\n",
      "[2022-02-17 22:46:34,456 - trainer - INFO] - Train Epoch:[96/100] Step:[130/250] Total Loss: 45.572277 GL_Loss: 0.533580 CRF_Loss: 45.038696\n",
      "[2022-02-17 22:46:47,734 - trainer - INFO] - Train Epoch:[96/100] Step:[140/250] Total Loss: 17.398439 GL_Loss: 0.707521 CRF_Loss: 16.690918\n",
      "[2022-02-17 22:47:02,444 - trainer - INFO] - Train Epoch:[96/100] Step:[150/250] Total Loss: 66.532654 GL_Loss: 0.340148 CRF_Loss: 66.192505\n",
      "[2022-02-17 22:47:21,595 - trainer - INFO] - [Step Validation] Epoch:[96/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.90184  | 0.936306 | 0.91875  | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.749064 | 0.531915 | 0.622084 | 0.531915 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.674497 | 0.640127 | 0.656863 | 0.640127 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.745721 | 0.649627 | 0.694365 | 0.649627 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 22:47:35,830 - trainer - INFO] - Train Epoch:[96/100] Step:[160/250] Total Loss: 16.664162 GL_Loss: 0.843789 CRF_Loss: 15.820374\n",
      "[2022-02-17 22:47:50,018 - trainer - INFO] - Train Epoch:[96/100] Step:[170/250] Total Loss: 14.713169 GL_Loss: 0.472324 CRF_Loss: 14.240845\n",
      "[2022-02-17 22:48:05,544 - trainer - INFO] - Train Epoch:[96/100] Step:[180/250] Total Loss: 74.988708 GL_Loss: 0.419132 CRF_Loss: 74.569580\n",
      "[2022-02-17 22:48:19,388 - trainer - INFO] - Train Epoch:[96/100] Step:[190/250] Total Loss: 311.187012 GL_Loss: 0.505612 CRF_Loss: 310.681396\n",
      "[2022-02-17 22:48:34,239 - trainer - INFO] - Train Epoch:[96/100] Step:[200/250] Total Loss: 13.815048 GL_Loss: 0.405014 CRF_Loss: 13.410034\n",
      "[2022-02-17 22:48:53,253 - trainer - INFO] - [Step Validation] Epoch:[96/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.896341 | 0.936306 | 0.915888 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.739623 | 0.521277 | 0.611544 | 0.521277 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.674419 | 0.646497 | 0.660163 | 0.646497 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.741463 | 0.647497 | 0.691302 | 0.647497 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 22:49:08,657 - trainer - INFO] - Train Epoch:[96/100] Step:[210/250] Total Loss: 25.305754 GL_Loss: 0.404630 CRF_Loss: 24.901123\n",
      "[2022-02-17 22:49:22,146 - trainer - INFO] - Train Epoch:[96/100] Step:[220/250] Total Loss: 21.475300 GL_Loss: 0.447101 CRF_Loss: 21.028198\n",
      "[2022-02-17 22:49:37,814 - trainer - INFO] - Train Epoch:[96/100] Step:[230/250] Total Loss: 42.188442 GL_Loss: 0.489711 CRF_Loss: 41.698730\n",
      "[2022-02-17 22:49:52,585 - trainer - INFO] - Train Epoch:[96/100] Step:[240/250] Total Loss: 13.979968 GL_Loss: 0.378894 CRF_Loss: 13.601074\n",
      "[2022-02-17 22:50:07,146 - trainer - INFO] - Train Epoch:[96/100] Step:[250/250] Total Loss: 17.445684 GL_Loss: 0.433966 CRF_Loss: 17.011719\n",
      "[2022-02-17 22:50:26,346 - trainer - INFO] - [Step Validation] Epoch:[96/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.90184  | 0.936306 | 0.91875  | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.755639 | 0.534574 | 0.626168 | 0.534574 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.681063 | 0.652866 | 0.666667 | 0.652866 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.75     | 0.654952 | 0.699261 | 0.654952 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 22:50:45,563 - trainer - INFO] - [Epoch Validation] Epoch:[96/100] Total Loss: 39.468560 GL_Loss: 0.004937 CRF_Loss: 38.974878 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.90184  | 0.936306 | 0.91875  | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.755639 | 0.534574 | 0.626168 | 0.534574 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.681063 | 0.652866 | 0.666667 | 0.652866 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.75     | 0.654952 | 0.699261 | 0.654952 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 22:51:00,622 - trainer - INFO] - Train Epoch:[97/100] Step:[10/250] Total Loss: 10.757060 GL_Loss: 0.498027 CRF_Loss: 10.259033\n",
      "[2022-02-17 22:51:15,629 - trainer - INFO] - Train Epoch:[97/100] Step:[20/250] Total Loss: 32.686687 GL_Loss: 0.567301 CRF_Loss: 32.119385\n",
      "[2022-02-17 22:51:29,845 - trainer - INFO] - Train Epoch:[97/100] Step:[30/250] Total Loss: 31.986889 GL_Loss: 0.254711 CRF_Loss: 31.732178\n",
      "[2022-02-17 22:51:45,756 - trainer - INFO] - Train Epoch:[97/100] Step:[40/250] Total Loss: 35.592758 GL_Loss: 0.423080 CRF_Loss: 35.169678\n",
      "[2022-02-17 22:52:00,314 - trainer - INFO] - Train Epoch:[97/100] Step:[50/250] Total Loss: 46.101826 GL_Loss: 0.641621 CRF_Loss: 45.460205\n",
      "[2022-02-17 22:52:19,381 - trainer - INFO] - [Step Validation] Epoch:[97/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.901235 | 0.929936 | 0.915361 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.740602 | 0.523936 | 0.613707 | 0.523936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.68     | 0.649682 | 0.664495 | 0.649682 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.744499 | 0.648562 | 0.693227 | 0.648562 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 22:52:33,951 - trainer - INFO] - Train Epoch:[97/100] Step:[60/250] Total Loss: 31.263245 GL_Loss: 0.440247 CRF_Loss: 30.822998\n",
      "[2022-02-17 22:52:48,023 - trainer - INFO] - Train Epoch:[97/100] Step:[70/250] Total Loss: 25.726454 GL_Loss: 0.452772 CRF_Loss: 25.273682\n",
      "[2022-02-17 22:53:02,428 - trainer - INFO] - Train Epoch:[97/100] Step:[80/250] Total Loss: 17.840000 GL_Loss: 0.425205 CRF_Loss: 17.414795\n",
      "[2022-02-17 22:53:16,075 - trainer - INFO] - Train Epoch:[97/100] Step:[90/250] Total Loss: 253.632462 GL_Loss: 0.445326 CRF_Loss: 253.187134\n",
      "[2022-02-17 22:53:30,372 - trainer - INFO] - Train Epoch:[97/100] Step:[100/250] Total Loss: 27.449186 GL_Loss: 0.555754 CRF_Loss: 26.893433\n",
      "[2022-02-17 22:53:49,698 - trainer - INFO] - [Step Validation] Epoch:[97/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.907407 | 0.936306 | 0.92163  | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.735849 | 0.518617 | 0.608424 | 0.518617 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.679181 | 0.633758 | 0.655684 | 0.633758 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.7      | 0.684783 | 0.692308 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.745679 | 0.643237 | 0.69068  | 0.643237 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 22:54:04,384 - trainer - INFO] - Train Epoch:[97/100] Step:[110/250] Total Loss: 11.764838 GL_Loss: 0.416571 CRF_Loss: 11.348267\n",
      "[2022-02-17 22:54:18,916 - trainer - INFO] - Train Epoch:[97/100] Step:[120/250] Total Loss: 15.204562 GL_Loss: 0.656711 CRF_Loss: 14.547852\n",
      "[2022-02-17 22:54:33,417 - trainer - INFO] - Train Epoch:[97/100] Step:[130/250] Total Loss: 42.054443 GL_Loss: 0.342773 CRF_Loss: 41.711670\n",
      "[2022-02-17 22:54:48,567 - trainer - INFO] - Train Epoch:[97/100] Step:[140/250] Total Loss: 151.975708 GL_Loss: 0.513800 CRF_Loss: 151.461914\n",
      "[2022-02-17 22:55:01,958 - trainer - INFO] - Train Epoch:[97/100] Step:[150/250] Total Loss: 53.502972 GL_Loss: 0.514448 CRF_Loss: 52.988525\n",
      "[2022-02-17 22:55:20,935 - trainer - INFO] - [Step Validation] Epoch:[97/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.902439 | 0.942675 | 0.922118 | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.70632  | 0.505319 | 0.589147 | 0.505319 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.682432 | 0.643312 | 0.662295 | 0.643312 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.677778 | 0.663043 | 0.67033  | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.733822 | 0.640043 | 0.683732 | 0.640043 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 22:55:36,491 - trainer - INFO] - Train Epoch:[97/100] Step:[160/250] Total Loss: 19.885530 GL_Loss: 0.352572 CRF_Loss: 19.532959\n",
      "[2022-02-17 22:55:51,639 - trainer - INFO] - Train Epoch:[97/100] Step:[170/250] Total Loss: 17.418367 GL_Loss: 0.714266 CRF_Loss: 16.704102\n",
      "[2022-02-17 22:56:06,532 - trainer - INFO] - Train Epoch:[97/100] Step:[180/250] Total Loss: 26.954418 GL_Loss: 0.525830 CRF_Loss: 26.428589\n",
      "[2022-02-17 22:56:20,794 - trainer - INFO] - Train Epoch:[97/100] Step:[190/250] Total Loss: 16.253105 GL_Loss: 0.422782 CRF_Loss: 15.830322\n",
      "[2022-02-17 22:56:35,820 - trainer - INFO] - Train Epoch:[97/100] Step:[200/250] Total Loss: 14.703734 GL_Loss: 0.476439 CRF_Loss: 14.227295\n",
      "[2022-02-17 22:56:55,273 - trainer - INFO] - [Step Validation] Epoch:[97/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.884848 | 0.929936 | 0.906832 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.740602 | 0.523936 | 0.613707 | 0.523936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.679739 | 0.66242  | 0.670968 | 0.66242  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.677778 | 0.663043 | 0.67033  | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.740024 | 0.651757 | 0.693092 | 0.651757 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 22:57:10,507 - trainer - INFO] - Train Epoch:[97/100] Step:[210/250] Total Loss: 16.959414 GL_Loss: 0.471010 CRF_Loss: 16.488403\n",
      "[2022-02-17 22:57:25,585 - trainer - INFO] - Train Epoch:[97/100] Step:[220/250] Total Loss: 15.700499 GL_Loss: 0.740660 CRF_Loss: 14.959839\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 22:57:39,629 - trainer - INFO] - Train Epoch:[97/100] Step:[230/250] Total Loss: 80.582611 GL_Loss: 0.413175 CRF_Loss: 80.169434\n",
      "[2022-02-17 22:57:53,681 - trainer - INFO] - Train Epoch:[97/100] Step:[240/250] Total Loss: 279.164124 GL_Loss: 0.587823 CRF_Loss: 278.576294\n",
      "[2022-02-17 22:58:07,630 - trainer - INFO] - Train Epoch:[97/100] Step:[250/250] Total Loss: 6.355075 GL_Loss: 0.404880 CRF_Loss: 5.950195\n",
      "[2022-02-17 22:58:26,685 - trainer - INFO] - [Step Validation] Epoch:[97/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.740602 | 0.523936 | 0.613707 | 0.523936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.695946 | 0.656051 | 0.67541  | 0.656051 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.684783 | 0.684783 | 0.684783 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.749082 | 0.651757 | 0.697039 | 0.651757 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 22:58:45,890 - trainer - INFO] - [Epoch Validation] Epoch:[97/100] Total Loss: 39.718384 GL_Loss: 0.004961 CRF_Loss: 39.222256 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.740602 | 0.523936 | 0.613707 | 0.523936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.695946 | 0.656051 | 0.67541  | 0.656051 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.684783 | 0.684783 | 0.684783 | 0.684783 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.749082 | 0.651757 | 0.697039 | 0.651757 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 22:59:01,759 - trainer - INFO] - Train Epoch:[98/100] Step:[10/250] Total Loss: 8.461137 GL_Loss: 0.561723 CRF_Loss: 7.899414\n",
      "[2022-02-17 22:59:16,052 - trainer - INFO] - Train Epoch:[98/100] Step:[20/250] Total Loss: 39.777214 GL_Loss: 0.390007 CRF_Loss: 39.387207\n",
      "[2022-02-17 22:59:31,630 - trainer - INFO] - Train Epoch:[98/100] Step:[30/250] Total Loss: 22.344904 GL_Loss: 0.426814 CRF_Loss: 21.918091\n",
      "[2022-02-17 22:59:45,689 - trainer - INFO] - Train Epoch:[98/100] Step:[40/250] Total Loss: 68.760368 GL_Loss: 0.393545 CRF_Loss: 68.366821\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 22:59:59,903 - trainer - INFO] - Train Epoch:[98/100] Step:[50/250] Total Loss: 60.922455 GL_Loss: 0.353239 CRF_Loss: 60.569214\n",
      "[2022-02-17 23:00:19,149 - trainer - INFO] - [Step Validation] Epoch:[98/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.90184  | 0.936306 | 0.91875  | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.705224 | 0.50266  | 0.586957 | 0.50266  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.68662  | 0.621019 | 0.652174 | 0.621019 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.696629 | 0.673913 | 0.685083 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.737562 | 0.631523 | 0.680436 | 0.631523 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 23:00:34,077 - trainer - INFO] - Train Epoch:[98/100] Step:[60/250] Total Loss: 18.085176 GL_Loss: 0.475313 CRF_Loss: 17.609863\n",
      "[2022-02-17 23:00:48,419 - trainer - INFO] - Train Epoch:[98/100] Step:[70/250] Total Loss: 52.656986 GL_Loss: 0.344486 CRF_Loss: 52.312500\n",
      "[2022-02-17 23:01:02,789 - trainer - INFO] - Train Epoch:[98/100] Step:[80/250] Total Loss: 72.181648 GL_Loss: 0.379769 CRF_Loss: 71.801880\n",
      "[2022-02-17 23:01:17,207 - trainer - INFO] - Train Epoch:[98/100] Step:[90/250] Total Loss: 58.038967 GL_Loss: 0.736109 CRF_Loss: 57.302856\n",
      "[2022-02-17 23:01:31,203 - trainer - INFO] - Train Epoch:[98/100] Step:[100/250] Total Loss: 91.001625 GL_Loss: 0.497474 CRF_Loss: 90.504150\n",
      "[2022-02-17 23:01:50,455 - trainer - INFO] - [Step Validation] Epoch:[98/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.907975 | 0.942675 | 0.925    | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.719697 | 0.505319 | 0.59375  | 0.505319 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.682432 | 0.643312 | 0.662295 | 0.643312 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.740467 | 0.641108 | 0.687215 | 0.641108 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 23:02:04,701 - trainer - INFO] - Train Epoch:[98/100] Step:[110/250] Total Loss: 36.097355 GL_Loss: 0.421695 CRF_Loss: 35.675659\n",
      "[2022-02-17 23:02:19,297 - trainer - INFO] - Train Epoch:[98/100] Step:[120/250] Total Loss: 25.010950 GL_Loss: 0.402551 CRF_Loss: 24.608398\n",
      "[2022-02-17 23:02:33,919 - trainer - INFO] - Train Epoch:[98/100] Step:[130/250] Total Loss: 51.173515 GL_Loss: 0.543878 CRF_Loss: 50.629639\n",
      "[2022-02-17 23:02:48,708 - trainer - INFO] - Train Epoch:[98/100] Step:[140/250] Total Loss: 24.149107 GL_Loss: 0.573424 CRF_Loss: 23.575684\n",
      "[2022-02-17 23:03:03,233 - trainer - INFO] - Train Epoch:[98/100] Step:[150/250] Total Loss: 12.960629 GL_Loss: 0.390316 CRF_Loss: 12.570312\n",
      "[2022-02-17 23:03:22,692 - trainer - INFO] - [Step Validation] Epoch:[98/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.735075 | 0.523936 | 0.611801 | 0.523936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.677632 | 0.656051 | 0.666667 | 0.656051 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.67033  | 0.663043 | 0.666667 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.738499 | 0.649627 | 0.691218 | 0.649627 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 23:03:37,394 - trainer - INFO] - Train Epoch:[98/100] Step:[160/250] Total Loss: 32.205658 GL_Loss: 0.430266 CRF_Loss: 31.775391\n",
      "[2022-02-17 23:03:51,919 - trainer - INFO] - Train Epoch:[98/100] Step:[170/250] Total Loss: 9.447469 GL_Loss: 0.390706 CRF_Loss: 9.056763\n",
      "[2022-02-17 23:04:05,839 - trainer - INFO] - Train Epoch:[98/100] Step:[180/250] Total Loss: 55.319687 GL_Loss: 0.447126 CRF_Loss: 54.872559\n",
      "[2022-02-17 23:04:20,042 - trainer - INFO] - Train Epoch:[98/100] Step:[190/250] Total Loss: 29.724693 GL_Loss: 0.492393 CRF_Loss: 29.232300\n",
      "[2022-02-17 23:04:34,404 - trainer - INFO] - Train Epoch:[98/100] Step:[200/250] Total Loss: 20.652464 GL_Loss: 0.485594 CRF_Loss: 20.166870\n",
      "[2022-02-17 23:04:53,647 - trainer - INFO] - [Step Validation] Epoch:[98/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.896341 | 0.936306 | 0.915888 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.737828 | 0.523936 | 0.612753 | 0.523936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.673267 | 0.649682 | 0.661264 | 0.649682 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.740291 | 0.649627 | 0.692002 | 0.649627 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 23:05:07,316 - trainer - INFO] - Train Epoch:[98/100] Step:[210/250] Total Loss: 7.691051 GL_Loss: 0.844616 CRF_Loss: 6.846436\n",
      "[2022-02-17 23:05:22,336 - trainer - INFO] - Train Epoch:[98/100] Step:[220/250] Total Loss: 33.642937 GL_Loss: 0.579339 CRF_Loss: 33.063599\n",
      "[2022-02-17 23:05:37,555 - trainer - INFO] - Train Epoch:[98/100] Step:[230/250] Total Loss: 17.837090 GL_Loss: 0.450980 CRF_Loss: 17.386108\n",
      "[2022-02-17 23:05:52,006 - trainer - INFO] - Train Epoch:[98/100] Step:[240/250] Total Loss: 19.939871 GL_Loss: 0.699148 CRF_Loss: 19.240723\n",
      "[2022-02-17 23:06:07,440 - trainer - INFO] - Train Epoch:[98/100] Step:[250/250] Total Loss: 47.503704 GL_Loss: 0.511762 CRF_Loss: 46.991943\n",
      "[2022-02-17 23:06:26,479 - trainer - INFO] - [Step Validation] Epoch:[98/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.737828 | 0.523936 | 0.612753 | 0.523936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.683168 | 0.659236 | 0.670989 | 0.659236 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.659341 | 0.652174 | 0.655738 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.740291 | 0.649627 | 0.692002 | 0.649627 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 23:06:45,692 - trainer - INFO] - [Epoch Validation] Epoch:[98/100] Total Loss: 40.593291 GL_Loss: 0.005017 CRF_Loss: 40.091578 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.737828 | 0.523936 | 0.612753 | 0.523936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.683168 | 0.659236 | 0.670989 | 0.659236 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.659341 | 0.652174 | 0.655738 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.740291 | 0.649627 | 0.692002 | 0.649627 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 23:07:00,533 - trainer - INFO] - Train Epoch:[99/100] Step:[10/250] Total Loss: 20.885918 GL_Loss: 0.554802 CRF_Loss: 20.331116\n",
      "[2022-02-17 23:07:14,764 - trainer - INFO] - Train Epoch:[99/100] Step:[20/250] Total Loss: 17.748703 GL_Loss: 0.597581 CRF_Loss: 17.151123\n",
      "[2022-02-17 23:07:28,757 - trainer - INFO] - Train Epoch:[99/100] Step:[30/250] Total Loss: 25.506569 GL_Loss: 0.414039 CRF_Loss: 25.092529\n",
      "[2022-02-17 23:07:43,365 - trainer - INFO] - Train Epoch:[99/100] Step:[40/250] Total Loss: 38.108658 GL_Loss: 0.681654 CRF_Loss: 37.427002\n",
      "[2022-02-17 23:07:57,591 - trainer - INFO] - Train Epoch:[99/100] Step:[50/250] Total Loss: 26.895731 GL_Loss: 0.270974 CRF_Loss: 26.624756\n",
      "[2022-02-17 23:08:16,740 - trainer - INFO] - [Step Validation] Epoch:[99/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.91358  | 0.942675 | 0.9279   | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.717557 | 0.5      | 0.589342 | 0.5      |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.693662 | 0.627389 | 0.658863 | 0.627389 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.745614 | 0.633653 | 0.685089 | 0.633653 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 23:08:31,794 - trainer - INFO] - Train Epoch:[99/100] Step:[60/250] Total Loss: 20.564915 GL_Loss: 0.510838 CRF_Loss: 20.054077\n",
      "[2022-02-17 23:08:46,346 - trainer - INFO] - Train Epoch:[99/100] Step:[70/250] Total Loss: 75.867996 GL_Loss: 0.364700 CRF_Loss: 75.503296\n",
      "[2022-02-17 23:09:00,677 - trainer - INFO] - Train Epoch:[99/100] Step:[80/250] Total Loss: 40.046913 GL_Loss: 0.326211 CRF_Loss: 39.720703\n",
      "[2022-02-17 23:09:14,310 - trainer - INFO] - Train Epoch:[99/100] Step:[90/250] Total Loss: 15.095216 GL_Loss: 0.461426 CRF_Loss: 14.633789\n",
      "[2022-02-17 23:09:29,147 - trainer - INFO] - Train Epoch:[99/100] Step:[100/250] Total Loss: 41.020393 GL_Loss: 0.464242 CRF_Loss: 40.556152\n",
      "[2022-02-17 23:09:48,175 - trainer - INFO] - [Step Validation] Epoch:[99/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.91358  | 0.942675 | 0.9279   | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.704545 | 0.494681 | 0.58125  | 0.494681 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.670068 | 0.627389 | 0.648026 | 0.627389 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.732099 | 0.631523 | 0.678102 | 0.631523 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 23:10:03,103 - trainer - INFO] - Train Epoch:[99/100] Step:[110/250] Total Loss: 42.504890 GL_Loss: 0.474496 CRF_Loss: 42.030396\n",
      "[2022-02-17 23:10:17,552 - trainer - INFO] - Train Epoch:[99/100] Step:[120/250] Total Loss: 16.620710 GL_Loss: 0.327619 CRF_Loss: 16.293091\n",
      "[2022-02-17 23:10:31,041 - trainer - INFO] - Train Epoch:[99/100] Step:[130/250] Total Loss: 33.046246 GL_Loss: 0.555767 CRF_Loss: 32.490479\n",
      "[2022-02-17 23:10:46,220 - trainer - INFO] - Train Epoch:[99/100] Step:[140/250] Total Loss: 35.548546 GL_Loss: 0.356041 CRF_Loss: 35.192505\n",
      "[2022-02-17 23:11:01,437 - trainer - INFO] - Train Epoch:[99/100] Step:[150/250] Total Loss: 26.850147 GL_Loss: 0.365285 CRF_Loss: 26.484863\n",
      "[2022-02-17 23:11:20,562 - trainer - INFO] - [Step Validation] Epoch:[99/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.896341 | 0.936306 | 0.915888 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.727612 | 0.518617 | 0.60559  | 0.518617 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.675497 | 0.649682 | 0.662338 | 0.649682 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.67033  | 0.663043 | 0.666667 | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.735758 | 0.646432 | 0.688209 | 0.646432 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 23:11:36,012 - trainer - INFO] - Train Epoch:[99/100] Step:[160/250] Total Loss: 25.689640 GL_Loss: 0.420353 CRF_Loss: 25.269287\n",
      "[2022-02-17 23:11:50,439 - trainer - INFO] - Train Epoch:[99/100] Step:[170/250] Total Loss: 46.379101 GL_Loss: 0.378246 CRF_Loss: 46.000854\n",
      "[2022-02-17 23:12:05,236 - trainer - INFO] - Train Epoch:[99/100] Step:[180/250] Total Loss: 25.032963 GL_Loss: 0.372318 CRF_Loss: 24.660645\n",
      "[2022-02-17 23:12:20,520 - trainer - INFO] - Train Epoch:[99/100] Step:[190/250] Total Loss: 19.675562 GL_Loss: 0.514062 CRF_Loss: 19.161499\n",
      "[2022-02-17 23:12:35,355 - trainer - INFO] - Train Epoch:[99/100] Step:[200/250] Total Loss: 11.691886 GL_Loss: 0.719351 CRF_Loss: 10.972534\n",
      "[2022-02-17 23:12:54,591 - trainer - INFO] - [Step Validation] Epoch:[99/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.913043 | 0.936306 | 0.924528 | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.709434 | 0.5      | 0.586583 | 0.5      |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.694545 | 0.60828  | 0.648557 | 0.60828  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.696629 | 0.673913 | 0.685083 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.744304 | 0.626198 | 0.680162 | 0.626198 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 23:13:09,063 - trainer - INFO] - Train Epoch:[99/100] Step:[210/250] Total Loss: 16.937763 GL_Loss: 0.476826 CRF_Loss: 16.460938\n",
      "[2022-02-17 23:13:23,693 - trainer - INFO] - Train Epoch:[99/100] Step:[220/250] Total Loss: 38.636097 GL_Loss: 0.533864 CRF_Loss: 38.102234\n",
      "[2022-02-17 23:13:38,370 - trainer - INFO] - Train Epoch:[99/100] Step:[230/250] Total Loss: 9.655106 GL_Loss: 0.334671 CRF_Loss: 9.320435\n",
      "[2022-02-17 23:13:52,389 - trainer - INFO] - Train Epoch:[99/100] Step:[240/250] Total Loss: 13.761812 GL_Loss: 0.453950 CRF_Loss: 13.307861\n",
      "[2022-02-17 23:14:06,607 - trainer - INFO] - Train Epoch:[99/100] Step:[250/250] Total Loss: 10.625538 GL_Loss: 0.422657 CRF_Loss: 10.202881\n",
      "[2022-02-17 23:14:25,517 - trainer - INFO] - [Step Validation] Epoch:[99/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.901235 | 0.929936 | 0.915361 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.746269 | 0.531915 | 0.621118 | 0.531915 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.692053 | 0.665605 | 0.678571 | 0.665605 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.659341 | 0.652174 | 0.655738 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.747266 | 0.654952 | 0.69807  | 0.654952 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 23:14:44,654 - trainer - INFO] - [Epoch Validation] Epoch:[99/100] Total Loss: 39.740479 GL_Loss: 0.004969 CRF_Loss: 39.243544 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.901235 | 0.929936 | 0.915361 | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.746269 | 0.531915 | 0.621118 | 0.531915 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.692053 | 0.665605 | 0.678571 | 0.665605 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.659341 | 0.652174 | 0.655738 | 0.652174 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.747266 | 0.654952 | 0.69807  | 0.654952 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 23:14:59,233 - trainer - INFO] - Train Epoch:[100/100] Step:[10/250] Total Loss: 47.981098 GL_Loss: 0.427509 CRF_Loss: 47.553589\n",
      "[2022-02-17 23:15:14,216 - trainer - INFO] - Train Epoch:[100/100] Step:[20/250] Total Loss: 17.819908 GL_Loss: 0.372521 CRF_Loss: 17.447388\n",
      "[2022-02-17 23:15:28,055 - trainer - INFO] - Train Epoch:[100/100] Step:[30/250] Total Loss: 301.451202 GL_Loss: 0.494772 CRF_Loss: 300.956421\n",
      "[2022-02-17 23:15:42,828 - trainer - INFO] - Train Epoch:[100/100] Step:[40/250] Total Loss: 12.610535 GL_Loss: 0.317932 CRF_Loss: 12.292603\n",
      "[2022-02-17 23:15:57,512 - trainer - INFO] - Train Epoch:[100/100] Step:[50/250] Total Loss: 23.207481 GL_Loss: 0.492272 CRF_Loss: 22.715210\n",
      "[2022-02-17 23:16:16,511 - trainer - INFO] - [Step Validation] Epoch:[100/100] Step:[50/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.90184  | 0.936306 | 0.91875  | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.725564 | 0.513298 | 0.601246 | 0.513298 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.674497 | 0.640127 | 0.656863 | 0.640127 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.738066 | 0.642173 | 0.686788 | 0.642173 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 23:16:29,996 - trainer - INFO] - Train Epoch:[100/100] Step:[60/250] Total Loss: 36.243999 GL_Loss: 0.495707 CRF_Loss: 35.748291\n",
      "[2022-02-17 23:16:45,619 - trainer - INFO] - Train Epoch:[100/100] Step:[70/250] Total Loss: 31.967457 GL_Loss: 0.381519 CRF_Loss: 31.585938\n",
      "[2022-02-17 23:17:00,665 - trainer - INFO] - Train Epoch:[100/100] Step:[80/250] Total Loss: 43.495354 GL_Loss: 0.403924 CRF_Loss: 43.091431\n",
      "[2022-02-17 23:17:15,066 - trainer - INFO] - Train Epoch:[100/100] Step:[90/250] Total Loss: 41.068867 GL_Loss: 0.386738 CRF_Loss: 40.682129\n",
      "Corrupt JPEG data: bad Huffman code\n",
      "[2022-02-17 23:17:30,661 - trainer - INFO] - Train Epoch:[100/100] Step:[100/250] Total Loss: 10.414121 GL_Loss: 0.451840 CRF_Loss: 9.962280\n",
      "[2022-02-17 23:17:49,868 - trainer - INFO] - [Step Validation] Epoch:[100/100] Step:[100/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.90184  | 0.936306 | 0.91875  | 0.936306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.728625 | 0.521277 | 0.607752 | 0.521277 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.673333 | 0.643312 | 0.65798  | 0.643312 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.677778 | 0.663043 | 0.67033  | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.737226 | 0.645367 | 0.688245 | 0.645367 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 23:18:05,107 - trainer - INFO] - Train Epoch:[100/100] Step:[110/250] Total Loss: 142.754456 GL_Loss: 0.384345 CRF_Loss: 142.370117\n",
      "[2022-02-17 23:18:20,606 - trainer - INFO] - Train Epoch:[100/100] Step:[120/250] Total Loss: 45.211861 GL_Loss: 0.452584 CRF_Loss: 44.759277\n",
      "[2022-02-17 23:18:35,561 - trainer - INFO] - Train Epoch:[100/100] Step:[130/250] Total Loss: 26.687355 GL_Loss: 0.473732 CRF_Loss: 26.213623\n",
      "[2022-02-17 23:18:49,297 - trainer - INFO] - Train Epoch:[100/100] Step:[140/250] Total Loss: 21.510517 GL_Loss: 0.532367 CRF_Loss: 20.978149\n",
      "[2022-02-17 23:19:03,155 - trainer - INFO] - Train Epoch:[100/100] Step:[150/250] Total Loss: 33.584194 GL_Loss: 0.292324 CRF_Loss: 33.291870\n",
      "[2022-02-17 23:19:22,242 - trainer - INFO] - [Step Validation] Epoch:[100/100] Step:[150/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.907975 | 0.942675 | 0.925    | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.721805 | 0.510638 | 0.598131 | 0.510638 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.675585 | 0.643312 | 0.659054 | 0.643312 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.681319 | 0.673913 | 0.677596 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.737485 | 0.643237 | 0.687144 | 0.643237 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 23:19:37,845 - trainer - INFO] - Train Epoch:[100/100] Step:[160/250] Total Loss: 19.295551 GL_Loss: 0.521137 CRF_Loss: 18.774414\n",
      "[2022-02-17 23:19:52,102 - trainer - INFO] - Train Epoch:[100/100] Step:[170/250] Total Loss: 21.436666 GL_Loss: 0.459188 CRF_Loss: 20.977478\n",
      "[2022-02-17 23:20:05,995 - trainer - INFO] - Train Epoch:[100/100] Step:[180/250] Total Loss: 20.981607 GL_Loss: 0.974894 CRF_Loss: 20.006714\n",
      "[2022-02-17 23:20:19,956 - trainer - INFO] - Train Epoch:[100/100] Step:[190/250] Total Loss: 22.973278 GL_Loss: 0.484019 CRF_Loss: 22.489258\n",
      "[2022-02-17 23:20:34,936 - trainer - INFO] - Train Epoch:[100/100] Step:[200/250] Total Loss: 14.438276 GL_Loss: 0.350386 CRF_Loss: 14.087891\n",
      "[2022-02-17 23:20:53,984 - trainer - INFO] - [Step Validation] Epoch:[100/100] Step:[200/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.895706 | 0.929936 | 0.9125   | 0.929936 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.729323 | 0.515957 | 0.604361 | 0.515957 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.675497 | 0.649682 | 0.662338 | 0.649682 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.677778 | 0.663043 | 0.67033  | 0.663043 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.736906 | 0.644302 | 0.6875   | 0.644302 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 23:21:08,124 - trainer - INFO] - Train Epoch:[100/100] Step:[210/250] Total Loss: 74.566109 GL_Loss: 0.269720 CRF_Loss: 74.296387\n",
      "[2022-02-17 23:21:23,758 - trainer - INFO] - Train Epoch:[100/100] Step:[220/250] Total Loss: 17.456039 GL_Loss: 0.352036 CRF_Loss: 17.104004\n",
      "[2022-02-17 23:21:37,679 - trainer - INFO] - Train Epoch:[100/100] Step:[230/250] Total Loss: 26.259577 GL_Loss: 0.326410 CRF_Loss: 25.933167\n",
      "[2022-02-17 23:21:52,254 - trainer - INFO] - Train Epoch:[100/100] Step:[240/250] Total Loss: 20.177206 GL_Loss: 0.464681 CRF_Loss: 19.712524\n",
      "[2022-02-17 23:22:05,886 - trainer - INFO] - Train Epoch:[100/100] Step:[250/250] Total Loss: 20.129747 GL_Loss: 0.430651 CRF_Loss: 19.699097\n",
      "[2022-02-17 23:22:24,952 - trainer - INFO] - [Step Validation] Epoch:[100/100] Step:[250/250]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.91358  | 0.942675 | 0.9279   | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.712121 | 0.5      | 0.5875   | 0.5      |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.696113 | 0.627389 | 0.659966 | 0.627389 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.744681 | 0.633653 | 0.684695 | 0.633653 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 23:22:44,341 - trainer - INFO] - [Epoch Validation] Epoch:[100/100] Total Loss: 40.198497 GL_Loss: 0.004922 CRF_Loss: 39.706250 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| date    | 0.91358  | 0.942675 | 0.9279   | 0.942675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| address | 0.712121 | 0.5      | 0.5875   | 0.5      |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| total   | 0.696113 | 0.627389 | 0.659966 | 0.627389 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| company | 0.688889 | 0.673913 | 0.681319 | 0.673913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.744681 | 0.633653 | 0.684695 | 0.633653 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-02-17 23:22:46,205 - trainer - INFO] - Saving checkpoint: saved/models/PICK_Default/test_0217_100852/checkpoint-epoch100.pth ...\n",
      "[2022-02-17 23:22:46,205 - train - INFO] - Training end...\n"
     ]
    }
   ],
   "source": [
    "# SROIE 2019 Dataset\n",
    "!python3 train.py -c config_icdar_2019.json -d 0 -dist false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-22 16:41:11,426 - train - INFO] - One GPU or CPU training mode start...\n",
      "[2022-03-22 16:41:11,436 - train - INFO] - Dataloader instances created. Train datasets: 154 samples Validation datasets: 52 samples.\n",
      "[2022-03-22 16:41:12,183 - train - INFO] - Model created, trainable parameters: 68565292.\n",
      "[2022-03-22 16:41:12,184 - train - INFO] - Optimizer and lr_scheduler created.\n",
      "[2022-03-22 16:41:12,184 - train - INFO] - Max_epochs: 100 Log_per_step: 10 Validation_per_step: 50.\n",
      "[2022-03-22 16:41:12,185 - train - INFO] - Training start...\n",
      "[2022-03-22 16:41:12,221 - trainer - WARNING] - Training is using GPU 0!\n",
      "[2022-03-22 16:41:33,864 - trainer - INFO] - Train Epoch:[1/100] Step:[10/77] Total Loss: 977.445801 GL_Loss: 1.847408 CRF_Loss: 975.598389\n",
      "[2022-03-22 16:41:52,057 - trainer - INFO] - Train Epoch:[1/100] Step:[20/77] Total Loss: 1388.615967 GL_Loss: 1.997756 CRF_Loss: 1386.618164\n",
      "[2022-03-22 16:42:11,242 - trainer - INFO] - Train Epoch:[1/100] Step:[30/77] Total Loss: 1119.417603 GL_Loss: 0.921780 CRF_Loss: 1118.495850\n",
      "[2022-03-22 16:42:31,167 - trainer - INFO] - Train Epoch:[1/100] Step:[40/77] Total Loss: 1568.953369 GL_Loss: 5.839357 CRF_Loss: 1563.114014\n",
      "[2022-03-22 16:42:51,000 - trainer - INFO] - Train Epoch:[1/100] Step:[50/77] Total Loss: 1245.574219 GL_Loss: 0.536890 CRF_Loss: 1245.037354\n",
      "[2022-03-22 16:43:03,072 - trainer - INFO] - [Step Validation] Epoch:[1/100] Step:[50/77]  \n",
      "+---------+-------------+------------+-------------+------------+\n",
      "| name    |         mEP |        mER |         mEF |        mEA |\n",
      "+=========+=============+============+=============+============+\n",
      "| keys    | 0.000235062 | 0.00456621 | 0.000447107 | 0.00456621 |\n",
      "+---------+-------------+------------+-------------+------------+\n",
      "| values  | 0.0014105   | 0.0360144  | 0.00271469  | 0.0360144  |\n",
      "+---------+-------------+------------+-------------+------------+\n",
      "| header  | 0           | 0          | 0           | 0          |\n",
      "+---------+-------------+------------+-------------+------------+\n",
      "| overall | 0.000822272 | 0.0169738  | 0.00156856  | 0.0169738  |\n",
      "+---------+-------------+------------+-------------+------------+\n",
      "[2022-03-22 16:43:05,098 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-03-22 16:43:24,069 - trainer - INFO] - Train Epoch:[1/100] Step:[60/77] Total Loss: 1001.471558 GL_Loss: 3.747146 CRF_Loss: 997.724426\n",
      "[2022-03-22 16:43:42,425 - trainer - INFO] - Train Epoch:[1/100] Step:[70/77] Total Loss: 2209.371826 GL_Loss: 1.906767 CRF_Loss: 2207.465088\n",
      "[2022-03-22 16:44:08,401 - trainer - INFO] - [Epoch Validation] Epoch:[1/100] Total Loss: 1362.040412 GL_Loss: 0.025647 CRF_Loss: 1359.475722 \n",
      "+---------+-------------+------------+-------------+------------+\n",
      "| name    |         mEP |        mER |         mEF |        mEA |\n",
      "+=========+=============+============+=============+============+\n",
      "| keys    | 0.000362188 | 0.00639269 | 0.000685535 | 0.00639269 |\n",
      "+---------+-------------+------------+-------------+------------+\n",
      "| values  | 0.00209869  | 0.0468187  | 0.00401731  | 0.0468187  |\n",
      "+---------+-------------+------------+-------------+------------+\n",
      "| header  | 0           | 0          | 0           | 0          |\n",
      "+---------+-------------+------------+-------------+------------+\n",
      "| overall | 0.00117575  | 0.0223084  | 0.00223377  | 0.0223084  |\n",
      "+---------+-------------+------------+-------------+------------+\n",
      "[2022-03-22 16:44:27,042 - trainer - INFO] - Train Epoch:[2/100] Step:[10/77] Total Loss: 1215.976318 GL_Loss: 2.841267 CRF_Loss: 1213.135010\n",
      "[2022-03-22 16:44:45,720 - trainer - INFO] - Train Epoch:[2/100] Step:[20/77] Total Loss: 1347.282104 GL_Loss: 1.343469 CRF_Loss: 1345.938599\n",
      "[2022-03-22 16:45:05,352 - trainer - INFO] - Train Epoch:[2/100] Step:[30/77] Total Loss: 1235.717041 GL_Loss: 9.041880 CRF_Loss: 1226.675171\n",
      "[2022-03-22 16:45:22,783 - trainer - INFO] - Train Epoch:[2/100] Step:[40/77] Total Loss: 901.635132 GL_Loss: 5.192507 CRF_Loss: 896.442627\n",
      "[2022-03-22 16:45:42,595 - trainer - INFO] - Train Epoch:[2/100] Step:[50/77] Total Loss: 1706.670898 GL_Loss: 2.592677 CRF_Loss: 1704.078247\n",
      "[2022-03-22 16:45:53,986 - trainer - INFO] - [Step Validation] Epoch:[2/100] Step:[50/77]  \n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| name    |       mEP |      mER |       mEF |      mEA |\n",
      "+=========+===========+==========+===========+==========+\n",
      "| keys    | 0.0167855 | 0.103196 | 0.0288744 | 0.103196 |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| values  | 0.0113341 | 0.115246 | 0.0206385 | 0.115246 |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| header  | 0         | 0        | 0         | 0        |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| overall | 0.012604  | 0.101358 | 0.0224201 | 0.101358 |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "[2022-03-22 16:45:56,170 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-03-22 16:46:15,787 - trainer - INFO] - Train Epoch:[2/100] Step:[60/77] Total Loss: 1197.962891 GL_Loss: 2.572463 CRF_Loss: 1195.390381\n",
      "[2022-03-22 16:46:34,256 - trainer - INFO] - Train Epoch:[2/100] Step:[70/77] Total Loss: 860.146851 GL_Loss: 2.097314 CRF_Loss: 858.049561\n",
      "[2022-03-22 16:46:59,078 - trainer - INFO] - [Epoch Validation] Epoch:[2/100] Total Loss: 1109.889312 GL_Loss: 0.029114 CRF_Loss: 1106.977893 \n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| name    |       mEP |      mER |       mEF |      mEA |\n",
      "+=========+===========+==========+===========+==========+\n",
      "| keys    | 0.0215671 | 0.126941 | 0.03687   | 0.126941 |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| values  | 0.0208397 | 0.164466 | 0.036992  | 0.164466 |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| header  | 0         | 0        | 0         | 0        |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| overall | 0.0204642 | 0.133851 | 0.0355007 | 0.133851 |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "[2022-03-22 16:47:19,776 - trainer - INFO] - Train Epoch:[3/100] Step:[10/77] Total Loss: 518.119324 GL_Loss: 1.743448 CRF_Loss: 516.375854\n",
      "[2022-03-22 16:47:39,013 - trainer - INFO] - Train Epoch:[3/100] Step:[20/77] Total Loss: 573.781677 GL_Loss: 3.339047 CRF_Loss: 570.442627\n",
      "[2022-03-22 16:47:58,882 - trainer - INFO] - Train Epoch:[3/100] Step:[30/77] Total Loss: 816.450134 GL_Loss: 1.936998 CRF_Loss: 814.513123\n",
      "[2022-03-22 16:48:18,211 - trainer - INFO] - Train Epoch:[3/100] Step:[40/77] Total Loss: 1041.633667 GL_Loss: 1.605289 CRF_Loss: 1040.028320\n",
      "[2022-03-22 16:48:40,077 - trainer - INFO] - Train Epoch:[3/100] Step:[50/77] Total Loss: 772.793579 GL_Loss: 1.999626 CRF_Loss: 770.793945\n",
      "[2022-03-22 16:48:52,526 - trainer - INFO] - [Step Validation] Epoch:[3/100] Step:[50/77]  \n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| name    |       mEP |       mER |       mEF |       mEA |\n",
      "+=========+===========+===========+===========+===========+\n",
      "| keys    | 0.0178737 | 0.052968  | 0.0267281 | 0.052968  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| values  | 0.0265833 | 0.122449  | 0.0436831 | 0.122449  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| header  | 0         | 0         | 0         | 0         |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| overall | 0.0218908 | 0.0775946 | 0.0341479 | 0.0775946 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "[2022-03-22 16:49:11,587 - trainer - INFO] - Train Epoch:[3/100] Step:[60/77] Total Loss: 1297.368896 GL_Loss: 2.427792 CRF_Loss: 1294.941162\n",
      "[2022-03-22 16:49:29,719 - trainer - INFO] - Train Epoch:[3/100] Step:[70/77] Total Loss: 1255.875488 GL_Loss: 4.481221 CRF_Loss: 1251.394287\n",
      "[2022-03-22 16:49:54,394 - trainer - INFO] - [Epoch Validation] Epoch:[3/100] Total Loss: 933.305253 GL_Loss: 0.028980 CRF_Loss: 930.407270 \n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| name    |       mEP |      mER |       mEF |      mEA |\n",
      "+=========+===========+==========+===========+==========+\n",
      "| keys    | 0.0317419 | 0.112329 | 0.049497  | 0.112329 |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| values  | 0.0540541 | 0.192077 | 0.0843659 | 0.192077 |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| header  | 0         | 0        | 0         | 0        |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| overall | 0.0297957 | 0.137245 | 0.0489619 | 0.137245 |\n",
      "+---------+-----------+----------+-----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-22 16:50:14,234 - trainer - INFO] - Train Epoch:[4/100] Step:[10/77] Total Loss: 892.303467 GL_Loss: 1.480733 CRF_Loss: 890.822754\n",
      "[2022-03-22 16:50:35,251 - trainer - INFO] - Train Epoch:[4/100] Step:[20/77] Total Loss: 750.983887 GL_Loss: 2.246683 CRF_Loss: 748.737183\n",
      "[2022-03-22 16:50:54,694 - trainer - INFO] - Train Epoch:[4/100] Step:[30/77] Total Loss: 486.553375 GL_Loss: 1.920549 CRF_Loss: 484.632812\n",
      "[2022-03-22 16:51:13,110 - trainer - INFO] - Train Epoch:[4/100] Step:[40/77] Total Loss: 918.009583 GL_Loss: 1.645334 CRF_Loss: 916.364258\n",
      "[2022-03-22 16:51:32,502 - trainer - INFO] - Train Epoch:[4/100] Step:[50/77] Total Loss: 897.079590 GL_Loss: 1.743748 CRF_Loss: 895.335815\n",
      "[2022-03-22 16:51:45,090 - trainer - INFO] - [Step Validation] Epoch:[4/100] Step:[50/77]  \n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| name    |       mEP |       mER |       mEF |       mEA |\n",
      "+=========+===========+===========+===========+===========+\n",
      "| keys    | 0.0661479 | 0.155251  | 0.0927694 | 0.155251  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| values  | 0.0566833 | 0.177671  | 0.0859466 | 0.177671  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| header  | 0.0113285 | 0.0820896 | 0.0199095 | 0.0820896 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| overall | 0.0534785 | 0.159554  | 0.0801071 | 0.159554  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "[2022-03-22 16:51:47,356 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-03-22 16:52:07,050 - trainer - INFO] - Train Epoch:[4/100] Step:[60/77] Total Loss: 1104.759521 GL_Loss: 2.328825 CRF_Loss: 1102.430664\n",
      "[2022-03-22 16:52:26,037 - trainer - INFO] - Train Epoch:[4/100] Step:[70/77] Total Loss: 1211.823364 GL_Loss: 1.175617 CRF_Loss: 1210.647705\n",
      "[2022-03-22 16:52:49,983 - trainer - INFO] - [Epoch Validation] Epoch:[4/100] Total Loss: 835.497407 GL_Loss: 0.019327 CRF_Loss: 833.564685 \n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| name    |       mEP |       mER |       mEF |       mEA |\n",
      "+=========+===========+===========+===========+===========+\n",
      "| keys    | 0.0604813 | 0.174429  | 0.089819  | 0.174429  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| values  | 0.0480519 | 0.222089  | 0.0790092 | 0.222089  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| header  | 0.125     | 0.0373134 | 0.0574713 | 0.0373134 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| overall | 0.0540579 | 0.184772  | 0.0836443 | 0.184772  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "[2022-03-22 16:53:10,412 - trainer - INFO] - Train Epoch:[5/100] Step:[10/77] Total Loss: 940.309021 GL_Loss: 1.650547 CRF_Loss: 938.658447\n",
      "[2022-03-22 16:53:30,039 - trainer - INFO] - Train Epoch:[5/100] Step:[20/77] Total Loss: 1018.130249 GL_Loss: 5.420632 CRF_Loss: 1012.709595\n",
      "[2022-03-22 16:53:47,902 - trainer - INFO] - Train Epoch:[5/100] Step:[30/77] Total Loss: 332.540924 GL_Loss: 2.191929 CRF_Loss: 330.348999\n",
      "[2022-03-22 16:54:06,903 - trainer - INFO] - Train Epoch:[5/100] Step:[40/77] Total Loss: 670.256226 GL_Loss: 2.097241 CRF_Loss: 668.158997\n",
      "[2022-03-22 16:54:25,104 - trainer - INFO] - Train Epoch:[5/100] Step:[50/77] Total Loss: 413.838165 GL_Loss: 1.808116 CRF_Loss: 412.030060\n",
      "[2022-03-22 16:54:36,513 - trainer - INFO] - [Step Validation] Epoch:[5/100] Step:[50/77]  \n",
      "+---------+------------+-----------+-----------+-----------+\n",
      "| name    |        mEP |       mER |       mEF |       mEA |\n",
      "+=========+============+===========+===========+===========+\n",
      "| keys    | 0.0883943  | 0.253881  | 0.131132  | 0.253881  |\n",
      "+---------+------------+-----------+-----------+-----------+\n",
      "| values  | 0.058664   | 0.207683  | 0.091486  | 0.207683  |\n",
      "+---------+------------+-----------+-----------+-----------+\n",
      "| header  | 0.00761421 | 0.0447761 | 0.0130152 | 0.0447761 |\n",
      "+---------+------------+-----------+-----------+-----------+\n",
      "| overall | 0.0664051  | 0.221629  | 0.102191  | 0.221629  |\n",
      "+---------+------------+-----------+-----------+-----------+\n",
      "[2022-03-22 16:54:38,679 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-03-22 16:54:58,031 - trainer - INFO] - Train Epoch:[5/100] Step:[60/77] Total Loss: 698.296753 GL_Loss: 1.288145 CRF_Loss: 697.008606\n",
      "[2022-03-22 16:55:15,295 - trainer - INFO] - Train Epoch:[5/100] Step:[70/77] Total Loss: 467.743134 GL_Loss: 4.038058 CRF_Loss: 463.705078\n",
      "[2022-03-22 16:55:40,029 - trainer - INFO] - [Epoch Validation] Epoch:[5/100] Total Loss: 705.817078 GL_Loss: 0.025480 CRF_Loss: 703.269095 \n",
      "+---------+------------+-----------+-----------+-----------+\n",
      "| name    |        mEP |       mER |       mEF |       mEA |\n",
      "+=========+============+===========+===========+===========+\n",
      "| keys    | 0.0791227  | 0.260274  | 0.121354  | 0.260274  |\n",
      "+---------+------------+-----------+-----------+-----------+\n",
      "| values  | 0.0774243  | 0.242497  | 0.117374  | 0.242497  |\n",
      "+---------+------------+-----------+-----------+-----------+\n",
      "| header  | 0.00794702 | 0.0895522 | 0.0145985 | 0.0895522 |\n",
      "+---------+------------+-----------+-----------+-----------+\n",
      "| overall | 0.0646289  | 0.241998  | 0.102014  | 0.241998  |\n",
      "+---------+------------+-----------+-----------+-----------+\n",
      "[2022-03-22 16:56:00,520 - trainer - INFO] - Train Epoch:[6/100] Step:[10/77] Total Loss: 364.019135 GL_Loss: 1.949784 CRF_Loss: 362.069336\n",
      "[2022-03-22 16:56:18,489 - trainer - INFO] - Train Epoch:[6/100] Step:[20/77] Total Loss: 350.465607 GL_Loss: 1.212791 CRF_Loss: 349.252808\n",
      "[2022-03-22 16:56:38,172 - trainer - INFO] - Train Epoch:[6/100] Step:[30/77] Total Loss: 381.292938 GL_Loss: 3.530059 CRF_Loss: 377.762878\n",
      "[2022-03-22 16:56:57,376 - trainer - INFO] - Train Epoch:[6/100] Step:[40/77] Total Loss: 728.595886 GL_Loss: 5.092253 CRF_Loss: 723.503662\n",
      "[2022-03-22 16:57:16,654 - trainer - INFO] - Train Epoch:[6/100] Step:[50/77] Total Loss: 966.085327 GL_Loss: 4.162582 CRF_Loss: 961.922729\n",
      "[2022-03-22 16:57:28,032 - trainer - INFO] - [Step Validation] Epoch:[6/100] Step:[50/77]  \n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| name    |       mEP |       mER |       mEF |       mEA |\n",
      "+=========+===========+===========+===========+===========+\n",
      "| keys    | 0.297396  | 0.740639  | 0.424385  | 0.740639  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| values  | 0.0956813 | 0.308523  | 0.146064  | 0.308523  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| header  | 0.05      | 0.0597015 | 0.0544218 | 0.0597015 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| overall | 0.193074  | 0.521823  | 0.28186   | 0.521823  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "[2022-03-22 16:57:30,120 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-03-22 16:57:49,547 - trainer - INFO] - Train Epoch:[6/100] Step:[60/77] Total Loss: 447.914948 GL_Loss: 2.992885 CRF_Loss: 444.922058\n",
      "[2022-03-22 16:58:07,134 - trainer - INFO] - Train Epoch:[6/100] Step:[70/77] Total Loss: 1077.227173 GL_Loss: 1.379977 CRF_Loss: 1075.847168\n",
      "[2022-03-22 16:58:31,200 - trainer - INFO] - [Epoch Validation] Epoch:[6/100] Total Loss: 614.197339 GL_Loss: 0.033879 CRF_Loss: 610.809452 \n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| name    |       mEP |       mER |       mEF |       mEA |\n",
      "+=========+===========+===========+===========+===========+\n",
      "| keys    | 0.243506  | 0.753425  | 0.368057  | 0.753425  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| values  | 0.132437  | 0.390156  | 0.197749  | 0.390156  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| header  | 0.0126743 | 0.0746269 | 0.0216685 | 0.0746269 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| overall | 0.174936  | 0.562561  | 0.266881  | 0.562561  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "[2022-03-22 16:58:52,612 - trainer - INFO] - Train Epoch:[7/100] Step:[10/77] Total Loss: 1179.273438 GL_Loss: 0.880603 CRF_Loss: 1178.392822\n",
      "[2022-03-22 16:59:11,691 - trainer - INFO] - Train Epoch:[7/100] Step:[20/77] Total Loss: 372.408508 GL_Loss: 1.438793 CRF_Loss: 370.969727\n",
      "[2022-03-22 16:59:30,161 - trainer - INFO] - Train Epoch:[7/100] Step:[30/77] Total Loss: 515.481567 GL_Loss: 1.637704 CRF_Loss: 513.843872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-22 16:59:48,545 - trainer - INFO] - Train Epoch:[7/100] Step:[40/77] Total Loss: 599.638428 GL_Loss: 0.724845 CRF_Loss: 598.913574\n",
      "[2022-03-22 17:00:05,979 - trainer - INFO] - Train Epoch:[7/100] Step:[50/77] Total Loss: 292.404114 GL_Loss: 0.871351 CRF_Loss: 291.532776\n",
      "[2022-03-22 17:00:17,296 - trainer - INFO] - [Step Validation] Epoch:[7/100] Step:[50/77]  \n",
      "+---------+------------+------------+------------+------------+\n",
      "| name    |        mEP |        mER |        mEF |        mEA |\n",
      "+=========+============+============+============+============+\n",
      "| keys    | 0.226173   | 0.708676   | 0.342908   | 0.708676   |\n",
      "+---------+------------+------------+------------+------------+\n",
      "| values  | 0.162496   | 0.569028   | 0.2528     | 0.569028   |\n",
      "+---------+------------+------------+------------+------------+\n",
      "| header  | 0.00183824 | 0.00746269 | 0.00294985 | 0.00746269 |\n",
      "+---------+------------+------------+------------+------------+\n",
      "| overall | 0.181515   | 0.606693   | 0.279428   | 0.606693   |\n",
      "+---------+------------+------------+------------+------------+\n",
      "[2022-03-22 17:00:36,577 - trainer - INFO] - Train Epoch:[7/100] Step:[60/77] Total Loss: 330.520599 GL_Loss: 1.603110 CRF_Loss: 328.917480\n",
      "[2022-03-22 17:00:55,380 - trainer - INFO] - Train Epoch:[7/100] Step:[70/77] Total Loss: 456.357086 GL_Loss: 2.642546 CRF_Loss: 453.714539\n",
      "[2022-03-22 17:01:18,870 - trainer - INFO] - [Epoch Validation] Epoch:[7/100] Total Loss: 528.302687 GL_Loss: 0.018285 CRF_Loss: 526.474198 \n",
      "+---------+----------+----------+-----------+----------+\n",
      "| name    |      mEP |      mER |       mEF |      mEA |\n",
      "+=========+==========+==========+===========+==========+\n",
      "| keys    | 0.214742 | 0.614612 | 0.318279  | 0.614612 |\n",
      "+---------+----------+----------+-----------+----------+\n",
      "| values  | 0.204824 | 0.621849 | 0.30815   | 0.621849 |\n",
      "+---------+----------+----------+-----------+----------+\n",
      "| header  | 0.016092 | 0.156716 | 0.0291869 | 0.156716 |\n",
      "+---------+----------+----------+-----------+----------+\n",
      "| overall | 0.173938 | 0.587779 | 0.268439  | 0.587779 |\n",
      "+---------+----------+----------+-----------+----------+\n",
      "[2022-03-22 17:01:37,592 - trainer - INFO] - Train Epoch:[8/100] Step:[10/77] Total Loss: 688.309265 GL_Loss: 3.243457 CRF_Loss: 685.065796\n",
      "[2022-03-22 17:01:56,929 - trainer - INFO] - Train Epoch:[8/100] Step:[20/77] Total Loss: 596.631531 GL_Loss: 3.057448 CRF_Loss: 593.574097\n",
      "[2022-03-22 17:02:17,050 - trainer - INFO] - Train Epoch:[8/100] Step:[30/77] Total Loss: 275.920563 GL_Loss: 2.823812 CRF_Loss: 273.096741\n",
      "[2022-03-22 17:02:37,016 - trainer - INFO] - Train Epoch:[8/100] Step:[40/77] Total Loss: 821.245056 GL_Loss: 0.655082 CRF_Loss: 820.589966\n",
      "[2022-03-22 17:02:55,576 - trainer - INFO] - Train Epoch:[8/100] Step:[50/77] Total Loss: 239.627975 GL_Loss: 2.106972 CRF_Loss: 237.520996\n",
      "[2022-03-22 17:03:07,026 - trainer - INFO] - [Step Validation] Epoch:[8/100] Step:[50/77]  \n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| name    |       mEP |       mER |       mEF |       mEA |\n",
      "+=========+===========+===========+===========+===========+\n",
      "| keys    | 0.28779   | 0.759817  | 0.417461  | 0.759817  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| values  | 0.233002  | 0.703481  | 0.35006   | 0.703481  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| header  | 0.0200501 | 0.0597015 | 0.0300188 | 0.0597015 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| overall | 0.24565   | 0.691562  | 0.362527  | 0.691562  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "[2022-03-22 17:03:09,101 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-03-22 17:03:27,542 - trainer - INFO] - Train Epoch:[8/100] Step:[60/77] Total Loss: 239.318710 GL_Loss: 1.782947 CRF_Loss: 237.535767\n",
      "[2022-03-22 17:03:45,614 - trainer - INFO] - Train Epoch:[8/100] Step:[70/77] Total Loss: 279.321777 GL_Loss: 0.863967 CRF_Loss: 278.457825\n",
      "[2022-03-22 17:04:10,421 - trainer - INFO] - [Epoch Validation] Epoch:[8/100] Total Loss: 480.376923 GL_Loss: 0.022262 CRF_Loss: 478.150766 \n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| name    |       mEP |      mER |       mEF |      mEA |\n",
      "+=========+===========+==========+===========+==========+\n",
      "| keys    | 0.261023  | 0.675799 | 0.37659   | 0.675799 |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| values  | 0.221368  | 0.656663 | 0.331114  | 0.656663 |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| header  | 0.0284431 | 0.141791 | 0.0473815 | 0.141791 |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| overall | 0.218614  | 0.633366 | 0.325037  | 0.633366 |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "[2022-03-22 17:04:29,404 - trainer - INFO] - Train Epoch:[9/100] Step:[10/77] Total Loss: 230.056747 GL_Loss: 1.734476 CRF_Loss: 228.322266\n",
      "[2022-03-22 17:04:48,923 - trainer - INFO] - Train Epoch:[9/100] Step:[20/77] Total Loss: 707.308044 GL_Loss: 1.289239 CRF_Loss: 706.018799\n",
      "[2022-03-22 17:05:07,828 - trainer - INFO] - Train Epoch:[9/100] Step:[30/77] Total Loss: 290.487122 GL_Loss: 1.151805 CRF_Loss: 289.335327\n",
      "[2022-03-22 17:05:24,945 - trainer - INFO] - Train Epoch:[9/100] Step:[40/77] Total Loss: 330.173859 GL_Loss: 3.332665 CRF_Loss: 326.841187\n",
      "[2022-03-22 17:05:43,058 - trainer - INFO] - Train Epoch:[9/100] Step:[50/77] Total Loss: 368.784576 GL_Loss: 1.533587 CRF_Loss: 367.250977\n",
      "[2022-03-22 17:05:54,386 - trainer - INFO] - [Step Validation] Epoch:[9/100] Step:[50/77]  \n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| name    |       mEP |      mER |       mEF |      mEA |\n",
      "+=========+===========+==========+===========+==========+\n",
      "| keys    | 0.28065   | 0.788128 | 0.413909  | 0.788128 |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| values  | 0.275113  | 0.729892 | 0.399606  | 0.729892 |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| header  | 0.0172216 | 0.11194  | 0.0298507 | 0.11194  |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| overall | 0.241391  | 0.72066  | 0.361645  | 0.72066  |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "[2022-03-22 17:06:13,169 - trainer - INFO] - Train Epoch:[9/100] Step:[60/77] Total Loss: 539.551636 GL_Loss: 3.516226 CRF_Loss: 536.035400\n",
      "[2022-03-22 17:06:33,953 - trainer - INFO] - Train Epoch:[9/100] Step:[70/77] Total Loss: 561.411377 GL_Loss: 1.368673 CRF_Loss: 560.042725\n",
      "[2022-03-22 17:06:58,866 - trainer - INFO] - [Epoch Validation] Epoch:[9/100] Total Loss: 432.521877 GL_Loss: 0.014335 CRF_Loss: 431.088362 \n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| name    |       mEP |      mER |       mEF |      mEA |\n",
      "+=========+===========+==========+===========+==========+\n",
      "| keys    | 0.176197  | 0.554338 | 0.267401  | 0.554338 |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| values  | 0.223994  | 0.67467  | 0.336326  | 0.67467  |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| header  | 0.0191987 | 0.171642 | 0.0345345 | 0.171642 |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| overall | 0.166667  | 0.57808  | 0.258737  | 0.57808  |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "[2022-03-22 17:07:18,069 - trainer - INFO] - Train Epoch:[10/100] Step:[10/77] Total Loss: 244.825134 GL_Loss: 1.839783 CRF_Loss: 242.985352\n",
      "[2022-03-22 17:07:36,733 - trainer - INFO] - Train Epoch:[10/100] Step:[20/77] Total Loss: 355.268402 GL_Loss: 2.770362 CRF_Loss: 352.498047\n",
      "[2022-03-22 17:07:54,331 - trainer - INFO] - Train Epoch:[10/100] Step:[30/77] Total Loss: 376.269897 GL_Loss: 1.155038 CRF_Loss: 375.114868\n",
      "[2022-03-22 17:08:12,709 - trainer - INFO] - Train Epoch:[10/100] Step:[40/77] Total Loss: 441.015350 GL_Loss: 3.462482 CRF_Loss: 437.552856\n",
      "[2022-03-22 17:08:33,670 - trainer - INFO] - Train Epoch:[10/100] Step:[50/77] Total Loss: 445.717499 GL_Loss: 2.159630 CRF_Loss: 443.557861\n",
      "[2022-03-22 17:08:45,035 - trainer - INFO] - [Step Validation] Epoch:[10/100] Step:[50/77]  \n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| name    |       mEP |      mER |       mEF |      mEA |\n",
      "+=========+===========+==========+===========+==========+\n",
      "| keys    | 0.323214  | 0.826484 | 0.464698  | 0.826484 |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| values  | 0.285981  | 0.734694 | 0.411705  | 0.734694 |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| header  | 0.0457256 | 0.171642 | 0.0722135 | 0.171642 |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| overall | 0.282932  | 0.746848 | 0.410393  | 0.746848 |\n",
      "+---------+-----------+----------+-----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-22 17:08:47,084 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-03-22 17:09:07,061 - trainer - INFO] - Train Epoch:[10/100] Step:[60/77] Total Loss: 515.765808 GL_Loss: 2.835847 CRF_Loss: 512.929932\n",
      "[2022-03-22 17:09:26,510 - trainer - INFO] - Train Epoch:[10/100] Step:[70/77] Total Loss: 215.541138 GL_Loss: 3.507317 CRF_Loss: 212.033813\n",
      "[2022-03-22 17:09:50,400 - trainer - INFO] - [Epoch Validation] Epoch:[10/100] Total Loss: 424.071201 GL_Loss: 0.022739 CRF_Loss: 421.797308 \n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| name    |      mEP |       mER |       mEF |       mEA |\n",
      "+=========+==========+===========+===========+===========+\n",
      "| keys    | 0.404118 | 0.860274  | 0.549912  | 0.860274  |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| values  | 0.289941 | 0.705882  | 0.411045  | 0.705882  |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| header  | 0.138889 | 0.0746269 | 0.0970874 | 0.0746269 |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "| overall | 0.347551 | 0.746848  | 0.474357  | 0.746848  |\n",
      "+---------+----------+-----------+-----------+-----------+\n",
      "[2022-03-22 17:10:07,403 - trainer - INFO] - Train Epoch:[11/100] Step:[10/77] Total Loss: 289.547638 GL_Loss: 0.948162 CRF_Loss: 288.599487\n",
      "[2022-03-22 17:10:27,090 - trainer - INFO] - Train Epoch:[11/100] Step:[20/77] Total Loss: 388.338440 GL_Loss: 1.605300 CRF_Loss: 386.733154\n",
      "[2022-03-22 17:10:45,681 - trainer - INFO] - Train Epoch:[11/100] Step:[30/77] Total Loss: 222.652649 GL_Loss: 2.489688 CRF_Loss: 220.162964\n",
      "[2022-03-22 17:11:02,720 - trainer - INFO] - Train Epoch:[11/100] Step:[40/77] Total Loss: 149.123383 GL_Loss: 1.427831 CRF_Loss: 147.695557\n",
      "[2022-03-22 17:11:22,621 - trainer - INFO] - Train Epoch:[11/100] Step:[50/77] Total Loss: 502.273102 GL_Loss: 1.574001 CRF_Loss: 500.699097\n",
      "[2022-03-22 17:11:34,019 - trainer - INFO] - [Step Validation] Epoch:[11/100] Step:[50/77]  \n",
      "+---------+-----------+----------+----------+----------+\n",
      "| name    |       mEP |      mER |      mEF |      mEA |\n",
      "+=========+===========+==========+==========+==========+\n",
      "| keys    | 0.431862  | 0.821918 | 0.566216 | 0.821918 |\n",
      "+---------+-----------+----------+----------+----------+\n",
      "| values  | 0.322057  | 0.571429 | 0.411943 | 0.571429 |\n",
      "+---------+-----------+----------+----------+----------+\n",
      "| header  | 0.0754717 | 0.149254 | 0.100251 | 0.149254 |\n",
      "+---------+-----------+----------+----------+----------+\n",
      "| overall | 0.364777  | 0.677013 | 0.474104 | 0.677013 |\n",
      "+---------+-----------+----------+----------+----------+\n",
      "[2022-03-22 17:11:53,058 - trainer - INFO] - Train Epoch:[11/100] Step:[60/77] Total Loss: 225.902466 GL_Loss: 2.650764 CRF_Loss: 223.251709\n",
      "[2022-03-22 17:12:12,850 - trainer - INFO] - Train Epoch:[11/100] Step:[70/77] Total Loss: 318.743958 GL_Loss: 1.782546 CRF_Loss: 316.961426\n",
      "[2022-03-22 17:12:38,743 - trainer - INFO] - [Epoch Validation] Epoch:[11/100] Total Loss: 341.847898 GL_Loss: 0.021683 CRF_Loss: 339.679633 \n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| name    |       mEP |       mER |       mEF |       mEA |\n",
      "+=========+===========+===========+===========+===========+\n",
      "| keys    | 0.314849  | 0.627397  | 0.419286  | 0.627397  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| values  | 0.288557  | 0.696279  | 0.40802   | 0.696279  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| header  | 0.0275862 | 0.0895522 | 0.0421793 | 0.0895522 |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "| overall | 0.276421  | 0.620272  | 0.382419  | 0.620272  |\n",
      "+---------+-----------+-----------+-----------+-----------+\n",
      "[2022-03-22 17:12:58,802 - trainer - INFO] - Train Epoch:[12/100] Step:[10/77] Total Loss: 443.097565 GL_Loss: 1.138451 CRF_Loss: 441.959106\n",
      "[2022-03-22 17:13:17,240 - trainer - INFO] - Train Epoch:[12/100] Step:[20/77] Total Loss: 180.565079 GL_Loss: 1.916640 CRF_Loss: 178.648438\n",
      "[2022-03-22 17:13:36,652 - trainer - INFO] - Train Epoch:[12/100] Step:[30/77] Total Loss: 123.655441 GL_Loss: 2.019940 CRF_Loss: 121.635498\n",
      "[2022-03-22 17:13:55,726 - trainer - INFO] - Train Epoch:[12/100] Step:[40/77] Total Loss: 402.146545 GL_Loss: 2.610829 CRF_Loss: 399.535706\n",
      "[2022-03-22 17:14:15,266 - trainer - INFO] - Train Epoch:[12/100] Step:[50/77] Total Loss: 439.165253 GL_Loss: 3.446441 CRF_Loss: 435.718811\n",
      "[2022-03-22 17:14:26,647 - trainer - INFO] - [Step Validation] Epoch:[12/100] Step:[50/77]  \n",
      "+---------+-----------+----------+----------+----------+\n",
      "| name    |       mEP |      mER |      mEF |      mEA |\n",
      "+=========+===========+==========+==========+==========+\n",
      "| keys    | 0.360251  | 0.733333 | 0.483153 | 0.733333 |\n",
      "+---------+-----------+----------+----------+----------+\n",
      "| values  | 0.332344  | 0.806723 | 0.470753 | 0.806723 |\n",
      "+---------+-----------+----------+----------+----------+\n",
      "| header  | 0.0766284 | 0.149254 | 0.101266 | 0.149254 |\n",
      "+---------+-----------+----------+----------+----------+\n",
      "| overall | 0.331339  | 0.725024 | 0.454822 | 0.725024 |\n",
      "+---------+-----------+----------+----------+----------+\n",
      "[2022-03-22 17:14:43,815 - trainer - INFO] - Train Epoch:[12/100] Step:[60/77] Total Loss: 139.813354 GL_Loss: 1.083009 CRF_Loss: 138.730347\n",
      "[2022-03-22 17:15:03,163 - trainer - INFO] - Train Epoch:[12/100] Step:[70/77] Total Loss: 250.746094 GL_Loss: 1.751345 CRF_Loss: 248.994751\n",
      "[2022-03-22 17:15:26,544 - trainer - INFO] - [Epoch Validation] Epoch:[12/100] Total Loss: 317.928735 GL_Loss: 0.016351 CRF_Loss: 316.293676 \n",
      "+---------+-----------+----------+----------+----------+\n",
      "| name    |       mEP |      mER |      mEF |      mEA |\n",
      "+=========+===========+==========+==========+==========+\n",
      "| keys    | 0.334855  | 0.803653 | 0.472737 | 0.803653 |\n",
      "+---------+-----------+----------+----------+----------+\n",
      "| values  | 0.301168  | 0.711885 | 0.423269 | 0.711885 |\n",
      "+---------+-----------+----------+----------+----------+\n",
      "| header  | 0.0508475 | 0.201493 | 0.081203 | 0.201493 |\n",
      "+---------+-----------+----------+----------+----------+\n",
      "| overall | 0.292512  | 0.727449 | 0.417246 | 0.727449 |\n",
      "+---------+-----------+----------+----------+----------+\n",
      "[2022-03-22 17:15:45,942 - trainer - INFO] - Train Epoch:[13/100] Step:[10/77] Total Loss: 203.509857 GL_Loss: 1.103979 CRF_Loss: 202.405884\n",
      "[2022-03-22 17:16:05,056 - trainer - INFO] - Train Epoch:[13/100] Step:[20/77] Total Loss: 262.986267 GL_Loss: 0.839182 CRF_Loss: 262.147095\n",
      "[2022-03-22 17:16:24,614 - trainer - INFO] - Train Epoch:[13/100] Step:[30/77] Total Loss: 77.105675 GL_Loss: 1.926357 CRF_Loss: 75.179321\n",
      "[2022-03-22 17:16:43,523 - trainer - INFO] - Train Epoch:[13/100] Step:[40/77] Total Loss: 256.544250 GL_Loss: 0.781558 CRF_Loss: 255.762695\n",
      "[2022-03-22 17:17:02,029 - trainer - INFO] - Train Epoch:[13/100] Step:[50/77] Total Loss: 487.746368 GL_Loss: 1.412259 CRF_Loss: 486.334106\n",
      "[2022-03-22 17:17:13,472 - trainer - INFO] - [Step Validation] Epoch:[13/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.481158 | 0.804566 | 0.602187 | 0.804566 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.328175 | 0.611044 | 0.427013 | 0.611044 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.109827 | 0.141791 | 0.123779 | 0.141791 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.396343 | 0.683317 | 0.501691 | 0.683317 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 17:17:15,663 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-03-22 17:17:33,134 - trainer - INFO] - Train Epoch:[13/100] Step:[60/77] Total Loss: 505.781677 GL_Loss: 1.234568 CRF_Loss: 504.547119\n",
      "[2022-03-22 17:17:52,409 - trainer - INFO] - Train Epoch:[13/100] Step:[70/77] Total Loss: 87.314659 GL_Loss: 3.207423 CRF_Loss: 84.107239\n",
      "[2022-03-22 17:18:18,196 - trainer - INFO] - [Epoch Validation] Epoch:[13/100] Total Loss: 279.117753 GL_Loss: 0.018492 CRF_Loss: 277.268544 \n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| name    |       mEP |      mER |       mEF |      mEA |\n",
      "+=========+===========+==========+===========+==========+\n",
      "| keys    | 0.33592   | 0.672146 | 0.447961  | 0.672146 |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| values  | 0.364893  | 0.855942 | 0.511661  | 0.855942 |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| header  | 0.0579937 | 0.276119 | 0.0958549 | 0.276119 |\n",
      "+---------+-----------+----------+-----------+----------+\n",
      "| overall | 0.310684  | 0.72066  | 0.434186  | 0.72066  |\n",
      "+---------+-----------+----------+-----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-22 17:18:37,600 - trainer - INFO] - Train Epoch:[14/100] Step:[10/77] Total Loss: 121.219177 GL_Loss: 2.329649 CRF_Loss: 118.889526\n",
      "[2022-03-22 17:18:55,637 - trainer - INFO] - Train Epoch:[14/100] Step:[20/77] Total Loss: 204.619766 GL_Loss: 1.359751 CRF_Loss: 203.260010\n",
      "[2022-03-22 17:19:13,541 - trainer - INFO] - Train Epoch:[14/100] Step:[30/77] Total Loss: 386.584106 GL_Loss: 0.834356 CRF_Loss: 385.749756\n",
      "[2022-03-22 17:19:32,265 - trainer - INFO] - Train Epoch:[14/100] Step:[40/77] Total Loss: 443.281677 GL_Loss: 1.772771 CRF_Loss: 441.508911\n",
      "[2022-03-22 17:19:50,708 - trainer - INFO] - Train Epoch:[14/100] Step:[50/77] Total Loss: 163.513138 GL_Loss: 3.093341 CRF_Loss: 160.419800\n",
      "[2022-03-22 17:20:02,120 - trainer - INFO] - [Step Validation] Epoch:[14/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.519283 | 0.873059 | 0.651226 | 0.873059 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.408451 | 0.626651 | 0.494552 | 0.626651 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.140496 | 0.126866 | 0.133333 | 0.126866 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.46142  | 0.725024 | 0.563938 | 0.725024 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 17:20:04,212 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-03-22 17:20:23,107 - trainer - INFO] - Train Epoch:[14/100] Step:[60/77] Total Loss: 244.386642 GL_Loss: 2.527692 CRF_Loss: 241.858948\n",
      "[2022-03-22 17:20:43,010 - trainer - INFO] - Train Epoch:[14/100] Step:[70/77] Total Loss: 370.518677 GL_Loss: 1.507928 CRF_Loss: 369.010742\n",
      "[2022-03-22 17:21:08,237 - trainer - INFO] - [Epoch Validation] Epoch:[14/100] Total Loss: 276.144860 GL_Loss: 0.027312 CRF_Loss: 273.413629 \n",
      "+---------+----------+----------+-----------+----------+\n",
      "| name    |      mEP |      mER |       mEF |      mEA |\n",
      "+=========+==========+==========+===========+==========+\n",
      "| keys    | 0.370563 | 0.781735 | 0.50279   | 0.781735 |\n",
      "+---------+----------+----------+-----------+----------+\n",
      "| values  | 0.375683 | 0.660264 | 0.478886  | 0.660264 |\n",
      "+---------+----------+----------+-----------+----------+\n",
      "| header  | 0.04914  | 0.298507 | 0.0843882 | 0.298507 |\n",
      "+---------+----------+----------+-----------+----------+\n",
      "| overall | 0.31517  | 0.701261 | 0.434887  | 0.701261 |\n",
      "+---------+----------+----------+-----------+----------+\n",
      "[2022-03-22 17:21:26,915 - trainer - INFO] - Train Epoch:[15/100] Step:[10/77] Total Loss: 65.325615 GL_Loss: 1.758844 CRF_Loss: 63.566772\n",
      "[2022-03-22 17:21:46,867 - trainer - INFO] - Train Epoch:[15/100] Step:[20/77] Total Loss: 248.443146 GL_Loss: 1.638709 CRF_Loss: 246.804443\n",
      "[2022-03-22 17:22:04,867 - trainer - INFO] - Train Epoch:[15/100] Step:[30/77] Total Loss: 89.574570 GL_Loss: 0.843492 CRF_Loss: 88.731079\n",
      "[2022-03-22 17:22:23,691 - trainer - INFO] - Train Epoch:[15/100] Step:[40/77] Total Loss: 441.019257 GL_Loss: 0.843464 CRF_Loss: 440.175781\n",
      "[2022-03-22 17:22:42,830 - trainer - INFO] - Train Epoch:[15/100] Step:[50/77] Total Loss: 189.000443 GL_Loss: 2.619944 CRF_Loss: 186.380493\n",
      "[2022-03-22 17:22:54,399 - trainer - INFO] - [Step Validation] Epoch:[15/100] Step:[50/77]  \n",
      "+---------+-----------+----------+----------+----------+\n",
      "| name    |       mEP |      mER |      mEF |      mEA |\n",
      "+=========+===========+==========+==========+==========+\n",
      "| keys    | 0.302278  | 0.678539 | 0.418238 | 0.678539 |\n",
      "+---------+-----------+----------+----------+----------+\n",
      "| values  | 0.359241  | 0.704682 | 0.475882 | 0.704682 |\n",
      "+---------+-----------+----------+----------+----------+\n",
      "| header  | 0.0508083 | 0.328358 | 0.088    | 0.328358 |\n",
      "+---------+-----------+----------+----------+----------+\n",
      "| overall | 0.277128  | 0.666343 | 0.391453 | 0.666343 |\n",
      "+---------+-----------+----------+----------+----------+\n",
      "[2022-03-22 17:23:12,407 - trainer - INFO] - Train Epoch:[15/100] Step:[60/77] Total Loss: 83.740173 GL_Loss: 2.682130 CRF_Loss: 81.058044\n",
      "[2022-03-22 17:23:32,327 - trainer - INFO] - Train Epoch:[15/100] Step:[70/77] Total Loss: 200.856598 GL_Loss: 2.710852 CRF_Loss: 198.145752\n",
      "[2022-03-22 17:23:57,040 - trainer - INFO] - [Epoch Validation] Epoch:[15/100] Total Loss: 249.936389 GL_Loss: 0.014774 CRF_Loss: 248.459030 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.404125 | 0.841096 | 0.54594  | 0.841096 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.313849 | 0.715486 | 0.43631  | 0.715486 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.108108 | 0.238806 | 0.148837 | 0.238806 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.346223 | 0.751212 | 0.47399  | 0.751212 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 17:24:16,548 - trainer - INFO] - Train Epoch:[16/100] Step:[10/77] Total Loss: 105.612259 GL_Loss: 5.333940 CRF_Loss: 100.278320\n",
      "[2022-03-22 17:24:34,618 - trainer - INFO] - Train Epoch:[16/100] Step:[20/77] Total Loss: 336.299408 GL_Loss: 1.312840 CRF_Loss: 334.986572\n",
      "[2022-03-22 17:24:54,723 - trainer - INFO] - Train Epoch:[16/100] Step:[30/77] Total Loss: 151.094757 GL_Loss: 1.811806 CRF_Loss: 149.282959\n",
      "[2022-03-22 17:25:14,029 - trainer - INFO] - Train Epoch:[16/100] Step:[40/77] Total Loss: 199.655945 GL_Loss: 1.181099 CRF_Loss: 198.474854\n",
      "[2022-03-22 17:25:32,879 - trainer - INFO] - Train Epoch:[16/100] Step:[50/77] Total Loss: 212.134979 GL_Loss: 2.740941 CRF_Loss: 209.394043\n",
      "[2022-03-22 17:25:44,453 - trainer - INFO] - [Step Validation] Epoch:[16/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.478528 | 0.783562 | 0.594183 | 0.783562 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.441195 | 0.833133 | 0.576891 | 0.833133 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.113712 | 0.253731 | 0.157044 | 0.253731 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.432742 | 0.769156 | 0.553868 | 0.769156 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 17:26:02,667 - trainer - INFO] - Train Epoch:[16/100] Step:[60/77] Total Loss: 75.485481 GL_Loss: 2.778451 CRF_Loss: 72.707031\n",
      "[2022-03-22 17:26:19,224 - trainer - INFO] - Train Epoch:[16/100] Step:[70/77] Total Loss: 110.142937 GL_Loss: 0.901543 CRF_Loss: 109.241394\n",
      "[2022-03-22 17:26:44,269 - trainer - INFO] - [Epoch Validation] Epoch:[16/100] Total Loss: 206.072975 GL_Loss: 0.019700 CRF_Loss: 204.102974 \n",
      "+---------+-----------+----------+----------+----------+\n",
      "| name    |       mEP |      mER |      mEF |      mEA |\n",
      "+=========+===========+==========+==========+==========+\n",
      "| keys    | 0.424631  | 0.815525 | 0.558474 | 0.815525 |\n",
      "+---------+-----------+----------+----------+----------+\n",
      "| values  | 0.447489  | 0.705882 | 0.547741 | 0.705882 |\n",
      "+---------+-----------+----------+----------+----------+\n",
      "| header  | 0.0740741 | 0.358209 | 0.122762 | 0.358209 |\n",
      "+---------+-----------+----------+----------+----------+\n",
      "| overall | 0.376138  | 0.741513 | 0.499102 | 0.741513 |\n",
      "+---------+-----------+----------+----------+----------+\n",
      "[2022-03-22 17:27:04,709 - trainer - INFO] - Train Epoch:[17/100] Step:[10/77] Total Loss: 46.563721 GL_Loss: 1.652831 CRF_Loss: 44.910889\n",
      "[2022-03-22 17:27:23,885 - trainer - INFO] - Train Epoch:[17/100] Step:[20/77] Total Loss: 222.990738 GL_Loss: 1.443862 CRF_Loss: 221.546875\n",
      "[2022-03-22 17:27:41,201 - trainer - INFO] - Train Epoch:[17/100] Step:[30/77] Total Loss: 81.632500 GL_Loss: 1.112849 CRF_Loss: 80.519653\n",
      "[2022-03-22 17:28:01,301 - trainer - INFO] - Train Epoch:[17/100] Step:[40/77] Total Loss: 80.474464 GL_Loss: 1.219948 CRF_Loss: 79.254517\n",
      "[2022-03-22 17:28:21,163 - trainer - INFO] - Train Epoch:[17/100] Step:[50/77] Total Loss: 85.641655 GL_Loss: 1.152397 CRF_Loss: 84.489258\n",
      "[2022-03-22 17:28:32,495 - trainer - INFO] - [Step Validation] Epoch:[17/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.476534 | 0.843836 | 0.609097 | 0.843836 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.418723 | 0.692677 | 0.521936 | 0.692677 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.16041  | 0.350746 | 0.220141 | 0.350746 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.428809 | 0.750727 | 0.545839 | 0.750727 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-22 17:28:51,985 - trainer - INFO] - Train Epoch:[17/100] Step:[60/77] Total Loss: 112.442276 GL_Loss: 0.978651 CRF_Loss: 111.463623\n",
      "[2022-03-22 17:29:09,277 - trainer - INFO] - Train Epoch:[17/100] Step:[70/77] Total Loss: 119.037521 GL_Loss: 1.211841 CRF_Loss: 117.825684\n",
      "[2022-03-22 17:29:33,401 - trainer - INFO] - [Epoch Validation] Epoch:[17/100] Total Loss: 173.056141 GL_Loss: 0.012486 CRF_Loss: 171.807505 \n",
      "+---------+-----------+----------+----------+----------+\n",
      "| name    |       mEP |      mER |      mEF |      mEA |\n",
      "+=========+===========+==========+==========+==========+\n",
      "| keys    | 0.431621  | 0.683105 | 0.528996 | 0.683105 |\n",
      "+---------+-----------+----------+----------+----------+\n",
      "| values  | 0.396565  | 0.637455 | 0.48895  | 0.637455 |\n",
      "+---------+-----------+----------+----------+----------+\n",
      "| header  | 0.0895197 | 0.30597  | 0.138514 | 0.30597  |\n",
      "+---------+-----------+----------+----------+----------+\n",
      "| overall | 0.373938  | 0.640155 | 0.472103 | 0.640155 |\n",
      "+---------+-----------+----------+----------+----------+\n",
      "[2022-03-22 17:29:53,121 - trainer - INFO] - Train Epoch:[18/100] Step:[10/77] Total Loss: 314.762909 GL_Loss: 1.399887 CRF_Loss: 313.363037\n",
      "[2022-03-22 17:30:12,239 - trainer - INFO] - Train Epoch:[18/100] Step:[20/77] Total Loss: 262.292664 GL_Loss: 2.123239 CRF_Loss: 260.169434\n",
      "[2022-03-22 17:30:30,989 - trainer - INFO] - Train Epoch:[18/100] Step:[30/77] Total Loss: 139.897003 GL_Loss: 0.961091 CRF_Loss: 138.935913\n",
      "[2022-03-22 17:30:50,569 - trainer - INFO] - Train Epoch:[18/100] Step:[40/77] Total Loss: 146.018555 GL_Loss: 2.173591 CRF_Loss: 143.844971\n",
      "[2022-03-22 17:31:09,073 - trainer - INFO] - Train Epoch:[18/100] Step:[50/77] Total Loss: 462.268860 GL_Loss: 1.326473 CRF_Loss: 460.942383\n",
      "[2022-03-22 17:31:21,670 - trainer - INFO] - [Step Validation] Epoch:[18/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.549579 | 0.774429 | 0.642911 | 0.774429 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.411531 | 0.745498 | 0.530316 | 0.745498 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.190789 | 0.216418 | 0.202797 | 0.216418 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.467541 | 0.726479 | 0.568933 | 0.726479 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 17:31:23,739 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-03-22 17:31:42,691 - trainer - INFO] - Train Epoch:[18/100] Step:[60/77] Total Loss: 244.917587 GL_Loss: 1.282698 CRF_Loss: 243.634888\n",
      "[2022-03-22 17:32:00,855 - trainer - INFO] - Train Epoch:[18/100] Step:[70/77] Total Loss: 35.614269 GL_Loss: 1.269541 CRF_Loss: 34.344727\n",
      "[2022-03-22 17:32:25,615 - trainer - INFO] - [Epoch Validation] Epoch:[18/100] Total Loss: 193.485316 GL_Loss: 0.015580 CRF_Loss: 191.927355 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.548863 | 0.815525 | 0.656135 | 0.815525 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.487825 | 0.721489 | 0.582082 | 0.721489 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.123077 | 0.179104 | 0.145897 | 0.179104 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.497053 | 0.736178 | 0.593432 | 0.736178 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 17:32:44,192 - trainer - INFO] - Train Epoch:[19/100] Step:[10/77] Total Loss: 37.550835 GL_Loss: 1.163263 CRF_Loss: 36.387573\n",
      "[2022-03-22 17:33:02,797 - trainer - INFO] - Train Epoch:[19/100] Step:[20/77] Total Loss: 303.593842 GL_Loss: 1.611169 CRF_Loss: 301.982666\n",
      "[2022-03-22 17:33:20,939 - trainer - INFO] - Train Epoch:[19/100] Step:[30/77] Total Loss: 98.537254 GL_Loss: 2.608789 CRF_Loss: 95.928467\n",
      "[2022-03-22 17:33:40,551 - trainer - INFO] - Train Epoch:[19/100] Step:[40/77] Total Loss: 418.602051 GL_Loss: 1.480222 CRF_Loss: 417.121826\n",
      "[2022-03-22 17:33:59,062 - trainer - INFO] - Train Epoch:[19/100] Step:[50/77] Total Loss: 282.258392 GL_Loss: 1.188808 CRF_Loss: 281.069580\n",
      "[2022-03-22 17:34:10,464 - trainer - INFO] - [Step Validation] Epoch:[19/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.498493 | 0.755251 | 0.600581 | 0.755251 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.423447 | 0.793517 | 0.552214 | 0.793517 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.123418 | 0.291045 | 0.173333 | 0.291045 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.431844 | 0.740543 | 0.545552 | 0.740543 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 17:34:29,074 - trainer - INFO] - Train Epoch:[19/100] Step:[60/77] Total Loss: 160.684814 GL_Loss: 2.355467 CRF_Loss: 158.329346\n",
      "[2022-03-22 17:34:47,668 - trainer - INFO] - Train Epoch:[19/100] Step:[70/77] Total Loss: 424.149017 GL_Loss: 1.457971 CRF_Loss: 422.691040\n",
      "[2022-03-22 17:35:12,570 - trainer - INFO] - [Epoch Validation] Epoch:[19/100] Total Loss: 212.278800 GL_Loss: 0.018534 CRF_Loss: 210.425441 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.356602 | 0.601826 | 0.447842 | 0.601826 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.338249 | 0.881152 | 0.488844 | 0.881152 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.208511 | 0.365672 | 0.265583 | 0.365672 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.339055 | 0.699321 | 0.45669  | 0.699321 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 17:35:32,342 - trainer - INFO] - Train Epoch:[20/100] Step:[10/77] Total Loss: 56.525787 GL_Loss: 0.947664 CRF_Loss: 55.578125\n",
      "[2022-03-22 17:35:49,164 - trainer - INFO] - Train Epoch:[20/100] Step:[20/77] Total Loss: 57.096729 GL_Loss: 1.508472 CRF_Loss: 55.588257\n",
      "[2022-03-22 17:36:06,753 - trainer - INFO] - Train Epoch:[20/100] Step:[30/77] Total Loss: 188.343765 GL_Loss: 2.043961 CRF_Loss: 186.299805\n",
      "[2022-03-22 17:36:25,599 - trainer - INFO] - Train Epoch:[20/100] Step:[40/77] Total Loss: 133.135773 GL_Loss: 1.800694 CRF_Loss: 131.335083\n",
      "[2022-03-22 17:36:44,592 - trainer - INFO] - Train Epoch:[20/100] Step:[50/77] Total Loss: 204.609695 GL_Loss: 1.256789 CRF_Loss: 203.352905\n",
      "[2022-03-22 17:36:56,071 - trainer - INFO] - [Step Validation] Epoch:[20/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.495291 | 0.816438 | 0.616552 | 0.816438 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.432644 | 0.728691 | 0.542934 | 0.728691 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.172222 | 0.231343 | 0.197452 | 0.231343 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.452184 | 0.742968 | 0.562202 | 0.742968 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 17:37:16,696 - trainer - INFO] - Train Epoch:[20/100] Step:[60/77] Total Loss: 58.702312 GL_Loss: 1.489423 CRF_Loss: 57.212891\n",
      "[2022-03-22 17:37:35,795 - trainer - INFO] - Train Epoch:[20/100] Step:[70/77] Total Loss: 273.241272 GL_Loss: 7.528863 CRF_Loss: 265.712402\n",
      "[2022-03-22 17:38:00,203 - trainer - INFO] - [Epoch Validation] Epoch:[20/100] Total Loss: 148.397641 GL_Loss: 0.037535 CRF_Loss: 144.644117 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.481631 | 0.873973 | 0.621025 | 0.873973 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.516854 | 0.717887 | 0.601005 | 0.717887 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.101493 | 0.253731 | 0.144989 | 0.253731 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.45674  | 0.770611 | 0.573543 | 0.770611 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-22 17:38:02,083 - trainer - INFO] - Saving checkpoint: saved/models/PICK_Default/test_0322_164111/checkpoint-epoch20.pth ...\n",
      "[2022-03-22 17:38:20,202 - trainer - INFO] - Train Epoch:[21/100] Step:[10/77] Total Loss: 20.150723 GL_Loss: 1.475674 CRF_Loss: 18.675049\n",
      "[2022-03-22 17:38:38,187 - trainer - INFO] - Train Epoch:[21/100] Step:[20/77] Total Loss: 114.303467 GL_Loss: 1.083494 CRF_Loss: 113.219971\n",
      "[2022-03-22 17:38:57,288 - trainer - INFO] - Train Epoch:[21/100] Step:[30/77] Total Loss: 28.509623 GL_Loss: 0.882669 CRF_Loss: 27.626953\n",
      "[2022-03-22 17:39:17,036 - trainer - INFO] - Train Epoch:[21/100] Step:[40/77] Total Loss: 107.620392 GL_Loss: 1.328402 CRF_Loss: 106.291992\n",
      "[2022-03-22 17:39:37,613 - trainer - INFO] - Train Epoch:[21/100] Step:[50/77] Total Loss: 229.122269 GL_Loss: 1.862990 CRF_Loss: 227.259277\n",
      "[2022-03-22 17:39:49,061 - trainer - INFO] - [Step Validation] Epoch:[21/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.578313 | 0.745205 | 0.651237 | 0.745205 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.494409 | 0.743097 | 0.593765 | 0.743097 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.215054 | 0.298507 | 0.25     | 0.298507 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.517726 | 0.715325 | 0.600692 | 0.715325 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 17:39:51,135 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-03-22 17:40:09,162 - trainer - INFO] - Train Epoch:[21/100] Step:[60/77] Total Loss: 118.382889 GL_Loss: 1.736407 CRF_Loss: 116.646484\n",
      "[2022-03-22 17:40:29,435 - trainer - INFO] - Train Epoch:[21/100] Step:[70/77] Total Loss: 165.081528 GL_Loss: 1.550528 CRF_Loss: 163.531006\n",
      "[2022-03-22 17:40:54,150 - trainer - INFO] - [Epoch Validation] Epoch:[21/100] Total Loss: 118.815608 GL_Loss: 0.016546 CRF_Loss: 117.160989 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.567677 | 0.769863 | 0.653488 | 0.769863 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.50853  | 0.751501 | 0.606589 | 0.751501 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.16242  | 0.380597 | 0.227679 | 0.380597 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.50165  | 0.737148 | 0.597015 | 0.737148 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 17:41:13,815 - trainer - INFO] - Train Epoch:[22/100] Step:[10/77] Total Loss: 137.180740 GL_Loss: 1.312331 CRF_Loss: 135.868408\n",
      "[2022-03-22 17:41:32,537 - trainer - INFO] - Train Epoch:[22/100] Step:[20/77] Total Loss: 58.882710 GL_Loss: 1.530783 CRF_Loss: 57.351929\n",
      "[2022-03-22 17:41:50,747 - trainer - INFO] - Train Epoch:[22/100] Step:[30/77] Total Loss: 95.488426 GL_Loss: 0.849020 CRF_Loss: 94.639404\n",
      "[2022-03-22 17:42:08,065 - trainer - INFO] - Train Epoch:[22/100] Step:[40/77] Total Loss: 66.724045 GL_Loss: 1.252124 CRF_Loss: 65.471924\n",
      "[2022-03-22 17:42:26,631 - trainer - INFO] - Train Epoch:[22/100] Step:[50/77] Total Loss: 113.579384 GL_Loss: 0.682902 CRF_Loss: 112.896484\n",
      "[2022-03-22 17:42:38,062 - trainer - INFO] - [Step Validation] Epoch:[22/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.500297 | 0.769863 | 0.606475 | 0.769863 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.496459 | 0.841537 | 0.624499 | 0.841537 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.131926 | 0.373134 | 0.194932 | 0.373134 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.458573 | 0.773036 | 0.575659 | 0.773036 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 17:42:57,796 - trainer - INFO] - Train Epoch:[22/100] Step:[60/77] Total Loss: 144.603378 GL_Loss: 1.553203 CRF_Loss: 143.050171\n",
      "[2022-03-22 17:43:17,594 - trainer - INFO] - Train Epoch:[22/100] Step:[70/77] Total Loss: 54.254417 GL_Loss: 1.555689 CRF_Loss: 52.698730\n",
      "[2022-03-22 17:43:42,984 - trainer - INFO] - [Epoch Validation] Epoch:[22/100] Total Loss: 98.944018 GL_Loss: 0.012547 CRF_Loss: 97.689303 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.51295  | 0.831963 | 0.634622 | 0.831963 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.463495 | 0.678271 | 0.550682 | 0.678271 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.159341 | 0.432836 | 0.232932 | 0.432836 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.456684 | 0.743938 | 0.565947 | 0.743938 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 17:44:02,417 - trainer - INFO] - Train Epoch:[23/100] Step:[10/77] Total Loss: 145.370789 GL_Loss: 1.572574 CRF_Loss: 143.798218\n",
      "[2022-03-22 17:44:20,984 - trainer - INFO] - Train Epoch:[23/100] Step:[20/77] Total Loss: 203.785446 GL_Loss: 1.432906 CRF_Loss: 202.352539\n",
      "[2022-03-22 17:44:39,619 - trainer - INFO] - Train Epoch:[23/100] Step:[30/77] Total Loss: 17.452484 GL_Loss: 0.780731 CRF_Loss: 16.671753\n",
      "[2022-03-22 17:44:59,368 - trainer - INFO] - Train Epoch:[23/100] Step:[40/77] Total Loss: 22.923315 GL_Loss: 0.504370 CRF_Loss: 22.418945\n",
      "[2022-03-22 17:45:18,548 - trainer - INFO] - Train Epoch:[23/100] Step:[50/77] Total Loss: 29.145111 GL_Loss: 1.227876 CRF_Loss: 27.917236\n",
      "[2022-03-22 17:45:30,002 - trainer - INFO] - [Step Validation] Epoch:[23/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.595355 | 0.772603 | 0.672496 | 0.772603 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.540605 | 0.815126 | 0.650072 | 0.815126 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.159259 | 0.320896 | 0.212871 | 0.320896 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.532067 | 0.760427 | 0.626073 | 0.760427 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 17:45:32,105 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-03-22 17:45:51,978 - trainer - INFO] - Train Epoch:[23/100] Step:[60/77] Total Loss: 51.452579 GL_Loss: 1.556460 CRF_Loss: 49.896118\n",
      "[2022-03-22 17:46:10,148 - trainer - INFO] - Train Epoch:[23/100] Step:[70/77] Total Loss: 65.962585 GL_Loss: 0.666684 CRF_Loss: 65.295898\n",
      "[2022-03-22 17:46:34,509 - trainer - INFO] - [Epoch Validation] Epoch:[23/100] Total Loss: 78.634651 GL_Loss: 0.010808 CRF_Loss: 77.553865 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.526671 | 0.712329 | 0.60559  | 0.712329 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.519856 | 0.864346 | 0.649234 | 0.864346 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.182635 | 0.455224 | 0.260684 | 0.455224 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.487812 | 0.757032 | 0.593311 | 0.757032 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 17:46:53,105 - trainer - INFO] - Train Epoch:[24/100] Step:[10/77] Total Loss: 12.390962 GL_Loss: 1.203340 CRF_Loss: 11.187622\n",
      "[2022-03-22 17:47:12,350 - trainer - INFO] - Train Epoch:[24/100] Step:[20/77] Total Loss: 69.220512 GL_Loss: 1.150441 CRF_Loss: 68.070068\n",
      "[2022-03-22 17:47:30,777 - trainer - INFO] - Train Epoch:[24/100] Step:[30/77] Total Loss: 55.722900 GL_Loss: 0.739625 CRF_Loss: 54.983276\n",
      "[2022-03-22 17:47:50,138 - trainer - INFO] - Train Epoch:[24/100] Step:[40/77] Total Loss: 43.499592 GL_Loss: 1.045001 CRF_Loss: 42.454590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-22 17:48:09,076 - trainer - INFO] - Train Epoch:[24/100] Step:[50/77] Total Loss: 70.334641 GL_Loss: 0.570481 CRF_Loss: 69.764160\n",
      "[2022-03-22 17:48:20,688 - trainer - INFO] - [Step Validation] Epoch:[24/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.560883 | 0.811872 | 0.663433 | 0.811872 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.538672 | 0.710684 | 0.612836 | 0.710684 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.160121 | 0.395522 | 0.227957 | 0.395522 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.508789 | 0.743938 | 0.604294 | 0.743938 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 17:48:41,177 - trainer - INFO] - Train Epoch:[24/100] Step:[60/77] Total Loss: 126.349060 GL_Loss: 1.094176 CRF_Loss: 125.254883\n",
      "[2022-03-22 17:48:58,913 - trainer - INFO] - Train Epoch:[24/100] Step:[70/77] Total Loss: 69.791771 GL_Loss: 0.574974 CRF_Loss: 69.216797\n",
      "[2022-03-22 17:49:23,819 - trainer - INFO] - [Epoch Validation] Epoch:[24/100] Total Loss: 70.185260 GL_Loss: 0.010869 CRF_Loss: 69.098405 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.582187 | 0.811872 | 0.678108 | 0.811872 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.515695 | 0.828331 | 0.635652 | 0.828331 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.242105 | 0.343284 | 0.283951 | 0.343284 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.531915 | 0.78807  | 0.635138 | 0.78807  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 17:49:43,827 - trainer - INFO] - Train Epoch:[25/100] Step:[10/77] Total Loss: 25.248905 GL_Loss: 1.116094 CRF_Loss: 24.132812\n",
      "[2022-03-22 17:50:02,677 - trainer - INFO] - Train Epoch:[25/100] Step:[20/77] Total Loss: 43.986359 GL_Loss: 1.195830 CRF_Loss: 42.790527\n",
      "[2022-03-22 17:50:22,452 - trainer - INFO] - Train Epoch:[25/100] Step:[30/77] Total Loss: 45.285088 GL_Loss: 0.980889 CRF_Loss: 44.304199\n",
      "[2022-03-22 17:50:41,216 - trainer - INFO] - Train Epoch:[25/100] Step:[40/77] Total Loss: 438.537781 GL_Loss: 0.551074 CRF_Loss: 437.986694\n",
      "[2022-03-22 17:51:02,641 - trainer - INFO] - Train Epoch:[25/100] Step:[50/77] Total Loss: 58.254044 GL_Loss: 1.049332 CRF_Loss: 57.204712\n",
      "[2022-03-22 17:51:13,975 - trainer - INFO] - [Step Validation] Epoch:[25/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.536967 | 0.782648 | 0.636938 | 0.782648 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.476336 | 0.7491   | 0.582361 | 0.7491   |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.162791 | 0.261194 | 0.200573 | 0.261194 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.485742 | 0.735209 | 0.584989 | 0.735209 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 17:51:30,782 - trainer - INFO] - Train Epoch:[25/100] Step:[60/77] Total Loss: 110.906219 GL_Loss: 1.010101 CRF_Loss: 109.896118\n",
      "[2022-03-22 17:51:47,448 - trainer - INFO] - Train Epoch:[25/100] Step:[70/77] Total Loss: 110.362328 GL_Loss: 1.267601 CRF_Loss: 109.094727\n",
      "[2022-03-22 17:52:11,120 - trainer - INFO] - [Epoch Validation] Epoch:[25/100] Total Loss: 91.004214 GL_Loss: 0.011138 CRF_Loss: 89.890425 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.565004 | 0.734247 | 0.638602 | 0.734247 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.535058 | 0.769508 | 0.631216 | 0.769508 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.213018 | 0.537313 | 0.305085 | 0.537313 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.512673 | 0.735694 | 0.604262 | 0.735694 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 17:52:30,278 - trainer - INFO] - Train Epoch:[26/100] Step:[10/77] Total Loss: 30.023575 GL_Loss: 1.905044 CRF_Loss: 28.118530\n",
      "[2022-03-22 17:52:49,911 - trainer - INFO] - Train Epoch:[26/100] Step:[20/77] Total Loss: 212.829681 GL_Loss: 3.152674 CRF_Loss: 209.677002\n",
      "[2022-03-22 17:53:09,229 - trainer - INFO] - Train Epoch:[26/100] Step:[30/77] Total Loss: 48.748196 GL_Loss: 1.640040 CRF_Loss: 47.108154\n",
      "[2022-03-22 17:53:27,718 - trainer - INFO] - Train Epoch:[26/100] Step:[40/77] Total Loss: 29.602549 GL_Loss: 0.879161 CRF_Loss: 28.723389\n",
      "[2022-03-22 17:53:45,820 - trainer - INFO] - Train Epoch:[26/100] Step:[50/77] Total Loss: 83.895119 GL_Loss: 3.194437 CRF_Loss: 80.700684\n",
      "[2022-03-22 17:53:57,364 - trainer - INFO] - [Step Validation] Epoch:[26/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.585366 | 0.745205 | 0.655685 | 0.745205 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.610009 | 0.848739 | 0.709839 | 0.848739 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.161074 | 0.537313 | 0.247849 | 0.537313 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.531667 | 0.773521 | 0.630186 | 0.773521 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 17:54:16,625 - trainer - INFO] - Train Epoch:[26/100] Step:[60/77] Total Loss: 193.283020 GL_Loss: 0.929990 CRF_Loss: 192.353027\n",
      "[2022-03-22 17:54:34,439 - trainer - INFO] - Train Epoch:[26/100] Step:[70/77] Total Loss: 97.430237 GL_Loss: 0.829895 CRF_Loss: 96.600342\n",
      "[2022-03-22 17:54:58,983 - trainer - INFO] - [Epoch Validation] Epoch:[26/100] Total Loss: 122.427778 GL_Loss: 0.014748 CRF_Loss: 120.952996 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.521712 | 0.768037 | 0.621352 | 0.768037 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.537822 | 0.776711 | 0.63556  | 0.776711 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.156156 | 0.38806  | 0.222698 | 0.38806  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.489199 | 0.746848 | 0.591171 | 0.746848 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 17:55:17,211 - trainer - INFO] - Train Epoch:[27/100] Step:[10/77] Total Loss: 74.443268 GL_Loss: 0.875151 CRF_Loss: 73.568115\n",
      "[2022-03-22 17:55:37,168 - trainer - INFO] - Train Epoch:[27/100] Step:[20/77] Total Loss: 32.031200 GL_Loss: 1.101026 CRF_Loss: 30.930176\n",
      "[2022-03-22 17:55:56,468 - trainer - INFO] - Train Epoch:[27/100] Step:[30/77] Total Loss: 24.721516 GL_Loss: 1.305379 CRF_Loss: 23.416138\n",
      "[2022-03-22 17:56:16,471 - trainer - INFO] - Train Epoch:[27/100] Step:[40/77] Total Loss: 42.215485 GL_Loss: 2.848298 CRF_Loss: 39.367188\n",
      "[2022-03-22 17:56:35,767 - trainer - INFO] - Train Epoch:[27/100] Step:[50/77] Total Loss: 158.688232 GL_Loss: 1.458259 CRF_Loss: 157.229980\n",
      "[2022-03-22 17:56:47,203 - trainer - INFO] - [Step Validation] Epoch:[27/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.542857 | 0.746119 | 0.628462 | 0.746119 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.527859 | 0.864346 | 0.655439 | 0.864346 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.111429 | 0.291045 | 0.161157 | 0.291045 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.489593 | 0.764306 | 0.596857 | 0.764306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 17:57:04,053 - trainer - INFO] - Train Epoch:[27/100] Step:[60/77] Total Loss: 60.909309 GL_Loss: 1.565314 CRF_Loss: 59.343994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-22 17:57:23,693 - trainer - INFO] - Train Epoch:[27/100] Step:[70/77] Total Loss: 77.863091 GL_Loss: 1.695858 CRF_Loss: 76.167236\n",
      "[2022-03-22 17:57:47,517 - trainer - INFO] - [Epoch Validation] Epoch:[27/100] Total Loss: 95.839609 GL_Loss: 0.014335 CRF_Loss: 94.406124 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.505256 | 0.702283 | 0.587696 | 0.702283 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.447273 | 0.885954 | 0.594442 | 0.885954 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.206278 | 0.343284 | 0.257703 | 0.343284 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.457437 | 0.753152 | 0.569177 | 0.753152 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 17:58:05,052 - trainer - INFO] - Train Epoch:[28/100] Step:[10/77] Total Loss: 122.929436 GL_Loss: 2.137446 CRF_Loss: 120.791992\n",
      "[2022-03-22 17:58:24,580 - trainer - INFO] - Train Epoch:[28/100] Step:[20/77] Total Loss: 269.169067 GL_Loss: 1.390254 CRF_Loss: 267.778809\n",
      "[2022-03-22 17:58:42,781 - trainer - INFO] - Train Epoch:[28/100] Step:[30/77] Total Loss: 99.970940 GL_Loss: 1.100703 CRF_Loss: 98.870239\n",
      "[2022-03-22 17:59:00,304 - trainer - INFO] - Train Epoch:[28/100] Step:[40/77] Total Loss: 260.169312 GL_Loss: 1.784789 CRF_Loss: 258.384521\n",
      "[2022-03-22 17:59:17,754 - trainer - INFO] - Train Epoch:[28/100] Step:[50/77] Total Loss: 45.838196 GL_Loss: 1.307924 CRF_Loss: 44.530273\n",
      "[2022-03-22 17:59:29,142 - trainer - INFO] - [Step Validation] Epoch:[28/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.493896 | 0.812785 | 0.614429 | 0.812785 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.503771 | 0.801921 | 0.618805 | 0.801921 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.127976 | 0.320896 | 0.182979 | 0.320896 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.462182 | 0.776431 | 0.579443 | 0.776431 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 17:59:48,196 - trainer - INFO] - Train Epoch:[28/100] Step:[60/77] Total Loss: 150.392456 GL_Loss: 1.051030 CRF_Loss: 149.341431\n",
      "[2022-03-22 18:00:07,506 - trainer - INFO] - Train Epoch:[28/100] Step:[70/77] Total Loss: 119.921310 GL_Loss: 2.280988 CRF_Loss: 117.640320\n",
      "[2022-03-22 18:00:34,336 - trainer - INFO] - [Epoch Validation] Epoch:[28/100] Total Loss: 149.504043 GL_Loss: 0.015079 CRF_Loss: 147.996113 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.446438 | 0.772603 | 0.565886 | 0.772603 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.464172 | 0.69988  | 0.558162 | 0.69988  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.140167 | 0.5      | 0.218954 | 0.5      |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.412235 | 0.725509 | 0.525742 | 0.725509 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 18:00:53,652 - trainer - INFO] - Train Epoch:[29/100] Step:[10/77] Total Loss: 34.781555 GL_Loss: 2.381410 CRF_Loss: 32.400146\n",
      "[2022-03-22 18:01:12,408 - trainer - INFO] - Train Epoch:[29/100] Step:[20/77] Total Loss: 84.525833 GL_Loss: 1.785602 CRF_Loss: 82.740234\n",
      "[2022-03-22 18:01:30,401 - trainer - INFO] - Train Epoch:[29/100] Step:[30/77] Total Loss: 73.937134 GL_Loss: 6.358646 CRF_Loss: 67.578491\n",
      "[2022-03-22 18:01:49,225 - trainer - INFO] - Train Epoch:[29/100] Step:[40/77] Total Loss: 103.024940 GL_Loss: 1.306309 CRF_Loss: 101.718628\n",
      "[2022-03-22 18:02:08,861 - trainer - INFO] - Train Epoch:[29/100] Step:[50/77] Total Loss: 162.560532 GL_Loss: 1.357653 CRF_Loss: 161.202881\n",
      "[2022-03-22 18:02:20,373 - trainer - INFO] - [Step Validation] Epoch:[29/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.508389 | 0.830137 | 0.630593 | 0.830137 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.498454 | 0.77431  | 0.606488 | 0.77431  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.165775 | 0.462687 | 0.244094 | 0.462687 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.467593 | 0.783705 | 0.585719 | 0.783705 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 18:02:41,101 - trainer - INFO] - Train Epoch:[29/100] Step:[60/77] Total Loss: 120.648323 GL_Loss: 1.432743 CRF_Loss: 119.215576\n",
      "[2022-03-22 18:02:58,286 - trainer - INFO] - Train Epoch:[29/100] Step:[70/77] Total Loss: 84.795845 GL_Loss: 1.083806 CRF_Loss: 83.712036\n",
      "[2022-03-22 18:03:21,570 - trainer - INFO] - [Epoch Validation] Epoch:[29/100] Total Loss: 96.271193 GL_Loss: 0.015822 CRF_Loss: 94.688997 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.455704 | 0.718721 | 0.55776  | 0.718721 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.509852 | 0.745498 | 0.605558 | 0.745498 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.138298 | 0.485075 | 0.215232 | 0.485075 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.431332 | 0.714355 | 0.537886 | 0.714355 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 18:03:41,697 - trainer - INFO] - Train Epoch:[30/100] Step:[10/77] Total Loss: 100.008858 GL_Loss: 0.899236 CRF_Loss: 99.109619\n",
      "[2022-03-22 18:04:00,643 - trainer - INFO] - Train Epoch:[30/100] Step:[20/77] Total Loss: 54.226715 GL_Loss: 0.694855 CRF_Loss: 53.531860\n",
      "[2022-03-22 18:04:20,289 - trainer - INFO] - Train Epoch:[30/100] Step:[30/77] Total Loss: 31.002092 GL_Loss: 1.393939 CRF_Loss: 29.608154\n",
      "[2022-03-22 18:04:39,717 - trainer - INFO] - Train Epoch:[30/100] Step:[40/77] Total Loss: 18.739834 GL_Loss: 0.736172 CRF_Loss: 18.003662\n",
      "[2022-03-22 18:04:58,778 - trainer - INFO] - Train Epoch:[30/100] Step:[50/77] Total Loss: 77.484756 GL_Loss: 2.171767 CRF_Loss: 75.312988\n",
      "[2022-03-22 18:05:10,313 - trainer - INFO] - [Step Validation] Epoch:[30/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.582494 | 0.844749 | 0.689527 | 0.844749 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.508165 | 0.635054 | 0.564568 | 0.635054 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.311258 | 0.350746 | 0.329825 | 0.350746 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.539928 | 0.727934 | 0.619992 | 0.727934 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 18:05:29,686 - trainer - INFO] - Train Epoch:[30/100] Step:[60/77] Total Loss: 67.493996 GL_Loss: 2.646824 CRF_Loss: 64.847168\n",
      "[2022-03-22 18:05:48,522 - trainer - INFO] - Train Epoch:[30/100] Step:[70/77] Total Loss: 38.543999 GL_Loss: 2.508599 CRF_Loss: 36.035400\n",
      "[2022-03-22 18:06:12,195 - trainer - INFO] - [Epoch Validation] Epoch:[30/100] Total Loss: 66.294579 GL_Loss: 0.017750 CRF_Loss: 64.519560 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.643717 | 0.879452 | 0.743342 | 0.879452 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.634872 | 0.743097 | 0.684735 | 0.743097 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.266272 | 0.335821 | 0.29703  | 0.335821 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.616288 | 0.78904  | 0.692046 | 0.78904  |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-22 18:06:30,041 - trainer - INFO] - Train Epoch:[31/100] Step:[10/77] Total Loss: 38.213860 GL_Loss: 0.675162 CRF_Loss: 37.538696\n",
      "[2022-03-22 18:06:48,432 - trainer - INFO] - Train Epoch:[31/100] Step:[20/77] Total Loss: 53.753803 GL_Loss: 1.034321 CRF_Loss: 52.719482\n",
      "[2022-03-22 18:07:05,825 - trainer - INFO] - Train Epoch:[31/100] Step:[30/77] Total Loss: 121.661636 GL_Loss: 1.027847 CRF_Loss: 120.633789\n",
      "[2022-03-22 18:07:25,255 - trainer - INFO] - Train Epoch:[31/100] Step:[40/77] Total Loss: 48.486187 GL_Loss: 0.779277 CRF_Loss: 47.706909\n",
      "[2022-03-22 18:07:46,152 - trainer - INFO] - Train Epoch:[31/100] Step:[50/77] Total Loss: 81.990524 GL_Loss: 0.947800 CRF_Loss: 81.042725\n",
      "[2022-03-22 18:07:57,557 - trainer - INFO] - [Step Validation] Epoch:[31/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.638791 | 0.830137 | 0.722002 | 0.830137 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.586799 | 0.779112 | 0.669417 | 0.779112 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.294798 | 0.380597 | 0.332248 | 0.380597 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.595485 | 0.78031  | 0.675483 | 0.78031  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 18:08:17,312 - trainer - INFO] - Train Epoch:[31/100] Step:[60/77] Total Loss: 63.270138 GL_Loss: 0.966670 CRF_Loss: 62.303467\n",
      "[2022-03-22 18:08:35,901 - trainer - INFO] - Train Epoch:[31/100] Step:[70/77] Total Loss: 19.668671 GL_Loss: 0.835418 CRF_Loss: 18.833252\n",
      "[2022-03-22 18:09:00,415 - trainer - INFO] - [Epoch Validation] Epoch:[31/100] Total Loss: 46.532928 GL_Loss: 0.011620 CRF_Loss: 45.370938 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.591995 | 0.837443 | 0.693646 | 0.837443 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.571171 | 0.761104 | 0.652599 | 0.761104 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.194346 | 0.410448 | 0.263789 | 0.410448 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.545887 | 0.778855 | 0.641886 | 0.778855 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 18:09:18,680 - trainer - INFO] - Train Epoch:[32/100] Step:[10/77] Total Loss: 3.873737 GL_Loss: 0.836994 CRF_Loss: 3.036743\n",
      "[2022-03-22 18:09:37,943 - trainer - INFO] - Train Epoch:[32/100] Step:[20/77] Total Loss: 8.153320 GL_Loss: 1.140625 CRF_Loss: 7.012695\n",
      "[2022-03-22 18:09:56,953 - trainer - INFO] - Train Epoch:[32/100] Step:[30/77] Total Loss: 31.260519 GL_Loss: 1.131124 CRF_Loss: 30.129395\n",
      "[2022-03-22 18:10:14,791 - trainer - INFO] - Train Epoch:[32/100] Step:[40/77] Total Loss: 19.914423 GL_Loss: 0.709589 CRF_Loss: 19.204834\n",
      "[2022-03-22 18:10:33,423 - trainer - INFO] - Train Epoch:[32/100] Step:[50/77] Total Loss: 27.625500 GL_Loss: 0.843518 CRF_Loss: 26.781982\n",
      "[2022-03-22 18:10:44,802 - trainer - INFO] - [Step Validation] Epoch:[32/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.596192 | 0.829224 | 0.693659 | 0.829224 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.594669 | 0.776711 | 0.673607 | 0.776711 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.209738 | 0.41791  | 0.279302 | 0.41791  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.559764 | 0.78128  | 0.652227 | 0.78128  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 18:11:05,476 - trainer - INFO] - Train Epoch:[32/100] Step:[60/77] Total Loss: 35.411163 GL_Loss: 0.968047 CRF_Loss: 34.443115\n",
      "[2022-03-22 18:11:23,404 - trainer - INFO] - Train Epoch:[32/100] Step:[70/77] Total Loss: 45.974918 GL_Loss: 0.646793 CRF_Loss: 45.328125\n",
      "[2022-03-22 18:11:48,251 - trainer - INFO] - [Epoch Validation] Epoch:[32/100] Total Loss: 33.667818 GL_Loss: 0.009447 CRF_Loss: 32.723151 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.598941 | 0.826484 | 0.694551 | 0.826484 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.566929 | 0.777911 | 0.65587  | 0.777911 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.224066 | 0.402985 | 0.288    | 0.402985 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.555095 | 0.77934  | 0.648376 | 0.77934  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 18:12:06,503 - trainer - INFO] - Train Epoch:[33/100] Step:[10/77] Total Loss: 16.555349 GL_Loss: 0.877371 CRF_Loss: 15.677979\n",
      "[2022-03-22 18:12:25,633 - trainer - INFO] - Train Epoch:[33/100] Step:[20/77] Total Loss: 17.737175 GL_Loss: 0.605339 CRF_Loss: 17.131836\n",
      "[2022-03-22 18:12:45,035 - trainer - INFO] - Train Epoch:[33/100] Step:[30/77] Total Loss: 57.328125 GL_Loss: 1.137209 CRF_Loss: 56.190918\n",
      "[2022-03-22 18:13:03,993 - trainer - INFO] - Train Epoch:[33/100] Step:[40/77] Total Loss: 32.899265 GL_Loss: 0.604467 CRF_Loss: 32.294800\n",
      "[2022-03-22 18:13:21,624 - trainer - INFO] - Train Epoch:[33/100] Step:[50/77] Total Loss: 81.099266 GL_Loss: 0.881978 CRF_Loss: 80.217285\n",
      "[2022-03-22 18:13:33,162 - trainer - INFO] - [Step Validation] Epoch:[33/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.61631  | 0.842009 | 0.711694 | 0.842009 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.578413 | 0.752701 | 0.654147 | 0.752701 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.286458 | 0.410448 | 0.337423 | 0.410448 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.578644 | 0.777886 | 0.663633 | 0.777886 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 18:13:52,646 - trainer - INFO] - Train Epoch:[33/100] Step:[60/77] Total Loss: 16.150625 GL_Loss: 0.943532 CRF_Loss: 15.207092\n",
      "[2022-03-22 18:14:11,886 - trainer - INFO] - Train Epoch:[33/100] Step:[70/77] Total Loss: 31.275581 GL_Loss: 0.777534 CRF_Loss: 30.498047\n",
      "[2022-03-22 18:14:37,471 - trainer - INFO] - [Epoch Validation] Epoch:[33/100] Total Loss: 32.423477 GL_Loss: 0.009088 CRF_Loss: 31.514684 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.631042 | 0.846575 | 0.723089 | 0.846575 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.577657 | 0.763505 | 0.657704 | 0.763505 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.305085 | 0.402985 | 0.347267 | 0.402985 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.588642 | 0.78419  | 0.672489 | 0.78419  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 18:14:57,906 - trainer - INFO] - Train Epoch:[34/100] Step:[10/77] Total Loss: 75.373924 GL_Loss: 1.012841 CRF_Loss: 74.361084\n",
      "[2022-03-22 18:15:18,442 - trainer - INFO] - Train Epoch:[34/100] Step:[20/77] Total Loss: 43.835995 GL_Loss: 0.646052 CRF_Loss: 43.189941\n",
      "[2022-03-22 18:15:35,735 - trainer - INFO] - Train Epoch:[34/100] Step:[30/77] Total Loss: 12.035806 GL_Loss: 0.706094 CRF_Loss: 11.329712\n",
      "[2022-03-22 18:15:53,838 - trainer - INFO] - Train Epoch:[34/100] Step:[40/77] Total Loss: 30.044632 GL_Loss: 0.735063 CRF_Loss: 29.309570\n",
      "[2022-03-22 18:16:13,179 - trainer - INFO] - Train Epoch:[34/100] Step:[50/77] Total Loss: 10.559974 GL_Loss: 0.766273 CRF_Loss: 9.793701\n",
      "[2022-03-22 18:16:24,520 - trainer - INFO] - [Step Validation] Epoch:[34/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.602776 | 0.832877 | 0.699387 | 0.832877 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.554146 | 0.786315 | 0.650124 | 0.786315 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.267677 | 0.395522 | 0.319277 | 0.395522 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.559972 | 0.785645 | 0.653885 | 0.785645 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-22 18:16:42,499 - trainer - INFO] - Train Epoch:[34/100] Step:[60/77] Total Loss: 28.135191 GL_Loss: 0.903746 CRF_Loss: 27.231445\n",
      "[2022-03-22 18:17:00,332 - trainer - INFO] - Train Epoch:[34/100] Step:[70/77] Total Loss: 9.557460 GL_Loss: 0.501674 CRF_Loss: 9.055786\n",
      "[2022-03-22 18:17:25,707 - trainer - INFO] - [Epoch Validation] Epoch:[34/100] Total Loss: 29.455591 GL_Loss: 0.008872 CRF_Loss: 28.568416 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.624484 | 0.829224 | 0.712436 | 0.829224 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.602089 | 0.761104 | 0.672322 | 0.761104 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.257778 | 0.432836 | 0.32312  | 0.432836 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.585652 | 0.775946 | 0.667501 | 0.775946 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 18:17:43,790 - trainer - INFO] - Train Epoch:[35/100] Step:[10/77] Total Loss: 40.135464 GL_Loss: 0.920499 CRF_Loss: 39.214966\n",
      "[2022-03-22 18:18:04,494 - trainer - INFO] - Train Epoch:[35/100] Step:[20/77] Total Loss: 9.839314 GL_Loss: 1.475301 CRF_Loss: 8.364014\n",
      "[2022-03-22 18:18:23,884 - trainer - INFO] - Train Epoch:[35/100] Step:[30/77] Total Loss: 73.795456 GL_Loss: 1.100141 CRF_Loss: 72.695312\n",
      "[2022-03-22 18:18:44,677 - trainer - INFO] - Train Epoch:[35/100] Step:[40/77] Total Loss: 68.605942 GL_Loss: 1.036360 CRF_Loss: 67.569580\n",
      "[2022-03-22 18:19:02,249 - trainer - INFO] - Train Epoch:[35/100] Step:[50/77] Total Loss: 13.496396 GL_Loss: 0.741269 CRF_Loss: 12.755127\n",
      "[2022-03-22 18:19:13,659 - trainer - INFO] - [Step Validation] Epoch:[35/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.619851 | 0.838356 | 0.712733 | 0.838356 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.572193 | 0.770708 | 0.656777 | 0.770708 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.236111 | 0.380597 | 0.291429 | 0.380597 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.571479 | 0.78128  | 0.660111 | 0.78128  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 18:19:32,462 - trainer - INFO] - Train Epoch:[35/100] Step:[60/77] Total Loss: 9.224227 GL_Loss: 0.860457 CRF_Loss: 8.363770\n",
      "[2022-03-22 18:19:50,430 - trainer - INFO] - Train Epoch:[35/100] Step:[70/77] Total Loss: 31.874958 GL_Loss: 0.638385 CRF_Loss: 31.236572\n",
      "[2022-03-22 18:20:15,333 - trainer - INFO] - [Epoch Validation] Epoch:[35/100] Total Loss: 27.875045 GL_Loss: 0.008792 CRF_Loss: 26.995837 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.640935 | 0.826484 | 0.721978 | 0.826484 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.629451 | 0.785114 | 0.698718 | 0.785114 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.251121 | 0.41791  | 0.313725 | 0.41791  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.603964 | 0.78322  | 0.68201  | 0.78322  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 18:20:35,743 - trainer - INFO] - Train Epoch:[36/100] Step:[10/77] Total Loss: 55.909737 GL_Loss: 0.892891 CRF_Loss: 55.016846\n",
      "[2022-03-22 18:20:56,968 - trainer - INFO] - Train Epoch:[36/100] Step:[20/77] Total Loss: 12.546128 GL_Loss: 0.545152 CRF_Loss: 12.000977\n",
      "[2022-03-22 18:21:16,032 - trainer - INFO] - Train Epoch:[36/100] Step:[30/77] Total Loss: 16.930140 GL_Loss: 0.635705 CRF_Loss: 16.294434\n",
      "[2022-03-22 18:21:35,311 - trainer - INFO] - Train Epoch:[36/100] Step:[40/77] Total Loss: 25.273523 GL_Loss: 0.647302 CRF_Loss: 24.626221\n",
      "[2022-03-22 18:21:52,030 - trainer - INFO] - Train Epoch:[36/100] Step:[50/77] Total Loss: 46.760677 GL_Loss: 0.846125 CRF_Loss: 45.914551\n",
      "[2022-03-22 18:22:03,517 - trainer - INFO] - [Step Validation] Epoch:[36/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.606041 | 0.842922 | 0.705118 | 0.842922 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.592896 | 0.781513 | 0.674262 | 0.781513 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.240741 | 0.38806  | 0.297143 | 0.38806  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.573141 | 0.788555 | 0.663809 | 0.788555 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 18:22:21,631 - trainer - INFO] - Train Epoch:[36/100] Step:[60/77] Total Loss: 18.492819 GL_Loss: 0.631490 CRF_Loss: 17.861328\n",
      "[2022-03-22 18:22:42,344 - trainer - INFO] - Train Epoch:[36/100] Step:[70/77] Total Loss: 26.491558 GL_Loss: 0.645854 CRF_Loss: 25.845703\n",
      "[2022-03-22 18:23:07,583 - trainer - INFO] - [Epoch Validation] Epoch:[36/100] Total Loss: 26.138341 GL_Loss: 0.007900 CRF_Loss: 25.348345 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.64     | 0.832877 | 0.72381  | 0.832877 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.623541 | 0.769508 | 0.688877 | 0.769508 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.245536 | 0.410448 | 0.307263 | 0.410448 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.600672 | 0.779825 | 0.678624 | 0.779825 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 18:23:26,812 - trainer - INFO] - Train Epoch:[37/100] Step:[10/77] Total Loss: 18.638800 GL_Loss: 0.666144 CRF_Loss: 17.972656\n",
      "[2022-03-22 18:23:45,406 - trainer - INFO] - Train Epoch:[37/100] Step:[20/77] Total Loss: 28.220999 GL_Loss: 0.506642 CRF_Loss: 27.714355\n",
      "[2022-03-22 18:24:05,080 - trainer - INFO] - Train Epoch:[37/100] Step:[30/77] Total Loss: 13.043362 GL_Loss: 0.875148 CRF_Loss: 12.168213\n",
      "[2022-03-22 18:24:21,082 - trainer - INFO] - Train Epoch:[37/100] Step:[40/77] Total Loss: 5.930164 GL_Loss: 0.867664 CRF_Loss: 5.062500\n",
      "[2022-03-22 18:24:39,742 - trainer - INFO] - Train Epoch:[37/100] Step:[50/77] Total Loss: 10.559004 GL_Loss: 0.896894 CRF_Loss: 9.662109\n",
      "[2022-03-22 18:24:51,207 - trainer - INFO] - [Step Validation] Epoch:[37/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.638851 | 0.852968 | 0.730544 | 0.852968 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.618677 | 0.763505 | 0.683503 | 0.763505 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.283422 | 0.395522 | 0.330218 | 0.395522 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.606276 | 0.7871   | 0.684955 | 0.7871   |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 18:25:13,436 - trainer - INFO] - Train Epoch:[37/100] Step:[60/77] Total Loss: 21.886234 GL_Loss: 0.447025 CRF_Loss: 21.439209\n",
      "[2022-03-22 18:25:33,849 - trainer - INFO] - Train Epoch:[37/100] Step:[70/77] Total Loss: 2.955167 GL_Loss: 0.659756 CRF_Loss: 2.295410\n",
      "[2022-03-22 18:25:57,180 - trainer - INFO] - [Epoch Validation] Epoch:[37/100] Total Loss: 25.729794 GL_Loss: 0.007761 CRF_Loss: 24.953727 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.630212 | 0.842009 | 0.720876 | 0.842009 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.606002 | 0.751501 | 0.670954 | 0.751501 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.265487 | 0.447761 | 0.333333 | 0.447761 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.590742 | 0.779825 | 0.672241 | 0.779825 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-22 18:26:16,145 - trainer - INFO] - Train Epoch:[38/100] Step:[10/77] Total Loss: 11.615049 GL_Loss: 0.650083 CRF_Loss: 10.964966\n",
      "[2022-03-22 18:26:36,372 - trainer - INFO] - Train Epoch:[38/100] Step:[20/77] Total Loss: 20.235649 GL_Loss: 0.737357 CRF_Loss: 19.498291\n",
      "[2022-03-22 18:26:52,578 - trainer - INFO] - Train Epoch:[38/100] Step:[30/77] Total Loss: 28.594355 GL_Loss: 0.606805 CRF_Loss: 27.987549\n",
      "[2022-03-22 18:27:12,433 - trainer - INFO] - Train Epoch:[38/100] Step:[40/77] Total Loss: 16.115765 GL_Loss: 0.820111 CRF_Loss: 15.295654\n",
      "[2022-03-22 18:27:31,424 - trainer - INFO] - Train Epoch:[38/100] Step:[50/77] Total Loss: 5.277783 GL_Loss: 0.409863 CRF_Loss: 4.867920\n",
      "[2022-03-22 18:27:42,917 - trainer - INFO] - [Step Validation] Epoch:[38/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.650602 | 0.838356 | 0.732642 | 0.838356 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.623389 | 0.755102 | 0.682953 | 0.755102 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.265116 | 0.425373 | 0.326648 | 0.425373 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.608729 | 0.777886 | 0.682989 | 0.777886 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 18:28:02,222 - trainer - INFO] - Train Epoch:[38/100] Step:[60/77] Total Loss: 20.390816 GL_Loss: 0.624947 CRF_Loss: 19.765869\n",
      "[2022-03-22 18:28:21,740 - trainer - INFO] - Train Epoch:[38/100] Step:[70/77] Total Loss: 16.692984 GL_Loss: 0.506216 CRF_Loss: 16.186768\n",
      "[2022-03-22 18:28:45,893 - trainer - INFO] - [Epoch Validation] Epoch:[38/100] Total Loss: 24.976185 GL_Loss: 0.007652 CRF_Loss: 24.210967 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.627955 | 0.824658 | 0.712989 | 0.824658 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.604915 | 0.768307 | 0.676891 | 0.768307 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.252381 | 0.395522 | 0.30814  | 0.395522 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.5898   | 0.774006 | 0.669463 | 0.774006 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 18:29:06,111 - trainer - INFO] - Train Epoch:[39/100] Step:[10/77] Total Loss: 24.678982 GL_Loss: 0.528103 CRF_Loss: 24.150879\n",
      "[2022-03-22 18:29:25,683 - trainer - INFO] - Train Epoch:[39/100] Step:[20/77] Total Loss: 6.245429 GL_Loss: 0.617011 CRF_Loss: 5.628418\n",
      "[2022-03-22 18:29:43,989 - trainer - INFO] - Train Epoch:[39/100] Step:[30/77] Total Loss: 98.066429 GL_Loss: 0.549097 CRF_Loss: 97.517334\n",
      "[2022-03-22 18:30:02,606 - trainer - INFO] - Train Epoch:[39/100] Step:[40/77] Total Loss: 34.825382 GL_Loss: 0.699406 CRF_Loss: 34.125977\n",
      "[2022-03-22 18:30:21,062 - trainer - INFO] - Train Epoch:[39/100] Step:[50/77] Total Loss: 7.291874 GL_Loss: 0.916630 CRF_Loss: 6.375244\n",
      "[2022-03-22 18:30:32,381 - trainer - INFO] - [Step Validation] Epoch:[39/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.597649 | 0.835616 | 0.696877 | 0.835616 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.554514 | 0.781513 | 0.648729 | 0.781513 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.258537 | 0.395522 | 0.312684 | 0.395522 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.556357 | 0.78516  | 0.651247 | 0.78516  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 18:30:51,537 - trainer - INFO] - Train Epoch:[39/100] Step:[60/77] Total Loss: 13.255589 GL_Loss: 0.558568 CRF_Loss: 12.697021\n",
      "[2022-03-22 18:31:08,640 - trainer - INFO] - Train Epoch:[39/100] Step:[70/77] Total Loss: 13.485120 GL_Loss: 0.799817 CRF_Loss: 12.685303\n",
      "[2022-03-22 18:31:33,416 - trainer - INFO] - [Epoch Validation] Epoch:[39/100] Total Loss: 25.676581 GL_Loss: 0.007217 CRF_Loss: 24.954905 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.629938 | 0.830137 | 0.716312 | 0.830137 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.643863 | 0.768307 | 0.700602 | 0.768307 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.259574 | 0.455224 | 0.330623 | 0.455224 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.602545 | 0.780795 | 0.680186 | 0.780795 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 18:31:53,805 - trainer - INFO] - Train Epoch:[40/100] Step:[10/77] Total Loss: 13.549164 GL_Loss: 0.386078 CRF_Loss: 13.163086\n",
      "[2022-03-22 18:32:14,223 - trainer - INFO] - Train Epoch:[40/100] Step:[20/77] Total Loss: 36.879185 GL_Loss: 0.741735 CRF_Loss: 36.137451\n",
      "[2022-03-22 18:32:33,536 - trainer - INFO] - Train Epoch:[40/100] Step:[30/77] Total Loss: 6.672085 GL_Loss: 1.590664 CRF_Loss: 5.081421\n",
      "[2022-03-22 18:32:50,702 - trainer - INFO] - Train Epoch:[40/100] Step:[40/77] Total Loss: 19.666334 GL_Loss: 0.696363 CRF_Loss: 18.969971\n",
      "[2022-03-22 18:33:07,843 - trainer - INFO] - Train Epoch:[40/100] Step:[50/77] Total Loss: 7.431461 GL_Loss: 0.618473 CRF_Loss: 6.812988\n",
      "[2022-03-22 18:33:19,132 - trainer - INFO] - [Step Validation] Epoch:[40/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.600658 | 0.83379  | 0.698279 | 0.83379  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.588181 | 0.764706 | 0.664927 | 0.764706 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.273171 | 0.41791  | 0.330383 | 0.41791  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.571937 | 0.778855 | 0.659548 | 0.778855 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 18:33:39,865 - trainer - INFO] - Train Epoch:[40/100] Step:[60/77] Total Loss: 13.346267 GL_Loss: 0.649001 CRF_Loss: 12.697266\n",
      "[2022-03-22 18:33:59,608 - trainer - INFO] - Train Epoch:[40/100] Step:[70/77] Total Loss: 6.640058 GL_Loss: 1.228314 CRF_Loss: 5.411743\n",
      "[2022-03-22 18:34:25,111 - trainer - INFO] - [Epoch Validation] Epoch:[40/100] Total Loss: 24.294639 GL_Loss: 0.007508 CRF_Loss: 23.543832 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.611631 | 0.835616 | 0.706291 | 0.835616 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.594891 | 0.782713 | 0.675998 | 0.782713 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.247706 | 0.402985 | 0.306818 | 0.402985 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.576868 | 0.78613  | 0.665435 | 0.78613  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 18:34:26,872 - trainer - INFO] - Saving checkpoint: saved/models/PICK_Default/test_0322_164111/checkpoint-epoch40.pth ...\n",
      "[2022-03-22 18:34:47,441 - trainer - INFO] - Train Epoch:[41/100] Step:[10/77] Total Loss: 22.224426 GL_Loss: 0.867616 CRF_Loss: 21.356812\n",
      "[2022-03-22 18:35:07,498 - trainer - INFO] - Train Epoch:[41/100] Step:[20/77] Total Loss: 37.277210 GL_Loss: 0.639637 CRF_Loss: 36.637573\n",
      "[2022-03-22 18:35:24,517 - trainer - INFO] - Train Epoch:[41/100] Step:[30/77] Total Loss: 15.776421 GL_Loss: 0.917534 CRF_Loss: 14.858887\n",
      "[2022-03-22 18:35:43,014 - trainer - INFO] - Train Epoch:[41/100] Step:[40/77] Total Loss: 28.938780 GL_Loss: 0.762999 CRF_Loss: 28.175781\n",
      "[2022-03-22 18:36:01,747 - trainer - INFO] - Train Epoch:[41/100] Step:[50/77] Total Loss: 5.235035 GL_Loss: 0.467823 CRF_Loss: 4.767212\n",
      "[2022-03-22 18:36:13,145 - trainer - INFO] - [Step Validation] Epoch:[41/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.625609 | 0.821005 | 0.710111 | 0.821005 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.588556 | 0.777911 | 0.670114 | 0.777911 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.29703  | 0.447761 | 0.357143 | 0.447761 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.586496 | 0.77934  | 0.669304 | 0.77934  |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-22 18:36:31,374 - trainer - INFO] - Train Epoch:[41/100] Step:[60/77] Total Loss: 7.143753 GL_Loss: 0.537795 CRF_Loss: 6.605957\n",
      "[2022-03-22 18:36:51,556 - trainer - INFO] - Train Epoch:[41/100] Step:[70/77] Total Loss: 31.926245 GL_Loss: 1.316870 CRF_Loss: 30.609375\n",
      "[2022-03-22 18:37:16,084 - trainer - INFO] - [Epoch Validation] Epoch:[41/100] Total Loss: 22.261006 GL_Loss: 0.007454 CRF_Loss: 21.515623 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.636553 | 0.83653  | 0.722968 | 0.83653  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.610628 | 0.758703 | 0.67666  | 0.758703 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.258883 | 0.380597 | 0.308157 | 0.380597 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.598652 | 0.775461 | 0.675681 | 0.775461 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 18:37:36,157 - trainer - INFO] - Train Epoch:[42/100] Step:[10/77] Total Loss: 37.856873 GL_Loss: 0.574157 CRF_Loss: 37.282715\n",
      "[2022-03-22 18:37:56,519 - trainer - INFO] - Train Epoch:[42/100] Step:[20/77] Total Loss: 9.281576 GL_Loss: 0.439657 CRF_Loss: 8.841919\n",
      "[2022-03-22 18:38:16,264 - trainer - INFO] - Train Epoch:[42/100] Step:[30/77] Total Loss: 83.492737 GL_Loss: 0.597106 CRF_Loss: 82.895630\n",
      "[2022-03-22 18:38:34,364 - trainer - INFO] - Train Epoch:[42/100] Step:[40/77] Total Loss: 12.001896 GL_Loss: 0.777775 CRF_Loss: 11.224121\n",
      "[2022-03-22 18:38:51,480 - trainer - INFO] - Train Epoch:[42/100] Step:[50/77] Total Loss: 27.385042 GL_Loss: 0.592073 CRF_Loss: 26.792969\n",
      "[2022-03-22 18:39:02,998 - trainer - INFO] - [Step Validation] Epoch:[42/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.622069 | 0.823744 | 0.708841 | 0.823744 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.597426 | 0.780312 | 0.676731 | 0.780312 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.26601  | 0.402985 | 0.320475 | 0.402985 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.585918 | 0.778855 | 0.668749 | 0.778855 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 18:39:20,978 - trainer - INFO] - Train Epoch:[42/100] Step:[60/77] Total Loss: 25.687984 GL_Loss: 0.632687 CRF_Loss: 25.055298\n",
      "[2022-03-22 18:39:41,059 - trainer - INFO] - Train Epoch:[42/100] Step:[70/77] Total Loss: 17.739922 GL_Loss: 0.651543 CRF_Loss: 17.088379\n",
      "[2022-03-22 18:40:05,344 - trainer - INFO] - [Epoch Validation] Epoch:[42/100] Total Loss: 22.273466 GL_Loss: 0.007233 CRF_Loss: 21.550202 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.606225 | 0.818265 | 0.696463 | 0.818265 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.59907  | 0.773109 | 0.675052 | 0.773109 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.226496 | 0.395522 | 0.288043 | 0.395522 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.571582 | 0.772551 | 0.657043 | 0.772551 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 18:40:25,663 - trainer - INFO] - Train Epoch:[43/100] Step:[10/77] Total Loss: 121.106911 GL_Loss: 0.620582 CRF_Loss: 120.486328\n",
      "[2022-03-22 18:40:44,094 - trainer - INFO] - Train Epoch:[43/100] Step:[20/77] Total Loss: 2.555569 GL_Loss: 0.514065 CRF_Loss: 2.041504\n",
      "[2022-03-22 18:41:02,240 - trainer - INFO] - Train Epoch:[43/100] Step:[30/77] Total Loss: 25.021833 GL_Loss: 0.754255 CRF_Loss: 24.267578\n",
      "[2022-03-22 18:41:19,492 - trainer - INFO] - Train Epoch:[43/100] Step:[40/77] Total Loss: 5.878285 GL_Loss: 1.010121 CRF_Loss: 4.868164\n",
      "[2022-03-22 18:41:38,621 - trainer - INFO] - Train Epoch:[43/100] Step:[50/77] Total Loss: 25.575920 GL_Loss: 0.821647 CRF_Loss: 24.754272\n",
      "[2022-03-22 18:41:50,196 - trainer - INFO] - [Step Validation] Epoch:[43/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.59154  | 0.817352 | 0.68635  | 0.817352 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.557278 | 0.776711 | 0.648947 | 0.776711 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.238532 | 0.38806  | 0.295455 | 0.38806  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.551176 | 0.773036 | 0.64352  | 0.773036 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 18:42:09,775 - trainer - INFO] - Train Epoch:[43/100] Step:[60/77] Total Loss: 37.217434 GL_Loss: 0.588529 CRF_Loss: 36.628906\n",
      "[2022-03-22 18:42:28,725 - trainer - INFO] - Train Epoch:[43/100] Step:[70/77] Total Loss: 22.632921 GL_Loss: 0.792101 CRF_Loss: 21.840820\n",
      "[2022-03-22 18:42:53,548 - trainer - INFO] - [Epoch Validation] Epoch:[43/100] Total Loss: 21.524633 GL_Loss: 0.007243 CRF_Loss: 20.800291 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.614119 | 0.818265 | 0.701644 | 0.818265 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.596279 | 0.769508 | 0.671908 | 0.769508 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.261468 | 0.425373 | 0.323864 | 0.425373 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.579215 | 0.773036 | 0.662235 | 0.773036 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 18:43:14,012 - trainer - INFO] - Train Epoch:[44/100] Step:[10/77] Total Loss: 28.868532 GL_Loss: 0.581667 CRF_Loss: 28.286865\n",
      "[2022-03-22 18:43:33,837 - trainer - INFO] - Train Epoch:[44/100] Step:[20/77] Total Loss: 13.286669 GL_Loss: 0.731737 CRF_Loss: 12.554932\n",
      "[2022-03-22 18:43:50,903 - trainer - INFO] - Train Epoch:[44/100] Step:[30/77] Total Loss: 17.619242 GL_Loss: 0.555278 CRF_Loss: 17.063965\n",
      "[2022-03-22 18:44:09,648 - trainer - INFO] - Train Epoch:[44/100] Step:[40/77] Total Loss: 59.425964 GL_Loss: 0.657410 CRF_Loss: 58.768555\n",
      "[2022-03-22 18:44:28,289 - trainer - INFO] - Train Epoch:[44/100] Step:[50/77] Total Loss: 6.603273 GL_Loss: 0.634645 CRF_Loss: 5.968628\n",
      "[2022-03-22 18:44:39,741 - trainer - INFO] - [Step Validation] Epoch:[44/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.643466 | 0.827397 | 0.723931 | 0.827397 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.596523 | 0.782713 | 0.677051 | 0.782713 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.295455 | 0.38806  | 0.335484 | 0.38806  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.601419 | 0.780795 | 0.679468 | 0.780795 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 18:44:58,156 - trainer - INFO] - Train Epoch:[44/100] Step:[60/77] Total Loss: 4.552386 GL_Loss: 0.614154 CRF_Loss: 3.938232\n",
      "[2022-03-22 18:45:16,974 - trainer - INFO] - Train Epoch:[44/100] Step:[70/77] Total Loss: 7.886662 GL_Loss: 0.603458 CRF_Loss: 7.283203\n",
      "[2022-03-22 18:45:41,951 - trainer - INFO] - [Epoch Validation] Epoch:[44/100] Total Loss: 20.694875 GL_Loss: 0.007040 CRF_Loss: 19.990853 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.633754 | 0.826484 | 0.7174   | 0.826484 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.609895 | 0.769508 | 0.680467 | 0.769508 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.296703 | 0.402985 | 0.341772 | 0.402985 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.601278 | 0.775946 | 0.677535 | 0.775946 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-22 18:46:02,313 - trainer - INFO] - Train Epoch:[45/100] Step:[10/77] Total Loss: 14.487657 GL_Loss: 0.583238 CRF_Loss: 13.904419\n",
      "[2022-03-22 18:46:20,055 - trainer - INFO] - Train Epoch:[45/100] Step:[20/77] Total Loss: 9.896385 GL_Loss: 0.741845 CRF_Loss: 9.154541\n",
      "[2022-03-22 18:46:37,858 - trainer - INFO] - Train Epoch:[45/100] Step:[30/77] Total Loss: 13.859881 GL_Loss: 1.250018 CRF_Loss: 12.609863\n",
      "[2022-03-22 18:46:57,811 - trainer - INFO] - Train Epoch:[45/100] Step:[40/77] Total Loss: 11.249713 GL_Loss: 0.766071 CRF_Loss: 10.483643\n",
      "[2022-03-22 18:47:17,300 - trainer - INFO] - Train Epoch:[45/100] Step:[50/77] Total Loss: 5.076702 GL_Loss: 0.639446 CRF_Loss: 4.437256\n",
      "[2022-03-22 18:47:28,740 - trainer - INFO] - [Step Validation] Epoch:[45/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.671587 | 0.83105  | 0.742857 | 0.83105  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.632572 | 0.764706 | 0.692391 | 0.764706 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.319767 | 0.410448 | 0.359477 | 0.410448 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.632202 | 0.776916 | 0.697128 | 0.776916 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 18:47:30,920 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-03-22 18:47:47,643 - trainer - INFO] - Train Epoch:[45/100] Step:[60/77] Total Loss: 13.839579 GL_Loss: 0.504679 CRF_Loss: 13.334900\n",
      "[2022-03-22 18:48:05,378 - trainer - INFO] - Train Epoch:[45/100] Step:[70/77] Total Loss: 34.000370 GL_Loss: 0.620852 CRF_Loss: 33.379517\n",
      "[2022-03-22 18:48:31,191 - trainer - INFO] - [Epoch Validation] Epoch:[45/100] Total Loss: 20.057062 GL_Loss: 0.006648 CRF_Loss: 19.392302 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.655859 | 0.812785 | 0.725938 | 0.812785 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.635674 | 0.804322 | 0.710122 | 0.804322 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.277778 | 0.410448 | 0.331325 | 0.410448 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.619011 | 0.78322  | 0.691501 | 0.78322  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 18:48:49,547 - trainer - INFO] - Train Epoch:[46/100] Step:[10/77] Total Loss: 16.610323 GL_Loss: 0.595187 CRF_Loss: 16.015137\n",
      "[2022-03-22 18:49:06,686 - trainer - INFO] - Train Epoch:[46/100] Step:[20/77] Total Loss: 1.877216 GL_Loss: 0.632343 CRF_Loss: 1.244873\n",
      "[2022-03-22 18:49:25,061 - trainer - INFO] - Train Epoch:[46/100] Step:[30/77] Total Loss: 13.486184 GL_Loss: 0.625100 CRF_Loss: 12.861084\n",
      "[2022-03-22 18:49:46,254 - trainer - INFO] - Train Epoch:[46/100] Step:[40/77] Total Loss: 27.335754 GL_Loss: 0.961243 CRF_Loss: 26.374512\n",
      "[2022-03-22 18:50:05,280 - trainer - INFO] - Train Epoch:[46/100] Step:[50/77] Total Loss: 49.574806 GL_Loss: 0.858253 CRF_Loss: 48.716553\n",
      "[2022-03-22 18:50:16,727 - trainer - INFO] - [Step Validation] Epoch:[46/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.60346  | 0.828311 | 0.698229 | 0.828311 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.573357 | 0.764706 | 0.65535  | 0.764706 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.259434 | 0.410448 | 0.317919 | 0.410448 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.565817 | 0.775461 | 0.654255 | 0.775461 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 18:50:35,975 - trainer - INFO] - Train Epoch:[46/100] Step:[60/77] Total Loss: 27.767828 GL_Loss: 0.446417 CRF_Loss: 27.321411\n",
      "[2022-03-22 18:50:55,684 - trainer - INFO] - Train Epoch:[46/100] Step:[70/77] Total Loss: 12.881847 GL_Loss: 0.846447 CRF_Loss: 12.035400\n",
      "[2022-03-22 18:51:20,734 - trainer - INFO] - [Epoch Validation] Epoch:[46/100] Total Loss: 18.279133 GL_Loss: 0.006978 CRF_Loss: 17.581319 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.59761  | 0.821918 | 0.692042 | 0.821918 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.573192 | 0.780312 | 0.660905 | 0.780312 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.27451  | 0.41791  | 0.331361 | 0.41791  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.564698 | 0.778855 | 0.654709 | 0.778855 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 18:51:40,868 - trainer - INFO] - Train Epoch:[47/100] Step:[10/77] Total Loss: 41.162815 GL_Loss: 0.725316 CRF_Loss: 40.437500\n",
      "[2022-03-22 18:51:59,304 - trainer - INFO] - Train Epoch:[47/100] Step:[20/77] Total Loss: 13.030658 GL_Loss: 0.516498 CRF_Loss: 12.514160\n",
      "[2022-03-22 18:52:16,424 - trainer - INFO] - Train Epoch:[47/100] Step:[30/77] Total Loss: 4.098861 GL_Loss: 0.400131 CRF_Loss: 3.698730\n",
      "[2022-03-22 18:52:34,010 - trainer - INFO] - Train Epoch:[47/100] Step:[40/77] Total Loss: 8.656639 GL_Loss: 0.625877 CRF_Loss: 8.030762\n",
      "[2022-03-22 18:52:52,273 - trainer - INFO] - Train Epoch:[47/100] Step:[50/77] Total Loss: 5.856310 GL_Loss: 0.653673 CRF_Loss: 5.202637\n",
      "[2022-03-22 18:53:03,631 - trainer - INFO] - [Step Validation] Epoch:[47/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.638313 | 0.815525 | 0.716119 | 0.815525 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.611423 | 0.783914 | 0.687007 | 0.783914 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.287234 | 0.402985 | 0.335404 | 0.402985 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.602637 | 0.775946 | 0.678397 | 0.775946 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 18:53:25,167 - trainer - INFO] - Train Epoch:[47/100] Step:[60/77] Total Loss: 15.607003 GL_Loss: 0.705147 CRF_Loss: 14.901855\n",
      "[2022-03-22 18:53:44,881 - trainer - INFO] - Train Epoch:[47/100] Step:[70/77] Total Loss: 18.807314 GL_Loss: 1.392152 CRF_Loss: 17.415161\n",
      "[2022-03-22 18:54:09,390 - trainer - INFO] - [Epoch Validation] Epoch:[47/100] Total Loss: 18.298584 GL_Loss: 0.006903 CRF_Loss: 17.608257 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.619788 | 0.800913 | 0.698805 | 0.800913 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.582369 | 0.785114 | 0.668712 | 0.785114 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.267943 | 0.41791  | 0.326531 | 0.41791  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.577721 | 0.769641 | 0.660012 | 0.769641 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 18:54:27,291 - trainer - INFO] - Train Epoch:[48/100] Step:[10/77] Total Loss: 34.865265 GL_Loss: 0.621125 CRF_Loss: 34.244141\n",
      "[2022-03-22 18:54:46,281 - trainer - INFO] - Train Epoch:[48/100] Step:[20/77] Total Loss: 10.379486 GL_Loss: 0.753754 CRF_Loss: 9.625732\n",
      "[2022-03-22 18:55:04,550 - trainer - INFO] - Train Epoch:[48/100] Step:[30/77] Total Loss: 12.200962 GL_Loss: 0.725621 CRF_Loss: 11.475342\n",
      "[2022-03-22 18:55:23,223 - trainer - INFO] - Train Epoch:[48/100] Step:[40/77] Total Loss: 16.767056 GL_Loss: 0.606166 CRF_Loss: 16.160889\n",
      "[2022-03-22 18:55:42,879 - trainer - INFO] - Train Epoch:[48/100] Step:[50/77] Total Loss: 16.910248 GL_Loss: 1.234711 CRF_Loss: 15.675537\n",
      "[2022-03-22 18:55:54,349 - trainer - INFO] - [Step Validation] Epoch:[48/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.621139 | 0.826484 | 0.709248 | 0.826484 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.586777 | 0.767107 | 0.664932 | 0.767107 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.331461 | 0.440299 | 0.378205 | 0.440299 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.588473 | 0.777401 | 0.66987  | 0.777401 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-22 18:56:12,375 - trainer - INFO] - Train Epoch:[48/100] Step:[60/77] Total Loss: 7.412087 GL_Loss: 0.678444 CRF_Loss: 6.733643\n",
      "[2022-03-22 18:56:30,936 - trainer - INFO] - Train Epoch:[48/100] Step:[70/77] Total Loss: 20.410999 GL_Loss: 0.531239 CRF_Loss: 19.879761\n",
      "[2022-03-22 18:56:56,777 - trainer - INFO] - [Epoch Validation] Epoch:[48/100] Total Loss: 17.841545 GL_Loss: 0.006888 CRF_Loss: 17.152747 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.625    | 0.812785 | 0.70663  | 0.812785 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.584958 | 0.756303 | 0.659686 | 0.756303 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.301508 | 0.447761 | 0.36036  | 0.447761 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.585185 | 0.766246 | 0.663587 | 0.766246 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 18:57:15,724 - trainer - INFO] - Train Epoch:[49/100] Step:[10/77] Total Loss: 19.312077 GL_Loss: 0.397770 CRF_Loss: 18.914307\n",
      "[2022-03-22 18:57:35,516 - trainer - INFO] - Train Epoch:[49/100] Step:[20/77] Total Loss: 8.160800 GL_Loss: 0.851474 CRF_Loss: 7.309326\n",
      "[2022-03-22 18:57:53,136 - trainer - INFO] - Train Epoch:[49/100] Step:[30/77] Total Loss: 14.820569 GL_Loss: 0.689465 CRF_Loss: 14.131104\n",
      "[2022-03-22 18:58:11,244 - trainer - INFO] - Train Epoch:[49/100] Step:[40/77] Total Loss: 25.652212 GL_Loss: 0.548818 CRF_Loss: 25.103394\n",
      "[2022-03-22 18:58:30,880 - trainer - INFO] - Train Epoch:[49/100] Step:[50/77] Total Loss: 6.223597 GL_Loss: 0.429896 CRF_Loss: 5.793701\n",
      "[2022-03-22 18:58:42,271 - trainer - INFO] - [Step Validation] Epoch:[49/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.633891 | 0.830137 | 0.718861 | 0.830137 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.610105 | 0.768307 | 0.680128 | 0.768307 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.269608 | 0.410448 | 0.325444 | 0.410448 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.596948 | 0.777886 | 0.675511 | 0.777886 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 18:59:02,176 - trainer - INFO] - Train Epoch:[49/100] Step:[60/77] Total Loss: 3.148889 GL_Loss: 0.558191 CRF_Loss: 2.590698\n",
      "[2022-03-22 18:59:19,626 - trainer - INFO] - Train Epoch:[49/100] Step:[70/77] Total Loss: 8.415671 GL_Loss: 0.620993 CRF_Loss: 7.794678\n",
      "[2022-03-22 18:59:45,168 - trainer - INFO] - [Epoch Validation] Epoch:[49/100] Total Loss: 17.859781 GL_Loss: 0.006846 CRF_Loss: 17.175219 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.599053 | 0.809132 | 0.688423 | 0.809132 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.580902 | 0.788715 | 0.669043 | 0.788715 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.235043 | 0.410448 | 0.298913 | 0.410448 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.561885 | 0.774976 | 0.651447 | 0.774976 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 19:00:06,393 - trainer - INFO] - Train Epoch:[50/100] Step:[10/77] Total Loss: 13.244953 GL_Loss: 1.013386 CRF_Loss: 12.231567\n",
      "[2022-03-22 19:00:25,820 - trainer - INFO] - Train Epoch:[50/100] Step:[20/77] Total Loss: 26.574638 GL_Loss: 0.673514 CRF_Loss: 25.901123\n",
      "[2022-03-22 19:00:44,344 - trainer - INFO] - Train Epoch:[50/100] Step:[30/77] Total Loss: 31.774639 GL_Loss: 0.743145 CRF_Loss: 31.031494\n",
      "[2022-03-22 19:01:02,341 - trainer - INFO] - Train Epoch:[50/100] Step:[40/77] Total Loss: 6.078373 GL_Loss: 0.416996 CRF_Loss: 5.661377\n",
      "[2022-03-22 19:01:20,718 - trainer - INFO] - Train Epoch:[50/100] Step:[50/77] Total Loss: 35.480999 GL_Loss: 0.628459 CRF_Loss: 34.852539\n",
      "[2022-03-22 19:01:32,314 - trainer - INFO] - [Step Validation] Epoch:[50/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.636042 | 0.821918 | 0.717131 | 0.821918 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.622478 | 0.777911 | 0.691569 | 0.777911 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.270531 | 0.41791  | 0.328446 | 0.41791  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.602328 | 0.777886 | 0.678942 | 0.777886 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 19:01:51,425 - trainer - INFO] - Train Epoch:[50/100] Step:[60/77] Total Loss: 23.762701 GL_Loss: 0.675543 CRF_Loss: 23.087158\n",
      "[2022-03-22 19:02:10,709 - trainer - INFO] - Train Epoch:[50/100] Step:[70/77] Total Loss: 103.219460 GL_Loss: 0.958719 CRF_Loss: 102.260742\n",
      "[2022-03-22 19:02:34,558 - trainer - INFO] - [Epoch Validation] Epoch:[50/100] Total Loss: 19.326506 GL_Loss: 0.006669 CRF_Loss: 18.659570 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.638614 | 0.824658 | 0.719809 | 0.824658 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.625    | 0.786315 | 0.696438 | 0.786315 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.27957  | 0.38806  | 0.325    | 0.38806  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.608006 | 0.780795 | 0.683652 | 0.780795 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 19:02:51,314 - trainer - INFO] - Train Epoch:[51/100] Step:[10/77] Total Loss: 1.572182 GL_Loss: 0.431313 CRF_Loss: 1.140869\n",
      "[2022-03-22 19:03:10,266 - trainer - INFO] - Train Epoch:[51/100] Step:[20/77] Total Loss: 6.058078 GL_Loss: 0.607394 CRF_Loss: 5.450684\n",
      "[2022-03-22 19:03:27,648 - trainer - INFO] - Train Epoch:[51/100] Step:[30/77] Total Loss: 7.879346 GL_Loss: 0.513135 CRF_Loss: 7.366211\n",
      "[2022-03-22 19:03:47,403 - trainer - INFO] - Train Epoch:[51/100] Step:[40/77] Total Loss: 14.822780 GL_Loss: 0.467311 CRF_Loss: 14.355469\n",
      "[2022-03-22 19:04:09,255 - trainer - INFO] - Train Epoch:[51/100] Step:[50/77] Total Loss: 23.920715 GL_Loss: 0.669983 CRF_Loss: 23.250732\n",
      "[2022-03-22 19:04:20,674 - trainer - INFO] - [Step Validation] Epoch:[51/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.669385 | 0.824658 | 0.738953 | 0.824658 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.638806 | 0.770708 | 0.698585 | 0.770708 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.318182 | 0.41791  | 0.36129  | 0.41791  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.632806 | 0.776431 | 0.6973   | 0.776431 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 19:04:22,842 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-03-22 19:04:42,457 - trainer - INFO] - Train Epoch:[51/100] Step:[60/77] Total Loss: 21.954447 GL_Loss: 0.646586 CRF_Loss: 21.307861\n",
      "[2022-03-22 19:05:01,445 - trainer - INFO] - Train Epoch:[51/100] Step:[70/77] Total Loss: 15.088463 GL_Loss: 0.607261 CRF_Loss: 14.481201\n",
      "[2022-03-22 19:05:24,971 - trainer - INFO] - [Epoch Validation] Epoch:[51/100] Total Loss: 17.131480 GL_Loss: 0.006346 CRF_Loss: 16.496920 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.600398 | 0.827397 | 0.695853 | 0.827397 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.569902 | 0.768307 | 0.654397 | 0.768307 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.282051 | 0.410448 | 0.334347 | 0.410448 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.566325 | 0.776431 | 0.65494  | 0.776431 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-22 19:05:43,674 - trainer - INFO] - Train Epoch:[52/100] Step:[10/77] Total Loss: 15.660192 GL_Loss: 0.660681 CRF_Loss: 14.999512\n",
      "[2022-03-22 19:06:01,527 - trainer - INFO] - Train Epoch:[52/100] Step:[20/77] Total Loss: 26.493217 GL_Loss: 1.070854 CRF_Loss: 25.422363\n",
      "[2022-03-22 19:06:19,708 - trainer - INFO] - Train Epoch:[52/100] Step:[30/77] Total Loss: 89.374680 GL_Loss: 0.475266 CRF_Loss: 88.899414\n",
      "[2022-03-22 19:06:39,802 - trainer - INFO] - Train Epoch:[52/100] Step:[40/77] Total Loss: 35.180241 GL_Loss: 0.654851 CRF_Loss: 34.525391\n",
      "[2022-03-22 19:06:58,959 - trainer - INFO] - Train Epoch:[52/100] Step:[50/77] Total Loss: 4.138535 GL_Loss: 0.470322 CRF_Loss: 3.668213\n",
      "[2022-03-22 19:07:10,529 - trainer - INFO] - [Step Validation] Epoch:[52/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.629167 | 0.827397 | 0.714793 | 0.827397 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.58079  | 0.776711 | 0.664612 | 0.776711 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.325444 | 0.410448 | 0.363036 | 0.410448 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.590525 | 0.779825 | 0.6721   | 0.779825 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 19:07:29,523 - trainer - INFO] - Train Epoch:[52/100] Step:[60/77] Total Loss: 62.665031 GL_Loss: 0.781121 CRF_Loss: 61.883911\n",
      "[2022-03-22 19:07:47,902 - trainer - INFO] - Train Epoch:[52/100] Step:[70/77] Total Loss: 6.703141 GL_Loss: 0.543229 CRF_Loss: 6.159912\n",
      "[2022-03-22 19:08:12,811 - trainer - INFO] - [Epoch Validation] Epoch:[52/100] Total Loss: 19.079609 GL_Loss: 0.006441 CRF_Loss: 18.435480 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.629449 | 0.823744 | 0.713608 | 0.823744 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.597109 | 0.793517 | 0.681443 | 0.793517 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.341463 | 0.41791  | 0.375839 | 0.41791  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.598743 | 0.78516  | 0.679396 | 0.78516  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 19:08:31,806 - trainer - INFO] - Train Epoch:[53/100] Step:[10/77] Total Loss: 2.267539 GL_Loss: 0.446739 CRF_Loss: 1.820801\n",
      "[2022-03-22 19:08:50,918 - trainer - INFO] - Train Epoch:[53/100] Step:[20/77] Total Loss: 27.515419 GL_Loss: 0.785683 CRF_Loss: 26.729736\n",
      "[2022-03-22 19:09:08,495 - trainer - INFO] - Train Epoch:[53/100] Step:[30/77] Total Loss: 6.937611 GL_Loss: 0.576283 CRF_Loss: 6.361328\n",
      "[2022-03-22 19:09:29,713 - trainer - INFO] - Train Epoch:[53/100] Step:[40/77] Total Loss: 36.834618 GL_Loss: 0.671042 CRF_Loss: 36.163574\n",
      "[2022-03-22 19:09:46,925 - trainer - INFO] - Train Epoch:[53/100] Step:[50/77] Total Loss: 13.009002 GL_Loss: 0.745940 CRF_Loss: 12.263062\n",
      "[2022-03-22 19:09:58,322 - trainer - INFO] - [Step Validation] Epoch:[53/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.634684 | 0.815525 | 0.713829 | 0.815525 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.602765 | 0.785114 | 0.68196  | 0.785114 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.284211 | 0.402985 | 0.333333 | 0.402985 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.596943 | 0.776431 | 0.674958 | 0.776431 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 19:10:16,924 - trainer - INFO] - Train Epoch:[53/100] Step:[60/77] Total Loss: 3.642166 GL_Loss: 0.499588 CRF_Loss: 3.142578\n",
      "[2022-03-22 19:10:36,131 - trainer - INFO] - Train Epoch:[53/100] Step:[70/77] Total Loss: 7.841602 GL_Loss: 0.498341 CRF_Loss: 7.343262\n",
      "[2022-03-22 19:11:00,819 - trainer - INFO] - [Epoch Validation] Epoch:[53/100] Total Loss: 15.824175 GL_Loss: 0.006261 CRF_Loss: 15.198105 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.662545 | 0.831963 | 0.737652 | 0.831963 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.627794 | 0.77551  | 0.693878 | 0.77551  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.325714 | 0.425373 | 0.368932 | 0.425373 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.625824 | 0.782735 | 0.69554  | 0.782735 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 19:11:19,203 - trainer - INFO] - Train Epoch:[54/100] Step:[10/77] Total Loss: 14.086721 GL_Loss: 0.896658 CRF_Loss: 13.190063\n",
      "[2022-03-22 19:11:39,942 - trainer - INFO] - Train Epoch:[54/100] Step:[20/77] Total Loss: 22.476440 GL_Loss: 0.817505 CRF_Loss: 21.658936\n",
      "[2022-03-22 19:11:57,440 - trainer - INFO] - Train Epoch:[54/100] Step:[30/77] Total Loss: 8.459356 GL_Loss: 0.462774 CRF_Loss: 7.996582\n",
      "[2022-03-22 19:12:14,772 - trainer - INFO] - Train Epoch:[54/100] Step:[40/77] Total Loss: 24.756901 GL_Loss: 0.509342 CRF_Loss: 24.247559\n",
      "[2022-03-22 19:12:32,840 - trainer - INFO] - Train Epoch:[54/100] Step:[50/77] Total Loss: 5.826292 GL_Loss: 0.603880 CRF_Loss: 5.222412\n",
      "[2022-03-22 19:12:44,382 - trainer - INFO] - [Step Validation] Epoch:[54/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.622069 | 0.823744 | 0.708841 | 0.823744 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.575221 | 0.780312 | 0.662252 | 0.780312 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.259615 | 0.402985 | 0.315789 | 0.402985 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.57604  | 0.778855 | 0.662268 | 0.778855 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 19:13:03,680 - trainer - INFO] - Train Epoch:[54/100] Step:[60/77] Total Loss: 8.891254 GL_Loss: 0.396870 CRF_Loss: 8.494385\n",
      "[2022-03-22 19:13:23,101 - trainer - INFO] - Train Epoch:[54/100] Step:[70/77] Total Loss: 25.803457 GL_Loss: 0.563954 CRF_Loss: 25.239502\n",
      "[2022-03-22 19:13:48,870 - trainer - INFO] - [Epoch Validation] Epoch:[54/100] Total Loss: 15.477564 GL_Loss: 0.006082 CRF_Loss: 14.869392 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.632624 | 0.814612 | 0.712176 | 0.814612 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.575306 | 0.788715 | 0.665316 | 0.788715 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.305556 | 0.410448 | 0.350318 | 0.410448 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.587116 | 0.777886 | 0.66917  | 0.777886 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 19:14:11,176 - trainer - INFO] - Train Epoch:[55/100] Step:[10/77] Total Loss: 15.402822 GL_Loss: 0.660879 CRF_Loss: 14.741943\n",
      "[2022-03-22 19:14:30,644 - trainer - INFO] - Train Epoch:[55/100] Step:[20/77] Total Loss: 14.648653 GL_Loss: 0.602755 CRF_Loss: 14.045898\n",
      "[2022-03-22 19:14:48,358 - trainer - INFO] - Train Epoch:[55/100] Step:[30/77] Total Loss: 12.753430 GL_Loss: 0.614759 CRF_Loss: 12.138672\n",
      "[2022-03-22 19:15:06,897 - trainer - INFO] - Train Epoch:[55/100] Step:[40/77] Total Loss: 11.195209 GL_Loss: 0.477435 CRF_Loss: 10.717773\n",
      "[2022-03-22 19:15:25,174 - trainer - INFO] - Train Epoch:[55/100] Step:[50/77] Total Loss: 61.486000 GL_Loss: 0.707435 CRF_Loss: 60.778564\n",
      "[2022-03-22 19:15:37,715 - trainer - INFO] - [Step Validation] Epoch:[55/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.609017 | 0.826484 | 0.701279 | 0.826484 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.594982 | 0.797119 | 0.681375 | 0.797119 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.273684 | 0.38806  | 0.320988 | 0.38806  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.580587 | 0.78613  | 0.667903 | 0.78613  |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-22 19:15:57,298 - trainer - INFO] - Train Epoch:[55/100] Step:[60/77] Total Loss: 31.868090 GL_Loss: 0.470629 CRF_Loss: 31.397461\n",
      "[2022-03-22 19:16:14,767 - trainer - INFO] - Train Epoch:[55/100] Step:[70/77] Total Loss: 6.193625 GL_Loss: 0.611716 CRF_Loss: 5.581909\n",
      "[2022-03-22 19:16:40,127 - trainer - INFO] - [Epoch Validation] Epoch:[55/100] Total Loss: 16.090014 GL_Loss: 0.006594 CRF_Loss: 15.430586 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.594352 | 0.845662 | 0.698078 | 0.845662 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.575571 | 0.786315 | 0.664637 | 0.786315 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.230769 | 0.358209 | 0.280702 | 0.358209 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.56095  | 0.79001  | 0.656061 | 0.79001  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 19:17:00,888 - trainer - INFO] - Train Epoch:[56/100] Step:[10/77] Total Loss: 2.721972 GL_Loss: 0.994799 CRF_Loss: 1.727173\n",
      "[2022-03-22 19:17:19,852 - trainer - INFO] - Train Epoch:[56/100] Step:[20/77] Total Loss: 9.260042 GL_Loss: 0.689974 CRF_Loss: 8.570068\n",
      "[2022-03-22 19:17:38,062 - trainer - INFO] - Train Epoch:[56/100] Step:[30/77] Total Loss: 3.414777 GL_Loss: 1.103009 CRF_Loss: 2.311768\n",
      "[2022-03-22 19:17:57,172 - trainer - INFO] - Train Epoch:[56/100] Step:[40/77] Total Loss: 9.930543 GL_Loss: 0.727051 CRF_Loss: 9.203491\n",
      "[2022-03-22 19:18:15,971 - trainer - INFO] - Train Epoch:[56/100] Step:[50/77] Total Loss: 10.175052 GL_Loss: 0.581301 CRF_Loss: 9.593750\n",
      "[2022-03-22 19:18:27,432 - trainer - INFO] - [Step Validation] Epoch:[56/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.634061 | 0.822831 | 0.716216 | 0.822831 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.608856 | 0.792317 | 0.688576 | 0.792317 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.32716  | 0.395522 | 0.358108 | 0.395522 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.605174 | 0.782735 | 0.682597 | 0.782735 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 19:18:45,619 - trainer - INFO] - Train Epoch:[56/100] Step:[60/77] Total Loss: 14.312312 GL_Loss: 0.539851 CRF_Loss: 13.772461\n",
      "[2022-03-22 19:19:04,359 - trainer - INFO] - Train Epoch:[56/100] Step:[70/77] Total Loss: 7.189864 GL_Loss: 0.495528 CRF_Loss: 6.694336\n",
      "[2022-03-22 19:19:28,783 - trainer - INFO] - [Epoch Validation] Epoch:[56/100] Total Loss: 15.211555 GL_Loss: 0.006646 CRF_Loss: 14.546939 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.654971 | 0.818265 | 0.727568 | 0.818265 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.621544 | 0.782713 | 0.69288  | 0.782713 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.345679 | 0.41791  | 0.378378 | 0.41791  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.621946 | 0.777886 | 0.69123  | 0.777886 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 19:19:50,042 - trainer - INFO] - Train Epoch:[57/100] Step:[10/77] Total Loss: 19.768597 GL_Loss: 0.544720 CRF_Loss: 19.223877\n",
      "[2022-03-22 19:20:09,507 - trainer - INFO] - Train Epoch:[57/100] Step:[20/77] Total Loss: 8.734292 GL_Loss: 0.662026 CRF_Loss: 8.072266\n",
      "[2022-03-22 19:20:27,437 - trainer - INFO] - Train Epoch:[57/100] Step:[30/77] Total Loss: 10.755693 GL_Loss: 0.575762 CRF_Loss: 10.179932\n",
      "[2022-03-22 19:20:44,366 - trainer - INFO] - Train Epoch:[57/100] Step:[40/77] Total Loss: 10.274108 GL_Loss: 0.629821 CRF_Loss: 9.644287\n",
      "[2022-03-22 19:21:02,297 - trainer - INFO] - Train Epoch:[57/100] Step:[50/77] Total Loss: 15.552237 GL_Loss: 0.740469 CRF_Loss: 14.811768\n",
      "[2022-03-22 19:21:13,647 - trainer - INFO] - [Step Validation] Epoch:[57/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.64245  | 0.823744 | 0.721889 | 0.823744 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.605916 | 0.762305 | 0.675173 | 0.762305 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.28125  | 0.402985 | 0.331288 | 0.402985 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.60174  | 0.771581 | 0.676158 | 0.771581 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 19:21:31,640 - trainer - INFO] - Train Epoch:[57/100] Step:[60/77] Total Loss: 14.977556 GL_Loss: 0.546282 CRF_Loss: 14.431274\n",
      "[2022-03-22 19:21:50,168 - trainer - INFO] - Train Epoch:[57/100] Step:[70/77] Total Loss: 7.476626 GL_Loss: 0.515445 CRF_Loss: 6.961182\n",
      "[2022-03-22 19:22:15,202 - trainer - INFO] - [Epoch Validation] Epoch:[57/100] Total Loss: 16.244293 GL_Loss: 0.006153 CRF_Loss: 15.628944 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.647399 | 0.818265 | 0.722872 | 0.818265 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.621723 | 0.797119 | 0.69858  | 0.797119 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.323171 | 0.395522 | 0.355705 | 0.395522 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.61659  | 0.78225  | 0.689611 | 0.78225  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 19:22:33,700 - trainer - INFO] - Train Epoch:[58/100] Step:[10/77] Total Loss: 4.082019 GL_Loss: 0.349109 CRF_Loss: 3.732910\n",
      "[2022-03-22 19:22:52,212 - trainer - INFO] - Train Epoch:[58/100] Step:[20/77] Total Loss: 3.254405 GL_Loss: 0.496592 CRF_Loss: 2.757812\n",
      "[2022-03-22 19:23:11,953 - trainer - INFO] - Train Epoch:[58/100] Step:[30/77] Total Loss: 11.644946 GL_Loss: 0.355152 CRF_Loss: 11.289795\n",
      "[2022-03-22 19:23:30,995 - trainer - INFO] - Train Epoch:[58/100] Step:[40/77] Total Loss: 7.548661 GL_Loss: 0.606278 CRF_Loss: 6.942383\n",
      "[2022-03-22 19:23:51,427 - trainer - INFO] - Train Epoch:[58/100] Step:[50/77] Total Loss: 11.018476 GL_Loss: 0.387129 CRF_Loss: 10.631348\n",
      "[2022-03-22 19:24:02,916 - trainer - INFO] - [Step Validation] Epoch:[58/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.64886  | 0.831963 | 0.729092 | 0.831963 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.625245 | 0.767107 | 0.688949 | 0.767107 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.290323 | 0.402985 | 0.3375   | 0.402985 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.614089 | 0.777886 | 0.68635  | 0.777886 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 19:24:21,950 - trainer - INFO] - Train Epoch:[58/100] Step:[60/77] Total Loss: 25.280085 GL_Loss: 0.724421 CRF_Loss: 24.555664\n",
      "[2022-03-22 19:24:41,876 - trainer - INFO] - Train Epoch:[58/100] Step:[70/77] Total Loss: 4.777715 GL_Loss: 0.627812 CRF_Loss: 4.149902\n",
      "[2022-03-22 19:25:04,924 - trainer - INFO] - [Epoch Validation] Epoch:[58/100] Total Loss: 14.779947 GL_Loss: 0.006133 CRF_Loss: 14.166660 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.608901 | 0.824658 | 0.700543 | 0.824658 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.592391 | 0.785114 | 0.675271 | 0.785114 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.273196 | 0.395522 | 0.323171 | 0.395522 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.578928 | 0.780795 | 0.664877 | 0.780795 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-22 19:25:23,471 - trainer - INFO] - Train Epoch:[59/100] Step:[10/77] Total Loss: 13.083858 GL_Loss: 0.657345 CRF_Loss: 12.426514\n",
      "[2022-03-22 19:25:41,170 - trainer - INFO] - Train Epoch:[59/100] Step:[20/77] Total Loss: 4.156362 GL_Loss: 0.381704 CRF_Loss: 3.774658\n",
      "[2022-03-22 19:26:00,074 - trainer - INFO] - Train Epoch:[59/100] Step:[30/77] Total Loss: 12.179824 GL_Loss: 0.565810 CRF_Loss: 11.614014\n",
      "[2022-03-22 19:26:21,067 - trainer - INFO] - Train Epoch:[59/100] Step:[40/77] Total Loss: 25.657650 GL_Loss: 0.652278 CRF_Loss: 25.005371\n",
      "[2022-03-22 19:26:37,965 - trainer - INFO] - Train Epoch:[59/100] Step:[50/77] Total Loss: 2.956892 GL_Loss: 0.578474 CRF_Loss: 2.378418\n",
      "[2022-03-22 19:26:49,283 - trainer - INFO] - [Step Validation] Epoch:[59/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.619048 | 0.819178 | 0.705189 | 0.819178 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.619227 | 0.788715 | 0.69377  | 0.788715 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.234513 | 0.395522 | 0.294444 | 0.395522 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.587354 | 0.77934  | 0.669862 | 0.77934  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 19:27:08,732 - trainer - INFO] - Train Epoch:[59/100] Step:[60/77] Total Loss: 16.402426 GL_Loss: 0.616782 CRF_Loss: 15.785645\n",
      "[2022-03-22 19:27:28,143 - trainer - INFO] - Train Epoch:[59/100] Step:[70/77] Total Loss: 9.218000 GL_Loss: 0.416853 CRF_Loss: 8.801147\n",
      "[2022-03-22 19:27:53,269 - trainer - INFO] - [Epoch Validation] Epoch:[59/100] Total Loss: 14.154821 GL_Loss: 0.006124 CRF_Loss: 13.542410 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.665702 | 0.840183 | 0.742834 | 0.840183 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.61575  | 0.779112 | 0.687864 | 0.779112 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.304348 | 0.365672 | 0.332203 | 0.365672 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.623027 | 0.784675 | 0.69457  | 0.784675 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 19:28:09,774 - trainer - INFO] - Train Epoch:[60/100] Step:[10/77] Total Loss: 2.718687 GL_Loss: 0.395444 CRF_Loss: 2.323242\n",
      "[2022-03-22 19:28:29,547 - trainer - INFO] - Train Epoch:[60/100] Step:[20/77] Total Loss: 27.434099 GL_Loss: 0.627947 CRF_Loss: 26.806152\n",
      "[2022-03-22 19:28:48,688 - trainer - INFO] - Train Epoch:[60/100] Step:[30/77] Total Loss: 4.591467 GL_Loss: 0.392615 CRF_Loss: 4.198853\n",
      "[2022-03-22 19:29:08,431 - trainer - INFO] - Train Epoch:[60/100] Step:[40/77] Total Loss: 2.171969 GL_Loss: 0.467868 CRF_Loss: 1.704102\n",
      "[2022-03-22 19:29:28,514 - trainer - INFO] - Train Epoch:[60/100] Step:[50/77] Total Loss: 47.562580 GL_Loss: 0.737383 CRF_Loss: 46.825195\n",
      "[2022-03-22 19:29:41,236 - trainer - INFO] - [Step Validation] Epoch:[60/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.631397 | 0.83379  | 0.718615 | 0.83379  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.624272 | 0.771909 | 0.690284 | 0.771909 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.256757 | 0.425373 | 0.320225 | 0.425373 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.59785  | 0.78225  | 0.677731 | 0.78225  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 19:30:03,766 - trainer - INFO] - Train Epoch:[60/100] Step:[60/77] Total Loss: 12.533191 GL_Loss: 2.073962 CRF_Loss: 10.459229\n",
      "[2022-03-22 19:30:23,484 - trainer - INFO] - Train Epoch:[60/100] Step:[70/77] Total Loss: 69.293129 GL_Loss: 0.657390 CRF_Loss: 68.635742\n",
      "[2022-03-22 19:30:49,144 - trainer - INFO] - [Epoch Validation] Epoch:[60/100] Total Loss: 13.927508 GL_Loss: 0.006240 CRF_Loss: 13.303546 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.630328 | 0.823744 | 0.714173 | 0.823744 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.599271 | 0.789916 | 0.681512 | 0.789916 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.251142 | 0.410448 | 0.311615 | 0.410448 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.5877   | 0.78322  | 0.671518 | 0.78322  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 19:30:51,125 - trainer - INFO] - Saving checkpoint: saved/models/PICK_Default/test_0322_164111/checkpoint-epoch60.pth ...\n",
      "[2022-03-22 19:31:10,626 - trainer - INFO] - Train Epoch:[61/100] Step:[10/77] Total Loss: 14.826983 GL_Loss: 0.587726 CRF_Loss: 14.239258\n",
      "[2022-03-22 19:31:29,132 - trainer - INFO] - Train Epoch:[61/100] Step:[20/77] Total Loss: 13.471446 GL_Loss: 0.594492 CRF_Loss: 12.876953\n",
      "[2022-03-22 19:31:49,632 - trainer - INFO] - Train Epoch:[61/100] Step:[30/77] Total Loss: 13.778078 GL_Loss: 0.507448 CRF_Loss: 13.270630\n",
      "[2022-03-22 19:32:06,786 - trainer - INFO] - Train Epoch:[61/100] Step:[40/77] Total Loss: 5.549883 GL_Loss: 0.484209 CRF_Loss: 5.065674\n",
      "[2022-03-22 19:32:26,051 - trainer - INFO] - Train Epoch:[61/100] Step:[50/77] Total Loss: 13.676595 GL_Loss: 0.528646 CRF_Loss: 13.147949\n",
      "[2022-03-22 19:32:37,449 - trainer - INFO] - [Step Validation] Epoch:[61/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.646974 | 0.820091 | 0.723319 | 0.820091 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.642715 | 0.773109 | 0.701907 | 0.773109 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.260274 | 0.425373 | 0.322946 | 0.425373 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.612878 | 0.775461 | 0.68465  | 0.775461 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 19:32:57,854 - trainer - INFO] - Train Epoch:[61/100] Step:[60/77] Total Loss: 12.068044 GL_Loss: 0.483083 CRF_Loss: 11.584961\n",
      "[2022-03-22 19:33:17,806 - trainer - INFO] - Train Epoch:[61/100] Step:[70/77] Total Loss: 31.209206 GL_Loss: 0.561012 CRF_Loss: 30.648193\n",
      "[2022-03-22 19:33:42,125 - trainer - INFO] - [Epoch Validation] Epoch:[61/100] Total Loss: 13.963353 GL_Loss: 0.006008 CRF_Loss: 13.362535 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.629158 | 0.811872 | 0.708931 | 0.811872 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.621442 | 0.786315 | 0.694224 | 0.786315 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.229787 | 0.402985 | 0.292683 | 0.402985 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.591414 | 0.774976 | 0.670865 | 0.774976 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 19:34:01,275 - trainer - INFO] - Train Epoch:[62/100] Step:[10/77] Total Loss: 11.680156 GL_Loss: 0.756572 CRF_Loss: 10.923584\n",
      "[2022-03-22 19:34:20,739 - trainer - INFO] - Train Epoch:[62/100] Step:[20/77] Total Loss: 11.642039 GL_Loss: 0.363963 CRF_Loss: 11.278076\n",
      "[2022-03-22 19:34:38,889 - trainer - INFO] - Train Epoch:[62/100] Step:[30/77] Total Loss: 5.762636 GL_Loss: 0.515932 CRF_Loss: 5.246704\n",
      "[2022-03-22 19:34:56,798 - trainer - INFO] - Train Epoch:[62/100] Step:[40/77] Total Loss: 9.996150 GL_Loss: 0.639949 CRF_Loss: 9.356201\n",
      "[2022-03-22 19:35:16,812 - trainer - INFO] - Train Epoch:[62/100] Step:[50/77] Total Loss: 10.437196 GL_Loss: 0.479432 CRF_Loss: 9.957764\n",
      "[2022-03-22 19:35:28,334 - trainer - INFO] - [Step Validation] Epoch:[62/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.63191  | 0.824658 | 0.715531 | 0.824658 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.624639 | 0.779112 | 0.693376 | 0.779112 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.251163 | 0.402985 | 0.309456 | 0.402985 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.598584 | 0.778855 | 0.676923 | 0.778855 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-22 19:35:47,069 - trainer - INFO] - Train Epoch:[62/100] Step:[60/77] Total Loss: 14.661051 GL_Loss: 0.761027 CRF_Loss: 13.900024\n",
      "[2022-03-22 19:36:06,780 - trainer - INFO] - Train Epoch:[62/100] Step:[70/77] Total Loss: 2.011687 GL_Loss: 0.603362 CRF_Loss: 1.408325\n",
      "[2022-03-22 19:36:30,855 - trainer - INFO] - [Epoch Validation] Epoch:[62/100] Total Loss: 17.192957 GL_Loss: 0.005997 CRF_Loss: 16.593219 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.616816 | 0.817352 | 0.703064 | 0.817352 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.593972 | 0.804322 | 0.683325 | 0.804322 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.245192 | 0.380597 | 0.298246 | 0.380597 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.579835 | 0.783705 | 0.666529 | 0.783705 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 19:36:49,460 - trainer - INFO] - Train Epoch:[63/100] Step:[10/77] Total Loss: 7.084659 GL_Loss: 0.955630 CRF_Loss: 6.129028\n",
      "[2022-03-22 19:37:08,468 - trainer - INFO] - Train Epoch:[63/100] Step:[20/77] Total Loss: 21.283884 GL_Loss: 0.670358 CRF_Loss: 20.613525\n",
      "[2022-03-22 19:37:26,715 - trainer - INFO] - Train Epoch:[63/100] Step:[30/77] Total Loss: 18.948055 GL_Loss: 0.607235 CRF_Loss: 18.340820\n",
      "[2022-03-22 19:37:45,366 - trainer - INFO] - Train Epoch:[63/100] Step:[40/77] Total Loss: 16.927265 GL_Loss: 0.534686 CRF_Loss: 16.392578\n",
      "[2022-03-22 19:38:04,736 - trainer - INFO] - Train Epoch:[63/100] Step:[50/77] Total Loss: 6.725513 GL_Loss: 0.598316 CRF_Loss: 6.127197\n",
      "[2022-03-22 19:38:16,099 - trainer - INFO] - [Step Validation] Epoch:[63/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.631989 | 0.815525 | 0.712121 | 0.815525 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.612873 | 0.788715 | 0.689764 | 0.788715 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.264423 | 0.410448 | 0.321637 | 0.410448 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.59599  | 0.778371 | 0.675079 | 0.778371 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 19:38:33,510 - trainer - INFO] - Train Epoch:[63/100] Step:[60/77] Total Loss: 7.947127 GL_Loss: 0.706893 CRF_Loss: 7.240234\n",
      "[2022-03-22 19:38:52,894 - trainer - INFO] - Train Epoch:[63/100] Step:[70/77] Total Loss: 22.702888 GL_Loss: 0.393073 CRF_Loss: 22.309814\n",
      "[2022-03-22 19:39:17,524 - trainer - INFO] - [Epoch Validation] Epoch:[63/100] Total Loss: 14.515532 GL_Loss: 0.005848 CRF_Loss: 13.930765 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.614353 | 0.83653  | 0.70843  | 0.83653  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.582811 | 0.781513 | 0.667692 | 0.781513 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.240741 | 0.38806  | 0.297143 | 0.38806  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.5733   | 0.78516  | 0.66271  | 0.78516  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 19:39:37,002 - trainer - INFO] - Train Epoch:[64/100] Step:[10/77] Total Loss: 3.177446 GL_Loss: 0.527544 CRF_Loss: 2.649902\n",
      "[2022-03-22 19:39:54,867 - trainer - INFO] - Train Epoch:[64/100] Step:[20/77] Total Loss: 17.854954 GL_Loss: 0.556370 CRF_Loss: 17.298584\n",
      "[2022-03-22 19:40:12,486 - trainer - INFO] - Train Epoch:[64/100] Step:[30/77] Total Loss: 5.771019 GL_Loss: 0.434594 CRF_Loss: 5.336426\n",
      "[2022-03-22 19:40:31,398 - trainer - INFO] - Train Epoch:[64/100] Step:[40/77] Total Loss: 30.382387 GL_Loss: 0.621156 CRF_Loss: 29.761230\n",
      "[2022-03-22 19:40:50,771 - trainer - INFO] - Train Epoch:[64/100] Step:[50/77] Total Loss: 53.269714 GL_Loss: 0.388611 CRF_Loss: 52.881104\n",
      "[2022-03-22 19:41:02,279 - trainer - INFO] - [Step Validation] Epoch:[64/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.647017 | 0.821918 | 0.724055 | 0.821918 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.613852 | 0.776711 | 0.685745 | 0.776711 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.363636 | 0.41791  | 0.388889 | 0.41791  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.616776 | 0.777401 | 0.687835 | 0.777401 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 19:41:22,801 - trainer - INFO] - Train Epoch:[64/100] Step:[60/77] Total Loss: 25.929726 GL_Loss: 0.692178 CRF_Loss: 25.237549\n",
      "[2022-03-22 19:41:42,465 - trainer - INFO] - Train Epoch:[64/100] Step:[70/77] Total Loss: 10.517704 GL_Loss: 0.507694 CRF_Loss: 10.010010\n",
      "[2022-03-22 19:42:05,260 - trainer - INFO] - [Epoch Validation] Epoch:[64/100] Total Loss: 14.054546 GL_Loss: 0.005833 CRF_Loss: 13.471278 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.647399 | 0.818265 | 0.722872 | 0.818265 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.618384 | 0.79952  | 0.697382 | 0.79952  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.267327 | 0.402985 | 0.321429 | 0.402985 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.606834 | 0.783705 | 0.684021 | 0.783705 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 19:42:24,606 - trainer - INFO] - Train Epoch:[65/100] Step:[10/77] Total Loss: 19.444748 GL_Loss: 1.263230 CRF_Loss: 18.181519\n",
      "[2022-03-22 19:42:44,999 - trainer - INFO] - Train Epoch:[65/100] Step:[20/77] Total Loss: 29.567863 GL_Loss: 0.539544 CRF_Loss: 29.028320\n",
      "[2022-03-22 19:43:04,346 - trainer - INFO] - Train Epoch:[65/100] Step:[30/77] Total Loss: 7.597438 GL_Loss: 1.054469 CRF_Loss: 6.542969\n",
      "[2022-03-22 19:43:22,291 - trainer - INFO] - Train Epoch:[65/100] Step:[40/77] Total Loss: 15.913278 GL_Loss: 0.791939 CRF_Loss: 15.121338\n",
      "[2022-03-22 19:43:40,547 - trainer - INFO] - Train Epoch:[65/100] Step:[50/77] Total Loss: 7.503487 GL_Loss: 0.667794 CRF_Loss: 6.835693\n",
      "[2022-03-22 19:43:52,003 - trainer - INFO] - [Step Validation] Epoch:[65/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.604336 | 0.814612 | 0.693893 | 0.814612 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.584079 | 0.783914 | 0.6694   | 0.783914 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.273171 | 0.41791  | 0.330383 | 0.41791  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.57199  | 0.776431 | 0.658712 | 0.776431 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 19:44:10,813 - trainer - INFO] - Train Epoch:[65/100] Step:[60/77] Total Loss: 4.885668 GL_Loss: 0.708422 CRF_Loss: 4.177246\n",
      "[2022-03-22 19:44:29,800 - trainer - INFO] - Train Epoch:[65/100] Step:[70/77] Total Loss: 12.382578 GL_Loss: 0.712168 CRF_Loss: 11.670410\n",
      "[2022-03-22 19:44:54,474 - trainer - INFO] - [Epoch Validation] Epoch:[65/100] Total Loss: 14.461449 GL_Loss: 0.005842 CRF_Loss: 13.877207 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.629424 | 0.828311 | 0.7153   | 0.828311 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.580902 | 0.788715 | 0.669043 | 0.788715 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.27451  | 0.41791  | 0.331361 | 0.41791  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.583573 | 0.785645 | 0.669698 | 0.785645 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-22 19:45:13,437 - trainer - INFO] - Train Epoch:[66/100] Step:[10/77] Total Loss: 5.134883 GL_Loss: 0.492549 CRF_Loss: 4.642334\n",
      "[2022-03-22 19:45:31,554 - trainer - INFO] - Train Epoch:[66/100] Step:[20/77] Total Loss: 5.086802 GL_Loss: 1.282846 CRF_Loss: 3.803955\n",
      "[2022-03-22 19:45:51,838 - trainer - INFO] - Train Epoch:[66/100] Step:[30/77] Total Loss: 52.836727 GL_Loss: 1.054808 CRF_Loss: 51.781921\n",
      "[2022-03-22 19:46:08,903 - trainer - INFO] - Train Epoch:[66/100] Step:[40/77] Total Loss: 5.341990 GL_Loss: 0.459787 CRF_Loss: 4.882202\n",
      "[2022-03-22 19:46:28,791 - trainer - INFO] - Train Epoch:[66/100] Step:[50/77] Total Loss: 8.228029 GL_Loss: 0.591311 CRF_Loss: 7.636719\n",
      "[2022-03-22 19:46:40,369 - trainer - INFO] - [Step Validation] Epoch:[66/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.648959 | 0.825571 | 0.726688 | 0.825571 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.624161 | 0.781513 | 0.69403  | 0.781513 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.28     | 0.41791  | 0.335329 | 0.41791  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.611153 | 0.78128  | 0.685824 | 0.78128  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 19:46:58,944 - trainer - INFO] - Train Epoch:[66/100] Step:[60/77] Total Loss: 20.283871 GL_Loss: 0.566586 CRF_Loss: 19.717285\n",
      "[2022-03-22 19:47:17,409 - trainer - INFO] - Train Epoch:[66/100] Step:[70/77] Total Loss: 1.247879 GL_Loss: 0.439408 CRF_Loss: 0.808472\n",
      "[2022-03-22 19:47:42,904 - trainer - INFO] - [Epoch Validation] Epoch:[66/100] Total Loss: 14.135056 GL_Loss: 0.005949 CRF_Loss: 13.540121 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.662252 | 0.821918 | 0.733496 | 0.821918 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.627184 | 0.77551  | 0.693505 | 0.77551  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.341317 | 0.425373 | 0.378738 | 0.425373 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.627152 | 0.777401 | 0.69424  | 0.777401 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 19:48:02,598 - trainer - INFO] - Train Epoch:[67/100] Step:[10/77] Total Loss: 10.231656 GL_Loss: 0.641080 CRF_Loss: 9.590576\n",
      "[2022-03-22 19:48:22,233 - trainer - INFO] - Train Epoch:[67/100] Step:[20/77] Total Loss: 5.481584 GL_Loss: 0.573625 CRF_Loss: 4.907959\n",
      "[2022-03-22 19:48:39,201 - trainer - INFO] - Train Epoch:[67/100] Step:[30/77] Total Loss: 12.010950 GL_Loss: 0.397913 CRF_Loss: 11.613037\n",
      "[2022-03-22 19:48:58,549 - trainer - INFO] - Train Epoch:[67/100] Step:[40/77] Total Loss: 5.030025 GL_Loss: 0.456539 CRF_Loss: 4.573486\n",
      "[2022-03-22 19:49:17,463 - trainer - INFO] - Train Epoch:[67/100] Step:[50/77] Total Loss: 8.765554 GL_Loss: 0.978201 CRF_Loss: 7.787354\n",
      "[2022-03-22 19:49:28,890 - trainer - INFO] - [Step Validation] Epoch:[67/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.650611 | 0.826484 | 0.728077 | 0.826484 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.623174 | 0.768307 | 0.688172 | 0.768307 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.302198 | 0.410448 | 0.348101 | 0.410448 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.615385 | 0.775946 | 0.686401 | 0.775946 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 19:49:47,088 - trainer - INFO] - Train Epoch:[67/100] Step:[60/77] Total Loss: 19.042995 GL_Loss: 0.605984 CRF_Loss: 18.437012\n",
      "[2022-03-22 19:50:06,241 - trainer - INFO] - Train Epoch:[67/100] Step:[70/77] Total Loss: 14.840517 GL_Loss: 1.004336 CRF_Loss: 13.836182\n",
      "[2022-03-22 19:50:30,439 - trainer - INFO] - [Epoch Validation] Epoch:[67/100] Total Loss: 14.120663 GL_Loss: 0.005799 CRF_Loss: 13.540782 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.609459 | 0.823744 | 0.700583 | 0.823744 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.597948 | 0.769508 | 0.672966 | 0.769508 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.251121 | 0.41791  | 0.313725 | 0.41791  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.576216 | 0.775461 | 0.661154 | 0.775461 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 19:50:50,327 - trainer - INFO] - Train Epoch:[68/100] Step:[10/77] Total Loss: 14.100090 GL_Loss: 0.718742 CRF_Loss: 13.381348\n",
      "[2022-03-22 19:51:09,998 - trainer - INFO] - Train Epoch:[68/100] Step:[20/77] Total Loss: 15.173960 GL_Loss: 0.997446 CRF_Loss: 14.176514\n",
      "[2022-03-22 19:51:27,180 - trainer - INFO] - Train Epoch:[68/100] Step:[30/77] Total Loss: 10.121851 GL_Loss: 0.488307 CRF_Loss: 9.633545\n",
      "[2022-03-22 19:51:47,456 - trainer - INFO] - Train Epoch:[68/100] Step:[40/77] Total Loss: 15.796533 GL_Loss: 0.836205 CRF_Loss: 14.960327\n",
      "[2022-03-22 19:52:07,281 - trainer - INFO] - Train Epoch:[68/100] Step:[50/77] Total Loss: 15.589504 GL_Loss: 0.502346 CRF_Loss: 15.087158\n",
      "[2022-03-22 19:52:19,816 - trainer - INFO] - [Step Validation] Epoch:[68/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.635724 | 0.825571 | 0.718315 | 0.825571 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.624404 | 0.786315 | 0.696068 | 0.786315 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.247664 | 0.395522 | 0.304598 | 0.395522 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.600372 | 0.781765 | 0.679166 | 0.781765 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 19:52:38,155 - trainer - INFO] - Train Epoch:[68/100] Step:[60/77] Total Loss: 8.516965 GL_Loss: 0.567014 CRF_Loss: 7.949951\n",
      "[2022-03-22 19:52:56,548 - trainer - INFO] - Train Epoch:[68/100] Step:[70/77] Total Loss: 23.655281 GL_Loss: 0.616951 CRF_Loss: 23.038330\n",
      "[2022-03-22 19:53:22,518 - trainer - INFO] - [Epoch Validation] Epoch:[68/100] Total Loss: 13.843869 GL_Loss: 0.006038 CRF_Loss: 13.240070 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.643846 | 0.807306 | 0.71637  | 0.807306 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.625962 | 0.781513 | 0.695141 | 0.781513 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.296482 | 0.440299 | 0.354354 | 0.440299 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.61026  | 0.773036 | 0.682071 | 0.773036 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 19:53:40,700 - trainer - INFO] - Train Epoch:[69/100] Step:[10/77] Total Loss: 13.325068 GL_Loss: 0.539180 CRF_Loss: 12.785889\n",
      "[2022-03-22 19:53:58,518 - trainer - INFO] - Train Epoch:[69/100] Step:[20/77] Total Loss: 14.598308 GL_Loss: 0.487956 CRF_Loss: 14.110352\n",
      "[2022-03-22 19:54:17,697 - trainer - INFO] - Train Epoch:[69/100] Step:[30/77] Total Loss: 24.533304 GL_Loss: 0.709085 CRF_Loss: 23.824219\n",
      "[2022-03-22 19:54:35,153 - trainer - INFO] - Train Epoch:[69/100] Step:[40/77] Total Loss: 17.813442 GL_Loss: 0.553432 CRF_Loss: 17.260010\n",
      "[2022-03-22 19:54:55,582 - trainer - INFO] - Train Epoch:[69/100] Step:[50/77] Total Loss: 22.513813 GL_Loss: 0.530904 CRF_Loss: 21.982910\n",
      "[2022-03-22 19:55:06,992 - trainer - INFO] - [Step Validation] Epoch:[69/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.642909 | 0.815525 | 0.719002 | 0.815525 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.629808 | 0.786315 | 0.699413 | 0.786315 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.254545 | 0.41791  | 0.316384 | 0.41791  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.605512 | 0.777886 | 0.680959 | 0.777886 |\n",
      "+---------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-22 19:55:26,841 - trainer - INFO] - Train Epoch:[69/100] Step:[60/77] Total Loss: 7.062491 GL_Loss: 0.445792 CRF_Loss: 6.616699\n",
      "[2022-03-22 19:55:47,424 - trainer - INFO] - Train Epoch:[69/100] Step:[70/77] Total Loss: 1.182976 GL_Loss: 0.424920 CRF_Loss: 0.758057\n",
      "[2022-03-22 19:56:11,173 - trainer - INFO] - [Epoch Validation] Epoch:[69/100] Total Loss: 14.213840 GL_Loss: 0.005923 CRF_Loss: 13.621529 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.647744 | 0.812785 | 0.72094  | 0.812785 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.61941  | 0.781513 | 0.691083 | 0.781513 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.304813 | 0.425373 | 0.35514  | 0.425373 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.611792 | 0.774976 | 0.683783 | 0.774976 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 19:56:30,973 - trainer - INFO] - Train Epoch:[70/100] Step:[10/77] Total Loss: 29.394329 GL_Loss: 0.720013 CRF_Loss: 28.674316\n",
      "[2022-03-22 19:56:50,525 - trainer - INFO] - Train Epoch:[70/100] Step:[20/77] Total Loss: 33.150688 GL_Loss: 0.534232 CRF_Loss: 32.616455\n",
      "[2022-03-22 19:57:07,162 - trainer - INFO] - Train Epoch:[70/100] Step:[30/77] Total Loss: 4.937503 GL_Loss: 1.105838 CRF_Loss: 3.831665\n",
      "[2022-03-22 19:57:25,980 - trainer - INFO] - Train Epoch:[70/100] Step:[40/77] Total Loss: 3.962249 GL_Loss: 0.660003 CRF_Loss: 3.302246\n",
      "[2022-03-22 19:57:44,574 - trainer - INFO] - Train Epoch:[70/100] Step:[50/77] Total Loss: 1.226312 GL_Loss: 0.439691 CRF_Loss: 0.786621\n",
      "[2022-03-22 19:57:55,992 - trainer - INFO] - [Step Validation] Epoch:[70/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.644043 | 0.814612 | 0.719355 | 0.814612 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.615313 | 0.791116 | 0.692227 | 0.791116 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.258537 | 0.395522 | 0.312684 | 0.395522 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.602781 | 0.777886 | 0.679229 | 0.777886 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 19:58:15,851 - trainer - INFO] - Train Epoch:[70/100] Step:[60/77] Total Loss: 14.336029 GL_Loss: 1.288543 CRF_Loss: 13.047485\n",
      "[2022-03-22 19:58:36,012 - trainer - INFO] - Train Epoch:[70/100] Step:[70/77] Total Loss: 14.335103 GL_Loss: 0.595357 CRF_Loss: 13.739746\n",
      "[2022-03-22 19:59:00,747 - trainer - INFO] - [Epoch Validation] Epoch:[70/100] Total Loss: 14.317043 GL_Loss: 0.006208 CRF_Loss: 13.696249 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.638589 | 0.810046 | 0.714171 | 0.810046 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.642512 | 0.798319 | 0.711991 | 0.798319 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.288557 | 0.432836 | 0.346269 | 0.432836 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.613333 | 0.780795 | 0.687007 | 0.780795 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 19:59:20,858 - trainer - INFO] - Train Epoch:[71/100] Step:[10/77] Total Loss: 7.349119 GL_Loss: 0.631101 CRF_Loss: 6.718018\n",
      "[2022-03-22 19:59:39,665 - trainer - INFO] - Train Epoch:[71/100] Step:[20/77] Total Loss: 2.829935 GL_Loss: 0.913919 CRF_Loss: 1.916016\n",
      "[2022-03-22 19:59:58,284 - trainer - INFO] - Train Epoch:[71/100] Step:[30/77] Total Loss: 16.175619 GL_Loss: 0.392660 CRF_Loss: 15.782959\n",
      "[2022-03-22 20:00:16,411 - trainer - INFO] - Train Epoch:[71/100] Step:[40/77] Total Loss: 3.866015 GL_Loss: 0.395556 CRF_Loss: 3.470459\n",
      "[2022-03-22 20:00:34,354 - trainer - INFO] - Train Epoch:[71/100] Step:[50/77] Total Loss: 10.546242 GL_Loss: 0.497657 CRF_Loss: 10.048584\n",
      "[2022-03-22 20:00:45,801 - trainer - INFO] - [Step Validation] Epoch:[71/100] Step:[50/77]  \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.628751 | 0.822831 | 0.712816 | 0.822831 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.584656 | 0.795918 | 0.674123 | 0.795918 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.28934  | 0.425373 | 0.344411 | 0.425373 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.586469 | 0.78613  | 0.671778 | 0.78613  |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 20:01:03,961 - trainer - INFO] - Train Epoch:[71/100] Step:[60/77] Total Loss: 26.127432 GL_Loss: 0.399160 CRF_Loss: 25.728271\n",
      "[2022-03-22 20:01:22,565 - trainer - INFO] - Train Epoch:[71/100] Step:[70/77] Total Loss: 8.542577 GL_Loss: 0.490087 CRF_Loss: 8.052490\n",
      "[2022-03-22 20:01:48,912 - trainer - INFO] - [Epoch Validation] Epoch:[71/100] Total Loss: 13.815831 GL_Loss: 0.006027 CRF_Loss: 13.213134 \n",
      "+---------+----------+----------+----------+----------+\n",
      "| name    |      mEP |      mER |      mEF |      mEA |\n",
      "+=========+==========+==========+==========+==========+\n",
      "| keys    | 0.651482 | 0.822831 | 0.727199 | 0.822831 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| values  | 0.63189  | 0.770708 | 0.694429 | 0.770708 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| header  | 0.298429 | 0.425373 | 0.350769 | 0.425373 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "| overall | 0.617761 | 0.775946 | 0.687876 | 0.775946 |\n",
      "+---------+----------+----------+----------+----------+\n",
      "[2022-03-22 20:01:48,913 - trainer - INFO] - Validation performance didn't improve for 40 epochs. Training stops.\n",
      "[2022-03-22 20:01:48,913 - train - INFO] - Training end...\n"
     ]
    }
   ],
   "source": [
    "# FUNSD Dataset\n",
    "!python3 train.py -c config_funsd.json -d 0 -dist false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-28 13:47:33,188 - train - INFO] - Distributed GPU training model start...\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"train.py\", line 162, in <module>\r\n",
      "    entry_point(config)\r\n",
      "  File \"train.py\", line 112, in entry_point\r\n",
      "    for key in ('MASTER_ADDR', 'MASTER_PORT', 'RANK', 'WORLD_SIZE')\r\n",
      "  File \"train.py\", line 112, in <dictcomp>\r\n",
      "    for key in ('MASTER_ADDR', 'MASTER_PORT', 'RANK', 'WORLD_SIZE')\r\n",
      "  File \"/usr/lib/python3.6/os.py\", line 669, in __getitem__\r\n",
      "    raise KeyError(key) from None\r\n",
      "KeyError: 'MASTER_ADDR'\r\n"
     ]
    }
   ],
   "source": [
    "# FUNSD Dataset\n",
    "!python3 train.py -c config_funsd.json --distributed false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-15 12:52:46,294 - train - INFO] - One GPU or CPU training mode start...\n",
      "[2022-03-15 12:52:46,304 - train - INFO] - Dataloader instances created. Train datasets: 70 samples Validation datasets: 50 samples.\n",
      "[2022-03-15 12:52:47,074 - train - INFO] - Model created, trainable parameters: 75911942.\n",
      "[2022-03-15 12:52:47,075 - train - INFO] - Optimizer and lr_scheduler created.\n",
      "[2022-03-15 12:52:47,075 - train - INFO] - Max_epochs: 100 Log_per_step: 10 Validation_per_step: 40.\n",
      "[2022-03-15 12:52:47,075 - train - INFO] - Training start...\n",
      "[2022-03-15 12:52:47,103 - trainer - WARNING] - Training is using GPU 0!\n",
      "[2022-03-15 12:53:11,162 - trainer - INFO] - Train Epoch:[1/100] Step:[10/35] Total Loss: 519.029907 GL_Loss: 1.049708 CRF_Loss: 517.980225\n",
      "[2022-03-15 12:53:31,115 - trainer - INFO] - Train Epoch:[1/100] Step:[20/35] Total Loss: 242.945038 GL_Loss: 2.577722 CRF_Loss: 240.367310\n",
      "[2022-03-15 12:53:51,139 - trainer - INFO] - Train Epoch:[1/100] Step:[30/35] Total Loss: 271.533875 GL_Loss: 2.220139 CRF_Loss: 269.313721\n",
      "[2022-03-15 12:54:11,535 - trainer - INFO] - [Epoch Validation] Epoch:[1/100] Total Loss: 502.270231 GL_Loss: 0.024547 CRF_Loss: 499.815547 \n",
      "+----------+-------+-------+-------+-------+\n",
      "| name     |   mEP |   mER |   mEF |   mEA |\n",
      "+==========+=======+=======+=======+=======+\n",
      "| h_key    |     0 |     0 |     0 |     0 |\n",
      "+----------+-------+-------+-------+-------+\n",
      "| h_answer |     0 |     0 |     0 |     0 |\n",
      "+----------+-------+-------+-------+-------+\n",
      "| overall  |     0 |     0 |     0 |     0 |\n",
      "+----------+-------+-------+-------+-------+\n",
      "[2022-03-15 12:54:31,780 - trainer - INFO] - Train Epoch:[2/100] Step:[10/35] Total Loss: 141.622452 GL_Loss: 0.922864 CRF_Loss: 140.699585\n",
      "[2022-03-15 12:54:52,111 - trainer - INFO] - Train Epoch:[2/100] Step:[20/35] Total Loss: 87.842468 GL_Loss: 0.486752 CRF_Loss: 87.355713\n",
      "[2022-03-15 12:55:12,032 - trainer - INFO] - Train Epoch:[2/100] Step:[30/35] Total Loss: 72.457306 GL_Loss: 0.337191 CRF_Loss: 72.120117\n",
      "[2022-03-15 12:55:32,214 - trainer - INFO] - [Epoch Validation] Epoch:[2/100] Total Loss: 106.299018 GL_Loss: 0.008987 CRF_Loss: 105.400314 \n",
      "+----------+----------+-----------+----------+-----------+\n",
      "| name     |      mEP |       mER |      mEF |       mEA |\n",
      "+==========+==========+===========+==========+===========+\n",
      "| h_key    | 0        | 0         | 0        | 0         |\n",
      "+----------+----------+-----------+----------+-----------+\n",
      "| h_answer | 0.291391 | 0.146667  | 0.195122 | 0.146667  |\n",
      "+----------+----------+-----------+----------+-----------+\n",
      "| overall  | 0.157143 | 0.0962801 | 0.119403 | 0.0962801 |\n",
      "+----------+----------+-----------+----------+-----------+\n",
      "[2022-03-15 12:55:52,316 - trainer - INFO] - Train Epoch:[3/100] Step:[10/35] Total Loss: 48.613365 GL_Loss: 0.595541 CRF_Loss: 48.017822\n",
      "[2022-03-15 12:56:11,971 - trainer - INFO] - Train Epoch:[3/100] Step:[20/35] Total Loss: 40.682098 GL_Loss: 0.353729 CRF_Loss: 40.328369\n",
      "[2022-03-15 12:56:32,716 - trainer - INFO] - Train Epoch:[3/100] Step:[30/35] Total Loss: 35.309475 GL_Loss: 0.386135 CRF_Loss: 34.923340\n",
      "[2022-03-15 12:56:52,725 - trainer - INFO] - [Epoch Validation] Epoch:[3/100] Total Loss: 45.063473 GL_Loss: 0.004697 CRF_Loss: 44.593785 \n",
      "+----------+-----------+----------+----------+----------+\n",
      "| name     |       mEP |      mER |      mEF |      mEA |\n",
      "+==========+===========+==========+==========+==========+\n",
      "| h_key    | 0.0542636 | 0.044586 | 0.048951 | 0.044586 |\n",
      "+----------+-----------+----------+----------+----------+\n",
      "| h_answer | 0.291391  | 0.146667 | 0.195122 | 0.146667 |\n",
      "+----------+-----------+----------+----------+----------+\n",
      "| overall  | 0.182143  | 0.111597 | 0.138399 | 0.111597 |\n",
      "+----------+-----------+----------+----------+----------+\n",
      "[2022-03-15 12:57:12,693 - trainer - INFO] - Train Epoch:[4/100] Step:[10/35] Total Loss: 36.300072 GL_Loss: 0.405296 CRF_Loss: 35.894775\n",
      "[2022-03-15 12:57:33,043 - trainer - INFO] - Train Epoch:[4/100] Step:[20/35] Total Loss: 31.539793 GL_Loss: 0.260496 CRF_Loss: 31.279297\n",
      "[2022-03-15 12:57:52,924 - trainer - INFO] - Train Epoch:[4/100] Step:[30/35] Total Loss: 55.640697 GL_Loss: 0.295482 CRF_Loss: 55.345215\n",
      "[2022-03-15 12:58:13,062 - trainer - INFO] - [Epoch Validation] Epoch:[4/100] Total Loss: 34.249328 GL_Loss: 0.003333 CRF_Loss: 33.915995 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_answer | 0.423841 | 0.213333 | 0.283814 | 0.213333 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_key    | 0.55814  | 0.458599 | 0.503497 | 0.458599 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.485714 | 0.297593 | 0.369064 | 0.297593 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 12:58:33,303 - trainer - INFO] - Train Epoch:[5/100] Step:[10/35] Total Loss: 25.391632 GL_Loss: 0.289093 CRF_Loss: 25.102539\n",
      "[2022-03-15 12:58:53,297 - trainer - INFO] - Train Epoch:[5/100] Step:[20/35] Total Loss: 30.967007 GL_Loss: 0.266811 CRF_Loss: 30.700195\n",
      "[2022-03-15 12:59:13,357 - trainer - INFO] - Train Epoch:[5/100] Step:[30/35] Total Loss: 26.198732 GL_Loss: 0.282717 CRF_Loss: 25.916016\n",
      "[2022-03-15 12:59:33,719 - trainer - INFO] - [Epoch Validation] Epoch:[5/100] Total Loss: 28.159993 GL_Loss: 0.002838 CRF_Loss: 27.876207 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_answer | 0.476821 | 0.24     | 0.31929  | 0.24     |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_key    | 0.612403 | 0.503185 | 0.552448 | 0.503185 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.539286 | 0.330416 | 0.409769 | 0.330416 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 12:59:53,417 - trainer - INFO] - Train Epoch:[6/100] Step:[10/35] Total Loss: 30.603037 GL_Loss: 0.211436 CRF_Loss: 30.391602\n",
      "[2022-03-15 13:00:13,905 - trainer - INFO] - Train Epoch:[6/100] Step:[20/35] Total Loss: 24.524616 GL_Loss: 0.206013 CRF_Loss: 24.318604\n",
      "[2022-03-15 13:00:34,234 - trainer - INFO] - Train Epoch:[6/100] Step:[30/35] Total Loss: 22.497433 GL_Loss: 0.185177 CRF_Loss: 22.312256\n",
      "[2022-03-15 13:00:54,412 - trainer - INFO] - [Epoch Validation] Epoch:[6/100] Total Loss: 24.982604 GL_Loss: 0.002283 CRF_Loss: 24.754283 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_answer | 0.476821 | 0.24     | 0.31929  | 0.24     |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_key    | 0.55814  | 0.458599 | 0.503497 | 0.458599 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.514286 | 0.315098 | 0.390773 | 0.315098 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 13:01:14,876 - trainer - INFO] - Train Epoch:[7/100] Step:[10/35] Total Loss: 21.612595 GL_Loss: 0.210251 CRF_Loss: 21.402344\n",
      "[2022-03-15 13:01:34,780 - trainer - INFO] - Train Epoch:[7/100] Step:[20/35] Total Loss: 24.116467 GL_Loss: 0.249524 CRF_Loss: 23.866943\n",
      "[2022-03-15 13:01:54,580 - trainer - INFO] - Train Epoch:[7/100] Step:[30/35] Total Loss: 24.911938 GL_Loss: 0.232006 CRF_Loss: 24.679932\n",
      "[2022-03-15 13:02:15,059 - trainer - INFO] - [Epoch Validation] Epoch:[7/100] Total Loss: 22.591247 GL_Loss: 0.002172 CRF_Loss: 22.374016 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_answer | 0.455696 | 0.24     | 0.31441  | 0.24     |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_key    | 0.632353 | 0.547771 | 0.587031 | 0.547771 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.537415 | 0.345733 | 0.420772 | 0.345733 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 13:02:35,762 - trainer - INFO] - Train Epoch:[8/100] Step:[10/35] Total Loss: 21.736488 GL_Loss: 0.238930 CRF_Loss: 21.497559\n",
      "[2022-03-15 13:02:56,179 - trainer - INFO] - Train Epoch:[8/100] Step:[20/35] Total Loss: 18.655378 GL_Loss: 0.188336 CRF_Loss: 18.467041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-15 13:03:15,369 - trainer - INFO] - Train Epoch:[8/100] Step:[30/35] Total Loss: 23.490559 GL_Loss: 0.208332 CRF_Loss: 23.282227\n",
      "[2022-03-15 13:03:35,679 - trainer - INFO] - [Epoch Validation] Epoch:[8/100] Total Loss: 20.685755 GL_Loss: 0.002026 CRF_Loss: 20.483126 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_answer | 0.455696 | 0.24     | 0.31441  | 0.24     |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_key    | 0.580882 | 0.503185 | 0.539249 | 0.503185 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.513605 | 0.330416 | 0.40213  | 0.330416 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 13:03:55,610 - trainer - INFO] - Train Epoch:[9/100] Step:[10/35] Total Loss: 19.659935 GL_Loss: 0.226342 CRF_Loss: 19.433594\n",
      "[2022-03-15 13:04:15,602 - trainer - INFO] - Train Epoch:[9/100] Step:[20/35] Total Loss: 18.317345 GL_Loss: 0.165978 CRF_Loss: 18.151367\n",
      "[2022-03-15 13:04:35,567 - trainer - INFO] - Train Epoch:[9/100] Step:[30/35] Total Loss: 18.367525 GL_Loss: 0.194186 CRF_Loss: 18.173340\n",
      "[2022-03-15 13:04:56,315 - trainer - INFO] - [Epoch Validation] Epoch:[9/100] Total Loss: 18.968133 GL_Loss: 0.001829 CRF_Loss: 18.785205 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_answer | 0.476821 | 0.24     | 0.31929  | 0.24     |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_key    | 0.666667 | 0.547771 | 0.601399 | 0.547771 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.564286 | 0.345733 | 0.428765 | 0.345733 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 13:05:16,810 - trainer - INFO] - Train Epoch:[10/100] Step:[10/35] Total Loss: 17.092228 GL_Loss: 0.232365 CRF_Loss: 16.859863\n",
      "[2022-03-15 13:05:36,962 - trainer - INFO] - Train Epoch:[10/100] Step:[20/35] Total Loss: 19.325895 GL_Loss: 0.166227 CRF_Loss: 19.159668\n",
      "[2022-03-15 13:05:57,206 - trainer - INFO] - Train Epoch:[10/100] Step:[30/35] Total Loss: 13.671250 GL_Loss: 0.147568 CRF_Loss: 13.523682\n",
      "[2022-03-15 13:06:17,378 - trainer - INFO] - [Epoch Validation] Epoch:[10/100] Total Loss: 16.338026 GL_Loss: 0.001814 CRF_Loss: 16.156627 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_answer | 0.455696 | 0.24     | 0.31441  | 0.24     |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_key    | 0.632353 | 0.547771 | 0.587031 | 0.547771 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.537415 | 0.345733 | 0.420772 | 0.345733 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 13:06:37,479 - trainer - INFO] - Train Epoch:[11/100] Step:[10/35] Total Loss: 12.663699 GL_Loss: 0.239138 CRF_Loss: 12.424561\n",
      "[2022-03-15 13:06:57,297 - trainer - INFO] - Train Epoch:[11/100] Step:[20/35] Total Loss: 16.171471 GL_Loss: 0.244713 CRF_Loss: 15.926758\n",
      "[2022-03-15 13:07:17,302 - trainer - INFO] - Train Epoch:[11/100] Step:[30/35] Total Loss: 11.934655 GL_Loss: 0.187585 CRF_Loss: 11.747070\n",
      "[2022-03-15 13:07:37,633 - trainer - INFO] - [Epoch Validation] Epoch:[11/100] Total Loss: 13.829780 GL_Loss: 0.002254 CRF_Loss: 13.604346 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_answer | 0.455696 | 0.24     | 0.31441  | 0.24     |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_key    | 0.691176 | 0.598726 | 0.641638 | 0.598726 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.564626 | 0.363239 | 0.442077 | 0.363239 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 13:07:58,287 - trainer - INFO] - Train Epoch:[12/100] Step:[10/35] Total Loss: 11.113824 GL_Loss: 0.163873 CRF_Loss: 10.949951\n",
      "[2022-03-15 13:08:18,008 - trainer - INFO] - Train Epoch:[12/100] Step:[20/35] Total Loss: 9.139204 GL_Loss: 0.144575 CRF_Loss: 8.994629\n",
      "[2022-03-15 13:08:38,258 - trainer - INFO] - Train Epoch:[12/100] Step:[30/35] Total Loss: 12.078454 GL_Loss: 0.184655 CRF_Loss: 11.893799\n",
      "[2022-03-15 13:08:58,185 - trainer - INFO] - [Epoch Validation] Epoch:[12/100] Total Loss: 11.104887 GL_Loss: 0.001808 CRF_Loss: 10.924058 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_answer | 0.455696 | 0.24     | 0.31441  | 0.24     |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_key    | 0.691176 | 0.598726 | 0.641638 | 0.598726 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.564626 | 0.363239 | 0.442077 | 0.363239 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 13:09:18,350 - trainer - INFO] - Train Epoch:[13/100] Step:[10/35] Total Loss: 8.656694 GL_Loss: 0.153765 CRF_Loss: 8.502930\n",
      "[2022-03-15 13:09:38,195 - trainer - INFO] - Train Epoch:[13/100] Step:[20/35] Total Loss: 8.220325 GL_Loss: 0.223010 CRF_Loss: 7.997314\n",
      "[2022-03-15 13:09:58,779 - trainer - INFO] - Train Epoch:[13/100] Step:[30/35] Total Loss: 7.531024 GL_Loss: 0.149188 CRF_Loss: 7.381836\n",
      "[2022-03-15 13:10:19,240 - trainer - INFO] - [Epoch Validation] Epoch:[13/100] Total Loss: 9.166334 GL_Loss: 0.001744 CRF_Loss: 8.991957 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_answer | 0.455696 | 0.24     | 0.31441  | 0.24     |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_key    | 0.632353 | 0.547771 | 0.587031 | 0.547771 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.537415 | 0.345733 | 0.420772 | 0.345733 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 13:10:39,369 - trainer - INFO] - Train Epoch:[14/100] Step:[10/35] Total Loss: 5.646174 GL_Loss: 0.167170 CRF_Loss: 5.479004\n",
      "[2022-03-15 13:11:00,212 - trainer - INFO] - Train Epoch:[14/100] Step:[20/35] Total Loss: 6.157029 GL_Loss: 0.186814 CRF_Loss: 5.970215\n",
      "[2022-03-15 13:11:19,713 - trainer - INFO] - Train Epoch:[14/100] Step:[30/35] Total Loss: 6.363849 GL_Loss: 0.154865 CRF_Loss: 6.208984\n",
      "[2022-03-15 13:11:40,013 - trainer - INFO] - [Epoch Validation] Epoch:[14/100] Total Loss: 7.543411 GL_Loss: 0.001814 CRF_Loss: 7.361991 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.735294 | 0.636943 | 0.682594 | 0.636943 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.771429 | 0.81     | 0.790244 | 0.81     |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.760532 | 0.750547 | 0.755507 | 0.750547 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 13:12:00,488 - trainer - INFO] - Train Epoch:[15/100] Step:[10/35] Total Loss: 7.565945 GL_Loss: 0.213894 CRF_Loss: 7.352051\n",
      "[2022-03-15 13:12:20,612 - trainer - INFO] - Train Epoch:[15/100] Step:[20/35] Total Loss: 4.647868 GL_Loss: 0.188395 CRF_Loss: 4.459473\n",
      "[2022-03-15 13:12:40,374 - trainer - INFO] - Train Epoch:[15/100] Step:[30/35] Total Loss: 8.830453 GL_Loss: 0.199105 CRF_Loss: 8.631348\n",
      "[2022-03-15 13:13:00,860 - trainer - INFO] - [Epoch Validation] Epoch:[15/100] Total Loss: 6.458731 GL_Loss: 0.001753 CRF_Loss: 6.283440 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_answer | 0.663551 | 0.473333 | 0.552529 | 0.473333 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_key    | 0.691176 | 0.598726 | 0.641638 | 0.598726 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.674286 | 0.516411 | 0.584882 | 0.516411 |\n",
      "+----------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-15 13:13:20,895 - trainer - INFO] - Train Epoch:[16/100] Step:[10/35] Total Loss: 3.705754 GL_Loss: 0.167424 CRF_Loss: 3.538330\n",
      "[2022-03-15 13:13:41,557 - trainer - INFO] - Train Epoch:[16/100] Step:[20/35] Total Loss: 3.593397 GL_Loss: 0.181287 CRF_Loss: 3.412109\n",
      "[2022-03-15 13:14:02,051 - trainer - INFO] - Train Epoch:[16/100] Step:[30/35] Total Loss: 4.136268 GL_Loss: 0.142372 CRF_Loss: 3.993896\n",
      "[2022-03-15 13:14:22,119 - trainer - INFO] - [Epoch Validation] Epoch:[16/100] Total Loss: 5.254260 GL_Loss: 0.001715 CRF_Loss: 5.082750 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.742647 | 0.643312 | 0.68942  | 0.643312 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.931596 | 0.953333 | 0.942339 | 0.953333 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.873589 | 0.846827 | 0.86     | 0.846827 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 13:14:42,044 - trainer - INFO] - Train Epoch:[17/100] Step:[10/35] Total Loss: 7.163999 GL_Loss: 0.193784 CRF_Loss: 6.970215\n",
      "[2022-03-15 13:15:02,135 - trainer - INFO] - Train Epoch:[17/100] Step:[20/35] Total Loss: 3.867290 GL_Loss: 0.209819 CRF_Loss: 3.657471\n",
      "[2022-03-15 13:15:22,232 - trainer - INFO] - Train Epoch:[17/100] Step:[30/35] Total Loss: 4.225733 GL_Loss: 0.184718 CRF_Loss: 4.041016\n",
      "[2022-03-15 13:15:42,348 - trainer - INFO] - [Epoch Validation] Epoch:[17/100] Total Loss: 4.218424 GL_Loss: 0.001689 CRF_Loss: 4.049484 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.742647 | 0.643312 | 0.68942  | 0.643312 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.90367  | 0.862144 | 0.882419 | 0.862144 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 13:16:02,788 - trainer - INFO] - Train Epoch:[18/100] Step:[10/35] Total Loss: 4.213109 GL_Loss: 0.150608 CRF_Loss: 4.062500\n",
      "[2022-03-15 13:16:22,112 - trainer - INFO] - Train Epoch:[18/100] Step:[20/35] Total Loss: 3.658930 GL_Loss: 0.169183 CRF_Loss: 3.489746\n",
      "[2022-03-15 13:16:41,094 - trainer - INFO] - Train Epoch:[18/100] Step:[30/35] Total Loss: 2.590523 GL_Loss: 0.131539 CRF_Loss: 2.458984\n",
      "[2022-03-15 13:17:01,440 - trainer - INFO] - [Epoch Validation] Epoch:[18/100] Total Loss: 3.086338 GL_Loss: 0.001684 CRF_Loss: 2.917955 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.742647 | 0.643312 | 0.68942  | 0.643312 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.931596 | 0.953333 | 0.942339 | 0.953333 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.873589 | 0.846827 | 0.86     | 0.846827 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 13:17:21,986 - trainer - INFO] - Train Epoch:[19/100] Step:[10/35] Total Loss: 2.463171 GL_Loss: 0.152625 CRF_Loss: 2.310547\n",
      "[2022-03-15 13:17:40,989 - trainer - INFO] - Train Epoch:[19/100] Step:[20/35] Total Loss: 1.547416 GL_Loss: 0.158256 CRF_Loss: 1.389160\n",
      "[2022-03-15 13:18:00,536 - trainer - INFO] - Train Epoch:[19/100] Step:[30/35] Total Loss: 2.364964 GL_Loss: 0.123509 CRF_Loss: 2.241455\n",
      "[2022-03-15 13:18:21,140 - trainer - INFO] - [Epoch Validation] Epoch:[19/100] Total Loss: 2.561646 GL_Loss: 0.001492 CRF_Loss: 2.412416 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.794118 | 0.687898 | 0.737201 | 0.687898 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 1        | 1        | 1        | 1        |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.93578  | 0.892779 | 0.913774 | 0.892779 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 13:18:41,052 - trainer - INFO] - Train Epoch:[20/100] Step:[10/35] Total Loss: 2.996200 GL_Loss: 0.140243 CRF_Loss: 2.855957\n",
      "[2022-03-15 13:19:00,747 - trainer - INFO] - Train Epoch:[20/100] Step:[20/35] Total Loss: 2.770074 GL_Loss: 0.154352 CRF_Loss: 2.615723\n",
      "[2022-03-15 13:19:20,094 - trainer - INFO] - Train Epoch:[20/100] Step:[30/35] Total Loss: 3.924471 GL_Loss: 0.149080 CRF_Loss: 3.775391\n",
      "[2022-03-15 13:19:39,527 - trainer - INFO] - [Epoch Validation] Epoch:[20/100] Total Loss: 2.152899 GL_Loss: 0.001487 CRF_Loss: 2.004248 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.794118 | 0.687898 | 0.737201 | 0.687898 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 1        | 1        | 1        | 1        |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.93578  | 0.892779 | 0.913774 | 0.892779 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 13:19:41,386 - trainer - INFO] - Saving current best: model_best.pth ...\n",
      "[2022-03-15 13:20:01,296 - trainer - INFO] - Train Epoch:[21/100] Step:[10/35] Total Loss: 0.888868 GL_Loss: 0.119581 CRF_Loss: 0.769287\n",
      "[2022-03-15 13:20:20,343 - trainer - INFO] - Train Epoch:[21/100] Step:[20/35] Total Loss: 0.865533 GL_Loss: 0.121881 CRF_Loss: 0.743652\n",
      "[2022-03-15 13:20:40,156 - trainer - INFO] - Train Epoch:[21/100] Step:[30/35] Total Loss: 1.670936 GL_Loss: 0.127479 CRF_Loss: 1.543457\n",
      "[2022-03-15 13:20:59,719 - trainer - INFO] - [Epoch Validation] Epoch:[21/100] Total Loss: 1.979956 GL_Loss: 0.001459 CRF_Loss: 1.834054 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.742647 | 0.643312 | 0.68942  | 0.643312 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.90367  | 0.862144 | 0.882419 | 0.862144 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 13:21:19,287 - trainer - INFO] - Train Epoch:[22/100] Step:[10/35] Total Loss: 0.985254 GL_Loss: 0.126123 CRF_Loss: 0.859131\n",
      "[2022-03-15 13:21:39,141 - trainer - INFO] - Train Epoch:[22/100] Step:[20/35] Total Loss: 3.406005 GL_Loss: 0.139404 CRF_Loss: 3.266602\n",
      "[2022-03-15 13:21:58,814 - trainer - INFO] - Train Epoch:[22/100] Step:[30/35] Total Loss: 1.722432 GL_Loss: 0.167257 CRF_Loss: 1.555176\n",
      "[2022-03-15 13:22:18,910 - trainer - INFO] - [Epoch Validation] Epoch:[22/100] Total Loss: 1.705681 GL_Loss: 0.001402 CRF_Loss: 1.565437 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.794118 | 0.687898 | 0.737201 | 0.687898 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 1        | 1        | 1        | 1        |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.93578  | 0.892779 | 0.913774 | 0.892779 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 13:22:39,338 - trainer - INFO] - Train Epoch:[23/100] Step:[10/35] Total Loss: 2.493991 GL_Loss: 0.159030 CRF_Loss: 2.334961\n",
      "[2022-03-15 13:22:58,991 - trainer - INFO] - Train Epoch:[23/100] Step:[20/35] Total Loss: 2.478689 GL_Loss: 0.142752 CRF_Loss: 2.335938\n",
      "[2022-03-15 13:23:17,406 - trainer - INFO] - Train Epoch:[23/100] Step:[30/35] Total Loss: 0.668180 GL_Loss: 0.159879 CRF_Loss: 0.508301\n",
      "[2022-03-15 13:23:37,388 - trainer - INFO] - [Epoch Validation] Epoch:[23/100] Total Loss: 1.518294 GL_Loss: 0.001437 CRF_Loss: 1.374637 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.794118 | 0.687898 | 0.737201 | 0.687898 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 1        | 1        | 1        | 1        |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.93578  | 0.892779 | 0.913774 | 0.892779 |\n",
      "+----------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-15 13:23:56,625 - trainer - INFO] - Train Epoch:[24/100] Step:[10/35] Total Loss: 0.667398 GL_Loss: 0.156655 CRF_Loss: 0.510742\n",
      "[2022-03-15 13:24:16,000 - trainer - INFO] - Train Epoch:[24/100] Step:[20/35] Total Loss: 1.408992 GL_Loss: 0.140437 CRF_Loss: 1.268555\n",
      "[2022-03-15 13:24:35,556 - trainer - INFO] - Train Epoch:[24/100] Step:[30/35] Total Loss: 1.324528 GL_Loss: 0.124821 CRF_Loss: 1.199707\n",
      "[2022-03-15 13:24:56,041 - trainer - INFO] - [Epoch Validation] Epoch:[24/100] Total Loss: 1.369145 GL_Loss: 0.001413 CRF_Loss: 1.227811 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.742647 | 0.643312 | 0.68942  | 0.643312 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.90367  | 0.862144 | 0.882419 | 0.862144 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 13:25:16,148 - trainer - INFO] - Train Epoch:[25/100] Step:[10/35] Total Loss: 1.187202 GL_Loss: 0.112983 CRF_Loss: 1.074219\n",
      "[2022-03-15 13:25:35,437 - trainer - INFO] - Train Epoch:[25/100] Step:[20/35] Total Loss: 1.543205 GL_Loss: 0.128166 CRF_Loss: 1.415039\n",
      "[2022-03-15 13:25:54,852 - trainer - INFO] - Train Epoch:[25/100] Step:[30/35] Total Loss: 0.492296 GL_Loss: 0.102892 CRF_Loss: 0.389404\n",
      "[2022-03-15 13:26:14,915 - trainer - INFO] - [Epoch Validation] Epoch:[25/100] Total Loss: 1.235849 GL_Loss: 0.001338 CRF_Loss: 1.102051 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.742647 | 0.643312 | 0.68942  | 0.643312 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.90367  | 0.862144 | 0.882419 | 0.862144 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 13:26:34,855 - trainer - INFO] - Train Epoch:[26/100] Step:[10/35] Total Loss: 1.242700 GL_Loss: 0.125513 CRF_Loss: 1.117188\n",
      "[2022-03-15 13:26:54,742 - trainer - INFO] - Train Epoch:[26/100] Step:[20/35] Total Loss: 1.098885 GL_Loss: 0.109627 CRF_Loss: 0.989258\n",
      "[2022-03-15 13:27:14,194 - trainer - INFO] - Train Epoch:[26/100] Step:[30/35] Total Loss: 1.612276 GL_Loss: 0.118624 CRF_Loss: 1.493652\n",
      "[2022-03-15 13:27:33,916 - trainer - INFO] - [Epoch Validation] Epoch:[26/100] Total Loss: 1.177508 GL_Loss: 0.001303 CRF_Loss: 1.047168 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.795322 | 0.866242 | 0.829268 | 0.866242 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 1        | 1        | 1        | 1        |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.92569  | 0.954048 | 0.939655 | 0.954048 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 13:27:54,150 - trainer - INFO] - Train Epoch:[27/100] Step:[10/35] Total Loss: 1.109827 GL_Loss: 0.106409 CRF_Loss: 1.003418\n",
      "[2022-03-15 13:28:13,518 - trainer - INFO] - Train Epoch:[27/100] Step:[20/35] Total Loss: 0.486726 GL_Loss: 0.116609 CRF_Loss: 0.370117\n",
      "[2022-03-15 13:28:33,213 - trainer - INFO] - Train Epoch:[27/100] Step:[30/35] Total Loss: 1.150834 GL_Loss: 0.161577 CRF_Loss: 0.989258\n",
      "[2022-03-15 13:28:53,360 - trainer - INFO] - [Epoch Validation] Epoch:[27/100] Total Loss: 1.126818 GL_Loss: 0.001291 CRF_Loss: 0.997726 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.86     | 0.821656 | 0.840391 | 0.821656 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.937778 | 0.923414 | 0.93054  | 0.923414 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 13:29:14,311 - trainer - INFO] - Train Epoch:[28/100] Step:[10/35] Total Loss: 0.380717 GL_Loss: 0.103861 CRF_Loss: 0.276855\n",
      "[2022-03-15 13:29:34,238 - trainer - INFO] - Train Epoch:[28/100] Step:[20/35] Total Loss: 0.450686 GL_Loss: 0.128909 CRF_Loss: 0.321777\n",
      "[2022-03-15 13:29:55,142 - trainer - INFO] - Train Epoch:[28/100] Step:[30/35] Total Loss: 1.547118 GL_Loss: 0.153563 CRF_Loss: 1.393555\n",
      "[2022-03-15 13:30:15,517 - trainer - INFO] - [Epoch Validation] Epoch:[28/100] Total Loss: 1.024470 GL_Loss: 0.001276 CRF_Loss: 0.896875 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.804196 | 0.732484 | 0.766667 | 0.732484 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.920993 | 0.892779 | 0.906667 | 0.892779 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 13:30:35,094 - trainer - INFO] - Train Epoch:[29/100] Step:[10/35] Total Loss: 1.934573 GL_Loss: 0.169436 CRF_Loss: 1.765137\n",
      "[2022-03-15 13:30:54,100 - trainer - INFO] - Train Epoch:[29/100] Step:[20/35] Total Loss: 0.413477 GL_Loss: 0.123438 CRF_Loss: 0.290039\n",
      "[2022-03-15 13:31:14,275 - trainer - INFO] - Train Epoch:[29/100] Step:[30/35] Total Loss: 1.182273 GL_Loss: 0.103171 CRF_Loss: 1.079102\n",
      "[2022-03-15 13:31:33,967 - trainer - INFO] - [Epoch Validation] Epoch:[29/100] Total Loss: 1.031623 GL_Loss: 0.001241 CRF_Loss: 0.907533 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.86     | 0.821656 | 0.840391 | 0.821656 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.937778 | 0.923414 | 0.93054  | 0.923414 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 13:31:53,458 - trainer - INFO] - Train Epoch:[30/100] Step:[10/35] Total Loss: 0.394390 GL_Loss: 0.100933 CRF_Loss: 0.293457\n",
      "[2022-03-15 13:32:13,652 - trainer - INFO] - Train Epoch:[30/100] Step:[20/35] Total Loss: 1.604965 GL_Loss: 0.158188 CRF_Loss: 1.446777\n",
      "[2022-03-15 13:32:32,738 - trainer - INFO] - Train Epoch:[30/100] Step:[30/35] Total Loss: 1.635834 GL_Loss: 0.150483 CRF_Loss: 1.485352\n",
      "[2022-03-15 13:32:52,845 - trainer - INFO] - [Epoch Validation] Epoch:[30/100] Total Loss: 0.917726 GL_Loss: 0.001238 CRF_Loss: 0.793973 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.794118 | 0.687898 | 0.737201 | 0.687898 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 1        | 1        | 1        | 1        |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.93578  | 0.892779 | 0.913774 | 0.892779 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 13:33:12,882 - trainer - INFO] - Train Epoch:[31/100] Step:[10/35] Total Loss: 0.356112 GL_Loss: 0.085604 CRF_Loss: 0.270508\n",
      "[2022-03-15 13:33:32,261 - trainer - INFO] - Train Epoch:[31/100] Step:[20/35] Total Loss: 0.296521 GL_Loss: 0.093396 CRF_Loss: 0.203125\n",
      "[2022-03-15 13:33:50,962 - trainer - INFO] - Train Epoch:[31/100] Step:[30/35] Total Loss: 0.323256 GL_Loss: 0.093764 CRF_Loss: 0.229492\n",
      "[2022-03-15 13:34:11,275 - trainer - INFO] - [Epoch Validation] Epoch:[31/100] Total Loss: 0.883562 GL_Loss: 0.001163 CRF_Loss: 0.767229 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.86     | 0.821656 | 0.840391 | 0.821656 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.937778 | 0.923414 | 0.93054  | 0.923414 |\n",
      "+----------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-15 13:34:31,895 - trainer - INFO] - Train Epoch:[32/100] Step:[10/35] Total Loss: 0.924950 GL_Loss: 0.117333 CRF_Loss: 0.807617\n",
      "[2022-03-15 13:34:52,116 - trainer - INFO] - Train Epoch:[32/100] Step:[20/35] Total Loss: 0.955331 GL_Loss: 0.115975 CRF_Loss: 0.839355\n",
      "[2022-03-15 13:35:13,292 - trainer - INFO] - Train Epoch:[32/100] Step:[30/35] Total Loss: 0.836316 GL_Loss: 0.120984 CRF_Loss: 0.715332\n",
      "[2022-03-15 13:35:34,950 - trainer - INFO] - [Epoch Validation] Epoch:[32/100] Total Loss: 0.819521 GL_Loss: 0.001202 CRF_Loss: 0.699344 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.86     | 0.821656 | 0.840391 | 0.821656 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.937778 | 0.923414 | 0.93054  | 0.923414 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 13:35:55,090 - trainer - INFO] - Train Epoch:[33/100] Step:[10/35] Total Loss: 1.420661 GL_Loss: 0.145759 CRF_Loss: 1.274902\n",
      "[2022-03-15 13:36:14,111 - trainer - INFO] - Train Epoch:[33/100] Step:[20/35] Total Loss: 0.796986 GL_Loss: 0.124623 CRF_Loss: 0.672363\n",
      "[2022-03-15 13:36:33,353 - trainer - INFO] - Train Epoch:[33/100] Step:[30/35] Total Loss: 0.795527 GL_Loss: 0.109492 CRF_Loss: 0.686035\n",
      "[2022-03-15 13:36:53,532 - trainer - INFO] - [Epoch Validation] Epoch:[33/100] Total Loss: 0.799155 GL_Loss: 0.001183 CRF_Loss: 0.680859 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.86     | 0.821656 | 0.840391 | 0.821656 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.937778 | 0.923414 | 0.93054  | 0.923414 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 13:37:13,325 - trainer - INFO] - Train Epoch:[34/100] Step:[10/35] Total Loss: 0.840661 GL_Loss: 0.138513 CRF_Loss: 0.702148\n",
      "[2022-03-15 13:37:32,947 - trainer - INFO] - Train Epoch:[34/100] Step:[20/35] Total Loss: 0.346212 GL_Loss: 0.084982 CRF_Loss: 0.261230\n",
      "[2022-03-15 13:37:52,433 - trainer - INFO] - Train Epoch:[34/100] Step:[30/35] Total Loss: 0.774964 GL_Loss: 0.105530 CRF_Loss: 0.669434\n",
      "[2022-03-15 13:38:12,523 - trainer - INFO] - [Epoch Validation] Epoch:[34/100] Total Loss: 0.798141 GL_Loss: 0.001174 CRF_Loss: 0.680706 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.906667 | 0.866242 | 0.885993 | 0.866242 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 1        | 1        | 1        | 1        |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.968889 | 0.954048 | 0.961411 | 0.954048 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 13:38:32,545 - trainer - INFO] - Train Epoch:[35/100] Step:[10/35] Total Loss: 0.854947 GL_Loss: 0.142544 CRF_Loss: 0.712402\n",
      "[2022-03-15 13:38:52,386 - trainer - INFO] - Train Epoch:[35/100] Step:[20/35] Total Loss: 0.323225 GL_Loss: 0.112287 CRF_Loss: 0.210938\n",
      "[2022-03-15 13:39:11,753 - trainer - INFO] - Train Epoch:[35/100] Step:[30/35] Total Loss: 1.387772 GL_Loss: 0.106034 CRF_Loss: 1.281738\n",
      "[2022-03-15 13:39:31,424 - trainer - INFO] - [Epoch Validation] Epoch:[35/100] Total Loss: 0.819251 GL_Loss: 0.001182 CRF_Loss: 0.701046 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.906667 | 0.866242 | 0.885993 | 0.866242 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 1        | 1        | 1        | 1        |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.968889 | 0.954048 | 0.961411 | 0.954048 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 13:39:51,689 - trainer - INFO] - Train Epoch:[36/100] Step:[10/35] Total Loss: 1.336226 GL_Loss: 0.153121 CRF_Loss: 1.183105\n",
      "[2022-03-15 13:40:11,118 - trainer - INFO] - Train Epoch:[36/100] Step:[20/35] Total Loss: 0.322492 GL_Loss: 0.094465 CRF_Loss: 0.228027\n",
      "[2022-03-15 13:40:30,232 - trainer - INFO] - Train Epoch:[36/100] Step:[30/35] Total Loss: 0.326731 GL_Loss: 0.107981 CRF_Loss: 0.218750\n",
      "[2022-03-15 13:40:50,095 - trainer - INFO] - [Epoch Validation] Epoch:[36/100] Total Loss: 0.797203 GL_Loss: 0.001200 CRF_Loss: 0.677176 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.906667 | 0.866242 | 0.885993 | 0.866242 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.953333 | 0.938731 | 0.945976 | 0.938731 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 13:41:10,007 - trainer - INFO] - Train Epoch:[37/100] Step:[10/35] Total Loss: 0.320497 GL_Loss: 0.091982 CRF_Loss: 0.228516\n",
      "[2022-03-15 13:41:29,279 - trainer - INFO] - Train Epoch:[37/100] Step:[20/35] Total Loss: 0.323966 GL_Loss: 0.111564 CRF_Loss: 0.212402\n",
      "[2022-03-15 13:41:48,842 - trainer - INFO] - Train Epoch:[37/100] Step:[30/35] Total Loss: 0.860085 GL_Loss: 0.140847 CRF_Loss: 0.719238\n",
      "[2022-03-15 13:42:08,817 - trainer - INFO] - [Epoch Validation] Epoch:[37/100] Total Loss: 0.794503 GL_Loss: 0.001185 CRF_Loss: 0.676032 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.845588 | 0.732484 | 0.784983 | 0.732484 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976109 | 0.953333 | 0.964587 | 0.953333 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.934732 | 0.877462 | 0.905192 | 0.877462 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 13:42:28,887 - trainer - INFO] - Train Epoch:[38/100] Step:[10/35] Total Loss: 0.817889 GL_Loss: 0.143572 CRF_Loss: 0.674316\n",
      "[2022-03-15 13:42:48,149 - trainer - INFO] - Train Epoch:[38/100] Step:[20/35] Total Loss: 1.280752 GL_Loss: 0.135733 CRF_Loss: 1.145020\n",
      "[2022-03-15 13:43:07,393 - trainer - INFO] - Train Epoch:[38/100] Step:[30/35] Total Loss: 0.833273 GL_Loss: 0.114523 CRF_Loss: 0.718750\n",
      "[2022-03-15 13:43:26,985 - trainer - INFO] - [Epoch Validation] Epoch:[38/100] Total Loss: 0.797253 GL_Loss: 0.001182 CRF_Loss: 0.679088 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.86     | 0.821656 | 0.840391 | 0.821656 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.937778 | 0.923414 | 0.93054  | 0.923414 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 13:43:46,055 - trainer - INFO] - Train Epoch:[39/100] Step:[10/35] Total Loss: 0.305230 GL_Loss: 0.093804 CRF_Loss: 0.211426\n",
      "[2022-03-15 13:44:05,602 - trainer - INFO] - Train Epoch:[39/100] Step:[20/35] Total Loss: 0.326107 GL_Loss: 0.083919 CRF_Loss: 0.242188\n",
      "[2022-03-15 13:44:25,308 - trainer - INFO] - Train Epoch:[39/100] Step:[30/35] Total Loss: 0.292282 GL_Loss: 0.096970 CRF_Loss: 0.195312\n",
      "[2022-03-15 13:44:45,426 - trainer - INFO] - [Epoch Validation] Epoch:[39/100] Total Loss: 0.775383 GL_Loss: 0.001166 CRF_Loss: 0.658775 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.86     | 0.821656 | 0.840391 | 0.821656 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.937778 | 0.923414 | 0.93054  | 0.923414 |\n",
      "+----------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-15 13:45:05,452 - trainer - INFO] - Train Epoch:[40/100] Step:[10/35] Total Loss: 0.847293 GL_Loss: 0.105593 CRF_Loss: 0.741699\n",
      "[2022-03-15 13:45:25,556 - trainer - INFO] - Train Epoch:[40/100] Step:[20/35] Total Loss: 0.914485 GL_Loss: 0.107845 CRF_Loss: 0.806641\n",
      "[2022-03-15 13:45:44,918 - trainer - INFO] - Train Epoch:[40/100] Step:[30/35] Total Loss: 0.946743 GL_Loss: 0.105923 CRF_Loss: 0.840820\n",
      "[2022-03-15 13:46:04,451 - trainer - INFO] - [Epoch Validation] Epoch:[40/100] Total Loss: 0.766148 GL_Loss: 0.001182 CRF_Loss: 0.647977 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.86     | 0.821656 | 0.840391 | 0.821656 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.937778 | 0.923414 | 0.93054  | 0.923414 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 13:46:06,284 - trainer - INFO] - Saving checkpoint: saved/models/PICK_Default/test_0315_125246/checkpoint-epoch40.pth ...\n",
      "[2022-03-15 13:46:27,059 - trainer - INFO] - Train Epoch:[41/100] Step:[10/35] Total Loss: 0.836620 GL_Loss: 0.146678 CRF_Loss: 0.689941\n",
      "[2022-03-15 13:46:47,050 - trainer - INFO] - Train Epoch:[41/100] Step:[20/35] Total Loss: 0.292937 GL_Loss: 0.098113 CRF_Loss: 0.194824\n",
      "[2022-03-15 13:47:06,412 - trainer - INFO] - Train Epoch:[41/100] Step:[30/35] Total Loss: 0.880360 GL_Loss: 0.155263 CRF_Loss: 0.725098\n",
      "[2022-03-15 13:47:26,370 - trainer - INFO] - [Epoch Validation] Epoch:[41/100] Total Loss: 0.779650 GL_Loss: 0.001214 CRF_Loss: 0.658231 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.86     | 0.821656 | 0.840391 | 0.821656 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.937778 | 0.923414 | 0.93054  | 0.923414 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 13:47:46,888 - trainer - INFO] - Train Epoch:[42/100] Step:[10/35] Total Loss: 0.324274 GL_Loss: 0.101617 CRF_Loss: 0.222656\n",
      "[2022-03-15 13:48:06,391 - trainer - INFO] - Train Epoch:[42/100] Step:[20/35] Total Loss: 1.578572 GL_Loss: 0.111775 CRF_Loss: 1.466797\n",
      "[2022-03-15 13:48:26,152 - trainer - INFO] - Train Epoch:[42/100] Step:[30/35] Total Loss: 0.800238 GL_Loss: 0.115667 CRF_Loss: 0.684570\n",
      "[2022-03-15 13:48:46,684 - trainer - INFO] - [Epoch Validation] Epoch:[42/100] Total Loss: 0.761948 GL_Loss: 0.001185 CRF_Loss: 0.643415 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.804196 | 0.732484 | 0.766667 | 0.732484 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.920993 | 0.892779 | 0.906667 | 0.892779 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 13:49:07,188 - trainer - INFO] - Train Epoch:[43/100] Step:[10/35] Total Loss: 0.750353 GL_Loss: 0.105822 CRF_Loss: 0.644531\n",
      "[2022-03-15 13:49:27,701 - trainer - INFO] - Train Epoch:[43/100] Step:[20/35] Total Loss: 0.784856 GL_Loss: 0.101263 CRF_Loss: 0.683594\n",
      "[2022-03-15 13:49:48,004 - trainer - INFO] - Train Epoch:[43/100] Step:[30/35] Total Loss: 0.311344 GL_Loss: 0.093570 CRF_Loss: 0.217773\n",
      "[2022-03-15 13:50:08,320 - trainer - INFO] - [Epoch Validation] Epoch:[43/100] Total Loss: 0.770813 GL_Loss: 0.001193 CRF_Loss: 0.651479 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.794118 | 0.687898 | 0.737201 | 0.687898 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 1        | 1        | 1        | 1        |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.93578  | 0.892779 | 0.913774 | 0.892779 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 13:50:28,921 - trainer - INFO] - Train Epoch:[44/100] Step:[10/35] Total Loss: 0.326144 GL_Loss: 0.085422 CRF_Loss: 0.240723\n",
      "[2022-03-15 13:50:49,132 - trainer - INFO] - Train Epoch:[44/100] Step:[20/35] Total Loss: 0.961068 GL_Loss: 0.110971 CRF_Loss: 0.850098\n",
      "[2022-03-15 13:51:08,725 - trainer - INFO] - Train Epoch:[44/100] Step:[30/35] Total Loss: 0.761290 GL_Loss: 0.102599 CRF_Loss: 0.658691\n",
      "[2022-03-15 13:51:28,855 - trainer - INFO] - [Epoch Validation] Epoch:[44/100] Total Loss: 0.751192 GL_Loss: 0.001185 CRF_Loss: 0.632701 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.853147 | 0.77707  | 0.813333 | 0.77707  |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 1        | 1        | 1        | 1        |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.952596 | 0.923414 | 0.937778 | 0.923414 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 13:51:48,678 - trainer - INFO] - Train Epoch:[45/100] Step:[10/35] Total Loss: 0.290052 GL_Loss: 0.093274 CRF_Loss: 0.196777\n",
      "[2022-03-15 13:52:08,745 - trainer - INFO] - Train Epoch:[45/100] Step:[20/35] Total Loss: 0.310990 GL_Loss: 0.097611 CRF_Loss: 0.213379\n",
      "[2022-03-15 13:52:28,804 - trainer - INFO] - Train Epoch:[45/100] Step:[30/35] Total Loss: 0.280715 GL_Loss: 0.094191 CRF_Loss: 0.186523\n",
      "[2022-03-15 13:52:49,715 - trainer - INFO] - [Epoch Validation] Epoch:[45/100] Total Loss: 0.748159 GL_Loss: 0.001198 CRF_Loss: 0.628376 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.86     | 0.821656 | 0.840391 | 0.821656 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.937778 | 0.923414 | 0.93054  | 0.923414 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 13:53:10,046 - trainer - INFO] - Train Epoch:[46/100] Step:[10/35] Total Loss: 0.789491 GL_Loss: 0.131776 CRF_Loss: 0.657715\n",
      "[2022-03-15 13:53:30,432 - trainer - INFO] - Train Epoch:[46/100] Step:[20/35] Total Loss: 0.312849 GL_Loss: 0.120467 CRF_Loss: 0.192383\n",
      "[2022-03-15 13:53:50,513 - trainer - INFO] - Train Epoch:[46/100] Step:[30/35] Total Loss: 0.888715 GL_Loss: 0.119672 CRF_Loss: 0.769043\n",
      "[2022-03-15 13:54:10,657 - trainer - INFO] - [Epoch Validation] Epoch:[46/100] Total Loss: 0.752808 GL_Loss: 0.001218 CRF_Loss: 0.631013 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.906667 | 0.866242 | 0.885993 | 0.866242 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 1        | 1        | 1        | 1        |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.968889 | 0.954048 | 0.961411 | 0.954048 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 13:54:31,164 - trainer - INFO] - Train Epoch:[47/100] Step:[10/35] Total Loss: 0.910347 GL_Loss: 0.118355 CRF_Loss: 0.791992\n",
      "[2022-03-15 13:54:50,961 - trainer - INFO] - Train Epoch:[47/100] Step:[20/35] Total Loss: 0.879278 GL_Loss: 0.116094 CRF_Loss: 0.763184\n",
      "[2022-03-15 13:55:11,280 - trainer - INFO] - Train Epoch:[47/100] Step:[30/35] Total Loss: 0.779702 GL_Loss: 0.140542 CRF_Loss: 0.639160\n",
      "[2022-03-15 13:55:31,217 - trainer - INFO] - [Epoch Validation] Epoch:[47/100] Total Loss: 0.747040 GL_Loss: 0.001198 CRF_Loss: 0.627232 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.906667 | 0.866242 | 0.885993 | 0.866242 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 1        | 1        | 1        | 1        |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.968889 | 0.954048 | 0.961411 | 0.954048 |\n",
      "+----------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-15 13:55:51,406 - trainer - INFO] - Train Epoch:[48/100] Step:[10/35] Total Loss: 1.201136 GL_Loss: 0.145471 CRF_Loss: 1.055664\n",
      "[2022-03-15 13:56:11,518 - trainer - INFO] - Train Epoch:[48/100] Step:[20/35] Total Loss: 0.275533 GL_Loss: 0.093404 CRF_Loss: 0.182129\n",
      "[2022-03-15 13:56:31,227 - trainer - INFO] - Train Epoch:[48/100] Step:[30/35] Total Loss: 0.301989 GL_Loss: 0.116931 CRF_Loss: 0.185059\n",
      "[2022-03-15 13:56:51,245 - trainer - INFO] - [Epoch Validation] Epoch:[48/100] Total Loss: 0.729643 GL_Loss: 0.001190 CRF_Loss: 0.610686 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.902098 | 0.821656 | 0.86     | 0.821656 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 1        | 1        | 1        | 1        |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.968397 | 0.938731 | 0.953333 | 0.938731 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 13:57:11,463 - trainer - INFO] - Train Epoch:[49/100] Step:[10/35] Total Loss: 0.306317 GL_Loss: 0.106122 CRF_Loss: 0.200195\n",
      "[2022-03-15 13:57:31,309 - trainer - INFO] - Train Epoch:[49/100] Step:[20/35] Total Loss: 0.854681 GL_Loss: 0.128607 CRF_Loss: 0.726074\n",
      "[2022-03-15 13:57:51,063 - trainer - INFO] - Train Epoch:[49/100] Step:[30/35] Total Loss: 0.900649 GL_Loss: 0.123793 CRF_Loss: 0.776855\n",
      "[2022-03-15 13:58:11,719 - trainer - INFO] - [Epoch Validation] Epoch:[49/100] Total Loss: 0.728950 GL_Loss: 0.001189 CRF_Loss: 0.610073 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.86     | 0.821656 | 0.840391 | 0.821656 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.937778 | 0.923414 | 0.93054  | 0.923414 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 13:58:31,727 - trainer - INFO] - Train Epoch:[50/100] Step:[10/35] Total Loss: 0.891857 GL_Loss: 0.128673 CRF_Loss: 0.763184\n",
      "[2022-03-15 13:58:51,653 - trainer - INFO] - Train Epoch:[50/100] Step:[20/35] Total Loss: 0.739230 GL_Loss: 0.113254 CRF_Loss: 0.625977\n",
      "[2022-03-15 13:59:11,508 - trainer - INFO] - Train Epoch:[50/100] Step:[30/35] Total Loss: 1.344834 GL_Loss: 0.144639 CRF_Loss: 1.200195\n",
      "[2022-03-15 13:59:32,003 - trainer - INFO] - [Epoch Validation] Epoch:[50/100] Total Loss: 0.713197 GL_Loss: 0.001190 CRF_Loss: 0.594224 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.853147 | 0.77707  | 0.813333 | 0.77707  |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.936795 | 0.908096 | 0.922222 | 0.908096 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 13:59:52,723 - trainer - INFO] - Train Epoch:[51/100] Step:[10/35] Total Loss: 0.781678 GL_Loss: 0.144960 CRF_Loss: 0.636719\n",
      "[2022-03-15 14:00:12,912 - trainer - INFO] - Train Epoch:[51/100] Step:[20/35] Total Loss: 0.739051 GL_Loss: 0.106239 CRF_Loss: 0.632812\n",
      "[2022-03-15 14:00:32,463 - trainer - INFO] - Train Epoch:[51/100] Step:[30/35] Total Loss: 0.306194 GL_Loss: 0.102093 CRF_Loss: 0.204102\n",
      "[2022-03-15 14:00:52,302 - trainer - INFO] - [Epoch Validation] Epoch:[51/100] Total Loss: 0.713402 GL_Loss: 0.001175 CRF_Loss: 0.595884 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.906667 | 0.866242 | 0.885993 | 0.866242 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 1        | 1        | 1        | 1        |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.968889 | 0.954048 | 0.961411 | 0.954048 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 14:01:12,082 - trainer - INFO] - Train Epoch:[52/100] Step:[10/35] Total Loss: 0.696460 GL_Loss: 0.136890 CRF_Loss: 0.559570\n",
      "[2022-03-15 14:01:32,388 - trainer - INFO] - Train Epoch:[52/100] Step:[20/35] Total Loss: 1.152654 GL_Loss: 0.150701 CRF_Loss: 1.001953\n",
      "[2022-03-15 14:01:52,434 - trainer - INFO] - Train Epoch:[52/100] Step:[30/35] Total Loss: 0.275368 GL_Loss: 0.096169 CRF_Loss: 0.179199\n",
      "[2022-03-15 14:02:12,744 - trainer - INFO] - [Epoch Validation] Epoch:[52/100] Total Loss: 0.720165 GL_Loss: 0.001175 CRF_Loss: 0.602679 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.902098 | 0.821656 | 0.86     | 0.821656 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 1        | 1        | 1        | 1        |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.968397 | 0.938731 | 0.953333 | 0.938731 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 14:02:32,850 - trainer - INFO] - Train Epoch:[53/100] Step:[10/35] Total Loss: 0.832772 GL_Loss: 0.146248 CRF_Loss: 0.686523\n",
      "[2022-03-15 14:02:53,055 - trainer - INFO] - Train Epoch:[53/100] Step:[20/35] Total Loss: 0.720315 GL_Loss: 0.150003 CRF_Loss: 0.570312\n",
      "[2022-03-15 14:03:12,973 - trainer - INFO] - Train Epoch:[53/100] Step:[30/35] Total Loss: 0.705135 GL_Loss: 0.105525 CRF_Loss: 0.599609\n",
      "[2022-03-15 14:03:33,599 - trainer - INFO] - [Epoch Validation] Epoch:[53/100] Total Loss: 0.725677 GL_Loss: 0.001164 CRF_Loss: 0.609277 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.853147 | 0.77707  | 0.813333 | 0.77707  |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.936795 | 0.908096 | 0.922222 | 0.908096 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 14:03:54,360 - trainer - INFO] - Train Epoch:[54/100] Step:[10/35] Total Loss: 0.719519 GL_Loss: 0.113562 CRF_Loss: 0.605957\n",
      "[2022-03-15 14:04:14,103 - trainer - INFO] - Train Epoch:[54/100] Step:[20/35] Total Loss: 1.261258 GL_Loss: 0.114285 CRF_Loss: 1.146973\n",
      "[2022-03-15 14:04:34,341 - trainer - INFO] - Train Epoch:[54/100] Step:[30/35] Total Loss: 0.304549 GL_Loss: 0.114607 CRF_Loss: 0.189941\n",
      "[2022-03-15 14:04:54,483 - trainer - INFO] - [Epoch Validation] Epoch:[54/100] Total Loss: 0.703906 GL_Loss: 0.001170 CRF_Loss: 0.586886 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.804196 | 0.732484 | 0.766667 | 0.732484 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.920993 | 0.892779 | 0.906667 | 0.892779 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 14:05:14,972 - trainer - INFO] - Train Epoch:[55/100] Step:[10/35] Total Loss: 0.692128 GL_Loss: 0.100331 CRF_Loss: 0.591797\n",
      "[2022-03-15 14:05:35,100 - trainer - INFO] - Train Epoch:[55/100] Step:[20/35] Total Loss: 0.706444 GL_Loss: 0.134179 CRF_Loss: 0.572266\n",
      "[2022-03-15 14:05:55,485 - trainer - INFO] - Train Epoch:[55/100] Step:[30/35] Total Loss: 0.680976 GL_Loss: 0.105781 CRF_Loss: 0.575195\n",
      "[2022-03-15 14:06:15,647 - trainer - INFO] - [Epoch Validation] Epoch:[55/100] Total Loss: 0.690016 GL_Loss: 0.001147 CRF_Loss: 0.575335 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.86     | 0.821656 | 0.840391 | 0.821656 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.937778 | 0.923414 | 0.93054  | 0.923414 |\n",
      "+----------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-15 14:06:36,456 - trainer - INFO] - Train Epoch:[56/100] Step:[10/35] Total Loss: 0.282081 GL_Loss: 0.106788 CRF_Loss: 0.175293\n",
      "[2022-03-15 14:06:56,235 - trainer - INFO] - Train Epoch:[56/100] Step:[20/35] Total Loss: 0.847028 GL_Loss: 0.108259 CRF_Loss: 0.738770\n",
      "[2022-03-15 14:07:15,988 - trainer - INFO] - Train Epoch:[56/100] Step:[30/35] Total Loss: 0.267536 GL_Loss: 0.094685 CRF_Loss: 0.172852\n",
      "[2022-03-15 14:07:36,349 - trainer - INFO] - [Epoch Validation] Epoch:[56/100] Total Loss: 0.686079 GL_Loss: 0.001154 CRF_Loss: 0.570661 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.804196 | 0.732484 | 0.766667 | 0.732484 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.920993 | 0.892779 | 0.906667 | 0.892779 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 14:07:57,507 - trainer - INFO] - Train Epoch:[57/100] Step:[10/35] Total Loss: 0.681217 GL_Loss: 0.099674 CRF_Loss: 0.581543\n",
      "[2022-03-15 14:08:17,490 - trainer - INFO] - Train Epoch:[57/100] Step:[20/35] Total Loss: 1.098391 GL_Loss: 0.144290 CRF_Loss: 0.954102\n",
      "[2022-03-15 14:08:37,689 - trainer - INFO] - Train Epoch:[57/100] Step:[30/35] Total Loss: 0.276585 GL_Loss: 0.104222 CRF_Loss: 0.172363\n",
      "[2022-03-15 14:08:57,547 - trainer - INFO] - [Epoch Validation] Epoch:[57/100] Total Loss: 0.691070 GL_Loss: 0.001148 CRF_Loss: 0.576228 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.902098 | 0.821656 | 0.86     | 0.821656 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 1        | 1        | 1        | 1        |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.968397 | 0.938731 | 0.953333 | 0.938731 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 14:09:18,221 - trainer - INFO] - Train Epoch:[58/100] Step:[10/35] Total Loss: 0.266937 GL_Loss: 0.094574 CRF_Loss: 0.172363\n",
      "[2022-03-15 14:09:38,223 - trainer - INFO] - Train Epoch:[58/100] Step:[20/35] Total Loss: 0.724697 GL_Loss: 0.107021 CRF_Loss: 0.617676\n",
      "[2022-03-15 14:09:58,317 - trainer - INFO] - Train Epoch:[58/100] Step:[30/35] Total Loss: 0.714250 GL_Loss: 0.099504 CRF_Loss: 0.614746\n",
      "[2022-03-15 14:10:18,552 - trainer - INFO] - [Epoch Validation] Epoch:[58/100] Total Loss: 0.683622 GL_Loss: 0.001165 CRF_Loss: 0.567132 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.853147 | 0.77707  | 0.813333 | 0.77707  |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.936795 | 0.908096 | 0.922222 | 0.908096 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 14:10:38,829 - trainer - INFO] - Train Epoch:[59/100] Step:[10/35] Total Loss: 0.280944 GL_Loss: 0.110534 CRF_Loss: 0.170410\n",
      "[2022-03-15 14:10:59,160 - trainer - INFO] - Train Epoch:[59/100] Step:[20/35] Total Loss: 0.955197 GL_Loss: 0.126095 CRF_Loss: 0.829102\n",
      "[2022-03-15 14:11:19,285 - trainer - INFO] - Train Epoch:[59/100] Step:[30/35] Total Loss: 0.604936 GL_Loss: 0.090775 CRF_Loss: 0.514160\n",
      "[2022-03-15 14:11:39,767 - trainer - INFO] - [Epoch Validation] Epoch:[59/100] Total Loss: 0.672833 GL_Loss: 0.001150 CRF_Loss: 0.557785 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.853147 | 0.77707  | 0.813333 | 0.77707  |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.936795 | 0.908096 | 0.922222 | 0.908096 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 14:12:00,208 - trainer - INFO] - Train Epoch:[60/100] Step:[10/35] Total Loss: 0.713214 GL_Loss: 0.107257 CRF_Loss: 0.605957\n",
      "[2022-03-15 14:12:20,223 - trainer - INFO] - Train Epoch:[60/100] Step:[20/35] Total Loss: 1.166101 GL_Loss: 0.139245 CRF_Loss: 1.026855\n",
      "[2022-03-15 14:12:39,876 - trainer - INFO] - Train Epoch:[60/100] Step:[30/35] Total Loss: 0.701405 GL_Loss: 0.105701 CRF_Loss: 0.595703\n",
      "[2022-03-15 14:13:00,752 - trainer - INFO] - [Epoch Validation] Epoch:[60/100] Total Loss: 0.673555 GL_Loss: 0.001137 CRF_Loss: 0.559891 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.902098 | 0.821656 | 0.86     | 0.821656 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 1        | 0.976667 | 0.988196 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.96789  | 0.923414 | 0.945129 | 0.923414 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 14:13:02,720 - trainer - INFO] - Saving checkpoint: saved/models/PICK_Default/test_0315_125246/checkpoint-epoch60.pth ...\n",
      "[2022-03-15 14:13:22,562 - trainer - INFO] - Train Epoch:[61/100] Step:[10/35] Total Loss: 0.258935 GL_Loss: 0.088525 CRF_Loss: 0.170410\n",
      "[2022-03-15 14:13:42,797 - trainer - INFO] - Train Epoch:[61/100] Step:[20/35] Total Loss: 1.237201 GL_Loss: 0.143451 CRF_Loss: 1.093750\n",
      "[2022-03-15 14:14:03,045 - trainer - INFO] - Train Epoch:[61/100] Step:[30/35] Total Loss: 0.705196 GL_Loss: 0.136349 CRF_Loss: 0.568848\n",
      "[2022-03-15 14:14:23,376 - trainer - INFO] - [Epoch Validation] Epoch:[61/100] Total Loss: 0.668674 GL_Loss: 0.001152 CRF_Loss: 0.553446 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.86     | 0.821656 | 0.840391 | 0.821656 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.937778 | 0.923414 | 0.93054  | 0.923414 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 14:14:43,876 - trainer - INFO] - Train Epoch:[62/100] Step:[10/35] Total Loss: 0.655414 GL_Loss: 0.124652 CRF_Loss: 0.530762\n",
      "[2022-03-15 14:15:03,765 - trainer - INFO] - Train Epoch:[62/100] Step:[20/35] Total Loss: 0.274653 GL_Loss: 0.105219 CRF_Loss: 0.169434\n",
      "[2022-03-15 14:15:24,427 - trainer - INFO] - Train Epoch:[62/100] Step:[30/35] Total Loss: 0.277231 GL_Loss: 0.111216 CRF_Loss: 0.166016\n",
      "[2022-03-15 14:15:44,279 - trainer - INFO] - [Epoch Validation] Epoch:[62/100] Total Loss: 0.661639 GL_Loss: 0.001152 CRF_Loss: 0.546443 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.906667 | 0.866242 | 0.885993 | 0.866242 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 1        | 1        | 1        | 1        |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.968889 | 0.954048 | 0.961411 | 0.954048 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 14:16:04,481 - trainer - INFO] - Train Epoch:[63/100] Step:[10/35] Total Loss: 0.811836 GL_Loss: 0.111152 CRF_Loss: 0.700684\n",
      "[2022-03-15 14:16:24,505 - trainer - INFO] - Train Epoch:[63/100] Step:[20/35] Total Loss: 1.251074 GL_Loss: 0.154883 CRF_Loss: 1.096191\n",
      "[2022-03-15 14:16:44,706 - trainer - INFO] - Train Epoch:[63/100] Step:[30/35] Total Loss: 0.677088 GL_Loss: 0.115077 CRF_Loss: 0.562012\n",
      "[2022-03-15 14:17:05,084 - trainer - INFO] - [Epoch Validation] Epoch:[63/100] Total Loss: 0.670611 GL_Loss: 0.001165 CRF_Loss: 0.554129 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.953333 | 0.910828 | 0.931596 | 0.910828 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 1        | 1        | 1        | 1        |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.984444 | 0.969365 | 0.976847 | 0.969365 |\n",
      "+----------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-15 14:17:25,326 - trainer - INFO] - Train Epoch:[64/100] Step:[10/35] Total Loss: 0.284362 GL_Loss: 0.112975 CRF_Loss: 0.171387\n",
      "[2022-03-15 14:17:45,128 - trainer - INFO] - Train Epoch:[64/100] Step:[20/35] Total Loss: 1.160522 GL_Loss: 0.120483 CRF_Loss: 1.040039\n",
      "[2022-03-15 14:18:05,000 - trainer - INFO] - Train Epoch:[64/100] Step:[30/35] Total Loss: 0.679856 GL_Loss: 0.113450 CRF_Loss: 0.566406\n",
      "[2022-03-15 14:18:25,050 - trainer - INFO] - [Epoch Validation] Epoch:[64/100] Total Loss: 0.667348 GL_Loss: 0.001156 CRF_Loss: 0.551772 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.86     | 0.821656 | 0.840391 | 0.821656 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.937778 | 0.923414 | 0.93054  | 0.923414 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 14:18:44,726 - trainer - INFO] - Train Epoch:[65/100] Step:[10/35] Total Loss: 0.734908 GL_Loss: 0.133834 CRF_Loss: 0.601074\n",
      "[2022-03-15 14:19:04,408 - trainer - INFO] - Train Epoch:[65/100] Step:[20/35] Total Loss: 0.691183 GL_Loss: 0.136496 CRF_Loss: 0.554688\n",
      "[2022-03-15 14:19:24,750 - trainer - INFO] - Train Epoch:[65/100] Step:[30/35] Total Loss: 1.038355 GL_Loss: 0.112574 CRF_Loss: 0.925781\n",
      "[2022-03-15 14:19:45,454 - trainer - INFO] - [Epoch Validation] Epoch:[65/100] Total Loss: 0.659332 GL_Loss: 0.001141 CRF_Loss: 0.545257 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.853147 | 0.77707  | 0.813333 | 0.77707  |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.952218 | 0.93     | 0.940978 | 0.93     |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.919725 | 0.877462 | 0.898096 | 0.877462 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 14:20:05,691 - trainer - INFO] - Train Epoch:[66/100] Step:[10/35] Total Loss: 0.833690 GL_Loss: 0.118358 CRF_Loss: 0.715332\n",
      "[2022-03-15 14:20:25,504 - trainer - INFO] - Train Epoch:[66/100] Step:[20/35] Total Loss: 0.794765 GL_Loss: 0.111659 CRF_Loss: 0.683105\n",
      "[2022-03-15 14:20:45,795 - trainer - INFO] - Train Epoch:[66/100] Step:[30/35] Total Loss: 0.643745 GL_Loss: 0.110542 CRF_Loss: 0.533203\n",
      "[2022-03-15 14:21:06,227 - trainer - INFO] - [Epoch Validation] Epoch:[66/100] Total Loss: 0.662219 GL_Loss: 0.001148 CRF_Loss: 0.547447 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.906667 | 0.866242 | 0.885993 | 0.866242 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 1        | 1        | 1        | 1        |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.968889 | 0.954048 | 0.961411 | 0.954048 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 14:21:26,142 - trainer - INFO] - Train Epoch:[67/100] Step:[10/35] Total Loss: 0.269788 GL_Loss: 0.090100 CRF_Loss: 0.179688\n",
      "[2022-03-15 14:21:45,989 - trainer - INFO] - Train Epoch:[67/100] Step:[20/35] Total Loss: 0.260536 GL_Loss: 0.091590 CRF_Loss: 0.168945\n",
      "[2022-03-15 14:22:06,470 - trainer - INFO] - Train Epoch:[67/100] Step:[30/35] Total Loss: 0.767248 GL_Loss: 0.152014 CRF_Loss: 0.615234\n",
      "[2022-03-15 14:22:26,558 - trainer - INFO] - [Epoch Validation] Epoch:[67/100] Total Loss: 0.660625 GL_Loss: 0.001148 CRF_Loss: 0.545857 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.804196 | 0.732484 | 0.766667 | 0.732484 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.920993 | 0.892779 | 0.906667 | 0.892779 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 14:22:46,346 - trainer - INFO] - Train Epoch:[68/100] Step:[10/35] Total Loss: 0.296980 GL_Loss: 0.105573 CRF_Loss: 0.191406\n",
      "[2022-03-15 14:23:06,394 - trainer - INFO] - Train Epoch:[68/100] Step:[20/35] Total Loss: 0.286176 GL_Loss: 0.109906 CRF_Loss: 0.176270\n",
      "[2022-03-15 14:23:26,804 - trainer - INFO] - Train Epoch:[68/100] Step:[30/35] Total Loss: 0.275347 GL_Loss: 0.102495 CRF_Loss: 0.172852\n",
      "[2022-03-15 14:23:47,277 - trainer - INFO] - [Epoch Validation] Epoch:[68/100] Total Loss: 0.659144 GL_Loss: 0.001162 CRF_Loss: 0.542941 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.804196 | 0.732484 | 0.766667 | 0.732484 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.920993 | 0.892779 | 0.906667 | 0.892779 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 14:24:07,328 - trainer - INFO] - Train Epoch:[69/100] Step:[10/35] Total Loss: 0.681054 GL_Loss: 0.143944 CRF_Loss: 0.537109\n",
      "[2022-03-15 14:24:28,005 - trainer - INFO] - Train Epoch:[69/100] Step:[20/35] Total Loss: 0.253902 GL_Loss: 0.090816 CRF_Loss: 0.163086\n",
      "[2022-03-15 14:24:47,770 - trainer - INFO] - Train Epoch:[69/100] Step:[30/35] Total Loss: 0.281810 GL_Loss: 0.095287 CRF_Loss: 0.186523\n",
      "[2022-03-15 14:25:07,868 - trainer - INFO] - [Epoch Validation] Epoch:[69/100] Total Loss: 0.661241 GL_Loss: 0.001147 CRF_Loss: 0.546554 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.86     | 0.821656 | 0.840391 | 0.821656 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.937778 | 0.923414 | 0.93054  | 0.923414 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 14:25:28,071 - trainer - INFO] - Train Epoch:[70/100] Step:[10/35] Total Loss: 1.230371 GL_Loss: 0.149316 CRF_Loss: 1.081055\n",
      "[2022-03-15 14:25:48,474 - trainer - INFO] - Train Epoch:[70/100] Step:[20/35] Total Loss: 0.270179 GL_Loss: 0.103187 CRF_Loss: 0.166992\n",
      "[2022-03-15 14:26:08,761 - trainer - INFO] - Train Epoch:[70/100] Step:[30/35] Total Loss: 0.671155 GL_Loss: 0.108655 CRF_Loss: 0.562500\n",
      "[2022-03-15 14:26:28,879 - trainer - INFO] - [Epoch Validation] Epoch:[70/100] Total Loss: 0.661157 GL_Loss: 0.001145 CRF_Loss: 0.546624 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.906667 | 0.866242 | 0.885993 | 0.866242 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.953333 | 0.938731 | 0.945976 | 0.938731 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 14:26:49,313 - trainer - INFO] - Train Epoch:[71/100] Step:[10/35] Total Loss: 0.286552 GL_Loss: 0.089774 CRF_Loss: 0.196777\n",
      "[2022-03-15 14:27:09,018 - trainer - INFO] - Train Epoch:[71/100] Step:[20/35] Total Loss: 0.299489 GL_Loss: 0.112478 CRF_Loss: 0.187012\n",
      "[2022-03-15 14:27:29,589 - trainer - INFO] - Train Epoch:[71/100] Step:[30/35] Total Loss: 0.679389 GL_Loss: 0.104682 CRF_Loss: 0.574707\n",
      "[2022-03-15 14:27:49,500 - trainer - INFO] - [Epoch Validation] Epoch:[71/100] Total Loss: 0.659325 GL_Loss: 0.001155 CRF_Loss: 0.543792 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.742647 | 0.643312 | 0.68942  | 0.643312 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.90367  | 0.862144 | 0.882419 | 0.862144 |\n",
      "+----------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-15 14:28:09,869 - trainer - INFO] - Train Epoch:[72/100] Step:[10/35] Total Loss: 0.696725 GL_Loss: 0.135690 CRF_Loss: 0.561035\n",
      "[2022-03-15 14:28:29,855 - trainer - INFO] - Train Epoch:[72/100] Step:[20/35] Total Loss: 0.767678 GL_Loss: 0.108010 CRF_Loss: 0.659668\n",
      "[2022-03-15 14:28:49,949 - trainer - INFO] - Train Epoch:[72/100] Step:[30/35] Total Loss: 0.694541 GL_Loss: 0.148154 CRF_Loss: 0.546387\n",
      "[2022-03-15 14:29:10,339 - trainer - INFO] - [Epoch Validation] Epoch:[72/100] Total Loss: 0.656295 GL_Loss: 0.001154 CRF_Loss: 0.540904 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.804196 | 0.732484 | 0.766667 | 0.732484 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.920993 | 0.892779 | 0.906667 | 0.892779 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 14:29:31,048 - trainer - INFO] - Train Epoch:[73/100] Step:[10/35] Total Loss: 0.641888 GL_Loss: 0.112591 CRF_Loss: 0.529297\n",
      "[2022-03-15 14:29:51,083 - trainer - INFO] - Train Epoch:[73/100] Step:[20/35] Total Loss: 0.657097 GL_Loss: 0.102410 CRF_Loss: 0.554688\n",
      "[2022-03-15 14:30:10,720 - trainer - INFO] - Train Epoch:[73/100] Step:[30/35] Total Loss: 0.276668 GL_Loss: 0.087215 CRF_Loss: 0.189453\n",
      "[2022-03-15 14:30:31,398 - trainer - INFO] - [Epoch Validation] Epoch:[73/100] Total Loss: 0.659206 GL_Loss: 0.001138 CRF_Loss: 0.545368 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.86     | 0.821656 | 0.840391 | 0.821656 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.937778 | 0.923414 | 0.93054  | 0.923414 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 14:30:51,633 - trainer - INFO] - Train Epoch:[74/100] Step:[10/35] Total Loss: 0.265319 GL_Loss: 0.093444 CRF_Loss: 0.171875\n",
      "[2022-03-15 14:31:11,921 - trainer - INFO] - Train Epoch:[74/100] Step:[20/35] Total Loss: 1.078188 GL_Loss: 0.143129 CRF_Loss: 0.935059\n",
      "[2022-03-15 14:31:31,500 - trainer - INFO] - Train Epoch:[74/100] Step:[30/35] Total Loss: 0.630293 GL_Loss: 0.095137 CRF_Loss: 0.535156\n",
      "[2022-03-15 14:31:51,583 - trainer - INFO] - [Epoch Validation] Epoch:[74/100] Total Loss: 0.649560 GL_Loss: 0.001146 CRF_Loss: 0.534933 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.86     | 0.821656 | 0.840391 | 0.821656 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.937778 | 0.923414 | 0.93054  | 0.923414 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 14:32:11,803 - trainer - INFO] - Train Epoch:[75/100] Step:[10/35] Total Loss: 1.033699 GL_Loss: 0.118660 CRF_Loss: 0.915039\n",
      "[2022-03-15 14:32:30,948 - trainer - INFO] - Train Epoch:[75/100] Step:[20/35] Total Loss: 0.269033 GL_Loss: 0.109854 CRF_Loss: 0.159180\n",
      "[2022-03-15 14:32:51,165 - trainer - INFO] - Train Epoch:[75/100] Step:[30/35] Total Loss: 0.672273 GL_Loss: 0.123445 CRF_Loss: 0.548828\n",
      "[2022-03-15 14:33:11,619 - trainer - INFO] - [Epoch Validation] Epoch:[75/100] Total Loss: 0.651964 GL_Loss: 0.001149 CRF_Loss: 0.537068 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.845588 | 0.732484 | 0.784983 | 0.732484 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 1        | 0.976667 | 0.988196 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.951049 | 0.892779 | 0.920993 | 0.892779 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 14:33:31,581 - trainer - INFO] - Train Epoch:[76/100] Step:[10/35] Total Loss: 0.702962 GL_Loss: 0.138020 CRF_Loss: 0.564941\n",
      "[2022-03-15 14:33:51,796 - trainer - INFO] - Train Epoch:[76/100] Step:[20/35] Total Loss: 0.299898 GL_Loss: 0.115328 CRF_Loss: 0.184570\n",
      "[2022-03-15 14:34:11,885 - trainer - INFO] - Train Epoch:[76/100] Step:[30/35] Total Loss: 0.672666 GL_Loss: 0.138486 CRF_Loss: 0.534180\n",
      "[2022-03-15 14:34:31,999 - trainer - INFO] - [Epoch Validation] Epoch:[76/100] Total Loss: 0.656143 GL_Loss: 0.001148 CRF_Loss: 0.541364 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.804196 | 0.732484 | 0.766667 | 0.732484 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.920993 | 0.892779 | 0.906667 | 0.892779 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 14:34:52,053 - trainer - INFO] - Train Epoch:[77/100] Step:[10/35] Total Loss: 0.657570 GL_Loss: 0.139992 CRF_Loss: 0.517578\n",
      "[2022-03-15 14:35:11,934 - trainer - INFO] - Train Epoch:[77/100] Step:[20/35] Total Loss: 0.275921 GL_Loss: 0.094769 CRF_Loss: 0.181152\n",
      "[2022-03-15 14:35:32,247 - trainer - INFO] - Train Epoch:[77/100] Step:[30/35] Total Loss: 0.697906 GL_Loss: 0.101714 CRF_Loss: 0.596191\n",
      "[2022-03-15 14:35:52,813 - trainer - INFO] - [Epoch Validation] Epoch:[77/100] Total Loss: 0.661562 GL_Loss: 0.001155 CRF_Loss: 0.546038 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.86     | 0.821656 | 0.840391 | 0.821656 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.937778 | 0.923414 | 0.93054  | 0.923414 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 14:36:12,977 - trainer - INFO] - Train Epoch:[78/100] Step:[10/35] Total Loss: 0.274316 GL_Loss: 0.107324 CRF_Loss: 0.166992\n",
      "[2022-03-15 14:36:32,710 - trainer - INFO] - Train Epoch:[78/100] Step:[20/35] Total Loss: 0.652770 GL_Loss: 0.093688 CRF_Loss: 0.559082\n",
      "[2022-03-15 14:36:53,040 - trainer - INFO] - Train Epoch:[78/100] Step:[30/35] Total Loss: 0.706625 GL_Loss: 0.133871 CRF_Loss: 0.572754\n",
      "[2022-03-15 14:37:13,259 - trainer - INFO] - [Epoch Validation] Epoch:[78/100] Total Loss: 0.648249 GL_Loss: 0.001140 CRF_Loss: 0.534249 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.86     | 0.821656 | 0.840391 | 0.821656 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.937778 | 0.923414 | 0.93054  | 0.923414 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 14:37:33,843 - trainer - INFO] - Train Epoch:[79/100] Step:[10/35] Total Loss: 0.688775 GL_Loss: 0.099419 CRF_Loss: 0.589355\n",
      "[2022-03-15 14:37:53,931 - trainer - INFO] - Train Epoch:[79/100] Step:[20/35] Total Loss: 0.676171 GL_Loss: 0.146874 CRF_Loss: 0.529297\n",
      "[2022-03-15 14:38:13,933 - trainer - INFO] - Train Epoch:[79/100] Step:[30/35] Total Loss: 0.290283 GL_Loss: 0.114014 CRF_Loss: 0.176270\n",
      "[2022-03-15 14:38:33,701 - trainer - INFO] - [Epoch Validation] Epoch:[79/100] Total Loss: 0.662919 GL_Loss: 0.001142 CRF_Loss: 0.548703 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.953333 | 0.910828 | 0.931596 | 0.910828 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 1        | 1        | 1        | 1        |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.984444 | 0.969365 | 0.976847 | 0.969365 |\n",
      "+----------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-15 14:38:53,700 - trainer - INFO] - Train Epoch:[80/100] Step:[10/35] Total Loss: 0.682079 GL_Loss: 0.140575 CRF_Loss: 0.541504\n",
      "[2022-03-15 14:39:14,396 - trainer - INFO] - Train Epoch:[80/100] Step:[20/35] Total Loss: 0.671390 GL_Loss: 0.136234 CRF_Loss: 0.535156\n",
      "[2022-03-15 14:39:34,490 - trainer - INFO] - Train Epoch:[80/100] Step:[30/35] Total Loss: 0.286727 GL_Loss: 0.081649 CRF_Loss: 0.205078\n",
      "[2022-03-15 14:39:54,520 - trainer - INFO] - [Epoch Validation] Epoch:[80/100] Total Loss: 0.660545 GL_Loss: 0.001134 CRF_Loss: 0.547168 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.86     | 0.821656 | 0.840391 | 0.821656 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.937778 | 0.923414 | 0.93054  | 0.923414 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 14:39:56,497 - trainer - INFO] - Saving checkpoint: saved/models/PICK_Default/test_0315_125246/checkpoint-epoch80.pth ...\n",
      "[2022-03-15 14:40:16,705 - trainer - INFO] - Train Epoch:[81/100] Step:[10/35] Total Loss: 0.259018 GL_Loss: 0.091538 CRF_Loss: 0.167480\n",
      "[2022-03-15 14:40:37,000 - trainer - INFO] - Train Epoch:[81/100] Step:[20/35] Total Loss: 0.280324 GL_Loss: 0.091360 CRF_Loss: 0.188965\n",
      "[2022-03-15 14:40:56,911 - trainer - INFO] - Train Epoch:[81/100] Step:[30/35] Total Loss: 0.656740 GL_Loss: 0.117190 CRF_Loss: 0.539551\n",
      "[2022-03-15 14:41:17,159 - trainer - INFO] - [Epoch Validation] Epoch:[81/100] Total Loss: 0.649890 GL_Loss: 0.001114 CRF_Loss: 0.538532 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.906667 | 0.866242 | 0.885993 | 0.866242 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.953333 | 0.938731 | 0.945976 | 0.938731 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 14:41:37,506 - trainer - INFO] - Train Epoch:[82/100] Step:[10/35] Total Loss: 0.280579 GL_Loss: 0.101868 CRF_Loss: 0.178711\n",
      "[2022-03-15 14:41:57,262 - trainer - INFO] - Train Epoch:[82/100] Step:[20/35] Total Loss: 1.029485 GL_Loss: 0.132512 CRF_Loss: 0.896973\n",
      "[2022-03-15 14:42:17,210 - trainer - INFO] - Train Epoch:[82/100] Step:[30/35] Total Loss: 0.715508 GL_Loss: 0.154962 CRF_Loss: 0.560547\n",
      "[2022-03-15 14:42:36,969 - trainer - INFO] - [Epoch Validation] Epoch:[82/100] Total Loss: 0.644452 GL_Loss: 0.001130 CRF_Loss: 0.531417 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.86     | 0.821656 | 0.840391 | 0.821656 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.937778 | 0.923414 | 0.93054  | 0.923414 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 14:42:57,165 - trainer - INFO] - Train Epoch:[83/100] Step:[10/35] Total Loss: 0.691844 GL_Loss: 0.135203 CRF_Loss: 0.556641\n",
      "[2022-03-15 14:43:17,025 - trainer - INFO] - Train Epoch:[83/100] Step:[20/35] Total Loss: 0.801569 GL_Loss: 0.113581 CRF_Loss: 0.687988\n",
      "[2022-03-15 14:43:37,264 - trainer - INFO] - Train Epoch:[83/100] Step:[30/35] Total Loss: 0.277005 GL_Loss: 0.089993 CRF_Loss: 0.187012\n",
      "[2022-03-15 14:43:57,379 - trainer - INFO] - [Epoch Validation] Epoch:[83/100] Total Loss: 0.647445 GL_Loss: 0.001144 CRF_Loss: 0.533036 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.86     | 0.821656 | 0.840391 | 0.821656 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.937778 | 0.923414 | 0.93054  | 0.923414 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 14:44:17,238 - trainer - INFO] - Train Epoch:[84/100] Step:[10/35] Total Loss: 0.286827 GL_Loss: 0.114464 CRF_Loss: 0.172363\n",
      "[2022-03-15 14:44:38,124 - trainer - INFO] - Train Epoch:[84/100] Step:[20/35] Total Loss: 0.701894 GL_Loss: 0.145254 CRF_Loss: 0.556641\n",
      "[2022-03-15 14:44:57,922 - trainer - INFO] - Train Epoch:[84/100] Step:[30/35] Total Loss: 0.278348 GL_Loss: 0.095731 CRF_Loss: 0.182617\n",
      "[2022-03-15 14:45:18,204 - trainer - INFO] - [Epoch Validation] Epoch:[84/100] Total Loss: 0.651639 GL_Loss: 0.001168 CRF_Loss: 0.534794 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.86     | 0.821656 | 0.840391 | 0.821656 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.937778 | 0.923414 | 0.93054  | 0.923414 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 14:45:38,833 - trainer - INFO] - Train Epoch:[85/100] Step:[10/35] Total Loss: 1.163125 GL_Loss: 0.148965 CRF_Loss: 1.014160\n",
      "[2022-03-15 14:45:58,750 - trainer - INFO] - Train Epoch:[85/100] Step:[20/35] Total Loss: 0.640805 GL_Loss: 0.103208 CRF_Loss: 0.537598\n",
      "[2022-03-15 14:46:18,627 - trainer - INFO] - Train Epoch:[85/100] Step:[30/35] Total Loss: 0.662629 GL_Loss: 0.131379 CRF_Loss: 0.531250\n",
      "[2022-03-15 14:46:39,029 - trainer - INFO] - [Epoch Validation] Epoch:[85/100] Total Loss: 0.650549 GL_Loss: 0.001142 CRF_Loss: 0.536328 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.906667 | 0.866242 | 0.885993 | 0.866242 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 1        | 1        | 1        | 1        |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.968889 | 0.954048 | 0.961411 | 0.954048 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 14:46:58,989 - trainer - INFO] - Train Epoch:[86/100] Step:[10/35] Total Loss: 0.284687 GL_Loss: 0.097187 CRF_Loss: 0.187500\n",
      "[2022-03-15 14:47:19,562 - trainer - INFO] - Train Epoch:[86/100] Step:[20/35] Total Loss: 0.766073 GL_Loss: 0.114706 CRF_Loss: 0.651367\n",
      "[2022-03-15 14:47:39,340 - trainer - INFO] - Train Epoch:[86/100] Step:[30/35] Total Loss: 0.689809 GL_Loss: 0.096547 CRF_Loss: 0.593262\n",
      "[2022-03-15 14:47:59,732 - trainer - INFO] - [Epoch Validation] Epoch:[86/100] Total Loss: 0.651723 GL_Loss: 0.001149 CRF_Loss: 0.536775 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.86     | 0.821656 | 0.840391 | 0.821656 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.937778 | 0.923414 | 0.93054  | 0.923414 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 14:48:20,205 - trainer - INFO] - Train Epoch:[87/100] Step:[10/35] Total Loss: 0.251755 GL_Loss: 0.088669 CRF_Loss: 0.163086\n",
      "[2022-03-15 14:48:39,593 - trainer - INFO] - Train Epoch:[87/100] Step:[20/35] Total Loss: 0.262448 GL_Loss: 0.103268 CRF_Loss: 0.159180\n",
      "[2022-03-15 14:48:59,467 - trainer - INFO] - Train Epoch:[87/100] Step:[30/35] Total Loss: 0.687005 GL_Loss: 0.113275 CRF_Loss: 0.573730\n",
      "[2022-03-15 14:49:20,133 - trainer - INFO] - [Epoch Validation] Epoch:[87/100] Total Loss: 0.655695 GL_Loss: 0.001141 CRF_Loss: 0.541560 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.906667 | 0.866242 | 0.885993 | 0.866242 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 1        | 1        | 1        | 1        |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.968889 | 0.954048 | 0.961411 | 0.954048 |\n",
      "+----------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-15 14:49:40,961 - trainer - INFO] - Train Epoch:[88/100] Step:[10/35] Total Loss: 0.275190 GL_Loss: 0.105756 CRF_Loss: 0.169434\n",
      "[2022-03-15 14:50:00,977 - trainer - INFO] - Train Epoch:[88/100] Step:[20/35] Total Loss: 0.264207 GL_Loss: 0.087938 CRF_Loss: 0.176270\n",
      "[2022-03-15 14:50:20,757 - trainer - INFO] - Train Epoch:[88/100] Step:[30/35] Total Loss: 0.799824 GL_Loss: 0.113300 CRF_Loss: 0.686523\n",
      "[2022-03-15 14:50:41,162 - trainer - INFO] - [Epoch Validation] Epoch:[88/100] Total Loss: 0.655547 GL_Loss: 0.001146 CRF_Loss: 0.540974 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.86     | 0.821656 | 0.840391 | 0.821656 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.937778 | 0.923414 | 0.93054  | 0.923414 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 14:51:01,679 - trainer - INFO] - Train Epoch:[89/100] Step:[10/35] Total Loss: 0.687119 GL_Loss: 0.116318 CRF_Loss: 0.570801\n",
      "[2022-03-15 14:51:21,732 - trainer - INFO] - Train Epoch:[89/100] Step:[20/35] Total Loss: 1.156491 GL_Loss: 0.109128 CRF_Loss: 1.047363\n",
      "[2022-03-15 14:51:42,135 - trainer - INFO] - Train Epoch:[89/100] Step:[30/35] Total Loss: 1.098018 GL_Loss: 0.174190 CRF_Loss: 0.923828\n",
      "[2022-03-15 14:52:02,242 - trainer - INFO] - [Epoch Validation] Epoch:[89/100] Total Loss: 0.656406 GL_Loss: 0.001150 CRF_Loss: 0.541364 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.906667 | 0.866242 | 0.885993 | 0.866242 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 1        | 1        | 1        | 1        |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.968889 | 0.954048 | 0.961411 | 0.954048 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 14:52:22,700 - trainer - INFO] - Train Epoch:[90/100] Step:[10/35] Total Loss: 0.694931 GL_Loss: 0.139267 CRF_Loss: 0.555664\n",
      "[2022-03-15 14:52:42,702 - trainer - INFO] - Train Epoch:[90/100] Step:[20/35] Total Loss: 1.182425 GL_Loss: 0.135062 CRF_Loss: 1.047363\n",
      "[2022-03-15 14:53:03,152 - trainer - INFO] - Train Epoch:[90/100] Step:[30/35] Total Loss: 0.284102 GL_Loss: 0.097578 CRF_Loss: 0.186523\n",
      "[2022-03-15 14:53:23,246 - trainer - INFO] - [Epoch Validation] Epoch:[90/100] Total Loss: 0.650243 GL_Loss: 0.001151 CRF_Loss: 0.535170 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.906667 | 0.866242 | 0.885993 | 0.866242 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 1        | 1        | 1        | 1        |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.968889 | 0.954048 | 0.961411 | 0.954048 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 14:53:44,175 - trainer - INFO] - Train Epoch:[91/100] Step:[10/35] Total Loss: 0.724301 GL_Loss: 0.144223 CRF_Loss: 0.580078\n",
      "[2022-03-15 14:54:04,743 - trainer - INFO] - Train Epoch:[91/100] Step:[20/35] Total Loss: 0.667730 GL_Loss: 0.103765 CRF_Loss: 0.563965\n",
      "[2022-03-15 14:54:24,208 - trainer - INFO] - Train Epoch:[91/100] Step:[30/35] Total Loss: 0.669453 GL_Loss: 0.131367 CRF_Loss: 0.538086\n",
      "[2022-03-15 14:54:44,156 - trainer - INFO] - [Epoch Validation] Epoch:[91/100] Total Loss: 0.649016 GL_Loss: 0.001149 CRF_Loss: 0.534110 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.845588 | 0.732484 | 0.784983 | 0.732484 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 1        | 1        | 1        | 1        |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.951835 | 0.908096 | 0.929451 | 0.908096 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 14:55:04,207 - trainer - INFO] - Train Epoch:[92/100] Step:[10/35] Total Loss: 0.638105 GL_Loss: 0.093671 CRF_Loss: 0.544434\n",
      "[2022-03-15 14:55:24,267 - trainer - INFO] - Train Epoch:[92/100] Step:[20/35] Total Loss: 1.142815 GL_Loss: 0.146722 CRF_Loss: 0.996094\n",
      "[2022-03-15 14:55:44,666 - trainer - INFO] - Train Epoch:[92/100] Step:[30/35] Total Loss: 0.652237 GL_Loss: 0.112198 CRF_Loss: 0.540039\n",
      "[2022-03-15 14:56:04,794 - trainer - INFO] - [Epoch Validation] Epoch:[92/100] Total Loss: 0.644303 GL_Loss: 0.001138 CRF_Loss: 0.530511 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.86     | 0.821656 | 0.840391 | 0.821656 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.937778 | 0.923414 | 0.93054  | 0.923414 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 14:56:24,675 - trainer - INFO] - Train Epoch:[93/100] Step:[10/35] Total Loss: 0.249886 GL_Loss: 0.093148 CRF_Loss: 0.156738\n",
      "[2022-03-15 14:56:45,354 - trainer - INFO] - Train Epoch:[93/100] Step:[20/35] Total Loss: 1.062132 GL_Loss: 0.152464 CRF_Loss: 0.909668\n",
      "[2022-03-15 14:57:05,238 - trainer - INFO] - Train Epoch:[93/100] Step:[30/35] Total Loss: 0.677593 GL_Loss: 0.115581 CRF_Loss: 0.562012\n",
      "[2022-03-15 14:57:26,002 - trainer - INFO] - [Epoch Validation] Epoch:[93/100] Total Loss: 0.651038 GL_Loss: 0.001151 CRF_Loss: 0.535910 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.804196 | 0.732484 | 0.766667 | 0.732484 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.920993 | 0.892779 | 0.906667 | 0.892779 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 14:57:46,700 - trainer - INFO] - Train Epoch:[94/100] Step:[10/35] Total Loss: 1.259884 GL_Loss: 0.107051 CRF_Loss: 1.152832\n",
      "[2022-03-15 14:58:06,810 - trainer - INFO] - Train Epoch:[94/100] Step:[20/35] Total Loss: 0.286507 GL_Loss: 0.102425 CRF_Loss: 0.184082\n",
      "[2022-03-15 14:58:26,605 - trainer - INFO] - Train Epoch:[94/100] Step:[30/35] Total Loss: 0.308183 GL_Loss: 0.113848 CRF_Loss: 0.194336\n",
      "[2022-03-15 14:58:46,588 - trainer - INFO] - [Epoch Validation] Epoch:[94/100] Total Loss: 0.648731 GL_Loss: 0.001143 CRF_Loss: 0.534417 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.794118 | 0.687898 | 0.737201 | 0.687898 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 1        | 1        | 1        | 1        |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.93578  | 0.892779 | 0.913774 | 0.892779 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 14:59:07,182 - trainer - INFO] - Train Epoch:[95/100] Step:[10/35] Total Loss: 1.246326 GL_Loss: 0.146228 CRF_Loss: 1.100098\n",
      "[2022-03-15 14:59:27,367 - trainer - INFO] - Train Epoch:[95/100] Step:[20/35] Total Loss: 0.667311 GL_Loss: 0.126295 CRF_Loss: 0.541016\n",
      "[2022-03-15 14:59:47,332 - trainer - INFO] - Train Epoch:[95/100] Step:[30/35] Total Loss: 0.270279 GL_Loss: 0.110611 CRF_Loss: 0.159668\n",
      "[2022-03-15 15:00:07,329 - trainer - INFO] - [Epoch Validation] Epoch:[95/100] Total Loss: 0.657487 GL_Loss: 0.001138 CRF_Loss: 0.543694 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.906667 | 0.866242 | 0.885993 | 0.866242 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 1        | 1        | 1        | 1        |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.968889 | 0.954048 | 0.961411 | 0.954048 |\n",
      "+----------+----------+----------+----------+----------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-15 15:00:27,579 - trainer - INFO] - Train Epoch:[96/100] Step:[10/35] Total Loss: 0.273540 GL_Loss: 0.110943 CRF_Loss: 0.162598\n",
      "[2022-03-15 15:00:47,159 - trainer - INFO] - Train Epoch:[96/100] Step:[20/35] Total Loss: 0.842080 GL_Loss: 0.120400 CRF_Loss: 0.721680\n",
      "[2022-03-15 15:01:07,809 - trainer - INFO] - Train Epoch:[96/100] Step:[30/35] Total Loss: 0.666413 GL_Loss: 0.131745 CRF_Loss: 0.534668\n",
      "[2022-03-15 15:01:28,479 - trainer - INFO] - [Epoch Validation] Epoch:[96/100] Total Loss: 0.655586 GL_Loss: 0.001154 CRF_Loss: 0.540137 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.804196 | 0.732484 | 0.766667 | 0.732484 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 0.976667 | 0.976667 | 0.976667 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.920993 | 0.892779 | 0.906667 | 0.892779 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 15:01:49,558 - trainer - INFO] - Train Epoch:[97/100] Step:[10/35] Total Loss: 1.220764 GL_Loss: 0.114319 CRF_Loss: 1.106445\n",
      "[2022-03-15 15:02:09,954 - trainer - INFO] - Train Epoch:[97/100] Step:[20/35] Total Loss: 0.757730 GL_Loss: 0.100503 CRF_Loss: 0.657227\n",
      "[2022-03-15 15:02:29,478 - trainer - INFO] - Train Epoch:[97/100] Step:[30/35] Total Loss: 0.303863 GL_Loss: 0.114898 CRF_Loss: 0.188965\n",
      "[2022-03-15 15:02:49,335 - trainer - INFO] - [Epoch Validation] Epoch:[97/100] Total Loss: 0.649396 GL_Loss: 0.001163 CRF_Loss: 0.533105 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.902098 | 0.821656 | 0.86     | 0.821656 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 1        | 1        | 1        | 1        |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.968397 | 0.938731 | 0.953333 | 0.938731 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 15:03:10,070 - trainer - INFO] - Train Epoch:[98/100] Step:[10/35] Total Loss: 1.166451 GL_Loss: 0.107857 CRF_Loss: 1.058594\n",
      "[2022-03-15 15:03:29,783 - trainer - INFO] - Train Epoch:[98/100] Step:[20/35] Total Loss: 1.312127 GL_Loss: 0.109979 CRF_Loss: 1.202148\n",
      "[2022-03-15 15:03:49,584 - trainer - INFO] - Train Epoch:[98/100] Step:[30/35] Total Loss: 0.277603 GL_Loss: 0.112564 CRF_Loss: 0.165039\n",
      "[2022-03-15 15:04:09,656 - trainer - INFO] - [Epoch Validation] Epoch:[98/100] Total Loss: 0.647886 GL_Loss: 0.001125 CRF_Loss: 0.535338 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.906667 | 0.866242 | 0.885993 | 0.866242 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 1        | 1        | 1        | 1        |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.968889 | 0.954048 | 0.961411 | 0.954048 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 15:04:29,808 - trainer - INFO] - Train Epoch:[99/100] Step:[10/35] Total Loss: 0.803461 GL_Loss: 0.118403 CRF_Loss: 0.685059\n",
      "[2022-03-15 15:04:49,866 - trainer - INFO] - Train Epoch:[99/100] Step:[20/35] Total Loss: 0.659366 GL_Loss: 0.105655 CRF_Loss: 0.553711\n",
      "[2022-03-15 15:05:09,507 - trainer - INFO] - Train Epoch:[99/100] Step:[30/35] Total Loss: 0.249889 GL_Loss: 0.085338 CRF_Loss: 0.164551\n",
      "[2022-03-15 15:05:30,185 - trainer - INFO] - [Epoch Validation] Epoch:[99/100] Total Loss: 0.650290 GL_Loss: 0.001144 CRF_Loss: 0.535868 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.845588 | 0.732484 | 0.784983 | 0.732484 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 1        | 0.976667 | 0.988196 | 0.976667 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.951049 | 0.892779 | 0.920993 | 0.892779 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 15:05:50,498 - trainer - INFO] - Train Epoch:[100/100] Step:[10/35] Total Loss: 0.283313 GL_Loss: 0.109485 CRF_Loss: 0.173828\n",
      "[2022-03-15 15:06:10,241 - trainer - INFO] - Train Epoch:[100/100] Step:[20/35] Total Loss: 0.748785 GL_Loss: 0.142828 CRF_Loss: 0.605957\n",
      "[2022-03-15 15:06:29,890 - trainer - INFO] - Train Epoch:[100/100] Step:[30/35] Total Loss: 1.254833 GL_Loss: 0.139111 CRF_Loss: 1.115723\n",
      "[2022-03-15 15:06:49,818 - trainer - INFO] - [Epoch Validation] Epoch:[100/100] Total Loss: 0.653887 GL_Loss: 0.001120 CRF_Loss: 0.541853 \n",
      "+----------+----------+----------+----------+----------+\n",
      "| name     |      mEP |      mER |      mEF |      mEA |\n",
      "+==========+==========+==========+==========+==========+\n",
      "| h_key    | 0.906667 | 0.866242 | 0.885993 | 0.866242 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| h_answer | 1        | 1        | 1        | 1        |\n",
      "+----------+----------+----------+----------+----------+\n",
      "| overall  | 0.968889 | 0.954048 | 0.961411 | 0.954048 |\n",
      "+----------+----------+----------+----------+----------+\n",
      "[2022-03-15 15:06:51,745 - trainer - INFO] - Saving checkpoint: saved/models/PICK_Default/test_0315_125246/checkpoint-epoch100.pth ...\n",
      "[2022-03-15 15:06:51,746 - train - INFO] - Training end...\n"
     ]
    }
   ],
   "source": [
    "# FORMs Dataset - Acceptance\n",
    "!python3 train.py -c config_dla_1400x1800.json -d 0 -dist false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python3 test.py --checkpoint ./saved/models/PICK_Default/test_0127_200925/model_best.pth \n",
    "--boxes_transcripts ./inference/test_boxes_and_transcripts/ \n",
    "--images_path ./inference/test_img/ --output_folder ./inference/output/ --gpu 0 --batch_size 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FORMs Dataset - Form1572"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint: ./saved/models/PICK_Default/test_0302_125836/model_best.pth \n",
      "with saved mEF 0.9550 ...\n",
      "0it [00:00, ?it/s]['inference/test_img/25.png']\n",
      "[[28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 16, 16, 16, 16, 16, 16, 16, 16, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 16, 16, 16, 16, 16, 16, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 16, 16, 16, 14, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 0, 14, 14, 14, 14, 14, 14, 16, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 16, 16, 16, 16, 16, 16, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 20, 20, 20, 20, 20, 20, 20, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 2, 16, 16, 16, 16, 16, 12, 26, 26, 26, 26, 26, 26, 26, 26, 26, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 14, 14, 14, 14, 14, 14, 14, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 13, 27, 27, 27, 27, 12, 16, 3, 17, 17, 2, 16, 16, 16, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('city', (563, 570)), ('city', (623, 628)), ('city', (845, 847)), ('address_1', (848, 848)), ('city', (849, 859)), ('address_1', (1129, 1135)), ('city', (1136, 1136)), ('city', (1207, 1212)), ('name_of_clinical_investigator', (1396, 1402)), ('city', (1471, 1476)), ('state', (1477, 1486)), ('city', (1487, 1496)), ('address_1', (1715, 1721)), ('zip_code', (1793, 1797)), ('state', (1798, 1798)), ('city', (1799, 1799)), ('country', (1800, 1802)), ('city', (1803, 1806)), ('city', (1890, 1905))]\n",
      "[{'entity_name': 'city', 'text': 'Suite 40'}, {'entity_name': 'city', 'text': 'LUSA33'}, {'entity_name': 'city', 'text': 'urr'}, {'entity_name': 'address_1', 'text': 'i'}, {'entity_name': 'city', 'text': 'culum Vitae'}, {'entity_name': 'address_1', 'text': 'Suite 4'}, {'entity_name': 'city', 'text': '0'}, {'entity_name': 'city', 'text': '34USAF'}, {'entity_name': 'name_of_clinical_investigator', 'text': 'uite 2E'}, {'entity_name': 'city', 'text': '91355U'}, {'entity_name': 'state', 'text': 'SACaliforn'}, {'entity_name': 'city', 'text': 'iaValencia'}, {'entity_name': 'address_1', 'text': 'uite 20'}, {'entity_name': 'zip_code', 'text': '27513'}, {'entity_name': 'state', 'text': 'N'}, {'entity_name': 'city', 'text': 'C'}, {'entity_name': 'country', 'text': 'USA'}, {'entity_name': 'city', 'text': 'Cary'}, {'entity_name': 'city', 'text': 'lissa Wright; AR'}]\n",
      "1it [00:00,  1.10it/s]['inference/test_img/19.png']\n",
      "[[28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "2it [00:01,  1.19it/s]['inference/test_img/31.png']\n",
      "[[28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 16, 16, 16, 16, 16, 16, 16, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 2, 16, 16, 16, 16, 16, 16, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 16, 16, 14, 16, 14, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 16, 16, 16, 16, 16, 16, 16, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 2, 16, 16, 16, 16, 16, 16, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 14, 14, 14, 16, 14, 16, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 2, 16, 16, 16, 16, 16, 12, 26, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 13, 27, 27, 27, 27, 17, 17, 2, 2, 16, 16, 16, 16, 16, 16, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('city', (548, 554)), ('city', (627, 633)), ('city', (848, 849)), ('address_1', (850, 850)), ('city', (851, 851)), ('address_1', (852, 852)), ('city', (853, 862)), ('city', (1125, 1131)), ('city', (1204, 1210)), ('address_1', (1395, 1397)), ('city', (1398, 1398)), ('address_1', (1399, 1399)), ('city', (1400, 1400)), ('city', (1470, 1475)), ('state', (1476, 1477)), ('city', (1478, 1495)), ('zip_code', (1805, 1809)), ('country', (1810, 1811)), ('city', (1812, 1812)), ('city', (1813, 1819))]\n",
      "[{'entity_name': 'city', 'text': 'uite 10'}, {'entity_name': 'city', 'text': '27408US'}, {'entity_name': 'city', 'text': 'ur'}, {'entity_name': 'address_1', 'text': 'r'}, {'entity_name': 'city', 'text': 'i'}, {'entity_name': 'address_1', 'text': 'c'}, {'entity_name': 'city', 'text': 'ulum Vitae'}, {'entity_name': 'city', 'text': 'uite 10'}, {'entity_name': 'city', 'text': '27408US'}, {'entity_name': 'address_1', 'text': 'uit'}, {'entity_name': 'city', 'text': 'e'}, {'entity_name': 'address_1', 'text': ' '}, {'entity_name': 'city', 'text': '2'}, {'entity_name': 'city', 'text': '91355U'}, {'entity_name': 'state', 'text': 'SA'}, {'entity_name': 'city', 'text': 'CaliforniaValencia'}, {'entity_name': 'zip_code', 'text': '91355'}, {'entity_name': 'country', 'text': 'US'}, {'entity_name': 'city', 'text': 'N'}, {'entity_name': 'city', 'text': 'CDurham'}]\n",
      "3it [00:02,  1.29it/s]\n"
     ]
    }
   ],
   "source": [
    "!python3 test.py --checkpoint ./saved/models/PICK_Default/test_0302_125836/model_best.pth \\\n",
    "                 --boxes_transcripts ./inference/test_boxes_and_transcripts/ \\\n",
    "                 --images_path ./inference/test_img/ --output_folder ./inference/output/ \\\n",
    "                 --gpu 0 --batch_size 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SROIE 2019 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint: ./saved/models/PICK_Default/test_0217_100852/model_best.pth \n",
      "with saved mEF 0.7006 ...\n",
      "0it [00:00, ?it/s]['inference/0_test_img/X00016469623.jpg']\n",
      "[[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 3, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 2, 6, 6, 6, 6, 6, 6, 6, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]]\n",
      "[('address', (60, 123)), ('address', (124, 153)), ('total', (571, 575)), ('date', (615, 622))]\n",
      "[{'entity_name': 'address', 'text': 'LOT 1851-A & 1851-B, JALAN KPB 6,KAWASAN PERINDUSTRIAN BALAKONG,'}, {'entity_name': 'address', 'text': '43300 SERI KEMBANGAN, SELANGOR'}, {'entity_name': 'total', 'text': '30.90'}, {'entity_name': 'date', 'text': '18-11-18'}]\n",
      "1it [00:00,  3.56it/s]['inference/0_test_img/asdf.jpg']\n",
      "[[1, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 8, 8, 8, 8, 8, 8, 8, 8, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 2, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 3, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 3, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 3, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 3, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]]\n",
      "[('company', (0, 12)), ('address', (13, 42)), ('address', (51, 82)), ('address', (83, 93)), ('address', (94, 111)), ('date', (142, 151)), ('total', (270, 278)), ('total', (287, 290)), ('total', (322, 325)), ('total', (349, 353))]\n",
      "[{'entity_name': 'company', 'text': 'TAN WOON YANN'}, {'entity_name': 'address', 'text': 'BOOK TA .K(TAMAN DAYA) SDN BND'}, {'entity_name': 'address', 'text': 'NO.53 55,57 & 59, JALAN SAGU 18,'}, {'entity_name': 'address', 'text': 'TAMAN DAYA,'}, {'entity_name': 'address', 'text': '81100 JOHOR BAHRU,'}, {'entity_name': 'date', 'text': '25/12/2018'}, {'entity_name': 'total', 'text': '9.0009.00'}, {'entity_name': 'total', 'text': '9.00'}, {'entity_name': 'total', 'text': '9.00'}, {'entity_name': 'total', 'text': '10.00'}]\n",
      "2it [00:00,  4.23it/s]['inference/0_test_img/091.jpg']\n",
      "[[8, 7, 7, 7, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 2, 6, 6, 6, 6, 6, 6, 6, 6, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 2, 6, 6, 6, 6, 6, 6, 6, 6, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('total', (1, 3)), ('address', (4, 46)), ('address', (47, 71)), ('address', (72, 166)), ('address', (178, 181)), ('address', (193, 206)), ('date', (299, 307)), ('date', (1314, 1322))]\n",
      "[{'entity_name': 'total', 'text': 'YDI'}, {'entity_name': 'address', 'text': 'N,otherTRI SHAAS SDN BHD (728515-N),company'}, {'entity_name': 'address', 'text': 'MYDIN MART SRI MUDA,other'}, {'entity_name': 'address', 'text': '4-20\\\\, JALAN RIA 25/62 TAMAN SRI MUDA,addressSEKSYEN 25\\\\, 40400 SHAH ALAM SELANGOR,addressTEL: '}, {'entity_name': 'address', 'text': ' FAX'}, {'entity_name': 'address', 'text': '59,otherGST ID'}, {'entity_name': 'date', 'text': '4/02/2017'}, {'entity_name': 'date', 'text': '4/02/2017'}]\n",
      "3it [00:00,  3.84it/s]['inference/0_test_img/050.jpg']\n",
      "[[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 0, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 2, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]]\n",
      "[('address', (0, 46)), ('address', (143, 233)), ('date', (284, 296))]\n",
      "[{'entity_name': 'address', 'text': \"MORGANFIELD'S R,otherHORNG OF SDCKY BONES,other\"}, {'entity_name': 'address', 'text': 'LOT 50\\\\, FLOOR T2\\\\,SKY AVENUE GENTING HIGHLANDS,addressPAHANG\\\\, 69000 PAHANG MALAYSLA,other'}, {'entity_name': 'date', 'text': '2018-03-23,da'}]\n",
      "4it [00:01,  3.93it/s]\n"
     ]
    }
   ],
   "source": [
    "!python3 test.py --checkpoint ./saved/models/PICK_Default/test_0217_100852/model_best.pth \\\n",
    "                 --boxes_transcripts ./inference/0_test_boxes_and_transcripts/ \\\n",
    "                 --images_path ./inference/0_test_img/ --output_folder ./inference/output/ \\\n",
    "                 --gpu 0 --batch_size 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FORMs Dataset - Acceptance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint: ./saved/models/PICK_Default/test_0315_125246/model_best.pth \n",
      "with saved mEF 0.9138 ...\n",
      "0it [00:00, ?it/s]['inference/1_test_img/36.png']\n",
      "[[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]]\n",
      "[('h_answer', (149, 214)), ('h_answer', (215, 277)), ('h_key', (278, 289)), ('h_answer', (290, 349)), ('h_answer', (350, 397)), ('h_answer', (398, 405)), ('h_key', (406, 418)), ('h_answer', (419, 434)), ('h_key', (435, 444))]\n",
      "[{'entity_name': 'h_answer', 'text': 'A Randomized, Double-blind, Placebo-Controlled Study to Assess the'}, {'entity_name': 'h_answer', 'text': 'Effects of Bempedoic Acid (ETC-1002) on the Occurrence of Major'}, {'entity_name': 'h_key', 'text': 'Study Title:'}, {'entity_name': 'h_answer', 'text': 'Cardiovascular Events in Patients with, or at High Risk for;'}, {'entity_name': 'h_answer', 'text': 'Cardiovascular Disease who are Statin Intolerant'}, {'entity_name': 'h_answer', 'text': '1002-043'}, {'entity_name': 'h_key', 'text': 'Study Number:'}, {'entity_name': 'h_answer', 'text': '10 November 2017'}, {'entity_name': 'h_key', 'text': 'Final Date'}]\n",
      "1it [00:00,  2.86it/s]['inference/1_test_img/37.png']\n",
      "[[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]]\n",
      "[('h_answer', (160, 233)), ('h_answer', (234, 299)), ('h_key', (300, 318)), ('h_answer', (319, 387)), ('h_answer', (388, 449)), ('h_key', (450, 459)), ('h_answer', (460, 466)), ('h_key', (467, 482))]\n",
      "[{'entity_name': 'h_answer', 'text': 'Estudio aleatorizado, doble ciego. controlado con placebo para evaluar los'}, {'entity_name': 'h_answer', 'text': 'efectos del acido bempedoico (ETC-[002) en la aparicion de eventos'}, {'entity_name': 'h_key', 'text': 'Titulo del estudio:'}, {'entity_name': 'h_answer', 'text': 'cardiovasculares mayores en pacientes con enfermedad cardiovascular 0'}, {'entity_name': 'h_answer', 'text': 'con alto riesgo de desarrollarla, que no toleran las estatinas'}, {'entity_name': 'h_key', 'text': 'Numero de1'}, {'entity_name': 'h_answer', 'text': '002-043'}, {'entity_name': 'h_key', 'text': 'estudio:Fecha fi'}]\n",
      "2it [00:00,  2.97it/s]\n"
     ]
    }
   ],
   "source": [
    "!python3 test.py --checkpoint ./saved/models/PICK_Default/test_0315_125246/model_best.pth \\\n",
    "                 --boxes_transcripts ./inference/1_test_boxes_and_transcripts/ \\\n",
    "                 --images_path ./inference/1_test_img/ --output_folder ./inference/output/ \\\n",
    "                 --gpu 0 --batch_size 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FUNSD Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint: ./saved/models/PICK_Default/test_0321_140123/model_best.pth \n",
      "with saved mEF 0.7276 ...\n",
      "0it [00:00, ?it/s]['inference/2_test_img/91814768_91814769.png']\n",
      "[[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 4, 4, 4, 4, 4, 4, 4, 4, 6, 6, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 6, 4, 4, 4, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 4, 4, 4, 6, 6, 6, 6, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 6, 4, 4, 4, 4, 4, 4, 1, 4, 5, 4, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 2, 5, 5, 5, 5, 6, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 3, 3, 3, 3, 3, 3, 3, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 2, 5, 5, 5, 5, 5, 0, 3, 3, 3, 3, 3, 3, 3, 0, 3, 2, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 5, 6, 5, 6, 5, 6, 5, 6, 5, 6, 5, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 6, 6, 6, 6, 6, 6, 6, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]]\n",
      "[('header', (17, 24)), ('header', (27, 30)), ('header', (38, 45)), ('header', (69, 71)), ('header', (76, 87)), ('header', (89, 97)), ('header', (100, 105)), ('header', (106, 107)), ('question', (108, 108)), ('header', (109, 109)), ('question', (110, 110)), ('header', (111, 111)), ('question', (112, 134)), ('answer', (135, 163)), ('answer', (164, 164)), ('question', (165, 174)), ('answer', (175, 185)), ('answer', (186, 271)), ('question', (272, 299)), ('question', (300, 321)), ('question', (322, 344)), ('question', (345, 384)), ('answer', (385, 385)), ('question', (386, 390)), ('answer', (392, 448)), ('question', (449, 468)), ('answer', (469, 493)), ('question', (494, 515)), ('question', (516, 540)), ('answer', (541, 580)), ('question', (581, 581)), ('answer', (582, 594)), ('question', (595, 596)), ('answer', (597, 608)), ('question', (609, 612)), ('answer', (613, 619)), ('question', (620, 621)), ('question', (622, 636)), ('answer', (637, 663)), ('answer', (664, 676)), ('answer', (677, 680)), ('question', (681, 686)), ('answer', (687, 694)), ('answer', (695, 696)), ('question', (697, 702)), ('question', (703, 728)), ('question', (729, 752)), ('question', (754, 758)), ('question', (759, 773)), ('question', (774, 779)), ('answer', (880, 895)), ('answer', (896, 897)), ('answer', (898, 908)), ('answer', (909, 910)), ('question', (911, 920)), ('question', (947, 959)), ('question', (962, 962)), ('question', (964, 964)), ('question', (966, 966)), ('question', (968, 968)), ('question', (970, 970)), ('question', (972, 972)), ('question', (974, 974)), ('answer', (1099, 1112)), ('answer', (1113, 1113)), ('question', (1114, 1129)), ('question', (1130, 1133)), ('question', (1134, 1152)), ('answer', (1153, 1181)), ('question', (1182, 1198)), ('question', (1199, 1243)), ('question', (1244, 1250)), ('question', (1251, 1259)), ('question', (1260, 1266)), ('question', (1267, 1285)), ('answer', (1286, 1296)), ('answer', (1297, 1326)), ('question', (1327, 1356)), ('answer', (1357, 1366)), ('answer', (1367, 1376)), ('answer', (1377, 1394)), ('answer', (1395, 1426)), ('answer', (1427, 1436)), ('question', (1437, 1466)), ('answer', (1467, 1467)), ('answer', (1475, 1484)), ('question', (1485, 1534)), ('answer', (1535, 1545)), ('question', (1546, 1601)), ('answer', (1689, 1699)), ('question', (1700, 1742))]\n",
      "[{'entity_name': 'header', 'text': 'ORRECTED'}, {'entity_name': 'header', 'text': 'ORM\"'}, {'entity_name': 'header', 'text': 'mmonweal'}, {'entity_name': 'header', 'text': 'ICE'}, {'entity_name': 'header', 'text': 'CAMPAIGN AND'}, {'entity_name': 'header', 'text': 'POLITICAL'}, {'entity_name': 'header', 'text': 'INANCE'}, {'entity_name': 'header', 'text': 'RE'}, {'entity_name': 'question', 'text': 'P'}, {'entity_name': 'header', 'text': 'O'}, {'entity_name': 'question', 'text': 'R'}, {'entity_name': 'header', 'text': 'T'}, {'entity_name': 'question', 'text': ' OF CORPORATE TREASURER'}, {'entity_name': 'answer', 'text': 'Form CPF 22 (formerly CPF 10)'}, {'entity_name': 'answer', 'text': ' '}, {'entity_name': 'question', 'text': 'File with:'}, {'entity_name': 'answer', 'text': '(CHECK ONE)'}, {'entity_name': 'answer', 'text': 'Director, Office of Campaign & Political Finance One Ashburton Place, Boston, MA 02108'}, {'entity_name': 'question', 'text': 'O 60th Day Prior to Election'}, {'entity_name': 'question', 'text': 'O 5th Day of the Month'}, {'entity_name': 'question', 'text': 'O 20th Day of the Month'}, {'entity_name': 'question', 'text': 'Please Print or Type, except Signatures.'}, {'entity_name': 'answer', 'text': 'O'}, {'entity_name': 'question', 'text': 'Final'}, {'entity_name': 'answer', 'text': 'M. Alfred Peterson; Assistant Treasurer Peter J. Marzullo'}, {'entity_name': 'question', 'text': '1. Name of Treasurer'}, {'entity_name': 'answer', 'text': 'Lorillard Tobacco Company'}, {'entity_name': 'question', 'text': '2. Name of Corporation'}, {'entity_name': 'question', 'text': '3. Address of Corporation'}, {'entity_name': 'answer', 'text': 'One Park Avenue New York. NY 10016 -5895'}, {'entity_name': 'question', 'text': '1'}, {'entity_name': 'answer', 'text': ' relating to '}, {'entity_name': 'question', 'text': 'To'}, {'entity_name': 'answer', 'text': 'bacco Excise'}, {'entity_name': 'question', 'text': ' Tax'}, {'entity_name': 'answer', 'text': ' Increa'}, {'entity_name': 'question', 'text': 'se'}, {'entity_name': 'question', 'text': '4. Question No.'}, {'entity_name': 'answer', 'text': '(Describe question briefly)'}, {'entity_name': 'answer', 'text': 'Massachusetts'}, {'entity_name': 'answer', 'text': '1992'}, {'entity_name': 'question', 'text': 'ballot'}, {'entity_name': 'answer', 'text': 'November'}, {'entity_name': 'answer', 'text': '3,'}, {'entity_name': 'question', 'text': 'on the'}, {'entity_name': 'question', 'text': 'submitted to the voters on'}, {'entity_name': 'question', 'text': '(Name of City/ Town of S'}, {'entity_name': 'question', 'text': 'ate)*'}, {'entity_name': 'question', 'text': '(Election Date)'}, {'entity_name': 'question', 'text': '*Note:'}, {'entity_name': 'answer', 'text': 'November 5. 1992'}, {'entity_name': 'answer', 'text': '92'}, {'entity_name': 'answer', 'text': 'October 16,'}, {'entity_name': 'answer', 'text': '19'}, {'entity_name': 'question', 'text': 'and Ending'}, {'entity_name': 'question', 'text': 'Fil in Dates:'}, {'entity_name': 'question', 'text': 'o'}, {'entity_name': 'question', 'text': 't'}, {'entity_name': 'question', 'text': 'i'}, {'entity_name': 'question', 'text': 'u'}, {'entity_name': 'question', 'text': 'i'}, {'entity_name': 'question', 'text': 'n'}, {'entity_name': 'question', 'text': 'I'}, {'entity_name': 'answer', 'text': 'March 30, 1993'}, {'entity_name': 'answer', 'text': ' '}, {'entity_name': 'question', 'text': 'Preasurer Senato'}, {'entity_name': 'question', 'text': 'Date'}, {'entity_name': 'question', 'text': 'Assistant Treasurer'}, {'entity_name': 'answer', 'text': 'EXPENDITURES OR DISBURSEMENTS'}, {'entity_name': 'question', 'text': 'Amount or Value**'}, {'entity_name': 'question', 'text': 'To Whom Paid (Alphabetical Listing Mandatory)'}, {'entity_name': 'question', 'text': 'Purpose'}, {'entity_name': 'question', 'text': 'Date Paid'}, {'entity_name': 'question', 'text': 'Address'}, {'entity_name': 'question', 'text': 'Oppose Tax Increase'}, {'entity_name': 'answer', 'text': '28, 482. 00'}, {'entity_name': 'answer', 'text': 'P. O. B03 5979 Boston, MA 0212'}, {'entity_name': 'question', 'text': 'Committee Against Unfair Taxes'}, {'entity_name': 'answer', 'text': '10/ 26/ 92'}, {'entity_name': 'answer', 'text': '19, 503 00'}, {'entity_name': 'answer', 'text': 'Oppose Tax increas'}, {'entity_name': 'answer', 'text': 'P. O. Box 5979. Boston, MA 02114'}, {'entity_name': 'answer', 'text': '10/ 30/ 92'}, {'entity_name': 'question', 'text': 'Committee Against Unfair Taxes'}, {'entity_name': 'answer', 'text': '9'}, {'entity_name': 'answer', 'text': '48, 585 00'}, {'entity_name': 'question', 'text': 'Total Expenditures or Disbursements on This Report'}, {'entity_name': 'answer', 'text': '508. 789 00'}, {'entity_name': 'question', 'text': 'Total Expenditures for Disbursements Previously Reported'}, {'entity_name': 'answer', 'text': '556 874. 00'}, {'entity_name': 'question', 'text': 'Total Expenditures or Disbursements to Date'}]\n",
      "1it [00:00,  2.19it/s]['inference/2_test_img/83641919_1921.png']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 5, 5, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 2, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 5, 5, 0, 2, 5, 5, 5, 5, 5, 5, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 2, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 0, 3, 0, 3, 3, 3, 3, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 3, 3, 3, 3, 3, 0, 3, 2, 5, 5, 5, 5, 5, 5, 5, 0, 3, 3, 3, 3, 3, 0, 3, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 3, 0, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 0, 3, 0, 3, 3, 3, 3, 0, 3, 2, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 3, 3, 3, 3, 3, 3, 0, 3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 0, 3, 0, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 0, 3, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 0, 3, 3, 2, 5, 5, 5, 0, 3, 3, 0, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 5, 5, 5, 5, 5, 5, 0, 3, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 3, 3, 2, 5, 5, 3, 3, 3, 3, 3, 3, 3, 0, 3, 6, 6, 6, 6, 6, 6, 6, 6, 0, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 2, 5, 5, 5, 5, 5, 5, 5, 3, 0, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]]\n",
      "[('question', (0, 2)), ('answer', (3, 13)), ('question', (14, 28)), ('question', (29, 34)), ('question', (35, 40)), ('answer', (41, 56)), ('answer', (57, 57)), ('question', (58, 62)), ('question', (63, 68)), ('question', (69, 76)), ('answer', (77, 117)), ('question', (118, 126)), ('question', (127, 133)), ('question', (134, 140)), ('question', (141, 144)), ('header', (203, 211)), ('question', (212, 215)), ('answer', (216, 216)), ('question', (217, 223)), ('answer', (224, 236)), ('question', (237, 243)), ('question', (244, 257)), ('question', (258, 271)), ('answer', (272, 273)), ('answer', (274, 286)), ('answer', (287, 288)), ('question', (289, 295)), ('question', (296, 309)), ('answer', (310, 321)), ('question', (322, 335)), ('answer', (336, 347)), ('question', (348, 361)), ('answer', (362, 373)), ('question', (374, 387)), ('question', (388, 394)), ('answer', (395, 396)), ('answer', (397, 401)), ('question', (402, 413)), ('question', (514, 528)), ('question', (529, 543)), ('question', (544, 557)), ('question', (558, 571)), ('question', (572, 587)), ('question', (588, 603)), ('question', (604, 616)), ('answer', (617, 622)), ('answer', (623, 624)), ('question', (625, 632)), ('answer', (633, 638)), ('answer', (639, 640)), ('question', (641, 652)), ('answer', (653, 656)), ('answer', (657, 660)), ('answer', (661, 665)), ('answer', (666, 670)), ('question', (671, 677)), ('answer', (678, 678)), ('answer', (679, 680)), ('answer', (681, 690)), ('answer', (691, 696)), ('answer', (697, 698)), ('answer', (699, 703)), ('answer', (704, 705)), ('question', (706, 714)), ('question', (715, 716)), ('answer', (717, 722)), ('answer', (723, 724)), ('answer', (725, 729)), ('answer', (730, 739)), ('answer', (740, 745)), ('answer', (746, 747)), ('answer', (748, 750)), ('answer', (751, 758)), ('answer', (759, 764)), ('answer', (765, 770)), ('answer', (771, 772)), ('question', (773, 784)), ('answer', (785, 815)), ('question', (885, 899)), ('question', (900, 914)), ('question', (915, 928)), ('question', (929, 942)), ('question', (943, 958)), ('question', (959, 974)), ('question', (975, 983)), ('answer', (984, 986)), ('question', (987, 990)), ('answer', (991, 993)), ('answer', (994, 996)), ('answer', (997, 1015)), ('question', (1016, 1022)), ('answer', (1023, 1024)), ('question', (1025, 1037)), ('answer', (1038, 1040)), ('question', (1041, 1043)), ('answer', (1044, 1050)), ('answer', (1051, 1052)), ('answer', (1061, 1062)), ('answer', (1063, 1071)), ('question', (1072, 1079)), ('answer', (1080, 1080)), ('answer', (1081, 1082))]\n",
      "[{'entity_name': 'question', 'text': 'TO:'}, {'entity_name': 'answer', 'text': 'S. P. ZOLOT'}, {'entity_name': 'question', 'text': 'SUBMISSION DATE'}, {'entity_name': 'question', 'text': 'OCT 05'}, {'entity_name': 'question', 'text': 'DEC 21'}, {'entity_name': 'answer', 'text': 'R. W. RICHARDSON'}, {'entity_name': 'answer', 'text': 'X'}, {'entity_name': 'question', 'text': 'FROM:'}, {'entity_name': 'question', 'text': 'NOV 16'}, {'entity_name': 'question', 'text': 'SUBJECT:'}, {'entity_name': 'answer', 'text': \"OLD GOLD- LIGHT BOX 100'S PROGRESS REPORT\"}, {'entity_name': 'question', 'text': 'GEOGRAPHY'}, {'entity_name': 'question', 'text': 'PARTIAL'}, {'entity_name': 'question', 'text': 'REGION:'}, {'entity_name': 'question', 'text': 'FULL'}, {'entity_name': 'header', 'text': 'DIVISION:'}, {'entity_name': 'question', 'text': 'FULL'}, {'entity_name': 'answer', 'text': 'X'}, {'entity_name': 'question', 'text': 'PARTIAL'}, {'entity_name': 'answer', 'text': 'Detroit North'}, {'entity_name': 'question', 'text': '# REPS:'}, {'entity_name': 'question', 'text': 'DIVISION NAME:'}, {'entity_name': 'question', 'text': 'DIVISION NAME:'}, {'entity_name': 'answer', 'text': '13'}, {'entity_name': 'answer', 'text': 'Detroit South'}, {'entity_name': 'answer', 'text': '12'}, {'entity_name': 'question', 'text': '# REPS:'}, {'entity_name': 'question', 'text': 'DIVISION NAME:'}, {'entity_name': 'answer', 'text': 'Detroit East'}, {'entity_name': 'question', 'text': 'DIVISION NAME:'}, {'entity_name': 'answer', 'text': 'Detroit West'}, {'entity_name': 'question', 'text': 'DIVISION NAME:'}, {'entity_name': 'answer', 'text': 'Grand Rapids'}, {'entity_name': 'question', 'text': 'DIVISION NAME:'}, {'entity_name': 'question', 'text': '# REPS:'}, {'entity_name': 'answer', 'text': '13'}, {'entity_name': 'answer', 'text': 'Flint'}, {'entity_name': 'question', 'text': 'DISTRIBUTION'}, {'entity_name': 'question', 'text': 'Name of Account'}, {'entity_name': 'question', 'text': 'Name of Account'}, {'entity_name': 'question', 'text': 'Ind/Lor Volume'}, {'entity_name': 'question', 'text': 'Ind/Lor Volume'}, {'entity_name': 'question', 'text': 'Number of Stores'}, {'entity_name': 'question', 'text': 'Number of Stores'}, {'entity_name': 'question', 'text': 'Quality Dairy'}, {'entity_name': 'answer', 'text': '151/15'}, {'entity_name': 'answer', 'text': '31'}, {'entity_name': 'question', 'text': 'Speedy Q'}, {'entity_name': 'answer', 'text': '196/13'}, {'entity_name': 'answer', 'text': '16'}, {'entity_name': 'question', 'text': 'Bay Stations'}, {'entity_name': 'answer', 'text': '81/9'}, {'entity_name': 'answer', 'text': '1818'}, {'entity_name': 'answer', 'text': '138/9'}, {'entity_name': 'answer', 'text': 'Schmu'}, {'entity_name': 'question', 'text': 'ckal Di'}, {'entity_name': 'answer', 'text': 'l'}, {'entity_name': 'answer', 'text': '22'}, {'entity_name': 'answer', 'text': 'Wilson Oil'}, {'entity_name': 'answer', 'text': '140/13'}, {'entity_name': 'answer', 'text': '15'}, {'entity_name': 'answer', 'text': '117/9'}, {'entity_name': 'answer', 'text': '24'}, {'entity_name': 'question', 'text': 'Quik Stop'}, {'entity_name': 'question', 'text': 'Fo'}, {'entity_name': 'answer', 'text': 'rwards'}, {'entity_name': 'answer', 'text': '19'}, {'entity_name': 'answer', 'text': '118/8'}, {'entity_name': 'answer', 'text': 'Phil Flint'}, {'entity_name': 'answer', 'text': '166/15'}, {'entity_name': 'answer', 'text': '15'}, {'entity_name': 'answer', 'text': '209'}, {'entity_name': 'answer', 'text': 'Arbor Rx'}, {'entity_name': 'answer', 'text': '115/13'}, {'entity_name': 'answer', 'text': '163/11'}, {'entity_name': 'answer', 'text': '32'}, {'entity_name': 'question', 'text': 'Imperial Oil'}, {'entity_name': 'answer', 'text': 'Direct Accounts and Chains Head'}, {'entity_name': 'question', 'text': 'Name of Account'}, {'entity_name': 'question', 'text': 'Name of Account'}, {'entity_name': 'question', 'text': 'Ind/Lor Volume'}, {'entity_name': 'question', 'text': 'Ind/Lor Volume'}, {'entity_name': 'question', 'text': 'Number of Stores'}, {'entity_name': 'question', 'text': 'Number of Stores'}, {'entity_name': 'question', 'text': 'Clark Gas'}, {'entity_name': 'answer', 'text': '142'}, {'entity_name': 'question', 'text': 'Emra'}, {'entity_name': 'answer', 'text': '237'}, {'entity_name': 'answer', 'text': '102'}, {'entity_name': 'answer', 'text': '7- Eleven Southland'}, {'entity_name': 'question', 'text': 'Walmart'}, {'entity_name': 'answer', 'text': '39'}, {'entity_name': 'question', 'text': 'Ultra Diamond'}, {'entity_name': 'answer', 'text': '184'}, {'entity_name': 'question', 'text': 'Dai'}, {'entity_name': 'answer', 'text': 'ry Mart'}, {'entity_name': 'answer', 'text': '32'}, {'entity_name': 'answer', 'text': '40'}, {'entity_name': 'answer', 'text': 'Mobil Oil'}, {'entity_name': 'question', 'text': 'ACA Amoc'}, {'entity_name': 'answer', 'text': 'o'}, {'entity_name': 'answer', 'text': '31'}]\n",
      "2it [00:00,  2.53it/s]['inference/2_test_img/93106788.png']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 2, 5, 5, 5, 5, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 2, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 2, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 6, 5, 5, 5, 5, 5, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 6, 6, 5, 6, 5, 6, 5, 6, 5, 6, 5, 5, 5, 5, 5, 5, 5, 6, 5, 5, 6, 6, 6, 5, 5, 5, 6, 5, 5, 6, 5, 6, 5, 6, 5, 5, 5, 5, 5, 6, 5, 6, 6, 6, 6, 5, 6, 6, 5, 6, 5, 5, 6, 5, 5, 5, 5, 6, 5, 6, 6, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]]\r\n",
      "[('question', (91, 95)), ('answer', (96, 109)), ('question', (110, 112)), ('question', (162, 172)), ('question', (186, 190)), ('question', (191, 198)), ('question', (199, 205)), ('question', (306, 311)), ('question', (312, 316)), ('question', (317, 324)), ('question', (325, 328)), ('question', (329, 343)), ('question', (344, 347)), ('question', (348, 356)), ('question', (357, 367)), ('question', (369, 369)), ('question', (476, 503)), ('question', (504, 539)), ('answer', (540, 600)), ('question', (601, 631)), ('question', (632, 704)), ('question', (705, 722)), ('question', (723, 731)), ('answer', (732, 755)), ('answer', (756, 785)), ('question', (844, 870)), ('question', (871, 893)), ('question', (894, 923)), ('question', (924, 924)), ('question', (926, 930)), ('answer', (931, 935)), ('question', (936, 946)), ('question', (948, 948)), ('question', (951, 951)), ('question', (953, 953)), ('question', (955, 955)), ('question', (957, 957)), ('question', (959, 965)), ('question', (967, 968)), ('question', (972, 974)), ('question', (976, 977)), ('question', (979, 979)), ('question', (981, 981)), ('question', (983, 987)), ('question', (989, 989)), ('question', (994, 994)), ('question', (997, 997)), ('question', (999, 1000)), ('question', (1002, 1005)), ('question', (1007, 1007)), ('question', (1010, 1033)), ('question', (1034, 1133)), ('question', (1134, 1220)), ('question', (1400, 1410)), ('question', (1411, 1415))]\r\n",
      "[{'entity_name': 'question', 'text': 'DATE:'}, {'entity_name': 'answer', 'text': 'MARCH 17, 1995'}, {'entity_name': 'question', 'text': 'TO:'}, {'entity_name': 'question', 'text': 'ADVERTISER:'}, {'entity_name': 'question', 'text': 'ATTN:'}, {'entity_name': 'question', 'text': 'PRODUCT:'}, {'entity_name': 'question', 'text': 'NEWPORT'}, {'entity_name': 'question', 'text': 'SPACE:'}, {'entity_name': 'question', 'text': 'DATE:'}, {'entity_name': 'question', 'text': 'CAPTION:'}, {'entity_name': 'question', 'text': 'AD#:'}, {'entity_name': 'question', 'text': 'FOUNTAIN COUPLE'}, {'entity_name': 'question', 'text': 'P5CE'}, {'entity_name': 'question', 'text': 'JUNE 1995'}, {'entity_name': 'question', 'text': 'NPT- 533- 7'}, {'entity_name': 'question', 'text': 'O'}, {'entity_name': 'question', 'text': 'POSITION URGENTLY REQUESTED:'}, {'entity_name': 'question', 'text': 'FAR FORWARD, OPPOSITE FULL EDITORIAL'}, {'entity_name': 'answer', 'text': '- Maintain at least six page separation from bompetitive ads.'}, {'entity_name': 'question', 'text': '- No coupon ad on backing page.'}, {'entity_name': 'question', 'text': '- No aditional/ advertising matter to cigarette within 6 pages of our ad.'}, {'entity_name': 'question', 'text': 'COPY INSTRUCTIONS:'}, {'entity_name': 'question', 'text': 'Cigarette'}, {'entity_name': 'answer', 'text': 'SURGEON GENERALS WARNING'}, {'entity_name': 'answer', 'text': 'Smoke contains carbon Monoxide'}, {'entity_name': 'question', 'text': 'SPACE BILLING INSTRUCTIONS:'}, {'entity_name': 'question', 'text': 'IMPORTANT INSTRUCTIONS:'}, {'entity_name': 'question', 'text': 'The space is being brdered by:'}, {'entity_name': 'question', 'text': 'A'}, {'entity_name': 'question', 'text': ' Chec'}, {'entity_name': 'answer', 'text': 'k mat'}, {'entity_name': 'question', 'text': 'erial caref'}, {'entity_name': 'question', 'text': 'l'}, {'entity_name': 'question', 'text': ' '}, {'entity_name': 'question', 'text': 'g'}, {'entity_name': 'question', 'text': 'i'}, {'entity_name': 'question', 'text': 's'}, {'entity_name': 'question', 'text': ' proof '}, {'entity_name': 'question', 'text': 'o '}, {'entity_name': 'question', 'text': 'e s'}, {'entity_name': 'question', 'text': 're'}, {'entity_name': 'question', 'text': 'i'}, {'entity_name': 'question', 'text': ' '}, {'entity_name': 'question', 'text': 'orres'}, {'entity_name': 'question', 'text': 'o'}, {'entity_name': 'question', 'text': 'i'}, {'entity_name': 'question', 'text': 'e'}, {'entity_name': 'question', 'text': 'er'}, {'entity_name': 'question', 'text': ' res'}, {'entity_name': 'question', 'text': 'e'}, {'entity_name': 'question', 'text': 'LOAILLARD MEDIA SERVICES'}, {'entity_name': 'question', 'text': 'B. Please inspect repro material immediately. They should produce good printing results. Advise us p'}, {'entity_name': 'question', 'text': 'Direct all invoices and full checking copies of all regional and national additions to:'}, {'entity_name': 'question', 'text': 'TEVE MOLLOY'}, {'entity_name': 'question', 'text': 'ATTN:'}]\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [00:01,  2.74it/s]\r",
      "3it [00:01,  2.84it/s]\r\n"
     ]
    }
   ],
   "source": [
    "!python3 test.py --checkpoint ./saved/models/PICK_Default/test_0321_140123/model_best.pth \\\n",
    "                 --boxes_transcripts ./inference/2_test_boxes_and_transcripts/ \\\n",
    "                 --images_path ./inference/2_test_img/ --output_folder ./inference/output/ \\\n",
    "                 --gpu 0 --batch_size 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint: ./saved/models/PICK_Default/test_0328_173509/model_best.pth \n",
      "with saved mEF 0.5680 ...\n",
      "0it [00:00, ?it/s]['inference/2_test_img/91814768_91814769.png']\n",
      "[[2, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 5, 6, 6, 6, 6, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 6, 5, 5, 5, 5, 5, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 4, 4, 4, 4, 6, 4, 4, 4, 6, 4, 4, 4, 6, 4, 4, 6, 4, 6, 4, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 5, 6, 5, 6, 5, 6, 5, 5, 5, 5, 6, 1, 4, 4, 4, 4, 2, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 2, 6, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 2, 5, 1, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 5, 1, 4, 4, 4, 5, 4, 5, 4, 5, 4, 5, 4, 5, 4, 5, 4, 5, 4, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]]\n",
      "[('values', (0, 0)), ('values', (2, 10)), ('values', (12, 12)), ('header', (17, 105)), ('keys', (106, 134)), ('values', (135, 163)), ('values', (164, 164)), ('keys', (165, 174)), ('values', (175, 175)), ('values', (177, 181)), ('values', (183, 183)), ('values', (273, 273)), ('values', (275, 299)), ('keys', (300, 305)), ('keys', (307, 309)), ('keys', (311, 313)), ('keys', (315, 316)), ('keys', (318, 318)), ('keys', (320, 320)), ('keys', (322, 322)), ('values', (373, 373)), ('values', (375, 375)), ('values', (377, 377)), ('values', (379, 379)), ('values', (381, 384)), ('keys', (386, 390)), ('values', (391, 391)), ('values', (392, 448)), ('keys', (449, 468)), ('values', (469, 493)), ('keys', (494, 515)), ('keys', (516, 540)), ('values', (541, 621)), ('keys', (622, 636)), ('values', (637, 663)), ('values', (664, 676)), ('values', (677, 680)), ('values', (681, 681)), ('values', (683, 686)), ('values', (687, 694)), ('values', (695, 696)), ('keys', (697, 702)), ('keys', (703, 728)), ('keys', (729, 758)), ('keys', (759, 773)), ('keys', (774, 779)), ('values', (780, 879)), ('values', (880, 895)), ('values', (896, 897)), ('values', (898, 908)), ('values', (909, 910)), ('keys', (911, 920)), ('values', (921, 946)), ('keys', (947, 959)), ('values', (960, 960)), ('values', (961, 1060)), ('values', (1061, 1098)), ('values', (1099, 1112)), ('values', (1113, 1113)), ('keys', (1114, 1129)), ('keys', (1130, 1133)), ('keys', (1134, 1152)), ('header', (1153, 1181)), ('keys', (1182, 1198)), ('keys', (1199, 1243)), ('keys', (1244, 1250)), ('keys', (1251, 1259)), ('values', (1260, 1266)), ('keys', (1267, 1270)), ('values', (1271, 1271)), ('keys', (1272, 1272)), ('values', (1273, 1273)), ('keys', (1274, 1274)), ('values', (1275, 1275)), ('keys', (1276, 1276)), ('values', (1277, 1277)), ('keys', (1278, 1278)), ('values', (1279, 1279)), ('keys', (1280, 1280)), ('values', (1281, 1281)), ('keys', (1282, 1282)), ('values', (1283, 1283)), ('keys', (1284, 1284)), ('values', (1285, 1285)), ('values', (1286, 1296)), ('values', (1297, 1326)), ('keys', (1327, 1356)), ('values', (1357, 1366)), ('values', (1367, 1376)), ('keys', (1377, 1394)), ('values', (1395, 1426)), ('values', (1427, 1436)), ('values', (1437, 1439)), ('keys', (1440, 1440)), ('values', (1441, 1466)), ('values', (1474, 1474)), ('values', (1475, 1484)), ('keys', (1485, 1534)), ('values', (1535, 1545)), ('keys', (1546, 1600)), ('values', (1689, 1699)), ('keys', (1700, 1742))]\n",
      "[{'entity_name': 'values', 'text': 'O'}, {'entity_name': 'values', 'text': 'fice Use '}, {'entity_name': 'values', 'text': 'n'}, {'entity_name': 'header', 'text': 'ORRECTED FORM\" The Commonwealth of Massachusetts OFFICE OF CAMPAIGN AND POLITICAL FINANCE'}, {'entity_name': 'keys', 'text': 'REPORT OF CORPORATE TREASURER'}, {'entity_name': 'values', 'text': 'Form CPF 22 (formerly CPF 10)'}, {'entity_name': 'values', 'text': ' '}, {'entity_name': 'keys', 'text': 'File with:'}, {'entity_name': 'values', 'text': '('}, {'entity_name': 'values', 'text': 'HECK '}, {'entity_name': 'values', 'text': 'N'}, {'entity_name': 'values', 'text': ' '}, {'entity_name': 'values', 'text': '0th Day Prior to Election'}, {'entity_name': 'keys', 'text': 'O 5th '}, {'entity_name': 'keys', 'text': 'ay '}, {'entity_name': 'keys', 'text': 'f t'}, {'entity_name': 'keys', 'text': 'e '}, {'entity_name': 'keys', 'text': 'o'}, {'entity_name': 'keys', 'text': 't'}, {'entity_name': 'keys', 'text': 'O'}, {'entity_name': 'values', 'text': ' '}, {'entity_name': 'values', 'text': 'i'}, {'entity_name': 'values', 'text': 'n'}, {'entity_name': 'values', 'text': 't'}, {'entity_name': 'values', 'text': 'res.'}, {'entity_name': 'keys', 'text': 'Final'}, {'entity_name': 'values', 'text': ' '}, {'entity_name': 'values', 'text': 'M. Alfred Peterson; Assistant Treasurer Peter J. Marzullo'}, {'entity_name': 'keys', 'text': '1. Name of Treasurer'}, {'entity_name': 'values', 'text': 'Lorillard Tobacco Company'}, {'entity_name': 'keys', 'text': '2. Name of Corporation'}, {'entity_name': 'keys', 'text': '3. Address of Corporation'}, {'entity_name': 'values', 'text': 'One Park Avenue New York. NY 10016 -58951 relating to Tobacco Excise Tax Increase'}, {'entity_name': 'keys', 'text': '4. Question No.'}, {'entity_name': 'values', 'text': '(Describe question briefly)'}, {'entity_name': 'values', 'text': 'Massachusetts'}, {'entity_name': 'values', 'text': '1992'}, {'entity_name': 'values', 'text': 'b'}, {'entity_name': 'values', 'text': 'llot'}, {'entity_name': 'values', 'text': 'November'}, {'entity_name': 'values', 'text': '3,'}, {'entity_name': 'keys', 'text': 'on the'}, {'entity_name': 'keys', 'text': 'submitted to the voters on'}, {'entity_name': 'keys', 'text': '(Name of City/ Town of State)*'}, {'entity_name': 'keys', 'text': '(Election Date)'}, {'entity_name': 'keys', 'text': '*Note:'}, {'entity_name': 'values', 'text': 'If this expenditure is made to influence a local ballot question, a copy of this form should be file'}, {'entity_name': 'values', 'text': 'November 5. 1992'}, {'entity_name': 'values', 'text': '92'}, {'entity_name': 'values', 'text': 'October 16,'}, {'entity_name': 'values', 'text': '19'}, {'entity_name': 'keys', 'text': 'and Ending'}, {'entity_name': 'values', 'text': 'Reporting Period Beginning'}, {'entity_name': 'keys', 'text': 'Fil in Dates:'}, {'entity_name': 'values', 'text': ' '}, {'entity_name': 'values', 'text': 'contribution I certify that this report is a true statement of the amount of value of gift, payment,'}, {'entity_name': 'values', 'text': 'Signed under the penalties of perjury.'}, {'entity_name': 'values', 'text': 'March 30, 1993'}, {'entity_name': 'values', 'text': ' '}, {'entity_name': 'keys', 'text': 'Preasurer Senato'}, {'entity_name': 'keys', 'text': 'Date'}, {'entity_name': 'keys', 'text': 'Assistant Treasurer'}, {'entity_name': 'header', 'text': 'EXPENDITURES OR DISBURSEMENTS'}, {'entity_name': 'keys', 'text': 'Amount or Value**'}, {'entity_name': 'keys', 'text': 'To Whom Paid (Alphabetical Listing Mandatory)'}, {'entity_name': 'keys', 'text': 'Purpose'}, {'entity_name': 'keys', 'text': 'Date Paid'}, {'entity_name': 'values', 'text': 'Address'}, {'entity_name': 'keys', 'text': 'Oppo'}, {'entity_name': 'values', 'text': 's'}, {'entity_name': 'keys', 'text': 'e'}, {'entity_name': 'values', 'text': ' '}, {'entity_name': 'keys', 'text': 'T'}, {'entity_name': 'values', 'text': 'a'}, {'entity_name': 'keys', 'text': 'x'}, {'entity_name': 'values', 'text': ' '}, {'entity_name': 'keys', 'text': 'I'}, {'entity_name': 'values', 'text': 'n'}, {'entity_name': 'keys', 'text': 'c'}, {'entity_name': 'values', 'text': 'r'}, {'entity_name': 'keys', 'text': 'e'}, {'entity_name': 'values', 'text': 'a'}, {'entity_name': 'keys', 'text': 's'}, {'entity_name': 'values', 'text': 'e'}, {'entity_name': 'values', 'text': '28, 482. 00'}, {'entity_name': 'values', 'text': 'P. O. B03 5979 Boston, MA 0212'}, {'entity_name': 'keys', 'text': 'Committee Against Unfair Taxes'}, {'entity_name': 'values', 'text': '10/ 26/ 92'}, {'entity_name': 'values', 'text': '19, 503 00'}, {'entity_name': 'keys', 'text': 'Oppose Tax increas'}, {'entity_name': 'values', 'text': 'P. O. Box 5979. Boston, MA 02114'}, {'entity_name': 'values', 'text': '10/ 30/ 92'}, {'entity_name': 'values', 'text': 'Com'}, {'entity_name': 'keys', 'text': 'm'}, {'entity_name': 'values', 'text': 'ittee Against Unfair Taxes'}, {'entity_name': 'values', 'text': '8'}, {'entity_name': 'values', 'text': '48, 585 00'}, {'entity_name': 'keys', 'text': 'Total Expenditures or Disbursements on This Report'}, {'entity_name': 'values', 'text': '508. 789 00'}, {'entity_name': 'keys', 'text': 'Total Expenditures for Disbursements Previously Reporte'}, {'entity_name': 'values', 'text': '556 874. 00'}, {'entity_name': 'keys', 'text': 'Total Expenditures or Disbursements to Date'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1it [00:00,  2.00it/s]['inference/2_test_img/83641919_1921.png']\n",
      "[[1, 4, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 1, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 4, 5, 4, 5, 4, 5, 4, 1, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 2, 5, 5, 5, 2, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 3, 4, 3, 4, 3, 4, 3, 4, 2, 4, 5, 5, 2, 1, 4, 4, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 1, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 2, 5, 2, 5, 5, 5, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 2, 5, 1, 4, 4, 4, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 2, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 5, 5, 2, 5, 5, 5, 2, 5, 5, 5, 5, 1, 5, 4, 5, 4, 5, 5, 4, 5, 4, 5, 4, 5, 2, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 2, 5, 2, 5, 5, 5, 5, 2, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 2, 5, 2, 5, 5, 5, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 2, 5, 2, 5, 5, 1, 4, 4, 4, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 2, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 5, 4, 5, 4, 5, 4, 5, 2, 5, 5, 1, 4, 4, 4, 2, 6, 5, 2, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 5, 4, 5, 2, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 1, 6, 4, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]]\n",
      "[('keys', (0, 2)), ('values', (3, 13)), ('keys', (14, 28)), ('keys', (29, 34)), ('keys', (35, 40)), ('values', (41, 56)), ('values', (57, 57)), ('keys', (58, 62)), ('keys', (63, 68)), ('keys', (69, 76)), ('values', (77, 117)), ('keys', (118, 118)), ('values', (119, 119)), ('keys', (120, 120)), ('values', (121, 121)), ('keys', (122, 122)), ('values', (123, 123)), ('keys', (124, 124)), ('values', (125, 125)), ('keys', (126, 126)), ('keys', (127, 133)), ('keys', (134, 140)), ('values', (141, 144)), ('values', (145, 145)), ('keys', (146, 202)), ('keys', (203, 203)), ('header', (204, 204)), ('keys', (205, 205)), ('header', (206, 206)), ('keys', (207, 207)), ('header', (208, 208)), ('keys', (209, 209)), ('header', (210, 210)), ('keys', (211, 211)), ('values', (212, 212)), ('keys', (213, 213)), ('values', (214, 215)), ('values', (216, 216)), ('keys', (217, 223)), ('values', (224, 236)), ('keys', (237, 243)), ('keys', (244, 257)), ('keys', (258, 271)), ('values', (272, 273)), ('keys', (274, 286)), ('values', (287, 288)), ('keys', (289, 295)), ('keys', (296, 309)), ('values', (310, 321)), ('keys', (322, 335)), ('values', (336, 347)), ('keys', (348, 361)), ('values', (362, 373)), ('keys', (374, 387)), ('keys', (388, 394)), ('values', (395, 396)), ('values', (397, 401)), ('keys', (402, 413)), ('values', (414, 513)), ('keys', (514, 528)), ('keys', (529, 543)), ('keys', (544, 557)), ('keys', (558, 571)), ('keys', (572, 587)), ('keys', (588, 603)), ('keys', (604, 616)), ('values', (617, 622)), ('values', (623, 624)), ('keys', (625, 632)), ('values', (633, 638)), ('values', (639, 640)), ('keys', (641, 652)), ('values', (653, 656)), ('values', (657, 660)), ('values', (661, 665)), ('keys', (666, 666)), ('values', (667, 667)), ('keys', (668, 668)), ('values', (669, 669)), ('keys', (670, 670)), ('values', (671, 672)), ('keys', (673, 673)), ('values', (674, 674)), ('keys', (675, 675)), ('values', (676, 676)), ('keys', (677, 677)), ('values', (678, 678)), ('values', (679, 680)), ('values', (681, 690)), ('values', (691, 696)), ('values', (697, 698)), ('values', (699, 703)), ('values', (704, 705)), ('keys', (706, 714)), ('keys', (715, 722)), ('values', (723, 724)), ('values', (725, 729)), ('keys', (730, 739)), ('values', (740, 745)), ('values', (746, 747)), ('values', (748, 750)), ('keys', (751, 758)), ('values', (759, 764)), ('values', (765, 770)), ('values', (771, 772)), ('keys', (773, 784)), ('values', (785, 884)), ('keys', (885, 899)), ('keys', (900, 914)), ('keys', (915, 928)), ('keys', (929, 942)), ('values', (943, 958)), ('keys', (959, 974)), ('keys', (975, 976)), ('values', (977, 977)), ('keys', (978, 978)), ('values', (979, 979)), ('keys', (980, 980)), ('values', (981, 981)), ('keys', (982, 982)), ('values', (983, 983)), ('values', (984, 986)), ('keys', (987, 990)), ('values', (991, 991)), ('values', (993, 993)), ('values', (994, 996)), ('values', (997, 1015)), ('keys', (1016, 1016)), ('values', (1017, 1020)), ('keys', (1021, 1021)), ('values', (1022, 1022)), ('values', (1023, 1024)), ('keys', (1025, 1037)), ('values', (1038, 1040)), ('keys', (1041, 1050)), ('values', (1051, 1051)), ('values', (1062, 1062)), ('keys', (1063, 1071)), ('keys', (1072, 1072)), ('keys', (1074, 1075))]\n",
      "[{'entity_name': 'keys', 'text': 'TO:'}, {'entity_name': 'values', 'text': 'S. P. ZOLOT'}, {'entity_name': 'keys', 'text': 'SUBMISSION DATE'}, {'entity_name': 'keys', 'text': 'OCT 05'}, {'entity_name': 'keys', 'text': 'DEC 21'}, {'entity_name': 'values', 'text': 'R. W. RICHARDSON'}, {'entity_name': 'values', 'text': 'X'}, {'entity_name': 'keys', 'text': 'FROM:'}, {'entity_name': 'keys', 'text': 'NOV 16'}, {'entity_name': 'keys', 'text': 'SUBJECT:'}, {'entity_name': 'values', 'text': \"OLD GOLD- LIGHT BOX 100'S PROGRESS REPORT\"}, {'entity_name': 'keys', 'text': 'G'}, {'entity_name': 'values', 'text': 'E'}, {'entity_name': 'keys', 'text': 'O'}, {'entity_name': 'values', 'text': 'G'}, {'entity_name': 'keys', 'text': 'R'}, {'entity_name': 'values', 'text': 'A'}, {'entity_name': 'keys', 'text': 'P'}, {'entity_name': 'values', 'text': 'H'}, {'entity_name': 'keys', 'text': 'Y'}, {'entity_name': 'keys', 'text': 'PARTIAL'}, {'entity_name': 'keys', 'text': 'REGION:'}, {'entity_name': 'values', 'text': 'FULL'}, {'entity_name': 'values', 'text': 'X'}, {'entity_name': 'keys', 'text': '(ONLY IF PARTIAL REGION, CONTINUE WITH DIVISION(S) SCOPE)'}, {'entity_name': 'keys', 'text': 'D'}, {'entity_name': 'header', 'text': 'I'}, {'entity_name': 'keys', 'text': 'V'}, {'entity_name': 'header', 'text': 'I'}, {'entity_name': 'keys', 'text': 'S'}, {'entity_name': 'header', 'text': 'I'}, {'entity_name': 'keys', 'text': 'O'}, {'entity_name': 'header', 'text': 'N'}, {'entity_name': 'keys', 'text': ':'}, {'entity_name': 'values', 'text': 'F'}, {'entity_name': 'keys', 'text': 'U'}, {'entity_name': 'values', 'text': 'LL'}, {'entity_name': 'values', 'text': 'X'}, {'entity_name': 'keys', 'text': 'PARTIAL'}, {'entity_name': 'values', 'text': 'Detroit North'}, {'entity_name': 'keys', 'text': '# REPS:'}, {'entity_name': 'keys', 'text': 'DIVISION NAME:'}, {'entity_name': 'keys', 'text': 'DIVISION NAME:'}, {'entity_name': 'values', 'text': '13'}, {'entity_name': 'keys', 'text': 'Detroit South'}, {'entity_name': 'values', 'text': '12'}, {'entity_name': 'keys', 'text': '# REPS:'}, {'entity_name': 'keys', 'text': 'DIVISION NAME:'}, {'entity_name': 'values', 'text': 'Detroit East'}, {'entity_name': 'keys', 'text': 'DIVISION NAME:'}, {'entity_name': 'values', 'text': 'Detroit West'}, {'entity_name': 'keys', 'text': 'DIVISION NAME:'}, {'entity_name': 'values', 'text': 'Grand Rapids'}, {'entity_name': 'keys', 'text': 'DIVISION NAME:'}, {'entity_name': 'keys', 'text': '# REPS:'}, {'entity_name': 'values', 'text': '13'}, {'entity_name': 'values', 'text': 'Flint'}, {'entity_name': 'keys', 'text': 'DISTRIBUTION'}, {'entity_name': 'values', 'text': 'Direct Accounts and Chains Headquartered within the Region (15+ Stores) Stocking No Old Gold Light B'}, {'entity_name': 'keys', 'text': 'Name of Account'}, {'entity_name': 'keys', 'text': 'Name of Account'}, {'entity_name': 'keys', 'text': 'Ind/Lor Volume'}, {'entity_name': 'keys', 'text': 'Ind/Lor Volume'}, {'entity_name': 'keys', 'text': 'Number of Stores'}, {'entity_name': 'keys', 'text': 'Number of Stores'}, {'entity_name': 'keys', 'text': 'Quality Dairy'}, {'entity_name': 'values', 'text': '151/15'}, {'entity_name': 'values', 'text': '31'}, {'entity_name': 'keys', 'text': 'Speedy Q'}, {'entity_name': 'values', 'text': '196/13'}, {'entity_name': 'values', 'text': '16'}, {'entity_name': 'keys', 'text': 'Bay Stations'}, {'entity_name': 'values', 'text': '81/9'}, {'entity_name': 'values', 'text': '1818'}, {'entity_name': 'values', 'text': '138/9'}, {'entity_name': 'keys', 'text': 'S'}, {'entity_name': 'values', 'text': 'c'}, {'entity_name': 'keys', 'text': 'h'}, {'entity_name': 'values', 'text': 'm'}, {'entity_name': 'keys', 'text': 'u'}, {'entity_name': 'values', 'text': 'ck'}, {'entity_name': 'keys', 'text': 'a'}, {'entity_name': 'values', 'text': 'l'}, {'entity_name': 'keys', 'text': ' '}, {'entity_name': 'values', 'text': 'D'}, {'entity_name': 'keys', 'text': 'i'}, {'entity_name': 'values', 'text': 'l'}, {'entity_name': 'values', 'text': '22'}, {'entity_name': 'values', 'text': 'Wilson Oil'}, {'entity_name': 'values', 'text': '140/13'}, {'entity_name': 'values', 'text': '15'}, {'entity_name': 'values', 'text': '117/9'}, {'entity_name': 'values', 'text': '24'}, {'entity_name': 'keys', 'text': 'Quik Stop'}, {'entity_name': 'keys', 'text': 'Forwards'}, {'entity_name': 'values', 'text': '19'}, {'entity_name': 'values', 'text': '118/8'}, {'entity_name': 'keys', 'text': 'Phil Flint'}, {'entity_name': 'values', 'text': '166/15'}, {'entity_name': 'values', 'text': '15'}, {'entity_name': 'values', 'text': '209'}, {'entity_name': 'keys', 'text': 'Arbor Rx'}, {'entity_name': 'values', 'text': '115/13'}, {'entity_name': 'values', 'text': '163/11'}, {'entity_name': 'values', 'text': '32'}, {'entity_name': 'keys', 'text': 'Imperial Oil'}, {'entity_name': 'values', 'text': 'Direct Accounts and Chains Headquartered Outside the Region. (15+ Stores) Stocking No Old Gold Light'}, {'entity_name': 'keys', 'text': 'Name of Account'}, {'entity_name': 'keys', 'text': 'Name of Account'}, {'entity_name': 'keys', 'text': 'Ind/Lor Volume'}, {'entity_name': 'keys', 'text': 'Ind/Lor Volume'}, {'entity_name': 'values', 'text': 'Number of Stores'}, {'entity_name': 'keys', 'text': 'Number of Stores'}, {'entity_name': 'keys', 'text': 'Cl'}, {'entity_name': 'values', 'text': 'a'}, {'entity_name': 'keys', 'text': 'r'}, {'entity_name': 'values', 'text': 'k'}, {'entity_name': 'keys', 'text': ' '}, {'entity_name': 'values', 'text': 'G'}, {'entity_name': 'keys', 'text': 'a'}, {'entity_name': 'values', 'text': 's'}, {'entity_name': 'values', 'text': '142'}, {'entity_name': 'keys', 'text': 'Emra'}, {'entity_name': 'values', 'text': '2'}, {'entity_name': 'values', 'text': '7'}, {'entity_name': 'values', 'text': '102'}, {'entity_name': 'values', 'text': '7- Eleven Southland'}, {'entity_name': 'keys', 'text': 'W'}, {'entity_name': 'values', 'text': 'alma'}, {'entity_name': 'keys', 'text': 'r'}, {'entity_name': 'values', 'text': 't'}, {'entity_name': 'values', 'text': '39'}, {'entity_name': 'keys', 'text': 'Ultra Diamond'}, {'entity_name': 'values', 'text': '184'}, {'entity_name': 'keys', 'text': 'Dairy Mart'}, {'entity_name': 'values', 'text': '3'}, {'entity_name': 'values', 'text': '0'}, {'entity_name': 'keys', 'text': 'Mobil Oil'}, {'entity_name': 'keys', 'text': 'A'}, {'entity_name': 'keys', 'text': 'A '}]\n",
      "2it [00:00,  2.33it/s]['inference/2_test_img/93106788.png']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 4, 2, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 5, 5, 5, 5, 5, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 6, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 5, 5, 2, 6, 5, 6, 5, 6, 5, 6, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 5, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 6, 5, 6, 6, 6, 6, 5, 6, 6, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 5, 6, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]]\r\n",
      "[('header', (0, 90)), ('keys', (91, 95)), ('values', (96, 109)), ('keys', (110, 112)), ('values', (113, 113)), ('values', (155, 161)), ('keys', (162, 172)), ('keys', (173, 174)), ('keys', (176, 185)), ('keys', (186, 190)), ('keys', (191, 198)), ('keys', (199, 205)), ('keys', (306, 311)), ('keys', (312, 316)), ('keys', (317, 324)), ('keys', (325, 328)), ('keys', (329, 343)), ('values', (344, 347)), ('values', (348, 348)), ('values', (350, 350)), ('values', (352, 352)), ('values', (354, 354)), ('values', (356, 356)), ('keys', (357, 367)), ('keys', (368, 369)), ('keys', (476, 503)), ('keys', (504, 539)), ('values', (540, 600)), ('keys', (601, 631)), ('keys', (632, 704)), ('keys', (705, 722)), ('keys', (723, 731)), ('values', (732, 755)), ('values', (756, 785)), ('keys', (786, 843)), ('keys', (844, 870)), ('keys', (871, 893)), ('keys', (894, 923)), ('values', (924, 924)), ('values', (926, 926)), ('values', (973, 973)), ('values', (978, 978)), ('values', (981, 981)), ('keys', (1010, 1033)), ('keys', (1034, 1034)), ('keys', (1134, 1220)), ('values', (1221, 1221)), ('values', (1223, 1223)), ('values', (1228, 1228)), ('values', (1231, 1232)), ('values', (1234, 1243)), ('values', (1246, 1246)), ('values', (1248, 1249)), ('values', (1251, 1258)), ('values', (1259, 1339)), ('values', (1340, 1390)), ('keys', (1411, 1415)), ('values', (1416, 1515))]\r\n",
      "[{'entity_name': 'header', 'text': 'LORILLARD MEDIA SERVICES ONE PARK AVENUE, NEW YORK, NY 10016- 5896 MAGAZINE INSERTION ORDER'}, {'entity_name': 'keys', 'text': 'DATE:'}, {'entity_name': 'values', 'text': 'MARCH 17, 1995'}, {'entity_name': 'keys', 'text': 'TO:'}, {'entity_name': 'values', 'text': 'E'}, {'entity_name': 'values', 'text': 'RILLARD'}, {'entity_name': 'keys', 'text': 'ADVERTISER:'}, {'entity_name': 'keys', 'text': 'JO'}, {'entity_name': 'keys', 'text': 'CE WINSTON'}, {'entity_name': 'keys', 'text': 'ATTN:'}, {'entity_name': 'keys', 'text': 'PRODUCT:'}, {'entity_name': 'keys', 'text': 'NEWPORT'}, {'entity_name': 'keys', 'text': 'SPACE:'}, {'entity_name': 'keys', 'text': 'DATE:'}, {'entity_name': 'keys', 'text': 'CAPTION:'}, {'entity_name': 'keys', 'text': 'AD#:'}, {'entity_name': 'keys', 'text': 'FOUNTAIN COUPLE'}, {'entity_name': 'values', 'text': 'P5CE'}, {'entity_name': 'values', 'text': 'J'}, {'entity_name': 'values', 'text': 'N'}, {'entity_name': 'values', 'text': ' '}, {'entity_name': 'values', 'text': '9'}, {'entity_name': 'values', 'text': '5'}, {'entity_name': 'keys', 'text': 'NPT- 533- 7'}, {'entity_name': 'keys', 'text': 'PO'}, {'entity_name': 'keys', 'text': 'POSITION URGENTLY REQUESTED:'}, {'entity_name': 'keys', 'text': 'FAR FORWARD, OPPOSITE FULL EDITORIAL'}, {'entity_name': 'values', 'text': '- Maintain at least six page separation from bompetitive ads.'}, {'entity_name': 'keys', 'text': '- No coupon ad on backing page.'}, {'entity_name': 'keys', 'text': '- No aditional/ advertising matter to cigarette within 6 pages of our ad.'}, {'entity_name': 'keys', 'text': 'COPY INSTRUCTIONS:'}, {'entity_name': 'keys', 'text': 'Cigarette'}, {'entity_name': 'values', 'text': 'SURGEON GENERALS WARNING'}, {'entity_name': 'values', 'text': 'Smoke contains carbon Monoxide'}, {'entity_name': 'keys', 'text': '5 COLOR PROOF ATTACHED, FILM FROM COLLIER WITH \"D\" WARNING'}, {'entity_name': 'keys', 'text': 'SPACE BILLING INSTRUCTIONS:'}, {'entity_name': 'keys', 'text': 'IMPORTANT INSTRUCTIONS:'}, {'entity_name': 'keys', 'text': 'The space is being brdered by:'}, {'entity_name': 'values', 'text': 'A'}, {'entity_name': 'values', 'text': ' '}, {'entity_name': 'values', 'text': ' '}, {'entity_name': 'values', 'text': ' '}, {'entity_name': 'values', 'text': ' '}, {'entity_name': 'keys', 'text': 'LOAILLARD MEDIA SERVICES'}, {'entity_name': 'keys', 'text': 'B'}, {'entity_name': 'keys', 'text': 'Direct all invoices and full checking copies of all regional and national additions to:'}, {'entity_name': 'values', 'text': 'C'}, {'entity_name': 'values', 'text': ' '}, {'entity_name': 'values', 'text': ' '}, {'entity_name': 'values', 'text': 'in'}, {'entity_name': 'values', 'text': 'ing will n'}, {'entity_name': 'values', 'text': ' '}, {'entity_name': 'values', 'text': 'e '}, {'entity_name': 'values', 'text': 'aid for.'}, {'entity_name': 'values', 'text': 'LORILLARD MEDIA SERVICES ONE PARK AVENUE 17TH FLOOR NEW YORK NEW YORK 10016- 5896'}, {'entity_name': 'values', 'text': 'D. Advise us at once if instructions are not clear.'}, {'entity_name': 'keys', 'text': 'ATTN:'}, {'entity_name': 'values', 'text': 'E. Under no circumstances are you to space out our advertisement without specific instructions from '}]\r\n",
      "\r",
      "3it [00:01,  2.59it/s]['inference/2_test_img/36.png']\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 4, 4, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 5, 6, 5, 6, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]]\n",
      "[('header', (0, 80)), ('header', (81, 97)), ('header', (107, 137)), ('keys', (138, 148)), ('values', (149, 214)), ('values', (215, 277)), ('keys', (278, 289)), ('values', (290, 349)), ('values', (350, 405)), ('keys', (406, 418)), ('values', (419, 434)), ('keys', (435, 445)), ('keys', (605, 609)), ('keys', (610, 616)), ('keys', (617, 636)), ('keys', (637, 666)), ('keys', (667, 678)), ('keys', (738, 745)), ('values', (783, 783)), ('values', (785, 785)), ('values', (818, 818)), ('values', (823, 823)), ('values', (825, 825)), ('keys', (827, 839))]\n",
      "[{'entity_name': 'header', 'text': 'Esperion Therapeutics, Inc_Bempedoic Acid (ETC-1002)Amendment 2, 15 November 2017'}, {'entity_name': 'header', 'text': 'Clinical Study Pr'}, {'entity_name': 'header', 'text': \"02-043INVESTIGATOR 'S SIGNATURE\"}, {'entity_name': 'keys', 'text': 'APPENDIX 5.'}, {'entity_name': 'values', 'text': 'A Randomized, Double-blind, Placebo-Controlled Study to Assess the'}, {'entity_name': 'values', 'text': 'Effects of Bempedoic Acid (ETC-1002) on the Occurrence of Major'}, {'entity_name': 'keys', 'text': 'Study Title:'}, {'entity_name': 'values', 'text': 'Cardiovascular Events in Patients with, or at High Risk for;'}, {'entity_name': 'values', 'text': 'Cardiovascular Disease who are Statin Intolerant1002-043'}, {'entity_name': 'keys', 'text': 'Study Number:'}, {'entity_name': 'values', 'text': '10 November 2017'}, {'entity_name': 'keys', 'text': 'Final Date:'}, {'entity_name': 'keys', 'text': 'Date:'}, {'entity_name': 'keys', 'text': 'Signed:'}, {'entity_name': 'keys', 'text': 'Name andKredentials:'}, {'entity_name': 'keys', 'text': 'Title:  Principal Investigator'}, {'entity_name': 'keys', 'text': 'Affiliation:'}, {'entity_name': 'keys', 'text': 'Address:'}, {'entity_name': 'values', 'text': 'r'}, {'entity_name': 'values', 'text': 'k'}, {'entity_name': 'values', 'text': ' '}, {'entity_name': 'values', 'text': '.'}, {'entity_name': 'values', 'text': '5'}, {'entity_name': 'keys', 'text': 'Phone Number:'}]\n",
      "4it [00:01,  3.02it/s]['inference/2_test_img/89368010.png']\n",
      "[[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 1, 5, 4, 5, 4, 5, 5, 4, 5, 4, 5, 5, 4, 5, 1, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 6, 6, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4]]\n",
      "[('header', (12, 33)), ('keys', (34, 43)), ('values', (44, 113)), ('values', (114, 124)), ('keys', (125, 136)), ('values', (137, 149)), ('keys', (150, 164)), ('values', (165, 177)), ('keys', (178, 221)), ('keys', (222, 272)), ('values', (273, 331)), ('values', (332, 381)), ('keys', (382, 405)), ('values', (406, 481)), ('values', (482, 509)), ('keys', (510, 558)), ('values', (559, 654)), ('values', (655, 661)), ('keys', (662, 662)), ('values', (663, 663)), ('keys', (664, 664)), ('values', (665, 665)), ('keys', (666, 666)), ('values', (667, 668)), ('keys', (669, 669)), ('values', (670, 670)), ('keys', (671, 671)), ('values', (672, 673)), ('keys', (674, 674)), ('values', (675, 675)), ('keys', (676, 679)), ('keys', (680, 713)), ('keys', (714, 722)), ('keys', (723, 728)), ('values', (729, 740)), ('keys', (741, 764)), ('keys', (765, 770)), ('values', (771, 781)), ('keys', (782, 801)), ('values', (802, 812)), ('keys', (813, 818)), ('keys', (819, 835)), ('keys', (844, 873)), ('keys', (874, 891))]\n",
      "[{'entity_name': 'header', 'text': 'FINAL REPORT AMENDMENT'}, {'entity_name': 'keys', 'text': 'Study Name'}, {'entity_name': 'values', 'text': 'Acute Toxicity of Reference Cigarette Smoke lafter Inhalation in Mice.'}, {'entity_name': 'values', 'text': 'I- 1725.001'}, {'entity_name': 'keys', 'text': 'Study Number'}, {'entity_name': 'values', 'text': '25 March 1982'}, {'entity_name': 'keys', 'text': 'Initiation Date'}, {'entity_name': 'values', 'text': '27 April 1982'}, {'entity_name': 'keys', 'text': 'Date of Final Report (Review Completed Date)'}, {'entity_name': 'keys', 'text': 'Part of Final Report to be Amended (Exact location)'}, {'entity_name': 'values', 'text': 'The attached is an addition to the I- 1725.001 Final Report'}, {'entity_name': 'values', 'text': 'Survival after repeated doses over a 14 day period'}, {'entity_name': 'keys', 'text': 'Reason for the Amendment'}, {'entity_name': 'values', 'text': \"may not be accurately predicted from survival after a single day's exposure.\"}, {'entity_name': 'values', 'text': 'The report of the results of'}, {'entity_name': 'keys', 'text': 'Amendment (Attach additional sheets as necessary)'}, {'entity_name': 'values', 'text': 'A 14 Day Repeated Dose Assay for Reference Cigarette Smoke in Mice (I- 1725.001- M1 is attached.'}, {'entity_name': 'values', 'text': '16/3/82'}, {'entity_name': 'keys', 'text': 'S'}, {'entity_name': 'values', 'text': 'T'}, {'entity_name': 'keys', 'text': 'U'}, {'entity_name': 'values', 'text': 'D'}, {'entity_name': 'keys', 'text': 'Y'}, {'entity_name': 'values', 'text': ' D'}, {'entity_name': 'keys', 'text': 'I'}, {'entity_name': 'values', 'text': 'R'}, {'entity_name': 'keys', 'text': 'E'}, {'entity_name': 'values', 'text': 'CT'}, {'entity_name': 'keys', 'text': 'O'}, {'entity_name': 'values', 'text': 'R'}, {'entity_name': 'keys', 'text': 'DATE'}, {'entity_name': 'keys', 'text': 'ACCEPT/ REJECT (as per 58.185 (c))'}, {'entity_name': 'keys', 'text': 'APPROVALS'}, {'entity_name': 'keys', 'text': 'Accept'}, {'entity_name': 'values', 'text': '03 June 1982'}, {'entity_name': 'keys', 'text': 'QUALITY ASSURANCE ASSOC.'}, {'entity_name': 'keys', 'text': 'Accept'}, {'entity_name': 'values', 'text': '3 June 1982'}, {'entity_name': 'keys', 'text': 'DIRECTOR OF RESEARCH'}, {'entity_name': 'values', 'text': '3 June 1982'}, {'entity_name': 'keys', 'text': 'Accept'}, {'entity_name': 'keys', 'text': 'DIRECTOR OF RA/QA'}, {'entity_name': 'keys', 'text': 'Received by REGULATORY AFFATRS'}, {'entity_name': 'keys', 'text': 'REGULATORY AFFAIRS'}]\n",
      "5it [00:01,  3.43it/s]['inference/2_test_img/00920294.png']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 4, 1, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 1, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 4, 4, 4, 4, 2, 6, 5, 5, 5, 5, 5, 4, 5, 5, 4, 5, 5, 5, 5, 4, 5, 5, 4, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 2, 5, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 1, 4, 4, 4, 4, 2, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 6, 1, 4, 4, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 2, 6, 6, 6, 2, 6, 5, 5, 1, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]]\n",
      "[('header', (0, 30)), ('keys', (31, 42)), ('values', (43, 48)), ('values', (49, 65)), ('keys', (66, 68)), ('keys', (69, 73)), ('values', (74, 84)), ('values', (85, 92)), ('keys', (93, 97)), ('keys', (98, 110)), ('values', (111, 122)), ('values', (123, 138)), ('keys', (139, 144)), ('values', (145, 145)), ('values', (147, 151)), ('keys', (152, 152)), ('values', (153, 154)), ('keys', (155, 155)), ('values', (156, 159)), ('keys', (160, 160)), ('values', (161, 162)), ('keys', (163, 163)), ('values', (164, 164)), ('values', (165, 191)), ('keys', (192, 203)), ('values', (204, 205)), ('values', (206, 208)), ('keys', (209, 220)), ('values', (221, 221)), ('values', (237, 237)), ('keys', (238, 246)), ('values', (247, 249)), ('values', (250, 258)), ('keys', (259, 267)), ('keys', (268, 276)), ('values', (277, 282)), ('values', (283, 313)), ('keys', (314, 323)), ('values', (324, 325)), ('keys', (326, 330)), ('values', (331, 331)), ('keys', (332, 342)), ('keys', (343, 356)), ('values', (357, 372)), ('values', (373, 373)), ('keys', (375, 378)), ('values', (379, 379)), ('keys', (380, 390)), ('values', (391, 391)), ('values', (392, 392)), ('values', (396, 396)), ('values', (398, 399)), ('keys', (400, 404)), ('keys', (405, 421)), ('values', (422, 430))]\n",
      "[{'entity_name': 'header', 'text': 'RJR Mailfile Table Update Sheet'}, {'entity_name': 'keys', 'text': 'Alert Number'}, {'entity_name': 'values', 'text': '970220'}, {'entity_name': 'values', 'text': 'RJR IR - Suz /Art'}, {'entity_name': 'keys', 'text': 'To:'}, {'entity_name': 'keys', 'text': 'From:'}, {'entity_name': 'values', 'text': 'Drew Huyett'}, {'entity_name': 'values', 'text': '3/ 7/ 97'}, {'entity_name': 'keys', 'text': 'Date:'}, {'entity_name': 'keys', 'text': 'Program Group'}, {'entity_name': 'values', 'text': '102- Eclipse'}, {'entity_name': 'values', 'text': 'Corp/ Multibrand'}, {'entity_name': 'keys', 'text': 'System'}, {'entity_name': 'values', 'text': 'M'}, {'entity_name': 'values', 'text': 'ilfil'}, {'entity_name': 'keys', 'text': 'e'}, {'entity_name': 'values', 'text': ' D'}, {'entity_name': 'keys', 'text': 'e'}, {'entity_name': 'values', 'text': 'scri'}, {'entity_name': 'keys', 'text': 'p'}, {'entity_name': 'values', 'text': 'ti'}, {'entity_name': 'keys', 'text': 'o'}, {'entity_name': 'values', 'text': 'n'}, {'entity_name': 'values', 'text': 'Mail Order- Indy Responders'}, {'entity_name': 'keys', 'text': 'Mailfile ID:'}, {'entity_name': 'values', 'text': '3,'}, {'entity_name': 'values', 'text': '984'}, {'entity_name': 'keys', 'text': 'Dataset Name'}, {'entity_name': 'values', 'text': ' '}, {'entity_name': 'values', 'text': ')'}, {'entity_name': 'keys', 'text': 'Quantity:'}, {'entity_name': 'values', 'text': '273'}, {'entity_name': 'values', 'text': '3/ 17/ 97'}, {'entity_name': 'keys', 'text': 'Maildate:'}, {'entity_name': 'keys', 'text': 'Program#:'}, {'entity_name': 'values', 'text': '700418'}, {'entity_name': 'values', 'text': 'BRC Codes w81 carton order form'}, {'entity_name': 'keys', 'text': 'T Codes NA'}, {'entity_name': 'values', 'text': '25'}, {'entity_name': 'keys', 'text': 'Seeds'}, {'entity_name': 'values', 'text': '5'}, {'entity_name': 'keys', 'text': 'Suppression'}, {'entity_name': 'keys', 'text': 'Mailfile Cells'}, {'entity_name': 'values', 'text': 'HD home delivery'}, {'entity_name': 'values', 'text': '1'}, {'entity_name': 'keys', 'text': 'SP s'}, {'entity_name': 'values', 'text': 'n'}, {'entity_name': 'keys', 'text': 'eak preview'}, {'entity_name': 'values', 'text': '3'}, {'entity_name': 'values', 'text': '4'}, {'entity_name': 'values', 'text': '8'}, {'entity_name': 'values', 'text': '10'}, {'entity_name': 'keys', 'text': 'Notes'}, {'entity_name': 'keys', 'text': 'This is for notes'}, {'entity_name': 'values', 'text': '51673 430'}]\n",
      "6it [00:01,  4.08it/s]['inference/2_test_img/99900038.png']\n",
      "[[0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5, 5, 5, 5, 5, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 1, 4, 4, 4, 4, 4, 6, 6, 6, 5, 5, 5, 5, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 4, 4, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]]\n",
      "[('header', (0, 134)), ('keys', (135, 135)), ('header', (136, 136)), ('keys', (137, 145)), ('values', (146, 211)), ('keys', (212, 223)), ('values', (224, 286)), ('values', (287, 346)), ('values', (347, 394)), ('values', (395, 402)), ('keys', (403, 415)), ('values', (416, 427)), ('keys', (428, 438)), ('keys', (590, 594)), ('keys', (595, 601)), ('keys', (602, 622)), ('keys', (623, 628)), ('values', (632, 635)), ('keys', (636, 647)), ('keys', (659, 666)), ('keys', (683, 695))]\n",
      "[{'entity_name': 'header', 'text': \"Bempedoic Acid (ETC-1002)Esperion Therapeutics; Inc.Amendment 3.1,30 July 2018Clinical Study Protocol 1002-043INVESTIGATOR 'S SIGNATURE\"}, {'entity_name': 'keys', 'text': 'A'}, {'entity_name': 'header', 'text': 'P'}, {'entity_name': 'keys', 'text': 'PENDIX 5.'}, {'entity_name': 'values', 'text': 'A Randomized, Double-blind, Placebo-Controlled Study to Assess the'}, {'entity_name': 'keys', 'text': 'Study Title:'}, {'entity_name': 'values', 'text': 'Effects of Bempedoic Acid (ETC-1002) on the Occurrence of Major'}, {'entity_name': 'values', 'text': 'Cardiovascular Events in Patients with, Or at High Risk for;'}, {'entity_name': 'values', 'text': 'Cardiovascular Disease who are Statin Intolerant'}, {'entity_name': 'values', 'text': '1002-043'}, {'entity_name': 'keys', 'text': 'Study Number:'}, {'entity_name': 'values', 'text': '30 July 2018'}, {'entity_name': 'keys', 'text': 'Final Date:'}, {'entity_name': 'keys', 'text': 'Date:'}, {'entity_name': 'keys', 'text': 'Signed:'}, {'entity_name': 'keys', 'text': 'Name and Credentials:'}, {'entity_name': 'keys', 'text': 'Title:'}, {'entity_name': 'values', 'text': 'kCcR'}, {'entity_name': 'keys', 'text': 'Affiliation:'}, {'entity_name': 'keys', 'text': 'Address:'}, {'entity_name': 'keys', 'text': 'Phone Number:'}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7it [00:01,  4.00it/s]\r",
      "7it [00:01,  3.65it/s]\r\n"
     ]
    }
   ],
   "source": [
    "# test_0322_164111   test_0322_064312    test_0328_173509\n",
    "!python3 test.py --checkpoint ./saved/models/PICK_Default/test_0328_173509/model_best.pth \\\n",
    "                 --boxes_transcripts ./inference/2_test_boxes_and_transcripts/ \\\n",
    "                 --images_path ./inference/2_test_img/ --output_folder ./inference/output/ \\\n",
    "                 --gpu 0 --batch_size 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
